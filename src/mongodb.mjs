// deno-lint-ignore-file

import { Buffer } from "node:buffer";
import $nodeTimers from "node:timers";
import $nodeCrypto from "node:crypto";
import $nodeHttp from "node:http";
import $nodeUrl from "node:url";
import $noteUtil from "node:util";
import $nodeStream from "node:stream";
import $nodeEvents from "node:events";
import $nodeFs from "node:fs";
import $nodeDns from "node:dns";
import $nodePunycode from "node:punycode";
import $nodeOs from "node:os";
import process from "node:process";
import $nodeZlib from "node:zlib";
import $nodeChildProcess from "node:child_process";
import $nodeFsPromises from "node:fs/promises";
import $nodeNet from "node:net";
import $nodeTls from "node:tls";

var commonjsGlobal =
  typeof globalThis !== "undefined"
    ? globalThis
    : typeof window !== "undefined"
    ? window
    : typeof global !== "undefined"
    ? global
    : typeof self !== "undefined"
    ? self
    : {};

var lib$2 = {};

var admin = {};

var bson$2 = {};

var bson$1 = {};

function isAnyArrayBuffer(value) {
  return ["[object ArrayBuffer]", "[object SharedArrayBuffer]"].includes(
    Object.prototype.toString.call(value),
  );
}
function isUint8Array(value) {
  return Object.prototype.toString.call(value) === "[object Uint8Array]";
}
function isRegExp(d) {
  return Object.prototype.toString.call(d) === "[object RegExp]";
}
function isMap$1(d) {
  return Object.prototype.toString.call(d) === "[object Map]";
}
function isDate(d) {
  return Object.prototype.toString.call(d) === "[object Date]";
}
function defaultInspect(x, _options) {
  return JSON.stringify(x, (k, v) => {
    if (typeof v === "bigint") {
      return { $numberLong: `${v}` };
    } else if (isMap$1(v)) {
      return Object.fromEntries(v);
    }
    return v;
  });
}
function getStylizeFunction(options) {
  const stylizeExists =
    options != null &&
    typeof options === "object" &&
    "stylize" in options &&
    typeof options.stylize === "function";
  if (stylizeExists) {
    return options.stylize;
  }
}

const BSON_MAJOR_VERSION = 6;
const BSON_INT32_MAX = 0x7fffffff;
const BSON_INT32_MIN = -0x80000000;
const BSON_INT64_MAX = Math.pow(2, 63) - 1;
const BSON_INT64_MIN = -Math.pow(2, 63);
const JS_INT_MAX = Math.pow(2, 53);
const JS_INT_MIN = -Math.pow(2, 53);
const BSON_DATA_NUMBER = 1;
const BSON_DATA_STRING = 2;
const BSON_DATA_OBJECT = 3;
const BSON_DATA_ARRAY = 4;
const BSON_DATA_BINARY = 5;
const BSON_DATA_UNDEFINED = 6;
const BSON_DATA_OID = 7;
const BSON_DATA_BOOLEAN = 8;
const BSON_DATA_DATE = 9;
const BSON_DATA_NULL = 10;
const BSON_DATA_REGEXP = 11;
const BSON_DATA_DBPOINTER = 12;
const BSON_DATA_CODE = 13;
const BSON_DATA_SYMBOL = 14;
const BSON_DATA_CODE_W_SCOPE = 15;
const BSON_DATA_INT = 16;
const BSON_DATA_TIMESTAMP = 17;
const BSON_DATA_LONG = 18;
const BSON_DATA_DECIMAL128 = 19;
const BSON_DATA_MIN_KEY = 0xff;
const BSON_DATA_MAX_KEY = 0x7f;
const BSON_BINARY_SUBTYPE_DEFAULT = 0;
const BSON_BINARY_SUBTYPE_UUID_NEW = 4;
const BSONType$1 = Object.freeze({
  double: 1,
  string: 2,
  object: 3,
  array: 4,
  binData: 5,
  undefined: 6,
  objectId: 7,
  bool: 8,
  date: 9,
  null: 10,
  regex: 11,
  dbPointer: 12,
  javascript: 13,
  symbol: 14,
  javascriptWithScope: 15,
  int: 16,
  timestamp: 17,
  long: 18,
  decimal: 19,
  minKey: -1,
  maxKey: 127,
});

class BSONError extends Error {
  get bsonError() {
    return true;
  }
  get name() {
    return "BSONError";
  }
  constructor(message) {
    super(message);
  }
  static isBSONError(value) {
    return (
      value != null &&
      typeof value === "object" &&
      "bsonError" in value &&
      value.bsonError === true &&
      "name" in value &&
      "message" in value &&
      "stack" in value
    );
  }
}
class BSONVersionError extends BSONError {
  get name() {
    return "BSONVersionError";
  }
  constructor() {
    super(
      `Unsupported BSON version, bson types must be from bson ${BSON_MAJOR_VERSION}.x.x`,
    );
  }
}
class BSONRuntimeError extends BSONError {
  get name() {
    return "BSONRuntimeError";
  }
  constructor(message) {
    super(message);
  }
}

function nodejsMathRandomBytes(byteLength) {
  return nodeJsByteUtils.fromNumberArray(
    Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)),
  );
}
const nodejsRandomBytes = (() => {
  try {
    return require("crypto").randomBytes;
  } catch {
    return nodejsMathRandomBytes;
  }
})();
const nodeJsByteUtils = {
  toLocalBufferType(potentialBuffer) {
    if (Buffer.isBuffer(potentialBuffer)) {
      return potentialBuffer;
    }
    if (ArrayBuffer.isView(potentialBuffer)) {
      return Buffer.from(
        potentialBuffer.buffer,
        potentialBuffer.byteOffset,
        potentialBuffer.byteLength,
      );
    }
    const stringTag =
      potentialBuffer?.[Symbol.toStringTag] ??
      Object.prototype.toString.call(potentialBuffer);
    if (
      stringTag === "ArrayBuffer" ||
      stringTag === "SharedArrayBuffer" ||
      stringTag === "[object ArrayBuffer]" ||
      stringTag === "[object SharedArrayBuffer]"
    ) {
      return Buffer.from(potentialBuffer);
    }
    throw new BSONError(`Cannot create Buffer from ${String(potentialBuffer)}`);
  },
  allocate(size) {
    return Buffer.alloc(size);
  },
  equals(a, b) {
    return nodeJsByteUtils.toLocalBufferType(a).equals(b);
  },
  fromNumberArray(array) {
    return Buffer.from(array);
  },
  fromBase64(base64) {
    return Buffer.from(base64, "base64");
  },
  toBase64(buffer) {
    return nodeJsByteUtils.toLocalBufferType(buffer).toString("base64");
  },
  fromISO88591(codePoints) {
    return Buffer.from(codePoints, "binary");
  },
  toISO88591(buffer) {
    return nodeJsByteUtils.toLocalBufferType(buffer).toString("binary");
  },
  fromHex(hex) {
    return Buffer.from(hex, "hex");
  },
  toHex(buffer) {
    return nodeJsByteUtils.toLocalBufferType(buffer).toString("hex");
  },
  fromUTF8(text) {
    return Buffer.from(text, "utf8");
  },
  toUTF8(buffer, start, end) {
    return nodeJsByteUtils
      .toLocalBufferType(buffer)
      .toString("utf8", start, end);
  },
  utf8ByteLength(input) {
    return Buffer.byteLength(input, "utf8");
  },
  encodeUTF8Into(buffer, source, byteOffset) {
    return nodeJsByteUtils
      .toLocalBufferType(buffer)
      .write(source, byteOffset, undefined, "utf8");
  },
  randomBytes: nodejsRandomBytes,
};

function isReactNative() {
  const { navigator } = globalThis;
  return typeof navigator === "object" && navigator.product === "ReactNative";
}
function webMathRandomBytes(byteLength) {
  if (byteLength < 0) {
    throw new RangeError(
      `The argument 'byteLength' is invalid. Received ${byteLength}`,
    );
  }
  return webByteUtils.fromNumberArray(
    Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)),
  );
}
const webRandomBytes = (() => {
  const { crypto } = globalThis;
  if (crypto != null && typeof crypto.getRandomValues === "function") {
    return (byteLength) => {
      return crypto.getRandomValues(webByteUtils.allocate(byteLength));
    };
  } else {
    if (isReactNative()) {
      const { console } = globalThis;
      console?.warn?.(
        "BSON: For React Native please polyfill crypto.getRandomValues, e.g. using: https://www.npmjs.com/package/react-native-get-random-values.",
      );
    }
    return webMathRandomBytes;
  }
})();
const HEX_DIGIT = /(\d|[a-f])/i;
const webByteUtils = {
  toLocalBufferType(potentialUint8array) {
    const stringTag =
      potentialUint8array?.[Symbol.toStringTag] ??
      Object.prototype.toString.call(potentialUint8array);
    if (stringTag === "Uint8Array") {
      return potentialUint8array;
    }
    if (ArrayBuffer.isView(potentialUint8array)) {
      return new Uint8Array(
        potentialUint8array.buffer.slice(
          potentialUint8array.byteOffset,
          potentialUint8array.byteOffset + potentialUint8array.byteLength,
        ),
      );
    }
    if (
      stringTag === "ArrayBuffer" ||
      stringTag === "SharedArrayBuffer" ||
      stringTag === "[object ArrayBuffer]" ||
      stringTag === "[object SharedArrayBuffer]"
    ) {
      return new Uint8Array(potentialUint8array);
    }
    throw new BSONError(
      `Cannot make a Uint8Array from ${String(potentialUint8array)}`,
    );
  },
  allocate(size) {
    if (typeof size !== "number") {
      throw new TypeError(
        `The "size" argument must be of type number. Received ${String(size)}`,
      );
    }
    return new Uint8Array(size);
  },
  equals(a, b) {
    if (a.byteLength !== b.byteLength) {
      return false;
    }
    for (let i = 0; i < a.byteLength; i++) {
      if (a[i] !== b[i]) {
        return false;
      }
    }
    return true;
  },
  fromNumberArray(array) {
    return Uint8Array.from(array);
  },
  fromBase64(base64) {
    return Uint8Array.from(atob(base64), (c) => c.charCodeAt(0));
  },
  toBase64(uint8array) {
    return btoa(webByteUtils.toISO88591(uint8array));
  },
  fromISO88591(codePoints) {
    return Uint8Array.from(codePoints, (c) => c.charCodeAt(0) & 0xff);
  },
  toISO88591(uint8array) {
    return Array.from(Uint16Array.from(uint8array), (b) =>
      String.fromCharCode(b),
    ).join("");
  },
  fromHex(hex) {
    const evenLengthHex =
      hex.length % 2 === 0 ? hex : hex.slice(0, hex.length - 1);
    const buffer = [];
    for (let i = 0; i < evenLengthHex.length; i += 2) {
      const firstDigit = evenLengthHex[i];
      const secondDigit = evenLengthHex[i + 1];
      if (!HEX_DIGIT.test(firstDigit)) {
        break;
      }
      if (!HEX_DIGIT.test(secondDigit)) {
        break;
      }
      const hexDigit = Number.parseInt(`${firstDigit}${secondDigit}`, 16);
      buffer.push(hexDigit);
    }
    return Uint8Array.from(buffer);
  },
  toHex(uint8array) {
    return Array.from(uint8array, (byte) =>
      byte.toString(16).padStart(2, "0"),
    ).join("");
  },
  fromUTF8(text) {
    return new TextEncoder().encode(text);
  },
  toUTF8(uint8array, start, end) {
    return new TextDecoder("utf8", { fatal: false }).decode(
      uint8array.slice(start, end),
    );
  },
  utf8ByteLength(input) {
    return webByteUtils.fromUTF8(input).byteLength;
  },
  encodeUTF8Into(buffer, source, byteOffset) {
    const bytes = webByteUtils.fromUTF8(source);
    buffer.set(bytes, byteOffset);
    return bytes.byteLength;
  },
  randomBytes: webRandomBytes,
};

const hasGlobalBuffer =
  typeof Buffer === "function" && Buffer.prototype?._isBuffer !== true;
const ByteUtils = hasGlobalBuffer ? nodeJsByteUtils : webByteUtils;
class BSONDataView extends DataView {
  static fromUint8Array(input) {
    return new DataView(input.buffer, input.byteOffset, input.byteLength);
  }
}

class BSONValue {
  get [Symbol.for("@@mdb.bson.version")]() {
    return BSON_MAJOR_VERSION;
  }
  [Symbol.for("nodejs.util.inspect.custom")](depth, options, inspect) {
    return this.inspect(depth, options, inspect);
  }
}

let Binary$1 = class Binary extends BSONValue {
  get _bsontype() {
    return "Binary";
  }
  constructor(buffer, subType) {
    super();
    if (
      !(buffer == null) &&
      typeof buffer === "string" &&
      !ArrayBuffer.isView(buffer) &&
      !isAnyArrayBuffer(buffer) &&
      !Array.isArray(buffer)
    ) {
      throw new BSONError(
        "Binary can only be constructed from Uint8Array or number[]",
      );
    }
    this.sub_type = subType ?? Binary.BSON_BINARY_SUBTYPE_DEFAULT;
    if (buffer == null) {
      this.buffer = ByteUtils.allocate(Binary.BUFFER_SIZE);
      this.position = 0;
    } else {
      this.buffer = Array.isArray(buffer)
        ? ByteUtils.fromNumberArray(buffer)
        : ByteUtils.toLocalBufferType(buffer);
      this.position = this.buffer.byteLength;
    }
  }
  put(byteValue) {
    if (typeof byteValue === "string" && byteValue.length !== 1) {
      throw new BSONError("only accepts single character String");
    } else if (typeof byteValue !== "number" && byteValue.length !== 1)
      throw new BSONError("only accepts single character Uint8Array or Array");
    let decodedByte;
    if (typeof byteValue === "string") {
      decodedByte = byteValue.charCodeAt(0);
    } else if (typeof byteValue === "number") {
      decodedByte = byteValue;
    } else {
      decodedByte = byteValue[0];
    }
    if (decodedByte < 0 || decodedByte > 255) {
      throw new BSONError(
        "only accepts number in a valid unsigned byte range 0-255",
      );
    }
    if (this.buffer.byteLength > this.position) {
      this.buffer[this.position++] = decodedByte;
    } else {
      const newSpace = ByteUtils.allocate(
        Binary.BUFFER_SIZE + this.buffer.length,
      );
      newSpace.set(this.buffer, 0);
      this.buffer = newSpace;
      this.buffer[this.position++] = decodedByte;
    }
  }
  write(sequence, offset) {
    offset = typeof offset === "number" ? offset : this.position;
    if (this.buffer.byteLength < offset + sequence.length) {
      const newSpace = ByteUtils.allocate(
        this.buffer.byteLength + sequence.length,
      );
      newSpace.set(this.buffer, 0);
      this.buffer = newSpace;
    }
    if (ArrayBuffer.isView(sequence)) {
      this.buffer.set(ByteUtils.toLocalBufferType(sequence), offset);
      this.position =
        offset + sequence.byteLength > this.position
          ? offset + sequence.length
          : this.position;
    } else if (typeof sequence === "string") {
      throw new BSONError("input cannot be string");
    }
  }
  read(position, length) {
    length = length && length > 0 ? length : this.position;
    return this.buffer.slice(position, position + length);
  }
  value() {
    return this.buffer.length === this.position
      ? this.buffer
      : this.buffer.subarray(0, this.position);
  }
  length() {
    return this.position;
  }
  toJSON() {
    return ByteUtils.toBase64(this.buffer);
  }
  toString(encoding) {
    if (encoding === "hex") return ByteUtils.toHex(this.buffer);
    if (encoding === "base64") return ByteUtils.toBase64(this.buffer);
    if (encoding === "utf8" || encoding === "utf-8")
      return ByteUtils.toUTF8(this.buffer, 0, this.buffer.byteLength);
    return ByteUtils.toUTF8(this.buffer, 0, this.buffer.byteLength);
  }
  toExtendedJSON(options) {
    options = options || {};
    const base64String = ByteUtils.toBase64(this.buffer);
    const subType = Number(this.sub_type).toString(16);
    if (options.legacy) {
      return {
        $binary: base64String,
        $type: subType.length === 1 ? "0" + subType : subType,
      };
    }
    return {
      $binary: {
        base64: base64String,
        subType: subType.length === 1 ? "0" + subType : subType,
      },
    };
  }
  toUUID() {
    if (this.sub_type === Binary.SUBTYPE_UUID) {
      return new UUID$1(this.buffer.slice(0, this.position));
    }
    throw new BSONError(
      `Binary sub_type "${this.sub_type}" is not supported for converting to UUID. Only "${Binary.SUBTYPE_UUID}" is currently supported.`,
    );
  }
  static createFromHexString(hex, subType) {
    return new Binary(ByteUtils.fromHex(hex), subType);
  }
  static createFromBase64(base64, subType) {
    return new Binary(ByteUtils.fromBase64(base64), subType);
  }
  static fromExtendedJSON(doc, options) {
    options = options || {};
    let data;
    let type;
    if ("$binary" in doc) {
      if (options.legacy && typeof doc.$binary === "string" && "$type" in doc) {
        type = doc.$type ? parseInt(doc.$type, 16) : 0;
        data = ByteUtils.fromBase64(doc.$binary);
      } else {
        if (typeof doc.$binary !== "string") {
          type = doc.$binary.subType ? parseInt(doc.$binary.subType, 16) : 0;
          data = ByteUtils.fromBase64(doc.$binary.base64);
        }
      }
    } else if ("$uuid" in doc) {
      type = 4;
      data = UUID$1.bytesFromString(doc.$uuid);
    }
    if (!data) {
      throw new BSONError(
        `Unexpected Binary Extended JSON format ${JSON.stringify(doc)}`,
      );
    }
    return type === BSON_BINARY_SUBTYPE_UUID_NEW
      ? new UUID$1(data)
      : new Binary(data, type);
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    const base64 = ByteUtils.toBase64(this.buffer.subarray(0, this.position));
    const base64Arg = inspect(base64, options);
    const subTypeArg = inspect(this.sub_type, options);
    return `Binary.createFromBase64(${base64Arg}, ${subTypeArg})`;
  }
};
Binary$1.BSON_BINARY_SUBTYPE_DEFAULT = 0;
Binary$1.BUFFER_SIZE = 256;
Binary$1.SUBTYPE_DEFAULT = 0;
Binary$1.SUBTYPE_FUNCTION = 1;
Binary$1.SUBTYPE_BYTE_ARRAY = 2;
Binary$1.SUBTYPE_UUID_OLD = 3;
Binary$1.SUBTYPE_UUID = 4;
Binary$1.SUBTYPE_MD5 = 5;
Binary$1.SUBTYPE_ENCRYPTED = 6;
Binary$1.SUBTYPE_COLUMN = 7;
Binary$1.SUBTYPE_USER_DEFINED = 128;
const UUID_BYTE_LENGTH = 16;
const UUID_WITHOUT_DASHES = /^[0-9A-F]{32}$/i;
const UUID_WITH_DASHES =
  /^[0-9A-F]{8}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{12}$/i;
let UUID$1 = class UUID extends Binary$1 {
  constructor(input) {
    let bytes;
    if (input == null) {
      bytes = UUID.generate();
    } else if (input instanceof UUID) {
      bytes = ByteUtils.toLocalBufferType(new Uint8Array(input.buffer));
    } else if (
      ArrayBuffer.isView(input) &&
      input.byteLength === UUID_BYTE_LENGTH
    ) {
      bytes = ByteUtils.toLocalBufferType(input);
    } else if (typeof input === "string") {
      bytes = UUID.bytesFromString(input);
    } else {
      throw new BSONError(
        "Argument passed in UUID constructor must be a UUID, a 16 byte Buffer or a 32/36 character hex string (dashes excluded/included, format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx).",
      );
    }
    super(bytes, BSON_BINARY_SUBTYPE_UUID_NEW);
  }
  get id() {
    return this.buffer;
  }
  set id(value) {
    this.buffer = value;
  }
  toHexString(includeDashes = true) {
    if (includeDashes) {
      return [
        ByteUtils.toHex(this.buffer.subarray(0, 4)),
        ByteUtils.toHex(this.buffer.subarray(4, 6)),
        ByteUtils.toHex(this.buffer.subarray(6, 8)),
        ByteUtils.toHex(this.buffer.subarray(8, 10)),
        ByteUtils.toHex(this.buffer.subarray(10, 16)),
      ].join("-");
    }
    return ByteUtils.toHex(this.buffer);
  }
  toString(encoding) {
    if (encoding === "hex") return ByteUtils.toHex(this.id);
    if (encoding === "base64") return ByteUtils.toBase64(this.id);
    return this.toHexString();
  }
  toJSON() {
    return this.toHexString();
  }
  equals(otherId) {
    if (!otherId) {
      return false;
    }
    if (otherId instanceof UUID) {
      return ByteUtils.equals(otherId.id, this.id);
    }
    try {
      return ByteUtils.equals(new UUID(otherId).id, this.id);
    } catch {
      return false;
    }
  }
  toBinary() {
    return new Binary$1(this.id, Binary$1.SUBTYPE_UUID);
  }
  static generate() {
    const bytes = ByteUtils.randomBytes(UUID_BYTE_LENGTH);
    bytes[6] = (bytes[6] & 0x0f) | 0x40;
    bytes[8] = (bytes[8] & 0x3f) | 0x80;
    return bytes;
  }
  static isValid(input) {
    if (!input) {
      return false;
    }
    if (typeof input === "string") {
      return UUID.isValidUUIDString(input);
    }
    if (isUint8Array(input)) {
      return input.byteLength === UUID_BYTE_LENGTH;
    }
    return (
      input._bsontype === "Binary" &&
      input.sub_type === this.SUBTYPE_UUID &&
      input.buffer.byteLength === 16
    );
  }
  static createFromHexString(hexString) {
    const buffer = UUID.bytesFromString(hexString);
    return new UUID(buffer);
  }
  static createFromBase64(base64) {
    return new UUID(ByteUtils.fromBase64(base64));
  }
  static bytesFromString(representation) {
    if (!UUID.isValidUUIDString(representation)) {
      throw new BSONError(
        "UUID string representation must be 32 hex digits or canonical hyphenated representation",
      );
    }
    return ByteUtils.fromHex(representation.replace(/-/g, ""));
  }
  static isValidUUIDString(representation) {
    return (
      UUID_WITHOUT_DASHES.test(representation) ||
      UUID_WITH_DASHES.test(representation)
    );
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    return `new UUID(${inspect(this.toHexString(), options)})`;
  }
};

let Code$1 = class Code extends BSONValue {
  get _bsontype() {
    return "Code";
  }
  constructor(code, scope) {
    super();
    this.code = code.toString();
    this.scope = scope ?? null;
  }
  toJSON() {
    if (this.scope != null) {
      return { code: this.code, scope: this.scope };
    }
    return { code: this.code };
  }
  toExtendedJSON() {
    if (this.scope) {
      return { $code: this.code, $scope: this.scope };
    }
    return { $code: this.code };
  }
  static fromExtendedJSON(doc) {
    return new Code(doc.$code, doc.$scope);
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    let parametersString = inspect(this.code, options);
    const multiLineFn = parametersString.includes("\n");
    if (this.scope != null) {
      parametersString += `,${multiLineFn ? "\n" : " "}${inspect(
        this.scope,
        options,
      )}`;
    }
    const endingNewline = multiLineFn && this.scope === null;
    return `new Code(${multiLineFn ? "\n" : ""}${parametersString}${
      endingNewline ? "\n" : ""
    })`;
  }
};

function isDBRefLike(value) {
  return (
    value != null &&
    typeof value === "object" &&
    "$id" in value &&
    value.$id != null &&
    "$ref" in value &&
    typeof value.$ref === "string" &&
    (!("$db" in value) || ("$db" in value && typeof value.$db === "string"))
  );
}
let DBRef$1 = class DBRef extends BSONValue {
  get _bsontype() {
    return "DBRef";
  }
  constructor(collection, oid, db, fields) {
    super();
    const parts = collection.split(".");
    if (parts.length === 2) {
      db = parts.shift();
      collection = parts.shift();
    }
    this.collection = collection;
    this.oid = oid;
    this.db = db;
    this.fields = fields || {};
  }
  get namespace() {
    return this.collection;
  }
  set namespace(value) {
    this.collection = value;
  }
  toJSON() {
    const o = Object.assign(
      {
        $ref: this.collection,
        $id: this.oid,
      },
      this.fields,
    );
    if (this.db != null) o.$db = this.db;
    return o;
  }
  toExtendedJSON(options) {
    options = options || {};
    let o = {
      $ref: this.collection,
      $id: this.oid,
    };
    if (options.legacy) {
      return o;
    }
    if (this.db) o.$db = this.db;
    o = Object.assign(o, this.fields);
    return o;
  }
  static fromExtendedJSON(doc) {
    const copy = Object.assign({}, doc);
    delete copy.$ref;
    delete copy.$id;
    delete copy.$db;
    return new DBRef(doc.$ref, doc.$id, doc.$db, copy);
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    const args = [
      inspect(this.namespace, options),
      inspect(this.oid, options),
      ...(this.db ? [inspect(this.db, options)] : []),
      ...(Object.keys(this.fields).length > 0
        ? [inspect(this.fields, options)]
        : []),
    ];
    args[1] = inspect === defaultInspect ? `new ObjectId(${args[1]})` : args[1];
    return `new DBRef(${args.join(", ")})`;
  }
};

let wasm = undefined;
try {
  wasm = new WebAssembly.Instance(
    new WebAssembly.Module(
      new Uint8Array([
        0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127,
        127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11,
        7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5,
        100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114,
        101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0,
        10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173,
        66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4,
        66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32,
        1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127,
        34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0,
        173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134,
        132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126,
        32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66,
        32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36,
        1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3,
        173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167,
        11,
      ]),
    ),
    {},
  ).exports;
} catch {}
const TWO_PWR_16_DBL = 1 << 16;
const TWO_PWR_24_DBL = 1 << 24;
const TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
const TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
const TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
const INT_CACHE = {};
const UINT_CACHE = {};
const MAX_INT64_STRING_LENGTH = 20;
const DECIMAL_REG_EX = /^(\+?0|(\+|-)?[1-9][0-9]*)$/;
let Long$1 = class Long extends BSONValue {
  get _bsontype() {
    return "Long";
  }
  get __isLong__() {
    return true;
  }
  constructor(low = 0, high, unsigned) {
    super();
    if (typeof low === "bigint") {
      Object.assign(this, Long.fromBigInt(low, !!high));
    } else if (typeof low === "string") {
      Object.assign(this, Long.fromString(low, !!high));
    } else {
      this.low = low | 0;
      this.high = high | 0;
      this.unsigned = !!unsigned;
    }
  }
  static fromBits(lowBits, highBits, unsigned) {
    return new Long(lowBits, highBits, unsigned);
  }
  static fromInt(value, unsigned) {
    let obj, cachedObj, cache;
    if (unsigned) {
      value >>>= 0;
      if ((cache = 0 <= value && value < 256)) {
        cachedObj = UINT_CACHE[value];
        if (cachedObj) return cachedObj;
      }
      obj = Long.fromBits(value, (value | 0) < 0 ? -1 : 0, true);
      if (cache) UINT_CACHE[value] = obj;
      return obj;
    } else {
      value |= 0;
      if ((cache = -128 <= value && value < 128)) {
        cachedObj = INT_CACHE[value];
        if (cachedObj) return cachedObj;
      }
      obj = Long.fromBits(value, value < 0 ? -1 : 0, false);
      if (cache) INT_CACHE[value] = obj;
      return obj;
    }
  }
  static fromNumber(value, unsigned) {
    if (isNaN(value)) return unsigned ? Long.UZERO : Long.ZERO;
    if (unsigned) {
      if (value < 0) return Long.UZERO;
      if (value >= TWO_PWR_64_DBL) return Long.MAX_UNSIGNED_VALUE;
    } else {
      if (value <= -TWO_PWR_63_DBL) return Long.MIN_VALUE;
      if (value + 1 >= TWO_PWR_63_DBL) return Long.MAX_VALUE;
    }
    if (value < 0) return Long.fromNumber(-value, unsigned).neg();
    return Long.fromBits(
      value % TWO_PWR_32_DBL | 0,
      (value / TWO_PWR_32_DBL) | 0,
      unsigned,
    );
  }
  static fromBigInt(value, unsigned) {
    return Long.fromString(value.toString(), unsigned);
  }
  static fromString(str, unsigned, radix) {
    if (str.length === 0) throw new BSONError("empty string");
    if (
      str === "NaN" ||
      str === "Infinity" ||
      str === "+Infinity" ||
      str === "-Infinity"
    )
      return Long.ZERO;
    if (typeof unsigned === "number") {
      (radix = unsigned), (unsigned = false);
    } else {
      unsigned = !!unsigned;
    }
    radix = radix || 10;
    if (radix < 2 || 36 < radix) throw new BSONError("radix");
    let p;
    if ((p = str.indexOf("-")) > 0) throw new BSONError("interior hyphen");
    else if (p === 0) {
      return Long.fromString(str.substring(1), unsigned, radix).neg();
    }
    const radixToPower = Long.fromNumber(Math.pow(radix, 8));
    let result = Long.ZERO;
    for (let i = 0; i < str.length; i += 8) {
      const size = Math.min(8, str.length - i),
        value = parseInt(str.substring(i, i + size), radix);
      if (size < 8) {
        const power = Long.fromNumber(Math.pow(radix, size));
        result = result.mul(power).add(Long.fromNumber(value));
      } else {
        result = result.mul(radixToPower);
        result = result.add(Long.fromNumber(value));
      }
    }
    result.unsigned = unsigned;
    return result;
  }
  static fromBytes(bytes, unsigned, le) {
    return le
      ? Long.fromBytesLE(bytes, unsigned)
      : Long.fromBytesBE(bytes, unsigned);
  }
  static fromBytesLE(bytes, unsigned) {
    return new Long(
      bytes[0] | (bytes[1] << 8) | (bytes[2] << 16) | (bytes[3] << 24),
      bytes[4] | (bytes[5] << 8) | (bytes[6] << 16) | (bytes[7] << 24),
      unsigned,
    );
  }
  static fromBytesBE(bytes, unsigned) {
    return new Long(
      (bytes[4] << 24) | (bytes[5] << 16) | (bytes[6] << 8) | bytes[7],
      (bytes[0] << 24) | (bytes[1] << 16) | (bytes[2] << 8) | bytes[3],
      unsigned,
    );
  }
  static isLong(value) {
    return (
      value != null &&
      typeof value === "object" &&
      "__isLong__" in value &&
      value.__isLong__ === true
    );
  }
  static fromValue(val, unsigned) {
    if (typeof val === "number") return Long.fromNumber(val, unsigned);
    if (typeof val === "string") return Long.fromString(val, unsigned);
    return Long.fromBits(
      val.low,
      val.high,
      typeof unsigned === "boolean" ? unsigned : val.unsigned,
    );
  }
  add(addend) {
    if (!Long.isLong(addend)) addend = Long.fromValue(addend);
    const a48 = this.high >>> 16;
    const a32 = this.high & 0xffff;
    const a16 = this.low >>> 16;
    const a00 = this.low & 0xffff;
    const b48 = addend.high >>> 16;
    const b32 = addend.high & 0xffff;
    const b16 = addend.low >>> 16;
    const b00 = addend.low & 0xffff;
    let c48 = 0,
      c32 = 0,
      c16 = 0,
      c00 = 0;
    c00 += a00 + b00;
    c16 += c00 >>> 16;
    c00 &= 0xffff;
    c16 += a16 + b16;
    c32 += c16 >>> 16;
    c16 &= 0xffff;
    c32 += a32 + b32;
    c48 += c32 >>> 16;
    c32 &= 0xffff;
    c48 += a48 + b48;
    c48 &= 0xffff;
    return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);
  }
  and(other) {
    if (!Long.isLong(other)) other = Long.fromValue(other);
    return Long.fromBits(
      this.low & other.low,
      this.high & other.high,
      this.unsigned,
    );
  }
  compare(other) {
    if (!Long.isLong(other)) other = Long.fromValue(other);
    if (this.eq(other)) return 0;
    const thisNeg = this.isNegative(),
      otherNeg = other.isNegative();
    if (thisNeg && !otherNeg) return -1;
    if (!thisNeg && otherNeg) return 1;
    if (!this.unsigned) return this.sub(other).isNegative() ? -1 : 1;
    return other.high >>> 0 > this.high >>> 0 ||
      (other.high === this.high && other.low >>> 0 > this.low >>> 0)
      ? -1
      : 1;
  }
  comp(other) {
    return this.compare(other);
  }
  divide(divisor) {
    if (!Long.isLong(divisor)) divisor = Long.fromValue(divisor);
    if (divisor.isZero()) throw new BSONError("division by zero");
    if (wasm) {
      if (
        !this.unsigned &&
        this.high === -0x80000000 &&
        divisor.low === -1 &&
        divisor.high === -1
      ) {
        return this;
      }
      const low = (this.unsigned ? wasm.div_u : wasm.div_s)(
        this.low,
        this.high,
        divisor.low,
        divisor.high,
      );
      return Long.fromBits(low, wasm.get_high(), this.unsigned);
    }
    if (this.isZero()) return this.unsigned ? Long.UZERO : Long.ZERO;
    let approx, rem, res;
    if (!this.unsigned) {
      if (this.eq(Long.MIN_VALUE)) {
        if (divisor.eq(Long.ONE) || divisor.eq(Long.NEG_ONE))
          return Long.MIN_VALUE;
        else if (divisor.eq(Long.MIN_VALUE)) return Long.ONE;
        else {
          const halfThis = this.shr(1);
          approx = halfThis.div(divisor).shl(1);
          if (approx.eq(Long.ZERO)) {
            return divisor.isNegative() ? Long.ONE : Long.NEG_ONE;
          } else {
            rem = this.sub(divisor.mul(approx));
            res = approx.add(rem.div(divisor));
            return res;
          }
        }
      } else if (divisor.eq(Long.MIN_VALUE))
        return this.unsigned ? Long.UZERO : Long.ZERO;
      if (this.isNegative()) {
        if (divisor.isNegative()) return this.neg().div(divisor.neg());
        return this.neg().div(divisor).neg();
      } else if (divisor.isNegative()) return this.div(divisor.neg()).neg();
      res = Long.ZERO;
    } else {
      if (!divisor.unsigned) divisor = divisor.toUnsigned();
      if (divisor.gt(this)) return Long.UZERO;
      if (divisor.gt(this.shru(1))) return Long.UONE;
      res = Long.UZERO;
    }
    rem = this;
    while (rem.gte(divisor)) {
      approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
      const log2 = Math.ceil(Math.log(approx) / Math.LN2);
      const delta = log2 <= 48 ? 1 : Math.pow(2, log2 - 48);
      let approxRes = Long.fromNumber(approx);
      let approxRem = approxRes.mul(divisor);
      while (approxRem.isNegative() || approxRem.gt(rem)) {
        approx -= delta;
        approxRes = Long.fromNumber(approx, this.unsigned);
        approxRem = approxRes.mul(divisor);
      }
      if (approxRes.isZero()) approxRes = Long.ONE;
      res = res.add(approxRes);
      rem = rem.sub(approxRem);
    }
    return res;
  }
  div(divisor) {
    return this.divide(divisor);
  }
  equals(other) {
    if (!Long.isLong(other)) other = Long.fromValue(other);
    if (
      this.unsigned !== other.unsigned &&
      this.high >>> 31 === 1 &&
      other.high >>> 31 === 1
    )
      return false;
    return this.high === other.high && this.low === other.low;
  }
  eq(other) {
    return this.equals(other);
  }
  getHighBits() {
    return this.high;
  }
  getHighBitsUnsigned() {
    return this.high >>> 0;
  }
  getLowBits() {
    return this.low;
  }
  getLowBitsUnsigned() {
    return this.low >>> 0;
  }
  getNumBitsAbs() {
    if (this.isNegative()) {
      return this.eq(Long.MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
    }
    const val = this.high !== 0 ? this.high : this.low;
    let bit;
    for (bit = 31; bit > 0; bit--) if ((val & (1 << bit)) !== 0) break;
    return this.high !== 0 ? bit + 33 : bit + 1;
  }
  greaterThan(other) {
    return this.comp(other) > 0;
  }
  gt(other) {
    return this.greaterThan(other);
  }
  greaterThanOrEqual(other) {
    return this.comp(other) >= 0;
  }
  gte(other) {
    return this.greaterThanOrEqual(other);
  }
  ge(other) {
    return this.greaterThanOrEqual(other);
  }
  isEven() {
    return (this.low & 1) === 0;
  }
  isNegative() {
    return !this.unsigned && this.high < 0;
  }
  isOdd() {
    return (this.low & 1) === 1;
  }
  isPositive() {
    return this.unsigned || this.high >= 0;
  }
  isZero() {
    return this.high === 0 && this.low === 0;
  }
  lessThan(other) {
    return this.comp(other) < 0;
  }
  lt(other) {
    return this.lessThan(other);
  }
  lessThanOrEqual(other) {
    return this.comp(other) <= 0;
  }
  lte(other) {
    return this.lessThanOrEqual(other);
  }
  modulo(divisor) {
    if (!Long.isLong(divisor)) divisor = Long.fromValue(divisor);
    if (wasm) {
      const low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(
        this.low,
        this.high,
        divisor.low,
        divisor.high,
      );
      return Long.fromBits(low, wasm.get_high(), this.unsigned);
    }
    return this.sub(this.div(divisor).mul(divisor));
  }
  mod(divisor) {
    return this.modulo(divisor);
  }
  rem(divisor) {
    return this.modulo(divisor);
  }
  multiply(multiplier) {
    if (this.isZero()) return Long.ZERO;
    if (!Long.isLong(multiplier)) multiplier = Long.fromValue(multiplier);
    if (wasm) {
      const low = wasm.mul(
        this.low,
        this.high,
        multiplier.low,
        multiplier.high,
      );
      return Long.fromBits(low, wasm.get_high(), this.unsigned);
    }
    if (multiplier.isZero()) return Long.ZERO;
    if (this.eq(Long.MIN_VALUE))
      return multiplier.isOdd() ? Long.MIN_VALUE : Long.ZERO;
    if (multiplier.eq(Long.MIN_VALUE))
      return this.isOdd() ? Long.MIN_VALUE : Long.ZERO;
    if (this.isNegative()) {
      if (multiplier.isNegative()) return this.neg().mul(multiplier.neg());
      else return this.neg().mul(multiplier).neg();
    } else if (multiplier.isNegative()) return this.mul(multiplier.neg()).neg();
    if (this.lt(Long.TWO_PWR_24) && multiplier.lt(Long.TWO_PWR_24))
      return Long.fromNumber(
        this.toNumber() * multiplier.toNumber(),
        this.unsigned,
      );
    const a48 = this.high >>> 16;
    const a32 = this.high & 0xffff;
    const a16 = this.low >>> 16;
    const a00 = this.low & 0xffff;
    const b48 = multiplier.high >>> 16;
    const b32 = multiplier.high & 0xffff;
    const b16 = multiplier.low >>> 16;
    const b00 = multiplier.low & 0xffff;
    let c48 = 0,
      c32 = 0,
      c16 = 0,
      c00 = 0;
    c00 += a00 * b00;
    c16 += c00 >>> 16;
    c00 &= 0xffff;
    c16 += a16 * b00;
    c32 += c16 >>> 16;
    c16 &= 0xffff;
    c16 += a00 * b16;
    c32 += c16 >>> 16;
    c16 &= 0xffff;
    c32 += a32 * b00;
    c48 += c32 >>> 16;
    c32 &= 0xffff;
    c32 += a16 * b16;
    c48 += c32 >>> 16;
    c32 &= 0xffff;
    c32 += a00 * b32;
    c48 += c32 >>> 16;
    c32 &= 0xffff;
    c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
    c48 &= 0xffff;
    return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);
  }
  mul(multiplier) {
    return this.multiply(multiplier);
  }
  negate() {
    if (!this.unsigned && this.eq(Long.MIN_VALUE)) return Long.MIN_VALUE;
    return this.not().add(Long.ONE);
  }
  neg() {
    return this.negate();
  }
  not() {
    return Long.fromBits(~this.low, ~this.high, this.unsigned);
  }
  notEquals(other) {
    return !this.equals(other);
  }
  neq(other) {
    return this.notEquals(other);
  }
  ne(other) {
    return this.notEquals(other);
  }
  or(other) {
    if (!Long.isLong(other)) other = Long.fromValue(other);
    return Long.fromBits(
      this.low | other.low,
      this.high | other.high,
      this.unsigned,
    );
  }
  shiftLeft(numBits) {
    if (Long.isLong(numBits)) numBits = numBits.toInt();
    if ((numBits &= 63) === 0) return this;
    else if (numBits < 32)
      return Long.fromBits(
        this.low << numBits,
        (this.high << numBits) | (this.low >>> (32 - numBits)),
        this.unsigned,
      );
    else return Long.fromBits(0, this.low << (numBits - 32), this.unsigned);
  }
  shl(numBits) {
    return this.shiftLeft(numBits);
  }
  shiftRight(numBits) {
    if (Long.isLong(numBits)) numBits = numBits.toInt();
    if ((numBits &= 63) === 0) return this;
    else if (numBits < 32)
      return Long.fromBits(
        (this.low >>> numBits) | (this.high << (32 - numBits)),
        this.high >> numBits,
        this.unsigned,
      );
    else
      return Long.fromBits(
        this.high >> (numBits - 32),
        this.high >= 0 ? 0 : -1,
        this.unsigned,
      );
  }
  shr(numBits) {
    return this.shiftRight(numBits);
  }
  shiftRightUnsigned(numBits) {
    if (Long.isLong(numBits)) numBits = numBits.toInt();
    numBits &= 63;
    if (numBits === 0) return this;
    else {
      const high = this.high;
      if (numBits < 32) {
        const low = this.low;
        return Long.fromBits(
          (low >>> numBits) | (high << (32 - numBits)),
          high >>> numBits,
          this.unsigned,
        );
      } else if (numBits === 32) return Long.fromBits(high, 0, this.unsigned);
      else return Long.fromBits(high >>> (numBits - 32), 0, this.unsigned);
    }
  }
  shr_u(numBits) {
    return this.shiftRightUnsigned(numBits);
  }
  shru(numBits) {
    return this.shiftRightUnsigned(numBits);
  }
  subtract(subtrahend) {
    if (!Long.isLong(subtrahend)) subtrahend = Long.fromValue(subtrahend);
    return this.add(subtrahend.neg());
  }
  sub(subtrahend) {
    return this.subtract(subtrahend);
  }
  toInt() {
    return this.unsigned ? this.low >>> 0 : this.low;
  }
  toNumber() {
    if (this.unsigned)
      return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
    return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
  }
  toBigInt() {
    return BigInt(this.toString());
  }
  toBytes(le) {
    return le ? this.toBytesLE() : this.toBytesBE();
  }
  toBytesLE() {
    const hi = this.high,
      lo = this.low;
    return [
      lo & 0xff,
      (lo >>> 8) & 0xff,
      (lo >>> 16) & 0xff,
      lo >>> 24,
      hi & 0xff,
      (hi >>> 8) & 0xff,
      (hi >>> 16) & 0xff,
      hi >>> 24,
    ];
  }
  toBytesBE() {
    const hi = this.high,
      lo = this.low;
    return [
      hi >>> 24,
      (hi >>> 16) & 0xff,
      (hi >>> 8) & 0xff,
      hi & 0xff,
      lo >>> 24,
      (lo >>> 16) & 0xff,
      (lo >>> 8) & 0xff,
      lo & 0xff,
    ];
  }
  toSigned() {
    if (!this.unsigned) return this;
    return Long.fromBits(this.low, this.high, false);
  }
  toString(radix) {
    radix = radix || 10;
    if (radix < 2 || 36 < radix) throw new BSONError("radix");
    if (this.isZero()) return "0";
    if (this.isNegative()) {
      if (this.eq(Long.MIN_VALUE)) {
        const radixLong = Long.fromNumber(radix),
          div = this.div(radixLong),
          rem1 = div.mul(radixLong).sub(this);
        return div.toString(radix) + rem1.toInt().toString(radix);
      } else return "-" + this.neg().toString(radix);
    }
    const radixToPower = Long.fromNumber(Math.pow(radix, 6), this.unsigned);
    let rem = this;
    let result = "";
    while (true) {
      const remDiv = rem.div(radixToPower);
      const intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0;
      let digits = intval.toString(radix);
      rem = remDiv;
      if (rem.isZero()) {
        return digits + result;
      } else {
        while (digits.length < 6) digits = "0" + digits;
        result = "" + digits + result;
      }
    }
  }
  toUnsigned() {
    if (this.unsigned) return this;
    return Long.fromBits(this.low, this.high, true);
  }
  xor(other) {
    if (!Long.isLong(other)) other = Long.fromValue(other);
    return Long.fromBits(
      this.low ^ other.low,
      this.high ^ other.high,
      this.unsigned,
    );
  }
  eqz() {
    return this.isZero();
  }
  le(other) {
    return this.lessThanOrEqual(other);
  }
  toExtendedJSON(options) {
    if (options && options.relaxed) return this.toNumber();
    return { $numberLong: this.toString() };
  }
  static fromExtendedJSON(doc, options) {
    const { useBigInt64 = false, relaxed = true } = { ...options };
    if (doc.$numberLong.length > MAX_INT64_STRING_LENGTH) {
      throw new BSONError("$numberLong string is too long");
    }
    if (!DECIMAL_REG_EX.test(doc.$numberLong)) {
      throw new BSONError(
        `$numberLong string "${doc.$numberLong}" is in an invalid format`,
      );
    }
    if (useBigInt64) {
      const bigIntResult = BigInt(doc.$numberLong);
      return BigInt.asIntN(64, bigIntResult);
    }
    const longResult = Long.fromString(doc.$numberLong);
    if (relaxed) {
      return longResult.toNumber();
    }
    return longResult;
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    const longVal = inspect(this.toString(), options);
    const unsignedVal = this.unsigned
      ? `, ${inspect(this.unsigned, options)}`
      : "";
    return `new Long(${longVal}${unsignedVal})`;
  }
};
Long$1.TWO_PWR_24 = Long$1.fromInt(TWO_PWR_24_DBL);
Long$1.MAX_UNSIGNED_VALUE = Long$1.fromBits(
  0xffffffff | 0,
  0xffffffff | 0,
  true,
);
Long$1.ZERO = Long$1.fromInt(0);
Long$1.UZERO = Long$1.fromInt(0, true);
Long$1.ONE = Long$1.fromInt(1);
Long$1.UONE = Long$1.fromInt(1, true);
Long$1.NEG_ONE = Long$1.fromInt(-1);
Long$1.MAX_VALUE = Long$1.fromBits(0xffffffff | 0, 0x7fffffff | 0, false);
Long$1.MIN_VALUE = Long$1.fromBits(0, 0x80000000 | 0, false);

const PARSE_STRING_REGEXP = /^(\+|-)?(\d+|(\d*\.\d*))?(E|e)?([-+])?(\d+)?$/;
const PARSE_INF_REGEXP = /^(\+|-)?(Infinity|inf)$/i;
const PARSE_NAN_REGEXP = /^(\+|-)?NaN$/i;
const EXPONENT_MAX = 6111;
const EXPONENT_MIN = -6176;
const EXPONENT_BIAS = 6176;
const MAX_DIGITS = 34;
const NAN_BUFFER = ByteUtils.fromNumberArray(
  [
    0x7c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00,
  ].reverse(),
);
const INF_NEGATIVE_BUFFER = ByteUtils.fromNumberArray(
  [
    0xf8, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00,
  ].reverse(),
);
const INF_POSITIVE_BUFFER = ByteUtils.fromNumberArray(
  [
    0x78, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00,
  ].reverse(),
);
const EXPONENT_REGEX = /^([-+])?(\d+)?$/;
const COMBINATION_MASK = 0x1f;
const EXPONENT_MASK = 0x3fff;
const COMBINATION_INFINITY = 30;
const COMBINATION_NAN = 31;
function isDigit(value) {
  return !isNaN(parseInt(value, 10));
}
function divideu128(value) {
  const DIVISOR = Long$1.fromNumber(1000 * 1000 * 1000);
  let _rem = Long$1.fromNumber(0);
  if (
    !value.parts[0] &&
    !value.parts[1] &&
    !value.parts[2] &&
    !value.parts[3]
  ) {
    return { quotient: value, rem: _rem };
  }
  for (let i = 0; i <= 3; i++) {
    _rem = _rem.shiftLeft(32);
    _rem = _rem.add(new Long$1(value.parts[i], 0));
    value.parts[i] = _rem.div(DIVISOR).low;
    _rem = _rem.modulo(DIVISOR);
  }
  return { quotient: value, rem: _rem };
}
function multiply64x2(left, right) {
  if (!left && !right) {
    return { high: Long$1.fromNumber(0), low: Long$1.fromNumber(0) };
  }
  const leftHigh = left.shiftRightUnsigned(32);
  const leftLow = new Long$1(left.getLowBits(), 0);
  const rightHigh = right.shiftRightUnsigned(32);
  const rightLow = new Long$1(right.getLowBits(), 0);
  let productHigh = leftHigh.multiply(rightHigh);
  let productMid = leftHigh.multiply(rightLow);
  const productMid2 = leftLow.multiply(rightHigh);
  let productLow = leftLow.multiply(rightLow);
  productHigh = productHigh.add(productMid.shiftRightUnsigned(32));
  productMid = new Long$1(productMid.getLowBits(), 0)
    .add(productMid2)
    .add(productLow.shiftRightUnsigned(32));
  productHigh = productHigh.add(productMid.shiftRightUnsigned(32));
  productLow = productMid
    .shiftLeft(32)
    .add(new Long$1(productLow.getLowBits(), 0));
  return { high: productHigh, low: productLow };
}
function lessThan(left, right) {
  const uhleft = left.high >>> 0;
  const uhright = right.high >>> 0;
  if (uhleft < uhright) {
    return true;
  } else if (uhleft === uhright) {
    const ulleft = left.low >>> 0;
    const ulright = right.low >>> 0;
    if (ulleft < ulright) return true;
  }
  return false;
}
function invalidErr(string, message) {
  throw new BSONError(
    `"${string}" is not a valid Decimal128 string - ${message}`,
  );
}
let Decimal128$1 = class Decimal128 extends BSONValue {
  get _bsontype() {
    return "Decimal128";
  }
  constructor(bytes) {
    super();
    if (typeof bytes === "string") {
      this.bytes = Decimal128.fromString(bytes).bytes;
    } else if (isUint8Array(bytes)) {
      if (bytes.byteLength !== 16) {
        throw new BSONError("Decimal128 must take a Buffer of 16 bytes");
      }
      this.bytes = bytes;
    } else {
      throw new BSONError("Decimal128 must take a Buffer or string");
    }
  }
  static fromString(representation) {
    return Decimal128._fromString(representation, { allowRounding: false });
  }
  static fromStringWithRounding(representation) {
    return Decimal128._fromString(representation, { allowRounding: true });
  }
  static _fromString(representation, options) {
    let isNegative = false;
    let sawSign = false;
    let sawRadix = false;
    let foundNonZero = false;
    let significantDigits = 0;
    let nDigitsRead = 0;
    let nDigits = 0;
    let radixPosition = 0;
    let firstNonZero = 0;
    const digits = [0];
    let nDigitsStored = 0;
    let digitsInsert = 0;
    let lastDigit = 0;
    let exponent = 0;
    let significandHigh = new Long$1(0, 0);
    let significandLow = new Long$1(0, 0);
    let biasedExponent = 0;
    let index = 0;
    if (representation.length >= 7000) {
      throw new BSONError(
        "" + representation + " not a valid Decimal128 string",
      );
    }
    const stringMatch = representation.match(PARSE_STRING_REGEXP);
    const infMatch = representation.match(PARSE_INF_REGEXP);
    const nanMatch = representation.match(PARSE_NAN_REGEXP);
    if (
      (!stringMatch && !infMatch && !nanMatch) ||
      representation.length === 0
    ) {
      throw new BSONError(
        "" + representation + " not a valid Decimal128 string",
      );
    }
    if (stringMatch) {
      const unsignedNumber = stringMatch[2];
      const e = stringMatch[4];
      const expSign = stringMatch[5];
      const expNumber = stringMatch[6];
      if (e && expNumber === undefined)
        invalidErr(representation, "missing exponent power");
      if (e && unsignedNumber === undefined)
        invalidErr(representation, "missing exponent base");
      if (e === undefined && (expSign || expNumber)) {
        invalidErr(representation, "missing e before exponent");
      }
    }
    if (representation[index] === "+" || representation[index] === "-") {
      sawSign = true;
      isNegative = representation[index++] === "-";
    }
    if (!isDigit(representation[index]) && representation[index] !== ".") {
      if (representation[index] === "i" || representation[index] === "I") {
        return new Decimal128(
          isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER,
        );
      } else if (representation[index] === "N") {
        return new Decimal128(NAN_BUFFER);
      }
    }
    while (isDigit(representation[index]) || representation[index] === ".") {
      if (representation[index] === ".") {
        if (sawRadix) invalidErr(representation, "contains multiple periods");
        sawRadix = true;
        index = index + 1;
        continue;
      }
      if (nDigitsStored < MAX_DIGITS) {
        if (representation[index] !== "0" || foundNonZero) {
          if (!foundNonZero) {
            firstNonZero = nDigitsRead;
          }
          foundNonZero = true;
          digits[digitsInsert++] = parseInt(representation[index], 10);
          nDigitsStored = nDigitsStored + 1;
        }
      }
      if (foundNonZero) nDigits = nDigits + 1;
      if (sawRadix) radixPosition = radixPosition + 1;
      nDigitsRead = nDigitsRead + 1;
      index = index + 1;
    }
    if (sawRadix && !nDigitsRead)
      throw new BSONError(
        "" + representation + " not a valid Decimal128 string",
      );
    if (representation[index] === "e" || representation[index] === "E") {
      const match = representation.substr(++index).match(EXPONENT_REGEX);
      if (!match || !match[2]) return new Decimal128(NAN_BUFFER);
      exponent = parseInt(match[0], 10);
      index = index + match[0].length;
    }
    if (representation[index]) return new Decimal128(NAN_BUFFER);
    if (!nDigitsStored) {
      digits[0] = 0;
      nDigits = 1;
      nDigitsStored = 1;
      significantDigits = 0;
    } else {
      lastDigit = nDigitsStored - 1;
      significantDigits = nDigits;
      if (significantDigits !== 1) {
        while (
          representation[
            firstNonZero +
              significantDigits -
              1 +
              Number(sawSign) +
              Number(sawRadix)
          ] === "0"
        ) {
          significantDigits = significantDigits - 1;
        }
      }
    }
    if (exponent <= radixPosition && radixPosition > exponent + (1 << 14)) {
      exponent = EXPONENT_MIN;
    } else {
      exponent = exponent - radixPosition;
    }
    while (exponent > EXPONENT_MAX) {
      lastDigit = lastDigit + 1;
      if (lastDigit >= MAX_DIGITS) {
        if (significantDigits === 0) {
          exponent = EXPONENT_MAX;
          break;
        }
        invalidErr(representation, "overflow");
      }
      exponent = exponent - 1;
    }
    if (options.allowRounding) {
      while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {
        if (lastDigit === 0 && significantDigits < nDigitsStored) {
          exponent = EXPONENT_MIN;
          significantDigits = 0;
          break;
        }
        if (nDigitsStored < nDigits) {
          nDigits = nDigits - 1;
        } else {
          lastDigit = lastDigit - 1;
        }
        if (exponent < EXPONENT_MAX) {
          exponent = exponent + 1;
        } else {
          const digitsString = digits.join("");
          if (digitsString.match(/^0+$/)) {
            exponent = EXPONENT_MAX;
            break;
          }
          invalidErr(representation, "overflow");
        }
      }
      if (lastDigit + 1 < significantDigits) {
        let endOfString = nDigitsRead;
        if (sawRadix) {
          firstNonZero = firstNonZero + 1;
          endOfString = endOfString + 1;
        }
        if (sawSign) {
          firstNonZero = firstNonZero + 1;
          endOfString = endOfString + 1;
        }
        const roundDigit = parseInt(
          representation[firstNonZero + lastDigit + 1],
          10,
        );
        let roundBit = 0;
        if (roundDigit >= 5) {
          roundBit = 1;
          if (roundDigit === 5) {
            roundBit = digits[lastDigit] % 2 === 1 ? 1 : 0;
            for (let i = firstNonZero + lastDigit + 2; i < endOfString; i++) {
              if (parseInt(representation[i], 10)) {
                roundBit = 1;
                break;
              }
            }
          }
        }
        if (roundBit) {
          let dIdx = lastDigit;
          for (; dIdx >= 0; dIdx--) {
            if (++digits[dIdx] > 9) {
              digits[dIdx] = 0;
              if (dIdx === 0) {
                if (exponent < EXPONENT_MAX) {
                  exponent = exponent + 1;
                  digits[dIdx] = 1;
                } else {
                  return new Decimal128(
                    isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER,
                  );
                }
              }
            } else {
              break;
            }
          }
        }
      }
    } else {
      while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {
        if (lastDigit === 0) {
          if (significantDigits === 0) {
            exponent = EXPONENT_MIN;
            break;
          }
          invalidErr(representation, "exponent underflow");
        }
        if (nDigitsStored < nDigits) {
          if (
            representation[nDigits - 1 + Number(sawSign) + Number(sawRadix)] !==
              "0" &&
            significantDigits !== 0
          ) {
            invalidErr(representation, "inexact rounding");
          }
          nDigits = nDigits - 1;
        } else {
          if (digits[lastDigit] !== 0) {
            invalidErr(representation, "inexact rounding");
          }
          lastDigit = lastDigit - 1;
        }
        if (exponent < EXPONENT_MAX) {
          exponent = exponent + 1;
        } else {
          invalidErr(representation, "overflow");
        }
      }
      if (lastDigit + 1 < significantDigits) {
        if (sawRadix) {
          firstNonZero = firstNonZero + 1;
        }
        if (sawSign) {
          firstNonZero = firstNonZero + 1;
        }
        const roundDigit = parseInt(
          representation[firstNonZero + lastDigit + 1],
          10,
        );
        if (roundDigit !== 0) {
          invalidErr(representation, "inexact rounding");
        }
      }
    }
    significandHigh = Long$1.fromNumber(0);
    significandLow = Long$1.fromNumber(0);
    if (significantDigits === 0) {
      significandHigh = Long$1.fromNumber(0);
      significandLow = Long$1.fromNumber(0);
    } else if (lastDigit < 17) {
      let dIdx = 0;
      significandLow = Long$1.fromNumber(digits[dIdx++]);
      significandHigh = new Long$1(0, 0);
      for (; dIdx <= lastDigit; dIdx++) {
        significandLow = significandLow.multiply(Long$1.fromNumber(10));
        significandLow = significandLow.add(Long$1.fromNumber(digits[dIdx]));
      }
    } else {
      let dIdx = 0;
      significandHigh = Long$1.fromNumber(digits[dIdx++]);
      for (; dIdx <= lastDigit - 17; dIdx++) {
        significandHigh = significandHigh.multiply(Long$1.fromNumber(10));
        significandHigh = significandHigh.add(Long$1.fromNumber(digits[dIdx]));
      }
      significandLow = Long$1.fromNumber(digits[dIdx++]);
      for (; dIdx <= lastDigit; dIdx++) {
        significandLow = significandLow.multiply(Long$1.fromNumber(10));
        significandLow = significandLow.add(Long$1.fromNumber(digits[dIdx]));
      }
    }
    const significand = multiply64x2(
      significandHigh,
      Long$1.fromString("100000000000000000"),
    );
    significand.low = significand.low.add(significandLow);
    if (lessThan(significand.low, significandLow)) {
      significand.high = significand.high.add(Long$1.fromNumber(1));
    }
    biasedExponent = exponent + EXPONENT_BIAS;
    const dec = { low: Long$1.fromNumber(0), high: Long$1.fromNumber(0) };
    if (
      significand.high
        .shiftRightUnsigned(49)
        .and(Long$1.fromNumber(1))
        .equals(Long$1.fromNumber(1))
    ) {
      dec.high = dec.high.or(Long$1.fromNumber(0x3).shiftLeft(61));
      dec.high = dec.high.or(
        Long$1.fromNumber(biasedExponent).and(
          Long$1.fromNumber(0x3fff).shiftLeft(47),
        ),
      );
      dec.high = dec.high.or(
        significand.high.and(Long$1.fromNumber(0x7fffffffffff)),
      );
    } else {
      dec.high = dec.high.or(
        Long$1.fromNumber(biasedExponent & 0x3fff).shiftLeft(49),
      );
      dec.high = dec.high.or(
        significand.high.and(Long$1.fromNumber(0x1ffffffffffff)),
      );
    }
    dec.low = significand.low;
    if (isNegative) {
      dec.high = dec.high.or(Long$1.fromString("9223372036854775808"));
    }
    const buffer = ByteUtils.allocate(16);
    index = 0;
    buffer[index++] = dec.low.low & 0xff;
    buffer[index++] = (dec.low.low >> 8) & 0xff;
    buffer[index++] = (dec.low.low >> 16) & 0xff;
    buffer[index++] = (dec.low.low >> 24) & 0xff;
    buffer[index++] = dec.low.high & 0xff;
    buffer[index++] = (dec.low.high >> 8) & 0xff;
    buffer[index++] = (dec.low.high >> 16) & 0xff;
    buffer[index++] = (dec.low.high >> 24) & 0xff;
    buffer[index++] = dec.high.low & 0xff;
    buffer[index++] = (dec.high.low >> 8) & 0xff;
    buffer[index++] = (dec.high.low >> 16) & 0xff;
    buffer[index++] = (dec.high.low >> 24) & 0xff;
    buffer[index++] = dec.high.high & 0xff;
    buffer[index++] = (dec.high.high >> 8) & 0xff;
    buffer[index++] = (dec.high.high >> 16) & 0xff;
    buffer[index++] = (dec.high.high >> 24) & 0xff;
    return new Decimal128(buffer);
  }
  toString() {
    let biased_exponent;
    let significand_digits = 0;
    const significand = new Array(36);
    for (let i = 0; i < significand.length; i++) significand[i] = 0;
    let index = 0;
    let is_zero = false;
    let significand_msb;
    let significand128 = { parts: [0, 0, 0, 0] };
    let j, k;
    const string = [];
    index = 0;
    const buffer = this.bytes;
    const low =
      buffer[index++] |
      (buffer[index++] << 8) |
      (buffer[index++] << 16) |
      (buffer[index++] << 24);
    const midl =
      buffer[index++] |
      (buffer[index++] << 8) |
      (buffer[index++] << 16) |
      (buffer[index++] << 24);
    const midh =
      buffer[index++] |
      (buffer[index++] << 8) |
      (buffer[index++] << 16) |
      (buffer[index++] << 24);
    const high =
      buffer[index++] |
      (buffer[index++] << 8) |
      (buffer[index++] << 16) |
      (buffer[index++] << 24);
    index = 0;
    const dec = {
      low: new Long$1(low, midl),
      high: new Long$1(midh, high),
    };
    if (dec.high.lessThan(Long$1.ZERO)) {
      string.push("-");
    }
    const combination = (high >> 26) & COMBINATION_MASK;
    if (combination >> 3 === 3) {
      if (combination === COMBINATION_INFINITY) {
        return string.join("") + "Infinity";
      } else if (combination === COMBINATION_NAN) {
        return "NaN";
      } else {
        biased_exponent = (high >> 15) & EXPONENT_MASK;
        significand_msb = 0x08 + ((high >> 14) & 0x01);
      }
    } else {
      significand_msb = (high >> 14) & 0x07;
      biased_exponent = (high >> 17) & EXPONENT_MASK;
    }
    const exponent = biased_exponent - EXPONENT_BIAS;
    significand128.parts[0] = (high & 0x3fff) + ((significand_msb & 0xf) << 14);
    significand128.parts[1] = midh;
    significand128.parts[2] = midl;
    significand128.parts[3] = low;
    if (
      significand128.parts[0] === 0 &&
      significand128.parts[1] === 0 &&
      significand128.parts[2] === 0 &&
      significand128.parts[3] === 0
    ) {
      is_zero = true;
    } else {
      for (k = 3; k >= 0; k--) {
        let least_digits = 0;
        const result = divideu128(significand128);
        significand128 = result.quotient;
        least_digits = result.rem.low;
        if (!least_digits) continue;
        for (j = 8; j >= 0; j--) {
          significand[k * 9 + j] = least_digits % 10;
          least_digits = Math.floor(least_digits / 10);
        }
      }
    }
    if (is_zero) {
      significand_digits = 1;
      significand[index] = 0;
    } else {
      significand_digits = 36;
      while (!significand[index]) {
        significand_digits = significand_digits - 1;
        index = index + 1;
      }
    }
    const scientific_exponent = significand_digits - 1 + exponent;
    if (
      scientific_exponent >= 34 ||
      scientific_exponent <= -7 ||
      exponent > 0
    ) {
      if (significand_digits > 34) {
        string.push(`${0}`);
        if (exponent > 0) string.push(`E+${exponent}`);
        else if (exponent < 0) string.push(`E${exponent}`);
        return string.join("");
      }
      string.push(`${significand[index++]}`);
      significand_digits = significand_digits - 1;
      if (significand_digits) {
        string.push(".");
      }
      for (let i = 0; i < significand_digits; i++) {
        string.push(`${significand[index++]}`);
      }
      string.push("E");
      if (scientific_exponent > 0) {
        string.push(`+${scientific_exponent}`);
      } else {
        string.push(`${scientific_exponent}`);
      }
    } else {
      if (exponent >= 0) {
        for (let i = 0; i < significand_digits; i++) {
          string.push(`${significand[index++]}`);
        }
      } else {
        let radix_position = significand_digits + exponent;
        if (radix_position > 0) {
          for (let i = 0; i < radix_position; i++) {
            string.push(`${significand[index++]}`);
          }
        } else {
          string.push("0");
        }
        string.push(".");
        while (radix_position++ < 0) {
          string.push("0");
        }
        for (
          let i = 0;
          i < significand_digits - Math.max(radix_position - 1, 0);
          i++
        ) {
          string.push(`${significand[index++]}`);
        }
      }
    }
    return string.join("");
  }
  toJSON() {
    return { $numberDecimal: this.toString() };
  }
  toExtendedJSON() {
    return { $numberDecimal: this.toString() };
  }
  static fromExtendedJSON(doc) {
    return Decimal128.fromString(doc.$numberDecimal);
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    const d128string = inspect(this.toString(), options);
    return `new Decimal128(${d128string})`;
  }
};

let Double$1 = class Double extends BSONValue {
  get _bsontype() {
    return "Double";
  }
  constructor(value) {
    super();
    if (value instanceof Number) {
      value = value.valueOf();
    }
    this.value = +value;
  }
  valueOf() {
    return this.value;
  }
  toJSON() {
    return this.value;
  }
  toString(radix) {
    return this.value.toString(radix);
  }
  toExtendedJSON(options) {
    if (
      options &&
      (options.legacy || (options.relaxed && isFinite(this.value)))
    ) {
      return this.value;
    }
    if (Object.is(Math.sign(this.value), -0)) {
      return { $numberDouble: "-0.0" };
    }
    return {
      $numberDouble: Number.isInteger(this.value)
        ? this.value.toFixed(1)
        : this.value.toString(),
    };
  }
  static fromExtendedJSON(doc, options) {
    const doubleValue = parseFloat(doc.$numberDouble);
    return options && options.relaxed ? doubleValue : new Double(doubleValue);
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    return `new Double(${inspect(this.value, options)})`;
  }
};

let Int32$1 = class Int32 extends BSONValue {
  get _bsontype() {
    return "Int32";
  }
  constructor(value) {
    super();
    if (value instanceof Number) {
      value = value.valueOf();
    }
    this.value = +value | 0;
  }
  valueOf() {
    return this.value;
  }
  toString(radix) {
    return this.value.toString(radix);
  }
  toJSON() {
    return this.value;
  }
  toExtendedJSON(options) {
    if (options && (options.relaxed || options.legacy)) return this.value;
    return { $numberInt: this.value.toString() };
  }
  static fromExtendedJSON(doc, options) {
    return options && options.relaxed
      ? parseInt(doc.$numberInt, 10)
      : new Int32(doc.$numberInt);
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    return `new Int32(${inspect(this.value, options)})`;
  }
};

let MaxKey$1 = class MaxKey extends BSONValue {
  get _bsontype() {
    return "MaxKey";
  }
  toExtendedJSON() {
    return { $maxKey: 1 };
  }
  static fromExtendedJSON() {
    return new MaxKey();
  }
  inspect() {
    return "new MaxKey()";
  }
};

let MinKey$1 = class MinKey extends BSONValue {
  get _bsontype() {
    return "MinKey";
  }
  toExtendedJSON() {
    return { $minKey: 1 };
  }
  static fromExtendedJSON() {
    return new MinKey();
  }
  inspect() {
    return "new MinKey()";
  }
};

const checkForHexRegExp = new RegExp("^[0-9a-fA-F]{24}$");
let PROCESS_UNIQUE = null;
const kId = Symbol("id");
let ObjectId$1 = class ObjectId extends BSONValue {
  get _bsontype() {
    return "ObjectId";
  }
  constructor(inputId) {
    super();
    let workingId;
    if (typeof inputId === "object" && inputId && "id" in inputId) {
      if (typeof inputId.id !== "string" && !ArrayBuffer.isView(inputId.id)) {
        throw new BSONError(
          "Argument passed in must have an id that is of type string or Buffer",
        );
      }
      if (
        "toHexString" in inputId &&
        typeof inputId.toHexString === "function"
      ) {
        workingId = ByteUtils.fromHex(inputId.toHexString());
      } else {
        workingId = inputId.id;
      }
    } else {
      workingId = inputId;
    }
    if (workingId == null || typeof workingId === "number") {
      this[kId] = ObjectId.generate(
        typeof workingId === "number" ? workingId : undefined,
      );
    } else if (ArrayBuffer.isView(workingId) && workingId.byteLength === 12) {
      this[kId] = ByteUtils.toLocalBufferType(workingId);
    } else if (typeof workingId === "string") {
      if (workingId.length === 24 && checkForHexRegExp.test(workingId)) {
        this[kId] = ByteUtils.fromHex(workingId);
      } else {
        throw new BSONError(
          "input must be a 24 character hex string, 12 byte Uint8Array, or an integer",
        );
      }
    } else {
      throw new BSONError(
        "Argument passed in does not match the accepted types",
      );
    }
    if (ObjectId.cacheHexString) {
      this.__id = ByteUtils.toHex(this.id);
    }
  }
  get id() {
    return this[kId];
  }
  set id(value) {
    this[kId] = value;
    if (ObjectId.cacheHexString) {
      this.__id = ByteUtils.toHex(value);
    }
  }
  toHexString() {
    if (ObjectId.cacheHexString && this.__id) {
      return this.__id;
    }
    const hexString = ByteUtils.toHex(this.id);
    if (ObjectId.cacheHexString && !this.__id) {
      this.__id = hexString;
    }
    return hexString;
  }
  static getInc() {
    return (ObjectId.index = (ObjectId.index + 1) % 0xffffff);
  }
  static generate(time) {
    if ("number" !== typeof time) {
      time = Math.floor(Date.now() / 1000);
    }
    const inc = ObjectId.getInc();
    const buffer = ByteUtils.allocate(12);
    BSONDataView.fromUint8Array(buffer).setUint32(0, time, false);
    if (PROCESS_UNIQUE === null) {
      PROCESS_UNIQUE = ByteUtils.randomBytes(5);
    }
    buffer[4] = PROCESS_UNIQUE[0];
    buffer[5] = PROCESS_UNIQUE[1];
    buffer[6] = PROCESS_UNIQUE[2];
    buffer[7] = PROCESS_UNIQUE[3];
    buffer[8] = PROCESS_UNIQUE[4];
    buffer[11] = inc & 0xff;
    buffer[10] = (inc >> 8) & 0xff;
    buffer[9] = (inc >> 16) & 0xff;
    return buffer;
  }
  toString(encoding) {
    if (encoding === "base64") return ByteUtils.toBase64(this.id);
    if (encoding === "hex") return this.toHexString();
    return this.toHexString();
  }
  toJSON() {
    return this.toHexString();
  }
  static is(variable) {
    return (
      variable != null &&
      typeof variable === "object" &&
      "_bsontype" in variable &&
      variable._bsontype === "ObjectId"
    );
  }
  equals(otherId) {
    if (otherId === undefined || otherId === null) {
      return false;
    }
    if (ObjectId.is(otherId)) {
      return (
        this[kId][11] === otherId[kId][11] &&
        ByteUtils.equals(this[kId], otherId[kId])
      );
    }
    if (typeof otherId === "string") {
      return otherId.toLowerCase() === this.toHexString();
    }
    if (
      typeof otherId === "object" &&
      typeof otherId.toHexString === "function"
    ) {
      const otherIdString = otherId.toHexString();
      const thisIdString = this.toHexString();
      return (
        typeof otherIdString === "string" &&
        otherIdString.toLowerCase() === thisIdString
      );
    }
    return false;
  }
  getTimestamp() {
    const timestamp = new Date();
    const time = BSONDataView.fromUint8Array(this.id).getUint32(0, false);
    timestamp.setTime(Math.floor(time) * 1000);
    return timestamp;
  }
  static createPk() {
    return new ObjectId();
  }
  static createFromTime(time) {
    const buffer = ByteUtils.fromNumberArray([
      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ]);
    BSONDataView.fromUint8Array(buffer).setUint32(0, time, false);
    return new ObjectId(buffer);
  }
  static createFromHexString(hexString) {
    if (hexString?.length !== 24) {
      throw new BSONError("hex string must be 24 characters");
    }
    return new ObjectId(ByteUtils.fromHex(hexString));
  }
  static createFromBase64(base64) {
    if (base64?.length !== 16) {
      throw new BSONError("base64 string must be 16 characters");
    }
    return new ObjectId(ByteUtils.fromBase64(base64));
  }
  static isValid(id) {
    if (id == null) return false;
    try {
      new ObjectId(id);
      return true;
    } catch {
      return false;
    }
  }
  toExtendedJSON() {
    if (this.toHexString) return { $oid: this.toHexString() };
    return { $oid: this.toString("hex") };
  }
  static fromExtendedJSON(doc) {
    return new ObjectId(doc.$oid);
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    return `new ObjectId(${inspect(this.toHexString(), options)})`;
  }
};
ObjectId$1.index = Math.floor(Math.random() * 0xffffff);

function internalCalculateObjectSize(
  object,
  serializeFunctions,
  ignoreUndefined,
) {
  let totalLength = 4 + 1;
  if (Array.isArray(object)) {
    for (let i = 0; i < object.length; i++) {
      totalLength += calculateElement(
        i.toString(),
        object[i],
        serializeFunctions,
        true,
        ignoreUndefined,
      );
    }
  } else {
    if (typeof object?.toBSON === "function") {
      object = object.toBSON();
    }
    for (const key of Object.keys(object)) {
      totalLength += calculateElement(
        key,
        object[key],
        serializeFunctions,
        false,
        ignoreUndefined,
      );
    }
  }
  return totalLength;
}
function calculateElement(
  name,
  value,
  serializeFunctions = false,
  isArray = false,
  ignoreUndefined = false,
) {
  if (typeof value?.toBSON === "function") {
    value = value.toBSON();
  }
  switch (typeof value) {
    case "string":
      return (
        1 +
        ByteUtils.utf8ByteLength(name) +
        1 +
        4 +
        ByteUtils.utf8ByteLength(value) +
        1
      );
    case "number":
      if (
        Math.floor(value) === value &&
        value >= JS_INT_MIN &&
        value <= JS_INT_MAX
      ) {
        if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {
          return (
            (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (4 + 1)
          );
        } else {
          return (
            (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1)
          );
        }
      } else {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1)
        );
      }
    case "undefined":
      if (isArray || !ignoreUndefined)
        return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;
      return 0;
    case "boolean":
      return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (1 + 1);
    case "object":
      if (
        value != null &&
        typeof value._bsontype === "string" &&
        value[Symbol.for("@@mdb.bson.version")] !== BSON_MAJOR_VERSION
      ) {
        throw new BSONVersionError();
      } else if (
        value == null ||
        value._bsontype === "MinKey" ||
        value._bsontype === "MaxKey"
      ) {
        return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;
      } else if (value._bsontype === "ObjectId") {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (12 + 1)
        );
      } else if (value instanceof Date || isDate(value)) {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1)
        );
      } else if (
        ArrayBuffer.isView(value) ||
        value instanceof ArrayBuffer ||
        isAnyArrayBuffer(value)
      ) {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
          (1 + 4 + 1) +
          value.byteLength
        );
      } else if (
        value._bsontype === "Long" ||
        value._bsontype === "Double" ||
        value._bsontype === "Timestamp"
      ) {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1)
        );
      } else if (value._bsontype === "Decimal128") {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (16 + 1)
        );
      } else if (value._bsontype === "Code") {
        if (value.scope != null && Object.keys(value.scope).length > 0) {
          return (
            (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
            1 +
            4 +
            4 +
            ByteUtils.utf8ByteLength(value.code.toString()) +
            1 +
            internalCalculateObjectSize(
              value.scope,
              serializeFunctions,
              ignoreUndefined,
            )
          );
        } else {
          return (
            (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
            1 +
            4 +
            ByteUtils.utf8ByteLength(value.code.toString()) +
            1
          );
        }
      } else if (value._bsontype === "Binary") {
        const binary = value;
        if (binary.sub_type === Binary$1.SUBTYPE_BYTE_ARRAY) {
          return (
            (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
            (binary.position + 1 + 4 + 1 + 4)
          );
        } else {
          return (
            (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
            (binary.position + 1 + 4 + 1)
          );
        }
      } else if (value._bsontype === "Symbol") {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
          ByteUtils.utf8ByteLength(value.value) +
          4 +
          1 +
          1
        );
      } else if (value._bsontype === "DBRef") {
        const ordered_values = Object.assign(
          {
            $ref: value.collection,
            $id: value.oid,
          },
          value.fields,
        );
        if (value.db != null) {
          ordered_values["$db"] = value.db;
        }
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
          1 +
          internalCalculateObjectSize(
            ordered_values,
            serializeFunctions,
            ignoreUndefined,
          )
        );
      } else if (value instanceof RegExp || isRegExp(value)) {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
          1 +
          ByteUtils.utf8ByteLength(value.source) +
          1 +
          (value.global ? 1 : 0) +
          (value.ignoreCase ? 1 : 0) +
          (value.multiline ? 1 : 0) +
          1
        );
      } else if (value._bsontype === "BSONRegExp") {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
          1 +
          ByteUtils.utf8ByteLength(value.pattern) +
          1 +
          ByteUtils.utf8ByteLength(value.options) +
          1
        );
      } else {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
          internalCalculateObjectSize(
            value,
            serializeFunctions,
            ignoreUndefined,
          ) +
          1
        );
      }
    case "function":
      if (serializeFunctions) {
        return (
          (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
          1 +
          4 +
          ByteUtils.utf8ByteLength(value.toString()) +
          1
        );
      }
  }
  return 0;
}

function alphabetize(str) {
  return str.split("").sort().join("");
}
let BSONRegExp$1 = class BSONRegExp extends BSONValue {
  get _bsontype() {
    return "BSONRegExp";
  }
  constructor(pattern, options) {
    super();
    this.pattern = pattern;
    this.options = alphabetize(options ?? "");
    if (this.pattern.indexOf("\x00") !== -1) {
      throw new BSONError(
        `BSON Regex patterns cannot contain null bytes, found: ${JSON.stringify(
          this.pattern,
        )}`,
      );
    }
    if (this.options.indexOf("\x00") !== -1) {
      throw new BSONError(
        `BSON Regex options cannot contain null bytes, found: ${JSON.stringify(
          this.options,
        )}`,
      );
    }
    for (let i = 0; i < this.options.length; i++) {
      if (
        !(
          this.options[i] === "i" ||
          this.options[i] === "m" ||
          this.options[i] === "x" ||
          this.options[i] === "l" ||
          this.options[i] === "s" ||
          this.options[i] === "u"
        )
      ) {
        throw new BSONError(
          `The regular expression option [${this.options[i]}] is not supported`,
        );
      }
    }
  }
  static parseOptions(options) {
    return options ? options.split("").sort().join("") : "";
  }
  toExtendedJSON(options) {
    options = options || {};
    if (options.legacy) {
      return { $regex: this.pattern, $options: this.options };
    }
    return {
      $regularExpression: { pattern: this.pattern, options: this.options },
    };
  }
  static fromExtendedJSON(doc) {
    if ("$regex" in doc) {
      if (typeof doc.$regex !== "string") {
        if (doc.$regex._bsontype === "BSONRegExp") {
          return doc;
        }
      } else {
        return new BSONRegExp(
          doc.$regex,
          BSONRegExp.parseOptions(doc.$options),
        );
      }
    }
    if ("$regularExpression" in doc) {
      return new BSONRegExp(
        doc.$regularExpression.pattern,
        BSONRegExp.parseOptions(doc.$regularExpression.options),
      );
    }
    throw new BSONError(
      `Unexpected BSONRegExp EJSON object form: ${JSON.stringify(doc)}`,
    );
  }
  inspect(depth, options, inspect) {
    const stylize = getStylizeFunction(options) ?? ((v) => v);
    inspect ??= defaultInspect;
    const pattern = stylize(inspect(this.pattern), "regexp");
    const flags = stylize(inspect(this.options), "regexp");
    return `new BSONRegExp(${pattern}, ${flags})`;
  }
};

let BSONSymbol$1 = class BSONSymbol extends BSONValue {
  get _bsontype() {
    return "BSONSymbol";
  }
  constructor(value) {
    super();
    this.value = value;
  }
  valueOf() {
    return this.value;
  }
  toString() {
    return this.value;
  }
  toJSON() {
    return this.value;
  }
  toExtendedJSON() {
    return { $symbol: this.value };
  }
  static fromExtendedJSON(doc) {
    return new BSONSymbol(doc.$symbol);
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    return `new BSONSymbol(${inspect(this.value, options)})`;
  }
};

const LongWithoutOverridesClass = Long$1;
let Timestamp$1 = class Timestamp extends LongWithoutOverridesClass {
  get _bsontype() {
    return "Timestamp";
  }
  constructor(low) {
    if (low == null) {
      super(0, 0, true);
    } else if (typeof low === "bigint") {
      super(low, true);
    } else if (Long$1.isLong(low)) {
      super(low.low, low.high, true);
    } else if (typeof low === "object" && "t" in low && "i" in low) {
      if (
        typeof low.t !== "number" &&
        (typeof low.t !== "object" || low.t._bsontype !== "Int32")
      ) {
        throw new BSONError(
          "Timestamp constructed from { t, i } must provide t as a number",
        );
      }
      if (
        typeof low.i !== "number" &&
        (typeof low.i !== "object" || low.i._bsontype !== "Int32")
      ) {
        throw new BSONError(
          "Timestamp constructed from { t, i } must provide i as a number",
        );
      }
      const t = Number(low.t);
      const i = Number(low.i);
      if (t < 0 || Number.isNaN(t)) {
        throw new BSONError(
          "Timestamp constructed from { t, i } must provide a positive t",
        );
      }
      if (i < 0 || Number.isNaN(i)) {
        throw new BSONError(
          "Timestamp constructed from { t, i } must provide a positive i",
        );
      }
      if (t > 4294967295) {
        throw new BSONError(
          "Timestamp constructed from { t, i } must provide t equal or less than uint32 max",
        );
      }
      if (i > 4294967295) {
        throw new BSONError(
          "Timestamp constructed from { t, i } must provide i equal or less than uint32 max",
        );
      }
      super(i, t, true);
    } else {
      throw new BSONError(
        "A Timestamp can only be constructed with: bigint, Long, or { t: number; i: number }",
      );
    }
  }
  toJSON() {
    return {
      $timestamp: this.toString(),
    };
  }
  static fromInt(value) {
    return new Timestamp(Long$1.fromInt(value, true));
  }
  static fromNumber(value) {
    return new Timestamp(Long$1.fromNumber(value, true));
  }
  static fromBits(lowBits, highBits) {
    return new Timestamp({ i: lowBits, t: highBits });
  }
  static fromString(str, optRadix) {
    return new Timestamp(Long$1.fromString(str, true, optRadix));
  }
  toExtendedJSON() {
    return { $timestamp: { t: this.high >>> 0, i: this.low >>> 0 } };
  }
  static fromExtendedJSON(doc) {
    const i = Long$1.isLong(doc.$timestamp.i)
      ? doc.$timestamp.i.getLowBitsUnsigned()
      : doc.$timestamp.i;
    const t = Long$1.isLong(doc.$timestamp.t)
      ? doc.$timestamp.t.getLowBitsUnsigned()
      : doc.$timestamp.t;
    return new Timestamp({ t, i });
  }
  inspect(depth, options, inspect) {
    inspect ??= defaultInspect;
    const t = inspect(this.high >>> 0, options);
    const i = inspect(this.low >>> 0, options);
    return `new Timestamp({ t: ${t}, i: ${i} })`;
  }
};
Timestamp$1.MAX_VALUE = Long$1.MAX_UNSIGNED_VALUE;

const FIRST_BIT = 0x80;
const FIRST_TWO_BITS = 0xc0;
const FIRST_THREE_BITS = 0xe0;
const FIRST_FOUR_BITS = 0xf0;
const FIRST_FIVE_BITS = 0xf8;
const TWO_BIT_CHAR = 0xc0;
const THREE_BIT_CHAR = 0xe0;
const FOUR_BIT_CHAR = 0xf0;
const CONTINUING_CHAR = 0x80;
function validateUtf8(bytes, start, end) {
  let continuation = 0;
  for (let i = start; i < end; i += 1) {
    const byte = bytes[i];
    if (continuation) {
      if ((byte & FIRST_TWO_BITS) !== CONTINUING_CHAR) {
        return false;
      }
      continuation -= 1;
    } else if (byte & FIRST_BIT) {
      if ((byte & FIRST_THREE_BITS) === TWO_BIT_CHAR) {
        continuation = 1;
      } else if ((byte & FIRST_FOUR_BITS) === THREE_BIT_CHAR) {
        continuation = 2;
      } else if ((byte & FIRST_FIVE_BITS) === FOUR_BIT_CHAR) {
        continuation = 3;
      } else {
        return false;
      }
    }
  }
  return !continuation;
}

const JS_INT_MAX_LONG = Long$1.fromNumber(JS_INT_MAX);
const JS_INT_MIN_LONG = Long$1.fromNumber(JS_INT_MIN);
function internalDeserialize(buffer, options, isArray) {
  options = options == null ? {} : options;
  const index = options && options.index ? options.index : 0;
  const size =
    buffer[index] |
    (buffer[index + 1] << 8) |
    (buffer[index + 2] << 16) |
    (buffer[index + 3] << 24);
  if (size < 5) {
    throw new BSONError(`bson size must be >= 5, is ${size}`);
  }
  if (options.allowObjectSmallerThanBufferSize && buffer.length < size) {
    throw new BSONError(
      `buffer length ${buffer.length} must be >= bson size ${size}`,
    );
  }
  if (!options.allowObjectSmallerThanBufferSize && buffer.length !== size) {
    throw new BSONError(
      `buffer length ${buffer.length} must === bson size ${size}`,
    );
  }
  if (size + index > buffer.byteLength) {
    throw new BSONError(
      `(bson size ${size} + options.index ${index} must be <= buffer length ${buffer.byteLength})`,
    );
  }
  if (buffer[index + size - 1] !== 0) {
    throw new BSONError(
      "One object, sized correctly, with a spot for an EOO, but the EOO isn't 0x00",
    );
  }
  return deserializeObject(buffer, index, options, isArray);
}
const allowedDBRefKeys = /^\$ref$|^\$id$|^\$db$/;
function deserializeObject(buffer, index, options, isArray = false) {
  const fieldsAsRaw =
    options["fieldsAsRaw"] == null ? null : options["fieldsAsRaw"];
  const raw = options["raw"] == null ? false : options["raw"];
  const bsonRegExp =
    typeof options["bsonRegExp"] === "boolean" ? options["bsonRegExp"] : false;
  const promoteBuffers = options.promoteBuffers ?? false;
  const promoteLongs = options.promoteLongs ?? true;
  const promoteValues = options.promoteValues ?? true;
  const useBigInt64 = options.useBigInt64 ?? false;
  if (useBigInt64 && !promoteValues) {
    throw new BSONError(
      "Must either request bigint or Long for int64 deserialization",
    );
  }
  if (useBigInt64 && !promoteLongs) {
    throw new BSONError(
      "Must either request bigint or Long for int64 deserialization",
    );
  }
  const validation =
    options.validation == null ? { utf8: true } : options.validation;
  let globalUTFValidation = true;
  let validationSetting;
  const utf8KeysSet = new Set();
  const utf8ValidatedKeys = validation.utf8;
  if (typeof utf8ValidatedKeys === "boolean") {
    validationSetting = utf8ValidatedKeys;
  } else {
    globalUTFValidation = false;
    const utf8ValidationValues = Object.keys(utf8ValidatedKeys).map(
      function (key) {
        return utf8ValidatedKeys[key];
      },
    );
    if (utf8ValidationValues.length === 0) {
      throw new BSONError("UTF-8 validation setting cannot be empty");
    }
    if (typeof utf8ValidationValues[0] !== "boolean") {
      throw new BSONError(
        "Invalid UTF-8 validation option, must specify boolean values",
      );
    }
    validationSetting = utf8ValidationValues[0];
    if (!utf8ValidationValues.every((item) => item === validationSetting)) {
      throw new BSONError(
        "Invalid UTF-8 validation option - keys must be all true or all false",
      );
    }
  }
  if (!globalUTFValidation) {
    for (const key of Object.keys(utf8ValidatedKeys)) {
      utf8KeysSet.add(key);
    }
  }
  const startIndex = index;
  if (buffer.length < 5)
    throw new BSONError("corrupt bson message < 5 bytes long");
  const size =
    buffer[index++] |
    (buffer[index++] << 8) |
    (buffer[index++] << 16) |
    (buffer[index++] << 24);
  if (size < 5 || size > buffer.length)
    throw new BSONError("corrupt bson message");
  const object = isArray ? [] : {};
  let arrayIndex = 0;
  const done = false;
  let isPossibleDBRef = isArray ? false : null;
  const dataview = new DataView(
    buffer.buffer,
    buffer.byteOffset,
    buffer.byteLength,
  );
  while (!done) {
    const elementType = buffer[index++];
    if (elementType === 0) break;
    let i = index;
    while (buffer[i] !== 0x00 && i < buffer.length) {
      i++;
    }
    if (i >= buffer.byteLength)
      throw new BSONError("Bad BSON Document: illegal CString");
    const name = isArray ? arrayIndex++ : ByteUtils.toUTF8(buffer, index, i);
    let shouldValidateKey = true;
    if (globalUTFValidation || utf8KeysSet.has(name)) {
      shouldValidateKey = validationSetting;
    } else {
      shouldValidateKey = !validationSetting;
    }
    if (isPossibleDBRef !== false && name[0] === "$") {
      isPossibleDBRef = allowedDBRefKeys.test(name);
    }
    let value;
    index = i + 1;
    if (elementType === BSON_DATA_STRING) {
      const stringSize =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      if (
        stringSize <= 0 ||
        stringSize > buffer.length - index ||
        buffer[index + stringSize - 1] !== 0
      ) {
        throw new BSONError("bad string length in bson");
      }
      value = getValidatedString(
        buffer,
        index,
        index + stringSize - 1,
        shouldValidateKey,
      );
      index = index + stringSize;
    } else if (elementType === BSON_DATA_OID) {
      const oid = ByteUtils.allocate(12);
      oid.set(buffer.subarray(index, index + 12));
      value = new ObjectId$1(oid);
      index = index + 12;
    } else if (elementType === BSON_DATA_INT && promoteValues === false) {
      value = new Int32$1(
        buffer[index++] |
          (buffer[index++] << 8) |
          (buffer[index++] << 16) |
          (buffer[index++] << 24),
      );
    } else if (elementType === BSON_DATA_INT) {
      value =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
    } else if (elementType === BSON_DATA_NUMBER && promoteValues === false) {
      value = new Double$1(dataview.getFloat64(index, true));
      index = index + 8;
    } else if (elementType === BSON_DATA_NUMBER) {
      value = dataview.getFloat64(index, true);
      index = index + 8;
    } else if (elementType === BSON_DATA_DATE) {
      const lowBits =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      const highBits =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      value = new Date(new Long$1(lowBits, highBits).toNumber());
    } else if (elementType === BSON_DATA_BOOLEAN) {
      if (buffer[index] !== 0 && buffer[index] !== 1)
        throw new BSONError("illegal boolean type value");
      value = buffer[index++] === 1;
    } else if (elementType === BSON_DATA_OBJECT) {
      const _index = index;
      const objectSize =
        buffer[index] |
        (buffer[index + 1] << 8) |
        (buffer[index + 2] << 16) |
        (buffer[index + 3] << 24);
      if (objectSize <= 0 || objectSize > buffer.length - index)
        throw new BSONError("bad embedded document length in bson");
      if (raw) {
        value = buffer.slice(index, index + objectSize);
      } else {
        let objectOptions = options;
        if (!globalUTFValidation) {
          objectOptions = {
            ...options,
            validation: { utf8: shouldValidateKey },
          };
        }
        value = deserializeObject(buffer, _index, objectOptions, false);
      }
      index = index + objectSize;
    } else if (elementType === BSON_DATA_ARRAY) {
      const _index = index;
      const objectSize =
        buffer[index] |
        (buffer[index + 1] << 8) |
        (buffer[index + 2] << 16) |
        (buffer[index + 3] << 24);
      let arrayOptions = options;
      const stopIndex = index + objectSize;
      if (fieldsAsRaw && fieldsAsRaw[name]) {
        arrayOptions = { ...options, raw: true };
      }
      if (!globalUTFValidation) {
        arrayOptions = {
          ...arrayOptions,
          validation: { utf8: shouldValidateKey },
        };
      }
      value = deserializeObject(buffer, _index, arrayOptions, true);
      index = index + objectSize;
      if (buffer[index - 1] !== 0)
        throw new BSONError("invalid array terminator byte");
      if (index !== stopIndex) throw new BSONError("corrupted array bson");
    } else if (elementType === BSON_DATA_UNDEFINED) {
      value = undefined;
    } else if (elementType === BSON_DATA_NULL) {
      value = null;
    } else if (elementType === BSON_DATA_LONG) {
      const dataview = BSONDataView.fromUint8Array(
        buffer.subarray(index, index + 8),
      );
      const lowBits =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      const highBits =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      const long = new Long$1(lowBits, highBits);
      if (useBigInt64) {
        value = dataview.getBigInt64(0, true);
      } else if (promoteLongs && promoteValues === true) {
        value =
          long.lessThanOrEqual(JS_INT_MAX_LONG) &&
          long.greaterThanOrEqual(JS_INT_MIN_LONG)
            ? long.toNumber()
            : long;
      } else {
        value = long;
      }
    } else if (elementType === BSON_DATA_DECIMAL128) {
      const bytes = ByteUtils.allocate(16);
      bytes.set(buffer.subarray(index, index + 16), 0);
      index = index + 16;
      value = new Decimal128$1(bytes);
    } else if (elementType === BSON_DATA_BINARY) {
      let binarySize =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      const totalBinarySize = binarySize;
      const subType = buffer[index++];
      if (binarySize < 0)
        throw new BSONError("Negative binary type element size found");
      if (binarySize > buffer.byteLength)
        throw new BSONError("Binary type size larger than document size");
      if (buffer["slice"] != null) {
        if (subType === Binary$1.SUBTYPE_BYTE_ARRAY) {
          binarySize =
            buffer[index++] |
            (buffer[index++] << 8) |
            (buffer[index++] << 16) |
            (buffer[index++] << 24);
          if (binarySize < 0)
            throw new BSONError(
              "Negative binary type element size found for subtype 0x02",
            );
          if (binarySize > totalBinarySize - 4)
            throw new BSONError(
              "Binary type with subtype 0x02 contains too long binary size",
            );
          if (binarySize < totalBinarySize - 4)
            throw new BSONError(
              "Binary type with subtype 0x02 contains too short binary size",
            );
        }
        if (promoteBuffers && promoteValues) {
          value = ByteUtils.toLocalBufferType(
            buffer.slice(index, index + binarySize),
          );
        } else {
          value = new Binary$1(
            buffer.slice(index, index + binarySize),
            subType,
          );
          if (
            subType === BSON_BINARY_SUBTYPE_UUID_NEW &&
            UUID$1.isValid(value)
          ) {
            value = value.toUUID();
          }
        }
      } else {
        const _buffer = ByteUtils.allocate(binarySize);
        if (subType === Binary$1.SUBTYPE_BYTE_ARRAY) {
          binarySize =
            buffer[index++] |
            (buffer[index++] << 8) |
            (buffer[index++] << 16) |
            (buffer[index++] << 24);
          if (binarySize < 0)
            throw new BSONError(
              "Negative binary type element size found for subtype 0x02",
            );
          if (binarySize > totalBinarySize - 4)
            throw new BSONError(
              "Binary type with subtype 0x02 contains too long binary size",
            );
          if (binarySize < totalBinarySize - 4)
            throw new BSONError(
              "Binary type with subtype 0x02 contains too short binary size",
            );
        }
        for (i = 0; i < binarySize; i++) {
          _buffer[i] = buffer[index + i];
        }
        if (promoteBuffers && promoteValues) {
          value = _buffer;
        } else {
          value = new Binary$1(
            buffer.slice(index, index + binarySize),
            subType,
          );
          if (
            subType === BSON_BINARY_SUBTYPE_UUID_NEW &&
            UUID$1.isValid(value)
          ) {
            value = value.toUUID();
          }
        }
      }
      index = index + binarySize;
    } else if (elementType === BSON_DATA_REGEXP && bsonRegExp === false) {
      i = index;
      while (buffer[i] !== 0x00 && i < buffer.length) {
        i++;
      }
      if (i >= buffer.length)
        throw new BSONError("Bad BSON Document: illegal CString");
      const source = ByteUtils.toUTF8(buffer, index, i);
      index = i + 1;
      i = index;
      while (buffer[i] !== 0x00 && i < buffer.length) {
        i++;
      }
      if (i >= buffer.length)
        throw new BSONError("Bad BSON Document: illegal CString");
      const regExpOptions = ByteUtils.toUTF8(buffer, index, i);
      index = i + 1;
      const optionsArray = new Array(regExpOptions.length);
      for (i = 0; i < regExpOptions.length; i++) {
        switch (regExpOptions[i]) {
          case "m":
            optionsArray[i] = "m";
            break;
          case "s":
            optionsArray[i] = "g";
            break;
          case "i":
            optionsArray[i] = "i";
            break;
        }
      }
      value = new RegExp(source, optionsArray.join(""));
    } else if (elementType === BSON_DATA_REGEXP && bsonRegExp === true) {
      i = index;
      while (buffer[i] !== 0x00 && i < buffer.length) {
        i++;
      }
      if (i >= buffer.length)
        throw new BSONError("Bad BSON Document: illegal CString");
      const source = ByteUtils.toUTF8(buffer, index, i);
      index = i + 1;
      i = index;
      while (buffer[i] !== 0x00 && i < buffer.length) {
        i++;
      }
      if (i >= buffer.length)
        throw new BSONError("Bad BSON Document: illegal CString");
      const regExpOptions = ByteUtils.toUTF8(buffer, index, i);
      index = i + 1;
      value = new BSONRegExp$1(source, regExpOptions);
    } else if (elementType === BSON_DATA_SYMBOL) {
      const stringSize =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      if (
        stringSize <= 0 ||
        stringSize > buffer.length - index ||
        buffer[index + stringSize - 1] !== 0
      ) {
        throw new BSONError("bad string length in bson");
      }
      const symbol = getValidatedString(
        buffer,
        index,
        index + stringSize - 1,
        shouldValidateKey,
      );
      value = promoteValues ? symbol : new BSONSymbol$1(symbol);
      index = index + stringSize;
    } else if (elementType === BSON_DATA_TIMESTAMP) {
      const i =
        buffer[index++] +
        buffer[index++] * (1 << 8) +
        buffer[index++] * (1 << 16) +
        buffer[index++] * (1 << 24);
      const t =
        buffer[index++] +
        buffer[index++] * (1 << 8) +
        buffer[index++] * (1 << 16) +
        buffer[index++] * (1 << 24);
      value = new Timestamp$1({ i, t });
    } else if (elementType === BSON_DATA_MIN_KEY) {
      value = new MinKey$1();
    } else if (elementType === BSON_DATA_MAX_KEY) {
      value = new MaxKey$1();
    } else if (elementType === BSON_DATA_CODE) {
      const stringSize =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      if (
        stringSize <= 0 ||
        stringSize > buffer.length - index ||
        buffer[index + stringSize - 1] !== 0
      ) {
        throw new BSONError("bad string length in bson");
      }
      const functionString = getValidatedString(
        buffer,
        index,
        index + stringSize - 1,
        shouldValidateKey,
      );
      value = new Code$1(functionString);
      index = index + stringSize;
    } else if (elementType === BSON_DATA_CODE_W_SCOPE) {
      const totalSize =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      if (totalSize < 4 + 4 + 4 + 1) {
        throw new BSONError(
          "code_w_scope total size shorter minimum expected length",
        );
      }
      const stringSize =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      if (
        stringSize <= 0 ||
        stringSize > buffer.length - index ||
        buffer[index + stringSize - 1] !== 0
      ) {
        throw new BSONError("bad string length in bson");
      }
      const functionString = getValidatedString(
        buffer,
        index,
        index + stringSize - 1,
        shouldValidateKey,
      );
      index = index + stringSize;
      const _index = index;
      const objectSize =
        buffer[index] |
        (buffer[index + 1] << 8) |
        (buffer[index + 2] << 16) |
        (buffer[index + 3] << 24);
      const scopeObject = deserializeObject(buffer, _index, options, false);
      index = index + objectSize;
      if (totalSize < 4 + 4 + objectSize + stringSize) {
        throw new BSONError(
          "code_w_scope total size is too short, truncating scope",
        );
      }
      if (totalSize > 4 + 4 + objectSize + stringSize) {
        throw new BSONError(
          "code_w_scope total size is too long, clips outer document",
        );
      }
      value = new Code$1(functionString, scopeObject);
    } else if (elementType === BSON_DATA_DBPOINTER) {
      const stringSize =
        buffer[index++] |
        (buffer[index++] << 8) |
        (buffer[index++] << 16) |
        (buffer[index++] << 24);
      if (
        stringSize <= 0 ||
        stringSize > buffer.length - index ||
        buffer[index + stringSize - 1] !== 0
      )
        throw new BSONError("bad string length in bson");
      if (validation != null && validation.utf8) {
        if (!validateUtf8(buffer, index, index + stringSize - 1)) {
          throw new BSONError("Invalid UTF-8 string in BSON document");
        }
      }
      const namespace = ByteUtils.toUTF8(buffer, index, index + stringSize - 1);
      index = index + stringSize;
      const oidBuffer = ByteUtils.allocate(12);
      oidBuffer.set(buffer.subarray(index, index + 12), 0);
      const oid = new ObjectId$1(oidBuffer);
      index = index + 12;
      value = new DBRef$1(namespace, oid);
    } else {
      throw new BSONError(
        `Detected unknown BSON type ${elementType.toString(
          16,
        )} for fieldname "${name}"`,
      );
    }
    if (name === "__proto__") {
      Object.defineProperty(object, name, {
        value,
        writable: true,
        enumerable: true,
        configurable: true,
      });
    } else {
      object[name] = value;
    }
  }
  if (size !== index - startIndex) {
    if (isArray) throw new BSONError("corrupt array bson");
    throw new BSONError("corrupt object bson");
  }
  if (!isPossibleDBRef) return object;
  if (isDBRefLike(object)) {
    const copy = Object.assign({}, object);
    delete copy.$ref;
    delete copy.$id;
    delete copy.$db;
    return new DBRef$1(object.$ref, object.$id, object.$db, copy);
  }
  return object;
}
function getValidatedString(buffer, start, end, shouldValidateUtf8) {
  const value = ByteUtils.toUTF8(buffer, start, end);
  if (shouldValidateUtf8) {
    for (let i = 0; i < value.length; i++) {
      if (value.charCodeAt(i) === 0xfffd) {
        if (!validateUtf8(buffer, start, end)) {
          throw new BSONError("Invalid UTF-8 string in BSON document");
        }
        break;
      }
    }
  }
  return value;
}

const regexp = /\x00/;
const ignoreKeys = new Set(["$db", "$ref", "$id", "$clusterTime"]);
function serializeString(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_STRING;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes + 1;
  buffer[index - 1] = 0;
  const size = ByteUtils.encodeUTF8Into(buffer, value, index + 4);
  buffer[index + 3] = ((size + 1) >> 24) & 0xff;
  buffer[index + 2] = ((size + 1) >> 16) & 0xff;
  buffer[index + 1] = ((size + 1) >> 8) & 0xff;
  buffer[index] = (size + 1) & 0xff;
  index = index + 4 + size;
  buffer[index++] = 0;
  return index;
}
const NUMBER_SPACE = new DataView(new ArrayBuffer(8), 0, 8);
const FOUR_BYTE_VIEW_ON_NUMBER = new Uint8Array(NUMBER_SPACE.buffer, 0, 4);
const EIGHT_BYTE_VIEW_ON_NUMBER = new Uint8Array(NUMBER_SPACE.buffer, 0, 8);
function serializeNumber(buffer, key, value, index) {
  const isNegativeZero = Object.is(value, -0);
  const type =
    !isNegativeZero &&
    Number.isSafeInteger(value) &&
    value <= BSON_INT32_MAX &&
    value >= BSON_INT32_MIN
      ? BSON_DATA_INT
      : BSON_DATA_NUMBER;
  if (type === BSON_DATA_INT) {
    NUMBER_SPACE.setInt32(0, value, true);
  } else {
    NUMBER_SPACE.setFloat64(0, value, true);
  }
  const bytes =
    type === BSON_DATA_INT
      ? FOUR_BYTE_VIEW_ON_NUMBER
      : EIGHT_BYTE_VIEW_ON_NUMBER;
  buffer[index++] = type;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0x00;
  buffer.set(bytes, index);
  index += bytes.byteLength;
  return index;
}
function serializeBigInt(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_LONG;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index += numberOfWrittenBytes;
  buffer[index++] = 0;
  NUMBER_SPACE.setBigInt64(0, value, true);
  buffer.set(EIGHT_BYTE_VIEW_ON_NUMBER, index);
  index += EIGHT_BYTE_VIEW_ON_NUMBER.byteLength;
  return index;
}
function serializeNull(buffer, key, _, index) {
  buffer[index++] = BSON_DATA_NULL;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  return index;
}
function serializeBoolean(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_BOOLEAN;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  buffer[index++] = value ? 1 : 0;
  return index;
}
function serializeDate(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_DATE;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  const dateInMilis = Long$1.fromNumber(value.getTime());
  const lowBits = dateInMilis.getLowBits();
  const highBits = dateInMilis.getHighBits();
  buffer[index++] = lowBits & 0xff;
  buffer[index++] = (lowBits >> 8) & 0xff;
  buffer[index++] = (lowBits >> 16) & 0xff;
  buffer[index++] = (lowBits >> 24) & 0xff;
  buffer[index++] = highBits & 0xff;
  buffer[index++] = (highBits >> 8) & 0xff;
  buffer[index++] = (highBits >> 16) & 0xff;
  buffer[index++] = (highBits >> 24) & 0xff;
  return index;
}
function serializeRegExp(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_REGEXP;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  if (value.source && value.source.match(regexp) != null) {
    throw new BSONError(
      "value " + value.source + " must not contain null bytes",
    );
  }
  index = index + ByteUtils.encodeUTF8Into(buffer, value.source, index);
  buffer[index++] = 0x00;
  if (value.ignoreCase) buffer[index++] = 0x69;
  if (value.global) buffer[index++] = 0x73;
  if (value.multiline) buffer[index++] = 0x6d;
  buffer[index++] = 0x00;
  return index;
}
function serializeBSONRegExp(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_REGEXP;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  if (value.pattern.match(regexp) != null) {
    throw new BSONError(
      "pattern " + value.pattern + " must not contain null bytes",
    );
  }
  index = index + ByteUtils.encodeUTF8Into(buffer, value.pattern, index);
  buffer[index++] = 0x00;
  const sortedOptions = value.options.split("").sort().join("");
  index = index + ByteUtils.encodeUTF8Into(buffer, sortedOptions, index);
  buffer[index++] = 0x00;
  return index;
}
function serializeMinMax(buffer, key, value, index) {
  if (value === null) {
    buffer[index++] = BSON_DATA_NULL;
  } else if (value._bsontype === "MinKey") {
    buffer[index++] = BSON_DATA_MIN_KEY;
  } else {
    buffer[index++] = BSON_DATA_MAX_KEY;
  }
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  return index;
}
function serializeObjectId(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_OID;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  const idValue = value.id;
  if (isUint8Array(idValue)) {
    for (let i = 0; i < 12; i++) {
      buffer[index++] = idValue[i];
    }
  } else {
    throw new BSONError(
      "object [" + JSON.stringify(value) + "] is not a valid ObjectId",
    );
  }
  return index;
}
function serializeBuffer(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_BINARY;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  const size = value.length;
  buffer[index++] = size & 0xff;
  buffer[index++] = (size >> 8) & 0xff;
  buffer[index++] = (size >> 16) & 0xff;
  buffer[index++] = (size >> 24) & 0xff;
  buffer[index++] = BSON_BINARY_SUBTYPE_DEFAULT;
  buffer.set(value, index);
  index = index + size;
  return index;
}
function serializeObject(
  buffer,
  key,
  value,
  index,
  checkKeys,
  depth,
  serializeFunctions,
  ignoreUndefined,
  path,
) {
  if (path.has(value)) {
    throw new BSONError("Cannot convert circular structure to BSON");
  }
  path.add(value);
  buffer[index++] = Array.isArray(value) ? BSON_DATA_ARRAY : BSON_DATA_OBJECT;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  const endIndex = serializeInto(
    buffer,
    value,
    checkKeys,
    index,
    depth + 1,
    serializeFunctions,
    ignoreUndefined,
    path,
  );
  path.delete(value);
  return endIndex;
}
function serializeDecimal128(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_DECIMAL128;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  buffer.set(value.bytes.subarray(0, 16), index);
  return index + 16;
}
function serializeLong(buffer, key, value, index) {
  buffer[index++] =
    value._bsontype === "Long" ? BSON_DATA_LONG : BSON_DATA_TIMESTAMP;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  const lowBits = value.getLowBits();
  const highBits = value.getHighBits();
  buffer[index++] = lowBits & 0xff;
  buffer[index++] = (lowBits >> 8) & 0xff;
  buffer[index++] = (lowBits >> 16) & 0xff;
  buffer[index++] = (lowBits >> 24) & 0xff;
  buffer[index++] = highBits & 0xff;
  buffer[index++] = (highBits >> 8) & 0xff;
  buffer[index++] = (highBits >> 16) & 0xff;
  buffer[index++] = (highBits >> 24) & 0xff;
  return index;
}
function serializeInt32(buffer, key, value, index) {
  value = value.valueOf();
  buffer[index++] = BSON_DATA_INT;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  buffer[index++] = value & 0xff;
  buffer[index++] = (value >> 8) & 0xff;
  buffer[index++] = (value >> 16) & 0xff;
  buffer[index++] = (value >> 24) & 0xff;
  return index;
}
function serializeDouble(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_NUMBER;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  NUMBER_SPACE.setFloat64(0, value.value, true);
  buffer.set(EIGHT_BYTE_VIEW_ON_NUMBER, index);
  index = index + 8;
  return index;
}
function serializeFunction(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_CODE;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  const functionString = value.toString();
  const size = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;
  buffer[index] = size & 0xff;
  buffer[index + 1] = (size >> 8) & 0xff;
  buffer[index + 2] = (size >> 16) & 0xff;
  buffer[index + 3] = (size >> 24) & 0xff;
  index = index + 4 + size - 1;
  buffer[index++] = 0;
  return index;
}
function serializeCode(
  buffer,
  key,
  value,
  index,
  checkKeys = false,
  depth = 0,
  serializeFunctions = false,
  ignoreUndefined = true,
  path,
) {
  if (value.scope && typeof value.scope === "object") {
    buffer[index++] = BSON_DATA_CODE_W_SCOPE;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    let startIndex = index;
    const functionString = value.code;
    index = index + 4;
    const codeSize =
      ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;
    buffer[index] = codeSize & 0xff;
    buffer[index + 1] = (codeSize >> 8) & 0xff;
    buffer[index + 2] = (codeSize >> 16) & 0xff;
    buffer[index + 3] = (codeSize >> 24) & 0xff;
    buffer[index + 4 + codeSize - 1] = 0;
    index = index + codeSize + 4;
    const endIndex = serializeInto(
      buffer,
      value.scope,
      checkKeys,
      index,
      depth + 1,
      serializeFunctions,
      ignoreUndefined,
      path,
    );
    index = endIndex - 1;
    const totalSize = endIndex - startIndex;
    buffer[startIndex++] = totalSize & 0xff;
    buffer[startIndex++] = (totalSize >> 8) & 0xff;
    buffer[startIndex++] = (totalSize >> 16) & 0xff;
    buffer[startIndex++] = (totalSize >> 24) & 0xff;
    buffer[index++] = 0;
  } else {
    buffer[index++] = BSON_DATA_CODE;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    const functionString = value.code.toString();
    const size =
      ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;
    buffer[index] = size & 0xff;
    buffer[index + 1] = (size >> 8) & 0xff;
    buffer[index + 2] = (size >> 16) & 0xff;
    buffer[index + 3] = (size >> 24) & 0xff;
    index = index + 4 + size - 1;
    buffer[index++] = 0;
  }
  return index;
}
function serializeBinary(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_BINARY;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  const data = value.buffer;
  let size = value.position;
  if (value.sub_type === Binary$1.SUBTYPE_BYTE_ARRAY) size = size + 4;
  buffer[index++] = size & 0xff;
  buffer[index++] = (size >> 8) & 0xff;
  buffer[index++] = (size >> 16) & 0xff;
  buffer[index++] = (size >> 24) & 0xff;
  buffer[index++] = value.sub_type;
  if (value.sub_type === Binary$1.SUBTYPE_BYTE_ARRAY) {
    size = size - 4;
    buffer[index++] = size & 0xff;
    buffer[index++] = (size >> 8) & 0xff;
    buffer[index++] = (size >> 16) & 0xff;
    buffer[index++] = (size >> 24) & 0xff;
  }
  buffer.set(data, index);
  index = index + value.position;
  return index;
}
function serializeSymbol(buffer, key, value, index) {
  buffer[index++] = BSON_DATA_SYMBOL;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  const size = ByteUtils.encodeUTF8Into(buffer, value.value, index + 4) + 1;
  buffer[index] = size & 0xff;
  buffer[index + 1] = (size >> 8) & 0xff;
  buffer[index + 2] = (size >> 16) & 0xff;
  buffer[index + 3] = (size >> 24) & 0xff;
  index = index + 4 + size - 1;
  buffer[index++] = 0x00;
  return index;
}
function serializeDBRef(
  buffer,
  key,
  value,
  index,
  depth,
  serializeFunctions,
  path,
) {
  buffer[index++] = BSON_DATA_OBJECT;
  const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
  index = index + numberOfWrittenBytes;
  buffer[index++] = 0;
  let startIndex = index;
  let output = {
    $ref: value.collection || value.namespace,
    $id: value.oid,
  };
  if (value.db != null) {
    output.$db = value.db;
  }
  output = Object.assign(output, value.fields);
  const endIndex = serializeInto(
    buffer,
    output,
    false,
    index,
    depth + 1,
    serializeFunctions,
    true,
    path,
  );
  const size = endIndex - startIndex;
  buffer[startIndex++] = size & 0xff;
  buffer[startIndex++] = (size >> 8) & 0xff;
  buffer[startIndex++] = (size >> 16) & 0xff;
  buffer[startIndex++] = (size >> 24) & 0xff;
  return endIndex;
}
function serializeInto(
  buffer,
  object,
  checkKeys,
  startingIndex,
  depth,
  serializeFunctions,
  ignoreUndefined,
  path,
) {
  if (path == null) {
    if (object == null) {
      buffer[0] = 0x05;
      buffer[1] = 0x00;
      buffer[2] = 0x00;
      buffer[3] = 0x00;
      buffer[4] = 0x00;
      return 5;
    }
    if (Array.isArray(object)) {
      throw new BSONError(
        "serialize does not support an array as the root input",
      );
    }
    if (typeof object !== "object") {
      throw new BSONError(
        "serialize does not support non-object as the root input",
      );
    } else if ("_bsontype" in object && typeof object._bsontype === "string") {
      throw new BSONError(`BSON types cannot be serialized as a document`);
    } else if (
      isDate(object) ||
      isRegExp(object) ||
      isUint8Array(object) ||
      isAnyArrayBuffer(object)
    ) {
      throw new BSONError(
        `date, regexp, typedarray, and arraybuffer cannot be BSON documents`,
      );
    }
    path = new Set();
  }
  path.add(object);
  let index = startingIndex + 4;
  if (Array.isArray(object)) {
    for (let i = 0; i < object.length; i++) {
      const key = `${i}`;
      let value = object[i];
      if (typeof value?.toBSON === "function") {
        value = value.toBSON();
      }
      if (typeof value === "string") {
        index = serializeString(buffer, key, value, index);
      } else if (typeof value === "number") {
        index = serializeNumber(buffer, key, value, index);
      } else if (typeof value === "bigint") {
        index = serializeBigInt(buffer, key, value, index);
      } else if (typeof value === "boolean") {
        index = serializeBoolean(buffer, key, value, index);
      } else if (value instanceof Date || isDate(value)) {
        index = serializeDate(buffer, key, value, index);
      } else if (value === undefined) {
        index = serializeNull(buffer, key, value, index);
      } else if (value === null) {
        index = serializeNull(buffer, key, value, index);
      } else if (isUint8Array(value)) {
        index = serializeBuffer(buffer, key, value, index);
      } else if (value instanceof RegExp || isRegExp(value)) {
        index = serializeRegExp(buffer, key, value, index);
      } else if (typeof value === "object" && value._bsontype == null) {
        index = serializeObject(
          buffer,
          key,
          value,
          index,
          checkKeys,
          depth,
          serializeFunctions,
          ignoreUndefined,
          path,
        );
      } else if (
        typeof value === "object" &&
        value[Symbol.for("@@mdb.bson.version")] !== BSON_MAJOR_VERSION
      ) {
        throw new BSONVersionError();
      } else if (value._bsontype === "ObjectId") {
        index = serializeObjectId(buffer, key, value, index);
      } else if (value._bsontype === "Decimal128") {
        index = serializeDecimal128(buffer, key, value, index);
      } else if (
        value._bsontype === "Long" ||
        value._bsontype === "Timestamp"
      ) {
        index = serializeLong(buffer, key, value, index);
      } else if (value._bsontype === "Double") {
        index = serializeDouble(buffer, key, value, index);
      } else if (typeof value === "function" && serializeFunctions) {
        index = serializeFunction(buffer, key, value, index);
      } else if (value._bsontype === "Code") {
        index = serializeCode(
          buffer,
          key,
          value,
          index,
          checkKeys,
          depth,
          serializeFunctions,
          ignoreUndefined,
          path,
        );
      } else if (value._bsontype === "Binary") {
        index = serializeBinary(buffer, key, value, index);
      } else if (value._bsontype === "BSONSymbol") {
        index = serializeSymbol(buffer, key, value, index);
      } else if (value._bsontype === "DBRef") {
        index = serializeDBRef(
          buffer,
          key,
          value,
          index,
          depth,
          serializeFunctions,
          path,
        );
      } else if (value._bsontype === "BSONRegExp") {
        index = serializeBSONRegExp(buffer, key, value, index);
      } else if (value._bsontype === "Int32") {
        index = serializeInt32(buffer, key, value, index);
      } else if (value._bsontype === "MinKey" || value._bsontype === "MaxKey") {
        index = serializeMinMax(buffer, key, value, index);
      } else if (typeof value._bsontype !== "undefined") {
        throw new BSONError(
          `Unrecognized or invalid _bsontype: ${String(value._bsontype)}`,
        );
      }
    }
  } else if (object instanceof Map || isMap$1(object)) {
    const iterator = object.entries();
    let done = false;
    while (!done) {
      const entry = iterator.next();
      done = !!entry.done;
      if (done) continue;
      const key = entry.value[0];
      let value = entry.value[1];
      if (typeof value?.toBSON === "function") {
        value = value.toBSON();
      }
      const type = typeof value;
      if (typeof key === "string" && !ignoreKeys.has(key)) {
        if (key.match(regexp) != null) {
          throw new BSONError("key " + key + " must not contain null bytes");
        }
        if (checkKeys) {
          if ("$" === key[0]) {
            throw new BSONError("key " + key + " must not start with '$'");
          } else if (~key.indexOf(".")) {
            throw new BSONError("key " + key + " must not contain '.'");
          }
        }
      }
      if (type === "string") {
        index = serializeString(buffer, key, value, index);
      } else if (type === "number") {
        index = serializeNumber(buffer, key, value, index);
      } else if (type === "bigint") {
        index = serializeBigInt(buffer, key, value, index);
      } else if (type === "boolean") {
        index = serializeBoolean(buffer, key, value, index);
      } else if (value instanceof Date || isDate(value)) {
        index = serializeDate(buffer, key, value, index);
      } else if (
        value === null ||
        (value === undefined && ignoreUndefined === false)
      ) {
        index = serializeNull(buffer, key, value, index);
      } else if (isUint8Array(value)) {
        index = serializeBuffer(buffer, key, value, index);
      } else if (value instanceof RegExp || isRegExp(value)) {
        index = serializeRegExp(buffer, key, value, index);
      } else if (type === "object" && value._bsontype == null) {
        index = serializeObject(
          buffer,
          key,
          value,
          index,
          checkKeys,
          depth,
          serializeFunctions,
          ignoreUndefined,
          path,
        );
      } else if (
        typeof value === "object" &&
        value[Symbol.for("@@mdb.bson.version")] !== BSON_MAJOR_VERSION
      ) {
        throw new BSONVersionError();
      } else if (value._bsontype === "ObjectId") {
        index = serializeObjectId(buffer, key, value, index);
      } else if (type === "object" && value._bsontype === "Decimal128") {
        index = serializeDecimal128(buffer, key, value, index);
      } else if (
        value._bsontype === "Long" ||
        value._bsontype === "Timestamp"
      ) {
        index = serializeLong(buffer, key, value, index);
      } else if (value._bsontype === "Double") {
        index = serializeDouble(buffer, key, value, index);
      } else if (value._bsontype === "Code") {
        index = serializeCode(
          buffer,
          key,
          value,
          index,
          checkKeys,
          depth,
          serializeFunctions,
          ignoreUndefined,
          path,
        );
      } else if (typeof value === "function" && serializeFunctions) {
        index = serializeFunction(buffer, key, value, index);
      } else if (value._bsontype === "Binary") {
        index = serializeBinary(buffer, key, value, index);
      } else if (value._bsontype === "BSONSymbol") {
        index = serializeSymbol(buffer, key, value, index);
      } else if (value._bsontype === "DBRef") {
        index = serializeDBRef(
          buffer,
          key,
          value,
          index,
          depth,
          serializeFunctions,
          path,
        );
      } else if (value._bsontype === "BSONRegExp") {
        index = serializeBSONRegExp(buffer, key, value, index);
      } else if (value._bsontype === "Int32") {
        index = serializeInt32(buffer, key, value, index);
      } else if (value._bsontype === "MinKey" || value._bsontype === "MaxKey") {
        index = serializeMinMax(buffer, key, value, index);
      } else if (typeof value._bsontype !== "undefined") {
        throw new BSONError(
          `Unrecognized or invalid _bsontype: ${String(value._bsontype)}`,
        );
      }
    }
  } else {
    if (typeof object?.toBSON === "function") {
      object = object.toBSON();
      if (object != null && typeof object !== "object") {
        throw new BSONError("toBSON function did not return an object");
      }
    }
    for (const key of Object.keys(object)) {
      let value = object[key];
      if (typeof value?.toBSON === "function") {
        value = value.toBSON();
      }
      const type = typeof value;
      if (typeof key === "string" && !ignoreKeys.has(key)) {
        if (key.match(regexp) != null) {
          throw new BSONError("key " + key + " must not contain null bytes");
        }
        if (checkKeys) {
          if ("$" === key[0]) {
            throw new BSONError("key " + key + " must not start with '$'");
          } else if (~key.indexOf(".")) {
            throw new BSONError("key " + key + " must not contain '.'");
          }
        }
      }
      if (type === "string") {
        index = serializeString(buffer, key, value, index);
      } else if (type === "number") {
        index = serializeNumber(buffer, key, value, index);
      } else if (type === "bigint") {
        index = serializeBigInt(buffer, key, value, index);
      } else if (type === "boolean") {
        index = serializeBoolean(buffer, key, value, index);
      } else if (value instanceof Date || isDate(value)) {
        index = serializeDate(buffer, key, value, index);
      } else if (value === undefined) {
        if (ignoreUndefined === false)
          index = serializeNull(buffer, key, value, index);
      } else if (value === null) {
        index = serializeNull(buffer, key, value, index);
      } else if (isUint8Array(value)) {
        index = serializeBuffer(buffer, key, value, index);
      } else if (value instanceof RegExp || isRegExp(value)) {
        index = serializeRegExp(buffer, key, value, index);
      } else if (type === "object" && value._bsontype == null) {
        index = serializeObject(
          buffer,
          key,
          value,
          index,
          checkKeys,
          depth,
          serializeFunctions,
          ignoreUndefined,
          path,
        );
      } else if (
        typeof value === "object" &&
        value[Symbol.for("@@mdb.bson.version")] !== BSON_MAJOR_VERSION
      ) {
        throw new BSONVersionError();
      } else if (value._bsontype === "ObjectId") {
        index = serializeObjectId(buffer, key, value, index);
      } else if (type === "object" && value._bsontype === "Decimal128") {
        index = serializeDecimal128(buffer, key, value, index);
      } else if (
        value._bsontype === "Long" ||
        value._bsontype === "Timestamp"
      ) {
        index = serializeLong(buffer, key, value, index);
      } else if (value._bsontype === "Double") {
        index = serializeDouble(buffer, key, value, index);
      } else if (value._bsontype === "Code") {
        index = serializeCode(
          buffer,
          key,
          value,
          index,
          checkKeys,
          depth,
          serializeFunctions,
          ignoreUndefined,
          path,
        );
      } else if (typeof value === "function" && serializeFunctions) {
        index = serializeFunction(buffer, key, value, index);
      } else if (value._bsontype === "Binary") {
        index = serializeBinary(buffer, key, value, index);
      } else if (value._bsontype === "BSONSymbol") {
        index = serializeSymbol(buffer, key, value, index);
      } else if (value._bsontype === "DBRef") {
        index = serializeDBRef(
          buffer,
          key,
          value,
          index,
          depth,
          serializeFunctions,
          path,
        );
      } else if (value._bsontype === "BSONRegExp") {
        index = serializeBSONRegExp(buffer, key, value, index);
      } else if (value._bsontype === "Int32") {
        index = serializeInt32(buffer, key, value, index);
      } else if (value._bsontype === "MinKey" || value._bsontype === "MaxKey") {
        index = serializeMinMax(buffer, key, value, index);
      } else if (typeof value._bsontype !== "undefined") {
        throw new BSONError(
          `Unrecognized or invalid _bsontype: ${String(value._bsontype)}`,
        );
      }
    }
  }
  path.delete(object);
  buffer[index++] = 0x00;
  const size = index - startingIndex;
  buffer[startingIndex++] = size & 0xff;
  buffer[startingIndex++] = (size >> 8) & 0xff;
  buffer[startingIndex++] = (size >> 16) & 0xff;
  buffer[startingIndex++] = (size >> 24) & 0xff;
  return index;
}

function isBSONType(value) {
  return (
    value != null &&
    typeof value === "object" &&
    "_bsontype" in value &&
    typeof value._bsontype === "string"
  );
}
const keysToCodecs = {
  $oid: ObjectId$1,
  $binary: Binary$1,
  $uuid: Binary$1,
  $symbol: BSONSymbol$1,
  $numberInt: Int32$1,
  $numberDecimal: Decimal128$1,
  $numberDouble: Double$1,
  $numberLong: Long$1,
  $minKey: MinKey$1,
  $maxKey: MaxKey$1,
  $regex: BSONRegExp$1,
  $regularExpression: BSONRegExp$1,
  $timestamp: Timestamp$1,
};
function deserializeValue(value, options = {}) {
  if (typeof value === "number") {
    const in32BitRange = value <= BSON_INT32_MAX && value >= BSON_INT32_MIN;
    const in64BitRange = value <= BSON_INT64_MAX && value >= BSON_INT64_MIN;
    if (options.relaxed || options.legacy) {
      return value;
    }
    if (Number.isInteger(value) && !Object.is(value, -0)) {
      if (in32BitRange) {
        return new Int32$1(value);
      }
      if (in64BitRange) {
        if (options.useBigInt64) {
          return BigInt(value);
        }
        return Long$1.fromNumber(value);
      }
    }
    return new Double$1(value);
  }
  if (value == null || typeof value !== "object") return value;
  if (value.$undefined) return null;
  const keys = Object.keys(value).filter(
    (k) => k.startsWith("$") && value[k] != null,
  );
  for (let i = 0; i < keys.length; i++) {
    const c = keysToCodecs[keys[i]];
    if (c) return c.fromExtendedJSON(value, options);
  }
  if (value.$date != null) {
    const d = value.$date;
    const date = new Date();
    if (options.legacy) {
      if (typeof d === "number") date.setTime(d);
      else if (typeof d === "string") date.setTime(Date.parse(d));
      else if (typeof d === "bigint") date.setTime(Number(d));
      else
        throw new BSONRuntimeError(
          `Unrecognized type for EJSON date: ${typeof d}`,
        );
    } else {
      if (typeof d === "string") date.setTime(Date.parse(d));
      else if (Long$1.isLong(d)) date.setTime(d.toNumber());
      else if (typeof d === "number" && options.relaxed) date.setTime(d);
      else if (typeof d === "bigint") date.setTime(Number(d));
      else
        throw new BSONRuntimeError(
          `Unrecognized type for EJSON date: ${typeof d}`,
        );
    }
    return date;
  }
  if (value.$code != null) {
    const copy = Object.assign({}, value);
    if (value.$scope) {
      copy.$scope = deserializeValue(value.$scope);
    }
    return Code$1.fromExtendedJSON(value);
  }
  if (isDBRefLike(value) || value.$dbPointer) {
    const v = value.$ref ? value : value.$dbPointer;
    if (v instanceof DBRef$1) return v;
    const dollarKeys = Object.keys(v).filter((k) => k.startsWith("$"));
    let valid = true;
    dollarKeys.forEach((k) => {
      if (["$ref", "$id", "$db"].indexOf(k) === -1) valid = false;
    });
    if (valid) return DBRef$1.fromExtendedJSON(v);
  }
  return value;
}
function serializeArray(array, options) {
  return array.map((v, index) => {
    options.seenObjects.push({ propertyName: `index ${index}`, obj: null });
    try {
      return serializeValue(v, options);
    } finally {
      options.seenObjects.pop();
    }
  });
}
function getISOString(date) {
  const isoStr = date.toISOString();
  return date.getUTCMilliseconds() !== 0 ? isoStr : isoStr.slice(0, -5) + "Z";
}
function serializeValue(value, options) {
  if (value instanceof Map || isMap$1(value)) {
    const obj = Object.create(null);
    for (const [k, v] of value) {
      if (typeof k !== "string") {
        throw new BSONError("Can only serialize maps with string keys");
      }
      obj[k] = v;
    }
    return serializeValue(obj, options);
  }
  if (
    (typeof value === "object" || typeof value === "function") &&
    value !== null
  ) {
    const index = options.seenObjects.findIndex((entry) => entry.obj === value);
    if (index !== -1) {
      const props = options.seenObjects.map((entry) => entry.propertyName);
      const leadingPart = props
        .slice(0, index)
        .map((prop) => `${prop} -> `)
        .join("");
      const alreadySeen = props[index];
      const circularPart =
        " -> " +
        props
          .slice(index + 1, props.length - 1)
          .map((prop) => `${prop} -> `)
          .join("");
      const current = props[props.length - 1];
      const leadingSpace = " ".repeat(
        leadingPart.length + alreadySeen.length / 2,
      );
      const dashes = "-".repeat(
        circularPart.length + (alreadySeen.length + current.length) / 2 - 1,
      );
      throw new BSONError(
        "Converting circular structure to EJSON:\n" +
          `    ${leadingPart}${alreadySeen}${circularPart}${current}\n` +
          `    ${leadingSpace}\\${dashes}/`,
      );
    }
    options.seenObjects[options.seenObjects.length - 1].obj = value;
  }
  if (Array.isArray(value)) return serializeArray(value, options);
  if (value === undefined) return null;
  if (value instanceof Date || isDate(value)) {
    const dateNum = value.getTime(),
      inRange = dateNum > -1 && dateNum < 253402318800000;
    if (options.legacy) {
      return options.relaxed && inRange
        ? { $date: value.getTime() }
        : { $date: getISOString(value) };
    }
    return options.relaxed && inRange
      ? { $date: getISOString(value) }
      : { $date: { $numberLong: value.getTime().toString() } };
  }
  if (typeof value === "number" && (!options.relaxed || !isFinite(value))) {
    if (Number.isInteger(value) && !Object.is(value, -0)) {
      if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {
        return { $numberInt: value.toString() };
      }
      if (value >= BSON_INT64_MIN && value <= BSON_INT64_MAX) {
        return { $numberLong: value.toString() };
      }
    }
    return { $numberDouble: Object.is(value, -0) ? "-0.0" : value.toString() };
  }
  if (typeof value === "bigint") {
    if (!options.relaxed) {
      return { $numberLong: BigInt.asIntN(64, value).toString() };
    }
    return Number(BigInt.asIntN(64, value));
  }
  if (value instanceof RegExp || isRegExp(value)) {
    let flags = value.flags;
    if (flags === undefined) {
      const match = value.toString().match(/[gimuy]*$/);
      if (match) {
        flags = match[0];
      }
    }
    const rx = new BSONRegExp$1(value.source, flags);
    return rx.toExtendedJSON(options);
  }
  if (value != null && typeof value === "object")
    return serializeDocument(value, options);
  return value;
}
const BSON_TYPE_MAPPINGS = {
  Binary: (o) => new Binary$1(o.value(), o.sub_type),
  Code: (o) => new Code$1(o.code, o.scope),
  DBRef: (o) => new DBRef$1(o.collection || o.namespace, o.oid, o.db, o.fields),
  Decimal128: (o) => new Decimal128$1(o.bytes),
  Double: (o) => new Double$1(o.value),
  Int32: (o) => new Int32$1(o.value),
  Long: (o) =>
    Long$1.fromBits(
      o.low != null ? o.low : o.low_,
      o.low != null ? o.high : o.high_,
      o.low != null ? o.unsigned : o.unsigned_,
    ),
  MaxKey: () => new MaxKey$1(),
  MinKey: () => new MinKey$1(),
  ObjectId: (o) => new ObjectId$1(o),
  BSONRegExp: (o) => new BSONRegExp$1(o.pattern, o.options),
  BSONSymbol: (o) => new BSONSymbol$1(o.value),
  Timestamp: (o) => Timestamp$1.fromBits(o.low, o.high),
};
function serializeDocument(doc, options) {
  if (doc == null || typeof doc !== "object")
    throw new BSONError("not an object instance");
  const bsontype = doc._bsontype;
  if (typeof bsontype === "undefined") {
    const _doc = {};
    for (const name of Object.keys(doc)) {
      options.seenObjects.push({ propertyName: name, obj: null });
      try {
        const value = serializeValue(doc[name], options);
        if (name === "__proto__") {
          Object.defineProperty(_doc, name, {
            value,
            writable: true,
            enumerable: true,
            configurable: true,
          });
        } else {
          _doc[name] = value;
        }
      } finally {
        options.seenObjects.pop();
      }
    }
    return _doc;
  } else if (
    doc != null &&
    typeof doc === "object" &&
    typeof doc._bsontype === "string" &&
    doc[Symbol.for("@@mdb.bson.version")] !== BSON_MAJOR_VERSION
  ) {
    throw new BSONVersionError();
  } else if (isBSONType(doc)) {
    let outDoc = doc;
    if (typeof outDoc.toExtendedJSON !== "function") {
      const mapper = BSON_TYPE_MAPPINGS[doc._bsontype];
      if (!mapper) {
        throw new BSONError(
          "Unrecognized or invalid _bsontype: " + doc._bsontype,
        );
      }
      outDoc = mapper(outDoc);
    }
    if (bsontype === "Code" && outDoc.scope) {
      outDoc = new Code$1(outDoc.code, serializeValue(outDoc.scope, options));
    } else if (bsontype === "DBRef" && outDoc.oid) {
      outDoc = new DBRef$1(
        serializeValue(outDoc.collection, options),
        serializeValue(outDoc.oid, options),
        serializeValue(outDoc.db, options),
        serializeValue(outDoc.fields, options),
      );
    }
    return outDoc.toExtendedJSON(options);
  } else {
    throw new BSONError(
      "_bsontype must be a string, but was: " + typeof bsontype,
    );
  }
}
function parse(text, options) {
  const ejsonOptions = {
    useBigInt64: options?.useBigInt64 ?? false,
    relaxed: options?.relaxed ?? true,
    legacy: options?.legacy ?? false,
  };
  return JSON.parse(text, (key, value) => {
    if (key.indexOf("\x00") !== -1) {
      throw new BSONError(
        `BSON Document field names cannot contain null bytes, found: ${JSON.stringify(
          key,
        )}`,
      );
    }
    return deserializeValue(value, ejsonOptions);
  });
}
function stringify(value, replacer, space, options) {
  if (space != null && typeof space === "object") {
    options = space;
    space = 0;
  }
  if (
    replacer != null &&
    typeof replacer === "object" &&
    !Array.isArray(replacer)
  ) {
    options = replacer;
    replacer = undefined;
    space = 0;
  }
  const serializeOptions = Object.assign(
    { relaxed: true, legacy: false },
    options,
    {
      seenObjects: [{ propertyName: "(root)", obj: null }],
    },
  );
  const doc = serializeValue(value, serializeOptions);
  return JSON.stringify(doc, replacer, space);
}
function EJSONserialize(value, options) {
  options = options || {};
  return JSON.parse(stringify(value, options));
}
function EJSONdeserialize(ejson, options) {
  options = options || {};
  return parse(JSON.stringify(ejson), options);
}
const EJSON = Object.create(null);
EJSON.parse = parse;
EJSON.stringify = stringify;
EJSON.serialize = EJSONserialize;
EJSON.deserialize = EJSONdeserialize;
Object.freeze(EJSON);

const MAXSIZE = 1024 * 1024 * 17;
let buffer = ByteUtils.allocate(MAXSIZE);
function setInternalBufferSize(size) {
  if (buffer.length < size) {
    buffer = ByteUtils.allocate(size);
  }
}
function serialize(object, options = {}) {
  const checkKeys =
    typeof options.checkKeys === "boolean" ? options.checkKeys : false;
  const serializeFunctions =
    typeof options.serializeFunctions === "boolean"
      ? options.serializeFunctions
      : false;
  const ignoreUndefined =
    typeof options.ignoreUndefined === "boolean"
      ? options.ignoreUndefined
      : true;
  const minInternalBufferSize =
    typeof options.minInternalBufferSize === "number"
      ? options.minInternalBufferSize
      : MAXSIZE;
  if (buffer.length < minInternalBufferSize) {
    buffer = ByteUtils.allocate(minInternalBufferSize);
  }
  const serializationIndex = serializeInto(
    buffer,
    object,
    checkKeys,
    0,
    0,
    serializeFunctions,
    ignoreUndefined,
    null,
  );
  const finishedBuffer = ByteUtils.allocate(serializationIndex);
  finishedBuffer.set(buffer.subarray(0, serializationIndex), 0);
  return finishedBuffer;
}
function serializeWithBufferAndIndex(object, finalBuffer, options = {}) {
  const checkKeys =
    typeof options.checkKeys === "boolean" ? options.checkKeys : false;
  const serializeFunctions =
    typeof options.serializeFunctions === "boolean"
      ? options.serializeFunctions
      : false;
  const ignoreUndefined =
    typeof options.ignoreUndefined === "boolean"
      ? options.ignoreUndefined
      : true;
  const startIndex = typeof options.index === "number" ? options.index : 0;
  const serializationIndex = serializeInto(
    buffer,
    object,
    checkKeys,
    0,
    0,
    serializeFunctions,
    ignoreUndefined,
    null,
  );
  finalBuffer.set(buffer.subarray(0, serializationIndex), startIndex);
  return startIndex + serializationIndex - 1;
}
function deserialize(buffer, options = {}) {
  return internalDeserialize(ByteUtils.toLocalBufferType(buffer), options);
}
function calculateObjectSize(object, options = {}) {
  options = options || {};
  const serializeFunctions =
    typeof options.serializeFunctions === "boolean"
      ? options.serializeFunctions
      : false;
  const ignoreUndefined =
    typeof options.ignoreUndefined === "boolean"
      ? options.ignoreUndefined
      : true;
  return internalCalculateObjectSize(
    object,
    serializeFunctions,
    ignoreUndefined,
  );
}
function deserializeStream(
  data,
  startIndex,
  numberOfDocuments,
  documents,
  docStartIndex,
  options,
) {
  const internalOptions = Object.assign(
    { allowObjectSmallerThanBufferSize: true, index: 0 },
    options,
  );
  const bufferData = ByteUtils.toLocalBufferType(data);
  let index = startIndex;
  for (let i = 0; i < numberOfDocuments; i++) {
    const size =
      bufferData[index] |
      (bufferData[index + 1] << 8) |
      (bufferData[index + 2] << 16) |
      (bufferData[index + 3] << 24);
    internalOptions.index = index;
    documents[docStartIndex + i] = internalDeserialize(
      bufferData,
      internalOptions,
    );
    index = index + size;
  }
  return index;
}

var bson = /*#__PURE__*/ Object.freeze({
  __proto__: null,
  BSONError: BSONError,
  BSONRegExp: BSONRegExp$1,
  BSONRuntimeError: BSONRuntimeError,
  BSONSymbol: BSONSymbol$1,
  BSONType: BSONType$1,
  BSONValue: BSONValue,
  BSONVersionError: BSONVersionError,
  Binary: Binary$1,
  Code: Code$1,
  DBRef: DBRef$1,
  Decimal128: Decimal128$1,
  Double: Double$1,
  EJSON: EJSON,
  Int32: Int32$1,
  Long: Long$1,
  MaxKey: MaxKey$1,
  MinKey: MinKey$1,
  ObjectId: ObjectId$1,
  Timestamp: Timestamp$1,
  UUID: UUID$1,
  calculateObjectSize: calculateObjectSize,
  deserialize: deserialize,
  deserializeStream: deserializeStream,
  serialize: serialize,
  serializeWithBufferAndIndex: serializeWithBufferAndIndex,
  setInternalBufferSize: setInternalBufferSize,
});

bson$1.BSON = bson;
bson$1.BSONError = BSONError;
bson$1.BSONRegExp = BSONRegExp$1;
bson$1.BSONRuntimeError = BSONRuntimeError;
bson$1.BSONSymbol = BSONSymbol$1;
bson$1.BSONType = BSONType$1;
bson$1.BSONValue = BSONValue;
bson$1.BSONVersionError = BSONVersionError;
bson$1.Binary = Binary$1;
bson$1.Code = Code$1;
bson$1.DBRef = DBRef$1;
bson$1.Decimal128 = Decimal128$1;
bson$1.Double = Double$1;
bson$1.EJSON = EJSON;
bson$1.Int32 = Int32$1;
bson$1.Long = Long$1;
bson$1.MaxKey = MaxKey$1;
bson$1.MinKey = MinKey$1;
bson$1.ObjectId = ObjectId$1;
bson$1.Timestamp = Timestamp$1;
bson$1.UUID = UUID$1;
bson$1.calculateObjectSize = calculateObjectSize;
bson$1.deserialize = deserialize;
bson$1.deserializeStream = deserializeStream;
bson$1.serialize = serialize;
bson$1.serializeWithBufferAndIndex = serializeWithBufferAndIndex;
bson$1.setInternalBufferSize = setInternalBufferSize;

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.resolveBSONOptions =
    exports.pluckBSONSerializeOptions =
    exports.UUID =
    exports.Timestamp =
    exports.serialize =
    exports.ObjectId =
    exports.MinKey =
    exports.MaxKey =
    exports.Long =
    exports.Int32 =
    exports.Double =
    exports.deserialize =
    exports.Decimal128 =
    exports.DBRef =
    exports.Code =
    exports.calculateObjectSize =
    exports.BSONType =
    exports.BSONSymbol =
    exports.BSONRegExp =
    exports.BSON =
    exports.Binary =
      void 0;
  var bson_1 = bson$1;
  Object.defineProperty(exports, "Binary", {
    enumerable: true,
    get: function () {
      return bson_1.Binary;
    },
  });
  Object.defineProperty(exports, "BSON", {
    enumerable: true,
    get: function () {
      return bson_1.BSON;
    },
  });
  Object.defineProperty(exports, "BSONRegExp", {
    enumerable: true,
    get: function () {
      return bson_1.BSONRegExp;
    },
  });
  Object.defineProperty(exports, "BSONSymbol", {
    enumerable: true,
    get: function () {
      return bson_1.BSONSymbol;
    },
  });
  Object.defineProperty(exports, "BSONType", {
    enumerable: true,
    get: function () {
      return bson_1.BSONType;
    },
  });
  Object.defineProperty(exports, "calculateObjectSize", {
    enumerable: true,
    get: function () {
      return bson_1.calculateObjectSize;
    },
  });
  Object.defineProperty(exports, "Code", {
    enumerable: true,
    get: function () {
      return bson_1.Code;
    },
  });
  Object.defineProperty(exports, "DBRef", {
    enumerable: true,
    get: function () {
      return bson_1.DBRef;
    },
  });
  Object.defineProperty(exports, "Decimal128", {
    enumerable: true,
    get: function () {
      return bson_1.Decimal128;
    },
  });
  Object.defineProperty(exports, "deserialize", {
    enumerable: true,
    get: function () {
      return bson_1.deserialize;
    },
  });
  Object.defineProperty(exports, "Double", {
    enumerable: true,
    get: function () {
      return bson_1.Double;
    },
  });
  Object.defineProperty(exports, "Int32", {
    enumerable: true,
    get: function () {
      return bson_1.Int32;
    },
  });
  Object.defineProperty(exports, "Long", {
    enumerable: true,
    get: function () {
      return bson_1.Long;
    },
  });
  Object.defineProperty(exports, "MaxKey", {
    enumerable: true,
    get: function () {
      return bson_1.MaxKey;
    },
  });
  Object.defineProperty(exports, "MinKey", {
    enumerable: true,
    get: function () {
      return bson_1.MinKey;
    },
  });
  Object.defineProperty(exports, "ObjectId", {
    enumerable: true,
    get: function () {
      return bson_1.ObjectId;
    },
  });
  Object.defineProperty(exports, "serialize", {
    enumerable: true,
    get: function () {
      return bson_1.serialize;
    },
  });
  Object.defineProperty(exports, "Timestamp", {
    enumerable: true,
    get: function () {
      return bson_1.Timestamp;
    },
  });
  Object.defineProperty(exports, "UUID", {
    enumerable: true,
    get: function () {
      return bson_1.UUID;
    },
  });
  function pluckBSONSerializeOptions(options) {
    const {
      fieldsAsRaw,
      useBigInt64,
      promoteValues,
      promoteBuffers,
      promoteLongs,
      serializeFunctions,
      ignoreUndefined,
      bsonRegExp,
      raw,
      enableUtf8Validation,
    } = options;
    return {
      fieldsAsRaw,
      useBigInt64,
      promoteValues,
      promoteBuffers,
      promoteLongs,
      serializeFunctions,
      ignoreUndefined,
      bsonRegExp,
      raw,
      enableUtf8Validation,
    };
  }
  exports.pluckBSONSerializeOptions = pluckBSONSerializeOptions;
  /**
   * Merge the given BSONSerializeOptions, preferring options over the parent's options, and
   * substituting defaults for values not set.
   *
   * @internal
   */
  function resolveBSONOptions(options, parent) {
    const parentOptions = parent?.bsonOptions;
    return {
      raw: options?.raw ?? parentOptions?.raw ?? false,
      useBigInt64: options?.useBigInt64 ?? parentOptions?.useBigInt64 ?? false,
      promoteLongs:
        options?.promoteLongs ?? parentOptions?.promoteLongs ?? true,
      promoteValues:
        options?.promoteValues ?? parentOptions?.promoteValues ?? true,
      promoteBuffers:
        options?.promoteBuffers ?? parentOptions?.promoteBuffers ?? false,
      ignoreUndefined:
        options?.ignoreUndefined ?? parentOptions?.ignoreUndefined ?? false,
      bsonRegExp: options?.bsonRegExp ?? parentOptions?.bsonRegExp ?? false,
      serializeFunctions:
        options?.serializeFunctions ??
        parentOptions?.serializeFunctions ??
        false,
      fieldsAsRaw: options?.fieldsAsRaw ?? parentOptions?.fieldsAsRaw ?? {},
      enableUtf8Validation:
        options?.enableUtf8Validation ??
        parentOptions?.enableUtf8Validation ??
        true,
    };
  }
  exports.resolveBSONOptions = resolveBSONOptions;
})(bson$2);

var execute_operation = {};

var error = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.isResumableError =
    exports.isNetworkTimeoutError =
    exports.isSDAMUnrecoverableError =
    exports.isNodeShuttingDownError =
    exports.isRetryableReadError =
    exports.isRetryableWriteError =
    exports.needsRetryableWriteLabel =
    exports.MongoWriteConcernError =
    exports.MongoServerSelectionError =
    exports.MongoSystemError =
    exports.MongoMissingDependencyError =
    exports.MongoMissingCredentialsError =
    exports.MongoCompatibilityError =
    exports.MongoInvalidArgumentError =
    exports.MongoParseError =
    exports.MongoNetworkTimeoutError =
    exports.MongoNetworkError =
    exports.isNetworkErrorBeforeHandshake =
    exports.MongoTopologyClosedError =
    exports.MongoCursorExhaustedError =
    exports.MongoServerClosedError =
    exports.MongoCursorInUseError =
    exports.MongoUnexpectedServerResponseError =
    exports.MongoGridFSChunkError =
    exports.MongoGridFSStreamError =
    exports.MongoTailableCursorError =
    exports.MongoChangeStreamError =
    exports.MongoAzureError =
    exports.MongoAWSError =
    exports.MongoKerberosError =
    exports.MongoExpiredSessionError =
    exports.MongoTransactionError =
    exports.MongoNotConnectedError =
    exports.MongoDecompressionError =
    exports.MongoBatchReExecutionError =
    exports.MongoRuntimeError =
    exports.MongoAPIError =
    exports.MongoDriverError =
    exports.MongoServerError =
    exports.MongoError =
    exports.MongoErrorLabel =
    exports.GET_MORE_RESUMABLE_CODES =
    exports.MONGODB_ERROR_CODES =
    exports.NODE_IS_RECOVERING_ERROR_MESSAGE =
    exports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE =
    exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE =
      void 0;
  /** @internal */
  const kErrorLabels = Symbol("errorLabels");
  /**
   * @internal
   * The legacy error message from the server that indicates the node is not a writable primary
   * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering
   */
  exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE = new RegExp(
    "not master",
    "i",
  );
  /**
   * @internal
   * The legacy error message from the server that indicates the node is not a primary or secondary
   * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering
   */
  exports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE = new RegExp(
    "not master or secondary",
    "i",
  );
  /**
   * @internal
   * The error message from the server that indicates the node is recovering
   * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering
   */
  exports.NODE_IS_RECOVERING_ERROR_MESSAGE = new RegExp(
    "node is recovering",
    "i",
  );
  /** @internal MongoDB Error Codes */
  exports.MONGODB_ERROR_CODES = Object.freeze({
    HostUnreachable: 6,
    HostNotFound: 7,
    NetworkTimeout: 89,
    ShutdownInProgress: 91,
    PrimarySteppedDown: 189,
    ExceededTimeLimit: 262,
    SocketException: 9001,
    NotWritablePrimary: 10107,
    InterruptedAtShutdown: 11600,
    InterruptedDueToReplStateChange: 11602,
    NotPrimaryNoSecondaryOk: 13435,
    NotPrimaryOrSecondary: 13436,
    StaleShardVersion: 63,
    StaleEpoch: 150,
    StaleConfig: 13388,
    RetryChangeStream: 234,
    FailedToSatisfyReadPreference: 133,
    CursorNotFound: 43,
    LegacyNotPrimary: 10058,
    WriteConcernFailed: 64,
    NamespaceNotFound: 26,
    IllegalOperation: 20,
    MaxTimeMSExpired: 50,
    UnknownReplWriteConcern: 79,
    UnsatisfiableWriteConcern: 100,
    Reauthenticate: 391,
  });
  // From spec@https://github.com/mongodb/specifications/blob/f93d78191f3db2898a59013a7ed5650352ef6da8/source/change-streams/change-streams.rst#resumable-error
  exports.GET_MORE_RESUMABLE_CODES = new Set([
    exports.MONGODB_ERROR_CODES.HostUnreachable,
    exports.MONGODB_ERROR_CODES.HostNotFound,
    exports.MONGODB_ERROR_CODES.NetworkTimeout,
    exports.MONGODB_ERROR_CODES.ShutdownInProgress,
    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,
    exports.MONGODB_ERROR_CODES.ExceededTimeLimit,
    exports.MONGODB_ERROR_CODES.SocketException,
    exports.MONGODB_ERROR_CODES.NotWritablePrimary,
    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,
    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,
    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,
    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary,
    exports.MONGODB_ERROR_CODES.StaleShardVersion,
    exports.MONGODB_ERROR_CODES.StaleEpoch,
    exports.MONGODB_ERROR_CODES.StaleConfig,
    exports.MONGODB_ERROR_CODES.RetryChangeStream,
    exports.MONGODB_ERROR_CODES.FailedToSatisfyReadPreference,
    exports.MONGODB_ERROR_CODES.CursorNotFound,
  ]);
  /** @public */
  exports.MongoErrorLabel = Object.freeze({
    RetryableWriteError: "RetryableWriteError",
    TransientTransactionError: "TransientTransactionError",
    UnknownTransactionCommitResult: "UnknownTransactionCommitResult",
    ResumableChangeStreamError: "ResumableChangeStreamError",
    HandshakeError: "HandshakeError",
    ResetPool: "ResetPool",
    InterruptInUseConnections: "InterruptInUseConnections",
    NoWritesPerformed: "NoWritesPerformed",
  });
  function isAggregateError(e) {
    return "errors" in e && Array.isArray(e.errors);
  }
  /**
   * @public
   * @category Error
   *
   * @privateRemarks
   * mongodb-client-encryption has a dependency on this error, it uses the constructor with a string argument
   */
  class MongoError extends Error {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, options) {
      super(message, options);
      this[kErrorLabels] = new Set();
    }
    /** @internal */
    static buildErrorMessage(e) {
      if (typeof e === "string") {
        return e;
      }
      if (isAggregateError(e) && e.message.length === 0) {
        return e.errors.length === 0
          ? "AggregateError has an empty errors array. Please check the `cause` property for more information."
          : e.errors.map(({ message }) => message).join(", ");
      }
      return e.message;
    }
    get name() {
      return "MongoError";
    }
    /** Legacy name for server error responses */
    get errmsg() {
      return this.message;
    }
    /**
     * Checks the error to see if it has an error label
     *
     * @param label - The error label to check for
     * @returns returns true if the error has the provided error label
     */
    hasErrorLabel(label) {
      return this[kErrorLabels].has(label);
    }
    addErrorLabel(label) {
      this[kErrorLabels].add(label);
    }
    get errorLabels() {
      return Array.from(this[kErrorLabels]);
    }
  }
  exports.MongoError = MongoError;
  /**
   * An error coming from the mongo server
   *
   * @public
   * @category Error
   */
  class MongoServerError extends MongoError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message.message || message.errmsg || message.$err || "n/a");
      if (message.errorLabels) {
        this[kErrorLabels] = new Set(message.errorLabels);
      }
      for (const name in message) {
        if (name !== "errorLabels" && name !== "errmsg" && name !== "message")
          this[name] = message[name];
      }
    }
    get name() {
      return "MongoServerError";
    }
  }
  exports.MongoServerError = MongoServerError;
  /**
   * An error generated by the driver
   *
   * @public
   * @category Error
   */
  class MongoDriverError extends MongoError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, options) {
      super(message, options);
    }
    get name() {
      return "MongoDriverError";
    }
  }
  exports.MongoDriverError = MongoDriverError;
  /**
   * An error generated when the driver API is used incorrectly
   *
   * @privateRemarks
   * Should **never** be directly instantiated
   *
   * @public
   * @category Error
   */
  class MongoAPIError extends MongoDriverError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, options) {
      super(message, options);
    }
    get name() {
      return "MongoAPIError";
    }
  }
  exports.MongoAPIError = MongoAPIError;
  /**
   * An error generated when the driver encounters unexpected input
   * or reaches an unexpected/invalid internal state
   *
   * @privateRemarks
   * Should **never** be directly instantiated.
   *
   * @public
   * @category Error
   */
  class MongoRuntimeError extends MongoDriverError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, options) {
      super(message, options);
    }
    get name() {
      return "MongoRuntimeError";
    }
  }
  exports.MongoRuntimeError = MongoRuntimeError;
  /**
   * An error generated when a batch command is re-executed after one of the commands in the batch
   * has failed
   *
   * @public
   * @category Error
   */
  class MongoBatchReExecutionError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(
      message = "This batch has already been executed, create new batch to execute",
    ) {
      super(message);
    }
    get name() {
      return "MongoBatchReExecutionError";
    }
  }
  exports.MongoBatchReExecutionError = MongoBatchReExecutionError;
  /**
   * An error generated when the driver fails to decompress
   * data received from the server.
   *
   * @public
   * @category Error
   */
  class MongoDecompressionError extends MongoRuntimeError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoDecompressionError";
    }
  }
  exports.MongoDecompressionError = MongoDecompressionError;
  /**
   * An error thrown when the user attempts to operate on a database or collection through a MongoClient
   * that has not yet successfully called the "connect" method
   *
   * @public
   * @category Error
   */
  class MongoNotConnectedError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoNotConnectedError";
    }
  }
  exports.MongoNotConnectedError = MongoNotConnectedError;
  /**
   * An error generated when the user makes a mistake in the usage of transactions.
   * (e.g. attempting to commit a transaction with a readPreference other than primary)
   *
   * @public
   * @category Error
   */
  class MongoTransactionError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoTransactionError";
    }
  }
  exports.MongoTransactionError = MongoTransactionError;
  /**
   * An error generated when the user attempts to operate
   * on a session that has expired or has been closed.
   *
   * @public
   * @category Error
   */
  class MongoExpiredSessionError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message = "Cannot use a session that has ended") {
      super(message);
    }
    get name() {
      return "MongoExpiredSessionError";
    }
  }
  exports.MongoExpiredSessionError = MongoExpiredSessionError;
  /**
   * A error generated when the user attempts to authenticate
   * via Kerberos, but fails to connect to the Kerberos client.
   *
   * @public
   * @category Error
   */
  class MongoKerberosError extends MongoRuntimeError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoKerberosError";
    }
  }
  exports.MongoKerberosError = MongoKerberosError;
  /**
   * A error generated when the user attempts to authenticate
   * via AWS, but fails
   *
   * @public
   * @category Error
   */
  class MongoAWSError extends MongoRuntimeError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoAWSError";
    }
  }
  exports.MongoAWSError = MongoAWSError;
  /**
   * A error generated when the user attempts to authenticate
   * via Azure, but fails.
   *
   * @public
   * @category Error
   */
  class MongoAzureError extends MongoRuntimeError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoAzureError";
    }
  }
  exports.MongoAzureError = MongoAzureError;
  /**
   * An error generated when a ChangeStream operation fails to execute.
   *
   * @public
   * @category Error
   */
  class MongoChangeStreamError extends MongoRuntimeError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoChangeStreamError";
    }
  }
  exports.MongoChangeStreamError = MongoChangeStreamError;
  /**
   * An error thrown when the user calls a function or method not supported on a tailable cursor
   *
   * @public
   * @category Error
   */
  class MongoTailableCursorError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message = "Tailable cursor does not support this operation") {
      super(message);
    }
    get name() {
      return "MongoTailableCursorError";
    }
  }
  exports.MongoTailableCursorError = MongoTailableCursorError;
  /** An error generated when a GridFSStream operation fails to execute.
   *
   * @public
   * @category Error
   */
  class MongoGridFSStreamError extends MongoRuntimeError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoGridFSStreamError";
    }
  }
  exports.MongoGridFSStreamError = MongoGridFSStreamError;
  /**
   * An error generated when a malformed or invalid chunk is
   * encountered when reading from a GridFSStream.
   *
   * @public
   * @category Error
   */
  class MongoGridFSChunkError extends MongoRuntimeError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoGridFSChunkError";
    }
  }
  exports.MongoGridFSChunkError = MongoGridFSChunkError;
  /**
   * An error generated when a **parsable** unexpected response comes from the server.
   * This is generally an error where the driver in a state expecting a certain behavior to occur in
   * the next message from MongoDB but it receives something else.
   * This error **does not** represent an issue with wire message formatting.
   *
   * #### Example
   * When an operation fails, it is the driver's job to retry it. It must perform serverSelection
   * again to make sure that it attempts the operation against a server in a good state. If server
   * selection returns a server that does not support retryable operations, this error is used.
   * This scenario is unlikely as retryable support would also have been determined on the first attempt
   * but it is possible the state change could report a selectable server that does not support retries.
   *
   * @public
   * @category Error
   */
  class MongoUnexpectedServerResponseError extends MongoRuntimeError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoUnexpectedServerResponseError";
    }
  }
  exports.MongoUnexpectedServerResponseError =
    MongoUnexpectedServerResponseError;
  /**
   * An error thrown when the user attempts to add options to a cursor that has already been
   * initialized
   *
   * @public
   * @category Error
   */
  class MongoCursorInUseError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message = "Cursor is already initialized") {
      super(message);
    }
    get name() {
      return "MongoCursorInUseError";
    }
  }
  exports.MongoCursorInUseError = MongoCursorInUseError;
  /**
   * An error generated when an attempt is made to operate
   * on a closed/closing server.
   *
   * @public
   * @category Error
   */
  class MongoServerClosedError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message = "Server is closed") {
      super(message);
    }
    get name() {
      return "MongoServerClosedError";
    }
  }
  exports.MongoServerClosedError = MongoServerClosedError;
  /**
   * An error thrown when an attempt is made to read from a cursor that has been exhausted
   *
   * @public
   * @category Error
   */
  class MongoCursorExhaustedError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message || "Cursor is exhausted");
    }
    get name() {
      return "MongoCursorExhaustedError";
    }
  }
  exports.MongoCursorExhaustedError = MongoCursorExhaustedError;
  /**
   * An error generated when an attempt is made to operate on a
   * dropped, or otherwise unavailable, database.
   *
   * @public
   * @category Error
   */
  class MongoTopologyClosedError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message = "Topology is closed") {
      super(message);
    }
    get name() {
      return "MongoTopologyClosedError";
    }
  }
  exports.MongoTopologyClosedError = MongoTopologyClosedError;
  /** @internal */
  const kBeforeHandshake = Symbol("beforeHandshake");
  function isNetworkErrorBeforeHandshake(err) {
    return err[kBeforeHandshake] === true;
  }
  exports.isNetworkErrorBeforeHandshake = isNetworkErrorBeforeHandshake;
  /**
   * An error indicating an issue with the network, including TCP errors and timeouts.
   * @public
   * @category Error
   */
  class MongoNetworkError extends MongoError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, options) {
      super(message, { cause: options?.cause });
      if (options && typeof options.beforeHandshake === "boolean") {
        this[kBeforeHandshake] = options.beforeHandshake;
      }
    }
    get name() {
      return "MongoNetworkError";
    }
  }
  exports.MongoNetworkError = MongoNetworkError;
  /**
   * An error indicating a network timeout occurred
   * @public
   * @category Error
   *
   * @privateRemarks
   * mongodb-client-encryption has a dependency on this error with an instanceof check
   */
  class MongoNetworkTimeoutError extends MongoNetworkError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, options) {
      super(message, options);
    }
    get name() {
      return "MongoNetworkTimeoutError";
    }
  }
  exports.MongoNetworkTimeoutError = MongoNetworkTimeoutError;
  /**
   * An error used when attempting to parse a value (like a connection string)
   * @public
   * @category Error
   */
  class MongoParseError extends MongoDriverError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoParseError";
    }
  }
  exports.MongoParseError = MongoParseError;
  /**
   * An error generated when the user supplies malformed or unexpected arguments
   * or when a required argument or field is not provided.
   *
   *
   * @public
   * @category Error
   */
  class MongoInvalidArgumentError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoInvalidArgumentError";
    }
  }
  exports.MongoInvalidArgumentError = MongoInvalidArgumentError;
  /**
   * An error generated when a feature that is not enabled or allowed for the current server
   * configuration is used
   *
   *
   * @public
   * @category Error
   */
  class MongoCompatibilityError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoCompatibilityError";
    }
  }
  exports.MongoCompatibilityError = MongoCompatibilityError;
  /**
   * An error generated when the user fails to provide authentication credentials before attempting
   * to connect to a mongo server instance.
   *
   *
   * @public
   * @category Error
   */
  class MongoMissingCredentialsError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message) {
      super(message);
    }
    get name() {
      return "MongoMissingCredentialsError";
    }
  }
  exports.MongoMissingCredentialsError = MongoMissingCredentialsError;
  /**
   * An error generated when a required module or dependency is not present in the local environment
   *
   * @public
   * @category Error
   */
  class MongoMissingDependencyError extends MongoAPIError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, options = {}) {
      super(message, options);
    }
    get name() {
      return "MongoMissingDependencyError";
    }
  }
  exports.MongoMissingDependencyError = MongoMissingDependencyError;
  /**
   * An error signifying a general system issue
   * @public
   * @category Error
   */
  class MongoSystemError extends MongoError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, reason) {
      if (reason && reason.error) {
        super(
          MongoError.buildErrorMessage(reason.error.message || reason.error),
          {
            cause: reason.error,
          },
        );
      } else {
        super(message);
      }
      if (reason) {
        this.reason = reason;
      }
      this.code = reason.error?.code;
    }
    get name() {
      return "MongoSystemError";
    }
  }
  exports.MongoSystemError = MongoSystemError;
  /**
   * An error signifying a client-side server selection error
   * @public
   * @category Error
   */
  class MongoServerSelectionError extends MongoSystemError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, reason) {
      super(message, reason);
    }
    get name() {
      return "MongoServerSelectionError";
    }
  }
  exports.MongoServerSelectionError = MongoServerSelectionError;
  function makeWriteConcernResultObject(input) {
    const output = Object.assign({}, input);
    if (output.ok === 0) {
      output.ok = 1;
      delete output.errmsg;
      delete output.code;
      delete output.codeName;
    }
    return output;
  }
  /**
   * An error thrown when the server reports a writeConcernError
   * @public
   * @category Error
   */
  class MongoWriteConcernError extends MongoServerError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(message, result) {
      if (result && Array.isArray(result.errorLabels)) {
        message.errorLabels = result.errorLabels;
      }
      super(message);
      this.errInfo = message.errInfo;
      if (result != null) {
        this.result = makeWriteConcernResultObject(result);
      }
    }
    get name() {
      return "MongoWriteConcernError";
    }
  }
  exports.MongoWriteConcernError = MongoWriteConcernError;
  // https://github.com/mongodb/specifications/blob/master/source/retryable-reads/retryable-reads.rst#retryable-error
  const RETRYABLE_READ_ERROR_CODES = new Set([
    exports.MONGODB_ERROR_CODES.HostUnreachable,
    exports.MONGODB_ERROR_CODES.HostNotFound,
    exports.MONGODB_ERROR_CODES.NetworkTimeout,
    exports.MONGODB_ERROR_CODES.ShutdownInProgress,
    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,
    exports.MONGODB_ERROR_CODES.SocketException,
    exports.MONGODB_ERROR_CODES.NotWritablePrimary,
    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,
    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,
    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,
    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary,
  ]);
  // see: https://github.com/mongodb/specifications/blob/master/source/retryable-writes/retryable-writes.rst#terms
  const RETRYABLE_WRITE_ERROR_CODES = new Set([
    ...RETRYABLE_READ_ERROR_CODES,
    exports.MONGODB_ERROR_CODES.ExceededTimeLimit,
  ]);
  function needsRetryableWriteLabel(error, maxWireVersion) {
    // pre-4.4 server, then the driver adds an error label for every valid case
    // execute operation will only inspect the label, code/message logic is handled here
    if (error instanceof MongoNetworkError) {
      return true;
    }
    if (error instanceof MongoError) {
      if (
        (maxWireVersion >= 9 ||
          error.hasErrorLabel(exports.MongoErrorLabel.RetryableWriteError)) &&
        !error.hasErrorLabel(exports.MongoErrorLabel.HandshakeError)
      ) {
        // If we already have the error label no need to add it again. 4.4+ servers add the label.
        // In the case where we have a handshake error, need to fall down to the logic checking
        // the codes.
        return false;
      }
    }
    if (error instanceof MongoWriteConcernError) {
      return RETRYABLE_WRITE_ERROR_CODES.has(
        error.result?.code ?? error.code ?? 0,
      );
    }
    if (error instanceof MongoError && typeof error.code === "number") {
      return RETRYABLE_WRITE_ERROR_CODES.has(error.code);
    }
    const isNotWritablePrimaryError =
      exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);
    if (isNotWritablePrimaryError) {
      return true;
    }
    const isNodeIsRecoveringError =
      exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);
    if (isNodeIsRecoveringError) {
      return true;
    }
    return false;
  }
  exports.needsRetryableWriteLabel = needsRetryableWriteLabel;
  function isRetryableWriteError(error) {
    return error.hasErrorLabel(exports.MongoErrorLabel.RetryableWriteError);
  }
  exports.isRetryableWriteError = isRetryableWriteError;
  /** Determines whether an error is something the driver should attempt to retry */
  function isRetryableReadError(error) {
    const hasRetryableErrorCode =
      typeof error.code === "number"
        ? RETRYABLE_READ_ERROR_CODES.has(error.code)
        : false;
    if (hasRetryableErrorCode) {
      return true;
    }
    if (error instanceof MongoNetworkError) {
      return true;
    }
    const isNotWritablePrimaryError =
      exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);
    if (isNotWritablePrimaryError) {
      return true;
    }
    const isNodeIsRecoveringError =
      exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);
    if (isNodeIsRecoveringError) {
      return true;
    }
    return false;
  }
  exports.isRetryableReadError = isRetryableReadError;
  const SDAM_RECOVERING_CODES = new Set([
    exports.MONGODB_ERROR_CODES.ShutdownInProgress,
    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,
    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,
    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,
    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary,
  ]);
  const SDAM_NOT_PRIMARY_CODES = new Set([
    exports.MONGODB_ERROR_CODES.NotWritablePrimary,
    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,
    exports.MONGODB_ERROR_CODES.LegacyNotPrimary,
  ]);
  const SDAM_NODE_SHUTTING_DOWN_ERROR_CODES = new Set([
    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,
    exports.MONGODB_ERROR_CODES.ShutdownInProgress,
  ]);
  function isRecoveringError(err) {
    if (typeof err.code === "number") {
      // If any error code exists, we ignore the error.message
      return SDAM_RECOVERING_CODES.has(err.code);
    }
    return (
      exports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE.test(err.message) ||
      exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(err.message)
    );
  }
  function isNotWritablePrimaryError(err) {
    if (typeof err.code === "number") {
      // If any error code exists, we ignore the error.message
      return SDAM_NOT_PRIMARY_CODES.has(err.code);
    }
    if (isRecoveringError(err)) {
      return false;
    }
    return exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(err.message);
  }
  function isNodeShuttingDownError(err) {
    return !!(
      typeof err.code === "number" &&
      SDAM_NODE_SHUTTING_DOWN_ERROR_CODES.has(err.code)
    );
  }
  exports.isNodeShuttingDownError = isNodeShuttingDownError;
  /**
   * Determines whether SDAM can recover from a given error. If it cannot
   * then the pool will be cleared, and server state will completely reset
   * locally.
   *
   * @see https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-master-and-node-is-recovering
   */
  function isSDAMUnrecoverableError(error) {
    // NOTE: null check is here for a strictly pre-CMAP world, a timeout or
    //       close event are considered unrecoverable
    if (error instanceof MongoParseError || error == null) {
      return true;
    }
    return isRecoveringError(error) || isNotWritablePrimaryError(error);
  }
  exports.isSDAMUnrecoverableError = isSDAMUnrecoverableError;
  function isNetworkTimeoutError(err) {
    return !!(
      err instanceof MongoNetworkError && err.message.match(/timed out/)
    );
  }
  exports.isNetworkTimeoutError = isNetworkTimeoutError;
  function isResumableError(error, wireVersion) {
    if (error == null || !(error instanceof MongoError)) {
      return false;
    }
    if (error instanceof MongoNetworkError) {
      return true;
    }
    if (wireVersion != null && wireVersion >= 9) {
      // DRIVERS-1308: For 4.4 drivers running against 4.4 servers, drivers will add a special case to treat the CursorNotFound error code as resumable
      if (error.code === exports.MONGODB_ERROR_CODES.CursorNotFound) {
        return true;
      }
      return error.hasErrorLabel(
        exports.MongoErrorLabel.ResumableChangeStreamError,
      );
    }
    if (typeof error.code === "number") {
      return exports.GET_MORE_RESUMABLE_CODES.has(error.code);
    }
    return false;
  }
  exports.isResumableError = isResumableError;
})(error);

var read_preference = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.ReadPreference = exports.ReadPreferenceMode = void 0;
  const error_1 = error;
  /** @public */
  exports.ReadPreferenceMode = Object.freeze({
    primary: "primary",
    primaryPreferred: "primaryPreferred",
    secondary: "secondary",
    secondaryPreferred: "secondaryPreferred",
    nearest: "nearest",
  });
  /**
   * The **ReadPreference** class is a class that represents a MongoDB ReadPreference and is
   * used to construct connections.
   * @public
   *
   * @see https://www.mongodb.com/docs/manual/core/read-preference/
   */
  class ReadPreference {
    /**
     * @param mode - A string describing the read preference mode (primary|primaryPreferred|secondary|secondaryPreferred|nearest)
     * @param tags - A tag set used to target reads to members with the specified tag(s). tagSet is not available if using read preference mode primary.
     * @param options - Additional read preference options
     */
    constructor(mode, tags, options) {
      if (!ReadPreference.isValid(mode)) {
        throw new error_1.MongoInvalidArgumentError(
          `Invalid read preference mode ${JSON.stringify(mode)}`,
        );
      }
      if (options == null && typeof tags === "object" && !Array.isArray(tags)) {
        options = tags;
        tags = undefined;
      } else if (tags && !Array.isArray(tags)) {
        throw new error_1.MongoInvalidArgumentError(
          "ReadPreference tags must be an array",
        );
      }
      this.mode = mode;
      this.tags = tags;
      this.hedge = options?.hedge;
      this.maxStalenessSeconds = undefined;
      this.minWireVersion = undefined;
      options = options ?? {};
      if (options.maxStalenessSeconds != null) {
        if (options.maxStalenessSeconds <= 0) {
          throw new error_1.MongoInvalidArgumentError(
            "maxStalenessSeconds must be a positive integer",
          );
        }
        this.maxStalenessSeconds = options.maxStalenessSeconds;
        // NOTE: The minimum required wire version is 5 for this read preference. If the existing
        //       topology has a lower value then a MongoError will be thrown during server selection.
        this.minWireVersion = 5;
      }
      if (this.mode === ReadPreference.PRIMARY) {
        if (this.tags && Array.isArray(this.tags) && this.tags.length > 0) {
          throw new error_1.MongoInvalidArgumentError(
            "Primary read preference cannot be combined with tags",
          );
        }
        if (this.maxStalenessSeconds) {
          throw new error_1.MongoInvalidArgumentError(
            "Primary read preference cannot be combined with maxStalenessSeconds",
          );
        }
        if (this.hedge) {
          throw new error_1.MongoInvalidArgumentError(
            "Primary read preference cannot be combined with hedge",
          );
        }
      }
    }
    // Support the deprecated `preference` property introduced in the porcelain layer
    get preference() {
      return this.mode;
    }
    static fromString(mode) {
      return new ReadPreference(mode);
    }
    /**
     * Construct a ReadPreference given an options object.
     *
     * @param options - The options object from which to extract the read preference.
     */
    static fromOptions(options) {
      if (!options) return;
      const readPreference =
        options.readPreference ??
        options.session?.transaction.options.readPreference;
      const readPreferenceTags = options.readPreferenceTags;
      if (readPreference == null) {
        return;
      }
      if (typeof readPreference === "string") {
        return new ReadPreference(readPreference, readPreferenceTags, {
          maxStalenessSeconds: options.maxStalenessSeconds,
          hedge: options.hedge,
        });
      } else if (
        !(readPreference instanceof ReadPreference) &&
        typeof readPreference === "object"
      ) {
        const mode = readPreference.mode || readPreference.preference;
        if (mode && typeof mode === "string") {
          return new ReadPreference(
            mode,
            readPreference.tags ?? readPreferenceTags,
            {
              maxStalenessSeconds: readPreference.maxStalenessSeconds,
              hedge: options.hedge,
            },
          );
        }
      }
      if (readPreferenceTags) {
        readPreference.tags = readPreferenceTags;
      }
      return readPreference;
    }
    /**
     * Replaces options.readPreference with a ReadPreference instance
     */
    static translate(options) {
      if (options.readPreference == null) return options;
      const r = options.readPreference;
      if (typeof r === "string") {
        options.readPreference = new ReadPreference(r);
      } else if (r && !(r instanceof ReadPreference) && typeof r === "object") {
        const mode = r.mode || r.preference;
        if (mode && typeof mode === "string") {
          options.readPreference = new ReadPreference(mode, r.tags, {
            maxStalenessSeconds: r.maxStalenessSeconds,
          });
        }
      } else if (!(r instanceof ReadPreference)) {
        throw new error_1.MongoInvalidArgumentError(
          `Invalid read preference: ${r}`,
        );
      }
      return options;
    }
    /**
     * Validate if a mode is legal
     *
     * @param mode - The string representing the read preference mode.
     */
    static isValid(mode) {
      const VALID_MODES = new Set([
        ReadPreference.PRIMARY,
        ReadPreference.PRIMARY_PREFERRED,
        ReadPreference.SECONDARY,
        ReadPreference.SECONDARY_PREFERRED,
        ReadPreference.NEAREST,
        null,
      ]);
      return VALID_MODES.has(mode);
    }
    /**
     * Validate if a mode is legal
     *
     * @param mode - The string representing the read preference mode.
     */
    isValid(mode) {
      return ReadPreference.isValid(
        typeof mode === "string" ? mode : this.mode,
      );
    }
    /**
     * Indicates that this readPreference needs the "SecondaryOk" bit when sent over the wire
     * @see https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#op-query
     */
    secondaryOk() {
      const NEEDS_SECONDARYOK = new Set([
        ReadPreference.PRIMARY_PREFERRED,
        ReadPreference.SECONDARY,
        ReadPreference.SECONDARY_PREFERRED,
        ReadPreference.NEAREST,
      ]);
      return NEEDS_SECONDARYOK.has(this.mode);
    }
    /**
     * Check if the two ReadPreferences are equivalent
     *
     * @param readPreference - The read preference with which to check equality
     */
    equals(readPreference) {
      return readPreference.mode === this.mode;
    }
    /** Return JSON representation */
    toJSON() {
      const readPreference = { mode: this.mode };
      if (Array.isArray(this.tags)) readPreference.tags = this.tags;
      if (this.maxStalenessSeconds)
        readPreference.maxStalenessSeconds = this.maxStalenessSeconds;
      if (this.hedge) readPreference.hedge = this.hedge;
      return readPreference;
    }
  }
  ReadPreference.PRIMARY = exports.ReadPreferenceMode.primary;
  ReadPreference.PRIMARY_PREFERRED =
    exports.ReadPreferenceMode.primaryPreferred;
  ReadPreference.SECONDARY = exports.ReadPreferenceMode.secondary;
  ReadPreference.SECONDARY_PREFERRED =
    exports.ReadPreferenceMode.secondaryPreferred;
  ReadPreference.NEAREST = exports.ReadPreferenceMode.nearest;
  ReadPreference.primary = new ReadPreference(
    exports.ReadPreferenceMode.primary,
  );
  ReadPreference.primaryPreferred = new ReadPreference(
    exports.ReadPreferenceMode.primaryPreferred,
  );
  ReadPreference.secondary = new ReadPreference(
    exports.ReadPreferenceMode.secondary,
  );
  ReadPreference.secondaryPreferred = new ReadPreference(
    exports.ReadPreferenceMode.secondaryPreferred,
  );
  ReadPreference.nearest = new ReadPreference(
    exports.ReadPreferenceMode.nearest,
  );
  exports.ReadPreference = ReadPreference;
})(read_preference);

var server_selection = {};

var common$1 = {};

Object.defineProperty(common$1, "__esModule", { value: true });
common$1._advanceClusterTime =
  common$1.drainTimerQueue =
  common$1.ServerType =
  common$1.TopologyType =
  common$1.STATE_CONNECTED =
  common$1.STATE_CONNECTING =
  common$1.STATE_CLOSED =
  common$1.STATE_CLOSING =
    void 0;
const timers_1$3 = $nodeTimers;
// shared state names
common$1.STATE_CLOSING = "closing";
common$1.STATE_CLOSED = "closed";
common$1.STATE_CONNECTING = "connecting";
common$1.STATE_CONNECTED = "connected";
/**
 * An enumeration of topology types we know about
 * @public
 */
common$1.TopologyType = Object.freeze({
  Single: "Single",
  ReplicaSetNoPrimary: "ReplicaSetNoPrimary",
  ReplicaSetWithPrimary: "ReplicaSetWithPrimary",
  Sharded: "Sharded",
  Unknown: "Unknown",
  LoadBalanced: "LoadBalanced",
});
/**
 * An enumeration of server types we know about
 * @public
 */
common$1.ServerType = Object.freeze({
  Standalone: "Standalone",
  Mongos: "Mongos",
  PossiblePrimary: "PossiblePrimary",
  RSPrimary: "RSPrimary",
  RSSecondary: "RSSecondary",
  RSArbiter: "RSArbiter",
  RSOther: "RSOther",
  RSGhost: "RSGhost",
  Unknown: "Unknown",
  LoadBalancer: "LoadBalancer",
});
/** @internal */
function drainTimerQueue(queue) {
  queue.forEach(timers_1$3.clearTimeout);
  queue.clear();
}
common$1.drainTimerQueue = drainTimerQueue;
/** Shared function to determine clusterTime for a given topology or session */
function _advanceClusterTime(entity, $clusterTime) {
  if (entity.clusterTime == null) {
    entity.clusterTime = $clusterTime;
  } else {
    if ($clusterTime.clusterTime.greaterThan(entity.clusterTime.clusterTime)) {
      entity.clusterTime = $clusterTime;
    }
  }
}
common$1._advanceClusterTime = _advanceClusterTime;

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.readPreferenceServerSelector =
    exports.secondaryWritableServerSelector =
    exports.sameServerSelector =
    exports.writableServerSelector =
    exports.MIN_SECONDARY_WRITE_WIRE_VERSION =
      void 0;
  const error_1 = error;
  const read_preference_1 = read_preference;
  const common_1 = common$1;
  // max staleness constants
  const IDLE_WRITE_PERIOD = 10000;
  const SMALLEST_MAX_STALENESS_SECONDS = 90;
  //  Minimum version to try writes on secondaries.
  exports.MIN_SECONDARY_WRITE_WIRE_VERSION = 13;
  /**
   * Returns a server selector that selects for writable servers
   */
  function writableServerSelector() {
    return (topologyDescription, servers) =>
      latencyWindowReducer(
        topologyDescription,
        servers.filter((s) => s.isWritable),
      );
  }
  exports.writableServerSelector = writableServerSelector;
  /**
   * The purpose of this selector is to select the same server, only
   * if it is in a state that it can have commands sent to it.
   */
  function sameServerSelector(description) {
    return (topologyDescription, servers) => {
      if (!description) return [];
      // Filter the servers to match the provided description only if
      // the type is not unknown.
      return servers.filter((sd) => {
        return (
          sd.address === description.address &&
          sd.type !== common_1.ServerType.Unknown
        );
      });
    };
  }
  exports.sameServerSelector = sameServerSelector;
  /**
   * Returns a server selector that uses a read preference to select a
   * server potentially for a write on a secondary.
   */
  function secondaryWritableServerSelector(wireVersion, readPreference) {
    // If server version < 5.0, read preference always primary.
    // If server version >= 5.0...
    // - If read preference is supplied, use that.
    // - If no read preference is supplied, use primary.
    if (
      !readPreference ||
      !wireVersion ||
      (wireVersion && wireVersion < exports.MIN_SECONDARY_WRITE_WIRE_VERSION)
    ) {
      return readPreferenceServerSelector(
        read_preference_1.ReadPreference.primary,
      );
    }
    return readPreferenceServerSelector(readPreference);
  }
  exports.secondaryWritableServerSelector = secondaryWritableServerSelector;
  /**
   * Reduces the passed in array of servers by the rules of the "Max Staleness" specification
   * found here: https://github.com/mongodb/specifications/blob/master/source/max-staleness/max-staleness.rst
   *
   * @param readPreference - The read preference providing max staleness guidance
   * @param topologyDescription - The topology description
   * @param servers - The list of server descriptions to be reduced
   * @returns The list of servers that satisfy the requirements of max staleness
   */
  function maxStalenessReducer(readPreference, topologyDescription, servers) {
    if (
      readPreference.maxStalenessSeconds == null ||
      readPreference.maxStalenessSeconds < 0
    ) {
      return servers;
    }
    const maxStaleness = readPreference.maxStalenessSeconds;
    const maxStalenessVariance =
      (topologyDescription.heartbeatFrequencyMS + IDLE_WRITE_PERIOD) / 1000;
    if (maxStaleness < maxStalenessVariance) {
      throw new error_1.MongoInvalidArgumentError(
        `Option "maxStalenessSeconds" must be at least ${maxStalenessVariance} seconds`,
      );
    }
    if (maxStaleness < SMALLEST_MAX_STALENESS_SECONDS) {
      throw new error_1.MongoInvalidArgumentError(
        `Option "maxStalenessSeconds" must be at least ${SMALLEST_MAX_STALENESS_SECONDS} seconds`,
      );
    }
    if (
      topologyDescription.type === common_1.TopologyType.ReplicaSetWithPrimary
    ) {
      const primary = Array.from(topologyDescription.servers.values()).filter(
        primaryFilter,
      )[0];
      return servers.reduce((result, server) => {
        const stalenessMS =
          server.lastUpdateTime -
          server.lastWriteDate -
          (primary.lastUpdateTime - primary.lastWriteDate) +
          topologyDescription.heartbeatFrequencyMS;
        const staleness = stalenessMS / 1000;
        const maxStalenessSeconds = readPreference.maxStalenessSeconds ?? 0;
        if (staleness <= maxStalenessSeconds) {
          result.push(server);
        }
        return result;
      }, []);
    }
    if (
      topologyDescription.type === common_1.TopologyType.ReplicaSetNoPrimary
    ) {
      if (servers.length === 0) {
        return servers;
      }
      const sMax = servers.reduce((max, s) =>
        s.lastWriteDate > max.lastWriteDate ? s : max,
      );
      return servers.reduce((result, server) => {
        const stalenessMS =
          sMax.lastWriteDate -
          server.lastWriteDate +
          topologyDescription.heartbeatFrequencyMS;
        const staleness = stalenessMS / 1000;
        const maxStalenessSeconds = readPreference.maxStalenessSeconds ?? 0;
        if (staleness <= maxStalenessSeconds) {
          result.push(server);
        }
        return result;
      }, []);
    }
    return servers;
  }
  /**
   * Determines whether a server's tags match a given set of tags
   *
   * @param tagSet - The requested tag set to match
   * @param serverTags - The server's tags
   */
  function tagSetMatch(tagSet, serverTags) {
    const keys = Object.keys(tagSet);
    const serverTagKeys = Object.keys(serverTags);
    for (let i = 0; i < keys.length; ++i) {
      const key = keys[i];
      if (
        serverTagKeys.indexOf(key) === -1 ||
        serverTags[key] !== tagSet[key]
      ) {
        return false;
      }
    }
    return true;
  }
  /**
   * Reduces a set of server descriptions based on tags requested by the read preference
   *
   * @param readPreference - The read preference providing the requested tags
   * @param servers - The list of server descriptions to reduce
   * @returns The list of servers matching the requested tags
   */
  function tagSetReducer(readPreference, servers) {
    if (
      readPreference.tags == null ||
      (Array.isArray(readPreference.tags) && readPreference.tags.length === 0)
    ) {
      return servers;
    }
    for (let i = 0; i < readPreference.tags.length; ++i) {
      const tagSet = readPreference.tags[i];
      const serversMatchingTagset = servers.reduce((matched, server) => {
        if (tagSetMatch(tagSet, server.tags)) matched.push(server);
        return matched;
      }, []);
      if (serversMatchingTagset.length) {
        return serversMatchingTagset;
      }
    }
    return [];
  }
  /**
   * Reduces a list of servers to ensure they fall within an acceptable latency window. This is
   * further specified in the "Server Selection" specification, found here:
   * https://github.com/mongodb/specifications/blob/master/source/server-selection/server-selection.rst
   *
   * @param topologyDescription - The topology description
   * @param servers - The list of servers to reduce
   * @returns The servers which fall within an acceptable latency window
   */
  function latencyWindowReducer(topologyDescription, servers) {
    const low = servers.reduce(
      (min, server) =>
        min === -1 ? server.roundTripTime : Math.min(server.roundTripTime, min),
      -1,
    );
    const high = low + topologyDescription.localThresholdMS;
    return servers.reduce((result, server) => {
      if (server.roundTripTime <= high && server.roundTripTime >= low)
        result.push(server);
      return result;
    }, []);
  }
  // filters
  function primaryFilter(server) {
    return server.type === common_1.ServerType.RSPrimary;
  }
  function secondaryFilter(server) {
    return server.type === common_1.ServerType.RSSecondary;
  }
  function nearestFilter(server) {
    return (
      server.type === common_1.ServerType.RSSecondary ||
      server.type === common_1.ServerType.RSPrimary
    );
  }
  function knownFilter(server) {
    return server.type !== common_1.ServerType.Unknown;
  }
  function loadBalancerFilter(server) {
    return server.type === common_1.ServerType.LoadBalancer;
  }
  /**
   * Returns a function which selects servers based on a provided read preference
   *
   * @param readPreference - The read preference to select with
   */
  function readPreferenceServerSelector(readPreference) {
    if (!readPreference.isValid()) {
      throw new error_1.MongoInvalidArgumentError(
        "Invalid read preference specified",
      );
    }
    return (topologyDescription, servers) => {
      const commonWireVersion = topologyDescription.commonWireVersion;
      if (
        commonWireVersion &&
        readPreference.minWireVersion &&
        readPreference.minWireVersion > commonWireVersion
      ) {
        throw new error_1.MongoCompatibilityError(
          `Minimum wire version '${readPreference.minWireVersion}' required, but found '${commonWireVersion}'`,
        );
      }
      if (topologyDescription.type === common_1.TopologyType.LoadBalanced) {
        return servers.filter(loadBalancerFilter);
      }
      if (topologyDescription.type === common_1.TopologyType.Unknown) {
        return [];
      }
      if (
        topologyDescription.type === common_1.TopologyType.Single ||
        topologyDescription.type === common_1.TopologyType.Sharded
      ) {
        return latencyWindowReducer(
          topologyDescription,
          servers.filter(knownFilter),
        );
      }
      const mode = readPreference.mode;
      if (mode === read_preference_1.ReadPreference.PRIMARY) {
        return servers.filter(primaryFilter);
      }
      if (mode === read_preference_1.ReadPreference.PRIMARY_PREFERRED) {
        const result = servers.filter(primaryFilter);
        if (result.length) {
          return result;
        }
      }
      const filter =
        mode === read_preference_1.ReadPreference.NEAREST
          ? nearestFilter
          : secondaryFilter;
      const selectedServers = latencyWindowReducer(
        topologyDescription,
        tagSetReducer(
          readPreference,
          maxStalenessReducer(
            readPreference,
            topologyDescription,
            servers.filter(filter),
          ),
        ),
      );
      if (
        mode === read_preference_1.ReadPreference.SECONDARY_PREFERRED &&
        selectedServers.length === 0
      ) {
        return servers.filter(primaryFilter);
      }
      return selectedServers;
    };
  }
  exports.readPreferenceServerSelector = readPreferenceServerSelector;
})(server_selection);

var utils$2 = {};

var constants$1 = {};

Object.defineProperty(constants$1, "__esModule", { value: true });
constants$1.OP_MSG =
  constants$1.OP_COMPRESSED =
  constants$1.OP_DELETE =
  constants$1.OP_QUERY =
  constants$1.OP_INSERT =
  constants$1.OP_UPDATE =
  constants$1.OP_REPLY =
  constants$1.MIN_SUPPORTED_QE_SERVER_VERSION =
  constants$1.MIN_SUPPORTED_QE_WIRE_VERSION =
  constants$1.MAX_SUPPORTED_WIRE_VERSION =
  constants$1.MIN_SUPPORTED_WIRE_VERSION =
  constants$1.MAX_SUPPORTED_SERVER_VERSION =
  constants$1.MIN_SUPPORTED_SERVER_VERSION =
    void 0;
constants$1.MIN_SUPPORTED_SERVER_VERSION = "3.6";
constants$1.MAX_SUPPORTED_SERVER_VERSION = "7.0";
constants$1.MIN_SUPPORTED_WIRE_VERSION = 6;
constants$1.MAX_SUPPORTED_WIRE_VERSION = 21;
constants$1.MIN_SUPPORTED_QE_WIRE_VERSION = 21;
constants$1.MIN_SUPPORTED_QE_SERVER_VERSION = "7.0";
constants$1.OP_REPLY = 1;
constants$1.OP_UPDATE = 2001;
constants$1.OP_INSERT = 2002;
constants$1.OP_QUERY = 2004;
constants$1.OP_DELETE = 2006;
constants$1.OP_COMPRESSED = 2012;
constants$1.OP_MSG = 2013;

var constants = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.TOPOLOGY_EVENTS =
    exports.CMAP_EVENTS =
    exports.HEARTBEAT_EVENTS =
    exports.RESUME_TOKEN_CHANGED =
    exports.END =
    exports.CHANGE =
    exports.INIT =
    exports.MORE =
    exports.RESPONSE =
    exports.SERVER_HEARTBEAT_FAILED =
    exports.SERVER_HEARTBEAT_SUCCEEDED =
    exports.SERVER_HEARTBEAT_STARTED =
    exports.COMMAND_FAILED =
    exports.COMMAND_SUCCEEDED =
    exports.COMMAND_STARTED =
    exports.CLUSTER_TIME_RECEIVED =
    exports.CONNECTION_CHECKED_IN =
    exports.CONNECTION_CHECKED_OUT =
    exports.CONNECTION_CHECK_OUT_FAILED =
    exports.CONNECTION_CHECK_OUT_STARTED =
    exports.CONNECTION_CLOSED =
    exports.CONNECTION_READY =
    exports.CONNECTION_CREATED =
    exports.CONNECTION_POOL_READY =
    exports.CONNECTION_POOL_CLEARED =
    exports.CONNECTION_POOL_CLOSED =
    exports.CONNECTION_POOL_CREATED =
    exports.TOPOLOGY_DESCRIPTION_CHANGED =
    exports.TOPOLOGY_CLOSED =
    exports.TOPOLOGY_OPENING =
    exports.SERVER_DESCRIPTION_CHANGED =
    exports.SERVER_CLOSED =
    exports.SERVER_OPENING =
    exports.DESCRIPTION_RECEIVED =
    exports.UNPINNED =
    exports.PINNED =
    exports.MESSAGE =
    exports.ENDED =
    exports.CLOSED =
    exports.CONNECT =
    exports.OPEN =
    exports.CLOSE =
    exports.TIMEOUT =
    exports.ERROR =
    exports.SYSTEM_JS_COLLECTION =
    exports.SYSTEM_COMMAND_COLLECTION =
    exports.SYSTEM_USER_COLLECTION =
    exports.SYSTEM_PROFILE_COLLECTION =
    exports.SYSTEM_INDEX_COLLECTION =
    exports.SYSTEM_NAMESPACE_COLLECTION =
      void 0;
  exports.LEGACY_HELLO_COMMAND_CAMEL_CASE =
    exports.LEGACY_HELLO_COMMAND =
    exports.MONGO_CLIENT_EVENTS =
    exports.LOCAL_SERVER_EVENTS =
    exports.SERVER_RELAY_EVENTS =
    exports.APM_EVENTS =
      void 0;
  exports.SYSTEM_NAMESPACE_COLLECTION = "system.namespaces";
  exports.SYSTEM_INDEX_COLLECTION = "system.indexes";
  exports.SYSTEM_PROFILE_COLLECTION = "system.profile";
  exports.SYSTEM_USER_COLLECTION = "system.users";
  exports.SYSTEM_COMMAND_COLLECTION = "$cmd";
  exports.SYSTEM_JS_COLLECTION = "system.js";
  // events
  exports.ERROR = "error";
  exports.TIMEOUT = "timeout";
  exports.CLOSE = "close";
  exports.OPEN = "open";
  exports.CONNECT = "connect";
  exports.CLOSED = "closed";
  exports.ENDED = "ended";
  exports.MESSAGE = "message";
  exports.PINNED = "pinned";
  exports.UNPINNED = "unpinned";
  exports.DESCRIPTION_RECEIVED = "descriptionReceived";
  exports.SERVER_OPENING = "serverOpening";
  exports.SERVER_CLOSED = "serverClosed";
  exports.SERVER_DESCRIPTION_CHANGED = "serverDescriptionChanged";
  exports.TOPOLOGY_OPENING = "topologyOpening";
  exports.TOPOLOGY_CLOSED = "topologyClosed";
  exports.TOPOLOGY_DESCRIPTION_CHANGED = "topologyDescriptionChanged";
  /** @internal */
  exports.CONNECTION_POOL_CREATED = "connectionPoolCreated";
  /** @internal */
  exports.CONNECTION_POOL_CLOSED = "connectionPoolClosed";
  /** @internal */
  exports.CONNECTION_POOL_CLEARED = "connectionPoolCleared";
  /** @internal */
  exports.CONNECTION_POOL_READY = "connectionPoolReady";
  /** @internal */
  exports.CONNECTION_CREATED = "connectionCreated";
  /** @internal */
  exports.CONNECTION_READY = "connectionReady";
  /** @internal */
  exports.CONNECTION_CLOSED = "connectionClosed";
  /** @internal */
  exports.CONNECTION_CHECK_OUT_STARTED = "connectionCheckOutStarted";
  /** @internal */
  exports.CONNECTION_CHECK_OUT_FAILED = "connectionCheckOutFailed";
  /** @internal */
  exports.CONNECTION_CHECKED_OUT = "connectionCheckedOut";
  /** @internal */
  exports.CONNECTION_CHECKED_IN = "connectionCheckedIn";
  exports.CLUSTER_TIME_RECEIVED = "clusterTimeReceived";
  exports.COMMAND_STARTED = "commandStarted";
  exports.COMMAND_SUCCEEDED = "commandSucceeded";
  exports.COMMAND_FAILED = "commandFailed";
  exports.SERVER_HEARTBEAT_STARTED = "serverHeartbeatStarted";
  exports.SERVER_HEARTBEAT_SUCCEEDED = "serverHeartbeatSucceeded";
  exports.SERVER_HEARTBEAT_FAILED = "serverHeartbeatFailed";
  exports.RESPONSE = "response";
  exports.MORE = "more";
  exports.INIT = "init";
  exports.CHANGE = "change";
  exports.END = "end";
  exports.RESUME_TOKEN_CHANGED = "resumeTokenChanged";
  /** @public */
  exports.HEARTBEAT_EVENTS = Object.freeze([
    exports.SERVER_HEARTBEAT_STARTED,
    exports.SERVER_HEARTBEAT_SUCCEEDED,
    exports.SERVER_HEARTBEAT_FAILED,
  ]);
  /** @public */
  exports.CMAP_EVENTS = Object.freeze([
    exports.CONNECTION_POOL_CREATED,
    exports.CONNECTION_POOL_READY,
    exports.CONNECTION_POOL_CLEARED,
    exports.CONNECTION_POOL_CLOSED,
    exports.CONNECTION_CREATED,
    exports.CONNECTION_READY,
    exports.CONNECTION_CLOSED,
    exports.CONNECTION_CHECK_OUT_STARTED,
    exports.CONNECTION_CHECK_OUT_FAILED,
    exports.CONNECTION_CHECKED_OUT,
    exports.CONNECTION_CHECKED_IN,
  ]);
  /** @public */
  exports.TOPOLOGY_EVENTS = Object.freeze([
    exports.SERVER_OPENING,
    exports.SERVER_CLOSED,
    exports.SERVER_DESCRIPTION_CHANGED,
    exports.TOPOLOGY_OPENING,
    exports.TOPOLOGY_CLOSED,
    exports.TOPOLOGY_DESCRIPTION_CHANGED,
    exports.ERROR,
    exports.TIMEOUT,
    exports.CLOSE,
  ]);
  /** @public */
  exports.APM_EVENTS = Object.freeze([
    exports.COMMAND_STARTED,
    exports.COMMAND_SUCCEEDED,
    exports.COMMAND_FAILED,
  ]);
  /**
   * All events that we relay to the `Topology`
   * @internal
   */
  exports.SERVER_RELAY_EVENTS = Object.freeze([
    exports.SERVER_HEARTBEAT_STARTED,
    exports.SERVER_HEARTBEAT_SUCCEEDED,
    exports.SERVER_HEARTBEAT_FAILED,
    exports.COMMAND_STARTED,
    exports.COMMAND_SUCCEEDED,
    exports.COMMAND_FAILED,
    ...exports.CMAP_EVENTS,
  ]);
  /**
   * All events we listen to from `Server` instances, but do not forward to the client
   * @internal
   */
  exports.LOCAL_SERVER_EVENTS = Object.freeze([
    exports.CONNECT,
    exports.DESCRIPTION_RECEIVED,
    exports.CLOSED,
    exports.ENDED,
  ]);
  /** @public */
  exports.MONGO_CLIENT_EVENTS = Object.freeze([
    ...exports.CMAP_EVENTS,
    ...exports.APM_EVENTS,
    ...exports.TOPOLOGY_EVENTS,
    ...exports.HEARTBEAT_EVENTS,
  ]);
  /**
   * @internal
   * The legacy hello command that was deprecated in MongoDB 5.0.
   */
  exports.LEGACY_HELLO_COMMAND = "ismaster";
  /**
   * @internal
   * The legacy hello command that was deprecated in MongoDB 5.0.
   */
  exports.LEGACY_HELLO_COMMAND_CAMEL_CASE = "isMaster";
})(constants);

var read_concern = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.ReadConcern = exports.ReadConcernLevel = void 0;
  /** @public */
  exports.ReadConcernLevel = Object.freeze({
    local: "local",
    majority: "majority",
    linearizable: "linearizable",
    available: "available",
    snapshot: "snapshot",
  });
  /**
   * The MongoDB ReadConcern, which allows for control of the consistency and isolation properties
   * of the data read from replica sets and replica set shards.
   * @public
   *
   * @see https://www.mongodb.com/docs/manual/reference/read-concern/index.html
   */
  class ReadConcern {
    /** Constructs a ReadConcern from the read concern level.*/
    constructor(level) {
      /**
       * A spec test exists that allows level to be any string.
       * "invalid readConcern with out stage"
       * @see ./test/spec/crud/v2/aggregate-out-readConcern.json
       * @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.rst#unknown-levels-and-additional-options-for-string-based-readconcerns
       */
      this.level = exports.ReadConcernLevel[level] ?? level;
    }
    /**
     * Construct a ReadConcern given an options object.
     *
     * @param options - The options object from which to extract the write concern.
     */
    static fromOptions(options) {
      if (options == null) {
        return;
      }
      if (options.readConcern) {
        const { readConcern } = options;
        if (readConcern instanceof ReadConcern) {
          return readConcern;
        } else if (typeof readConcern === "string") {
          return new ReadConcern(readConcern);
        } else if ("level" in readConcern && readConcern.level) {
          return new ReadConcern(readConcern.level);
        }
      }
      if (options.level) {
        return new ReadConcern(options.level);
      }
      return;
    }
    static get MAJORITY() {
      return exports.ReadConcernLevel.majority;
    }
    static get AVAILABLE() {
      return exports.ReadConcernLevel.available;
    }
    static get LINEARIZABLE() {
      return exports.ReadConcernLevel.linearizable;
    }
    static get SNAPSHOT() {
      return exports.ReadConcernLevel.snapshot;
    }
    toJSON() {
      return { level: this.level };
    }
  }
  exports.ReadConcern = ReadConcern;
})(read_concern);

var write_concern = {};

Object.defineProperty(write_concern, "__esModule", { value: true });
write_concern.WriteConcern = write_concern.WRITE_CONCERN_KEYS = void 0;
write_concern.WRITE_CONCERN_KEYS = ["w", "wtimeout", "j", "journal", "fsync"];
/**
 * A MongoDB WriteConcern, which describes the level of acknowledgement
 * requested from MongoDB for write operations.
 * @public
 *
 * @see https://www.mongodb.com/docs/manual/reference/write-concern/
 */
let WriteConcern$1 = class WriteConcern {
  /**
   * Constructs a WriteConcern from the write concern properties.
   * @param w - request acknowledgment that the write operation has propagated to a specified number of mongod instances or to mongod instances with specified tags.
   * @param wtimeoutMS - specify a time limit to prevent write operations from blocking indefinitely
   * @param journal - request acknowledgment that the write operation has been written to the on-disk journal
   * @param fsync - equivalent to the j option. Is deprecated and will be removed in the next major version.
   */
  constructor(w, wtimeoutMS, journal, fsync) {
    if (w != null) {
      if (!Number.isNaN(Number(w))) {
        this.w = Number(w);
      } else {
        this.w = w;
      }
    }
    if (wtimeoutMS != null) {
      this.wtimeoutMS = this.wtimeout = wtimeoutMS;
    }
    if (journal != null) {
      this.journal = this.j = journal;
    }
    if (fsync != null) {
      this.journal = this.j = fsync ? true : false;
    }
  }
  /**
   * Apply a write concern to a command document. Will modify and return the command.
   */
  static apply(command, writeConcern) {
    const wc = {};
    // The write concern document sent to the server has w/wtimeout/j fields.
    if (writeConcern.w != null) wc.w = writeConcern.w;
    if (writeConcern.wtimeoutMS != null) wc.wtimeout = writeConcern.wtimeoutMS;
    if (writeConcern.journal != null) wc.j = writeConcern.j;
    command.writeConcern = wc;
    return command;
  }
  /** Construct a WriteConcern given an options object. */
  static fromOptions(options, inherit) {
    if (options == null) return undefined;
    inherit = inherit ?? {};
    let opts;
    if (typeof options === "string" || typeof options === "number") {
      opts = { w: options };
    } else if (options instanceof WriteConcern) {
      opts = options;
    } else {
      opts = options.writeConcern;
    }
    const parentOpts =
      inherit instanceof WriteConcern ? inherit : inherit.writeConcern;
    const {
      w = undefined,
      wtimeout = undefined,
      j = undefined,
      fsync = undefined,
      journal = undefined,
      wtimeoutMS = undefined,
    } = {
      ...parentOpts,
      ...opts,
    };
    if (
      w != null ||
      wtimeout != null ||
      wtimeoutMS != null ||
      j != null ||
      journal != null ||
      fsync != null
    ) {
      return new WriteConcern(w, wtimeout ?? wtimeoutMS, j ?? journal, fsync);
    }
    return undefined;
  }
};
write_concern.WriteConcern = WriteConcern$1;

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.TimeoutController =
    exports.request =
    exports.matchesParentDomain =
    exports.parseUnsignedInteger =
    exports.parseInteger =
    exports.compareObjectId =
    exports.commandSupportsReadConcern =
    exports.shuffle =
    exports.supportsRetryableWrites =
    exports.enumToString =
    exports.emitWarningOnce =
    exports.emitWarning =
    exports.MONGODB_WARNING_CODE =
    exports.DEFAULT_PK_FACTORY =
    exports.HostAddress =
    exports.BufferPool =
    exports.List =
    exports.deepCopy =
    exports.isRecord =
    exports.setDifference =
    exports.isHello =
    exports.isSuperset =
    exports.resolveOptions =
    exports.hasAtomicOperators =
    exports.calculateDurationInMs =
    exports.now =
    exports.makeStateMachine =
    exports.errorStrictEqual =
    exports.arrayStrictEqual =
    exports.eachAsync =
    exports.maxWireVersion =
    exports.uuidV4 =
    exports.maybeCallback =
    exports.makeCounter =
    exports.MongoDBCollectionNamespace =
    exports.MongoDBNamespace =
    exports.ns =
    exports.getTopology =
    exports.decorateWithExplain =
    exports.decorateWithReadConcern =
    exports.decorateWithCollation =
    exports.isPromiseLike =
    exports.applyRetryableWrites =
    exports.filterOptions =
    exports.mergeOptions =
    exports.isObject =
    exports.normalizeHintField =
    exports.hostMatchesWildcards =
    exports.ByteUtils =
      void 0;
  const crypto = $nodeCrypto;
  const http = $nodeHttp;
  const timers_1 = $nodeTimers;
  const url = $nodeUrl;
  const url_1 = $nodeUrl;
  const bson_1 = bson$2;
  const constants_1 = constants$1;
  const constants_2 = constants;
  const error_1 = error;
  const read_concern_1 = read_concern;
  const read_preference_1 = read_preference;
  const common_1 = common$1;
  const write_concern_1 = write_concern;
  exports.ByteUtils = {
    toLocalBufferType(buffer) {
      return Buffer.isBuffer(buffer)
        ? buffer
        : Buffer.from(buffer.buffer, buffer.byteOffset, buffer.byteLength);
    },
    equals(seqA, seqB) {
      return exports.ByteUtils.toLocalBufferType(seqA).equals(seqB);
    },
    compare(seqA, seqB) {
      return exports.ByteUtils.toLocalBufferType(seqA).compare(seqB);
    },
    toBase64(uint8array) {
      return exports.ByteUtils.toLocalBufferType(uint8array).toString("base64");
    },
  };
  /**
   * Determines if a connection's address matches a user provided list
   * of domain wildcards.
   */
  function hostMatchesWildcards(host, wildcards) {
    for (const wildcard of wildcards) {
      if (
        host === wildcard ||
        (wildcard.startsWith("*.") &&
          host?.endsWith(wildcard.substring(2, wildcard.length))) ||
        (wildcard.startsWith("*/") &&
          host?.endsWith(wildcard.substring(2, wildcard.length)))
      ) {
        return true;
      }
    }
    return false;
  }
  exports.hostMatchesWildcards = hostMatchesWildcards;
  /**
   * Ensure Hint field is in a shape we expect:
   * - object of index names mapping to 1 or -1
   * - just an index name
   * @internal
   */
  function normalizeHintField(hint) {
    let finalHint = undefined;
    if (typeof hint === "string") {
      finalHint = hint;
    } else if (Array.isArray(hint)) {
      finalHint = {};
      hint.forEach((param) => {
        finalHint[param] = 1;
      });
    } else if (hint != null && typeof hint === "object") {
      finalHint = {};
      for (const name in hint) {
        finalHint[name] = hint[name];
      }
    }
    return finalHint;
  }
  exports.normalizeHintField = normalizeHintField;
  const TO_STRING = (object) => Object.prototype.toString.call(object);
  /**
   * Checks if arg is an Object:
   * - **NOTE**: the check is based on the `[Symbol.toStringTag]() === 'Object'`
   * @internal
   */
  function isObject(arg) {
    return "[object Object]" === TO_STRING(arg);
  }
  exports.isObject = isObject;
  /** @internal */
  function mergeOptions(target, source) {
    return { ...target, ...source };
  }
  exports.mergeOptions = mergeOptions;
  /** @internal */
  function filterOptions(options, names) {
    const filterOptions = {};
    for (const name in options) {
      if (names.includes(name)) {
        filterOptions[name] = options[name];
      }
    }
    // Filtered options
    return filterOptions;
  }
  exports.filterOptions = filterOptions;
  /**
   * Applies retryWrites: true to a command if retryWrites is set on the command's database.
   * @internal
   *
   * @param target - The target command to which we will apply retryWrites.
   * @param db - The database from which we can inherit a retryWrites value.
   */
  function applyRetryableWrites(target, db) {
    if (db && db.s.options?.retryWrites) {
      target.retryWrites = true;
    }
    return target;
  }
  exports.applyRetryableWrites = applyRetryableWrites;
  /**
   * Applies a write concern to a command based on well defined inheritance rules, optionally
   * detecting support for the write concern in the first place.
   * @internal
   *
   * @param target - the target command we will be applying the write concern to
   * @param sources - sources where we can inherit default write concerns from
   * @param options - optional settings passed into a command for write concern overrides
   */
  /**
   * Checks if a given value is a Promise
   *
   * @typeParam T - The resolution type of the possible promise
   * @param value - An object that could be a promise
   * @returns true if the provided value is a Promise
   */
  function isPromiseLike(value) {
    return !!value && typeof value.then === "function";
  }
  exports.isPromiseLike = isPromiseLike;
  /**
   * Applies collation to a given command.
   * @internal
   *
   * @param command - the command on which to apply collation
   * @param target - target of command
   * @param options - options containing collation settings
   */
  function decorateWithCollation(command, target, options) {
    const capabilities = getTopology(target).capabilities;
    if (options.collation && typeof options.collation === "object") {
      if (capabilities && capabilities.commandsTakeCollation) {
        command.collation = options.collation;
      } else {
        throw new error_1.MongoCompatibilityError(
          `Current topology does not support collation`,
        );
      }
    }
  }
  exports.decorateWithCollation = decorateWithCollation;
  /**
   * Applies a read concern to a given command.
   * @internal
   *
   * @param command - the command on which to apply the read concern
   * @param coll - the parent collection of the operation calling this method
   */
  function decorateWithReadConcern(command, coll, options) {
    if (options && options.session && options.session.inTransaction()) {
      return;
    }
    const readConcern = Object.assign({}, command.readConcern || {});
    if (coll.s.readConcern) {
      Object.assign(readConcern, coll.s.readConcern);
    }
    if (Object.keys(readConcern).length > 0) {
      Object.assign(command, { readConcern: readConcern });
    }
  }
  exports.decorateWithReadConcern = decorateWithReadConcern;
  /**
   * Applies an explain to a given command.
   * @internal
   *
   * @param command - the command on which to apply the explain
   * @param options - the options containing the explain verbosity
   */
  function decorateWithExplain(command, explain) {
    if (command.explain) {
      return command;
    }
    return { explain: command, verbosity: explain.verbosity };
  }
  exports.decorateWithExplain = decorateWithExplain;
  /**
   * A helper function to get the topology from a given provider. Throws
   * if the topology cannot be found.
   * @throws MongoNotConnectedError
   * @internal
   */
  function getTopology(provider) {
    // MongoClient or ClientSession or AbstractCursor
    if ("topology" in provider && provider.topology) {
      return provider.topology;
    } else if ("client" in provider && provider.client.topology) {
      return provider.client.topology;
    }
    throw new error_1.MongoNotConnectedError(
      "MongoClient must be connected to perform this operation",
    );
  }
  exports.getTopology = getTopology;
  /** @internal */
  function ns(ns) {
    return MongoDBNamespace.fromString(ns);
  }
  exports.ns = ns;
  /** @public */
  class MongoDBNamespace {
    /**
     * Create a namespace object
     *
     * @param db - database name
     * @param collection - collection name
     */
    constructor(db, collection) {
      this.db = db;
      this.collection = collection;
      this.collection = collection === "" ? undefined : collection;
    }
    toString() {
      return this.collection ? `${this.db}.${this.collection}` : this.db;
    }
    withCollection(collection) {
      return new MongoDBCollectionNamespace(this.db, collection);
    }
    static fromString(namespace) {
      if (typeof namespace !== "string" || namespace === "") {
        // TODO(NODE-3483): Replace with MongoNamespaceError
        throw new error_1.MongoRuntimeError(
          `Cannot parse namespace from "${namespace}"`,
        );
      }
      const [db, ...collectionParts] = namespace.split(".");
      const collection = collectionParts.join(".");
      return new MongoDBNamespace(
        db,
        collection === "" ? undefined : collection,
      );
    }
  }
  exports.MongoDBNamespace = MongoDBNamespace;
  /**
   * @public
   *
   * A class representing a collection's namespace.  This class enforces (through Typescript) that
   * the `collection` portion of the namespace is defined and should only be
   * used in scenarios where this can be guaranteed.
   */
  class MongoDBCollectionNamespace extends MongoDBNamespace {
    constructor(db, collection) {
      super(db, collection);
      this.collection = collection;
    }
    static fromString(namespace) {
      return super.fromString(namespace);
    }
  }
  exports.MongoDBCollectionNamespace = MongoDBCollectionNamespace;
  /** @internal */
  function* makeCounter(seed = 0) {
    let count = seed;
    while (true) {
      const newCount = count;
      count += 1;
      yield newCount;
    }
  }
  exports.makeCounter = makeCounter;
  function maybeCallback(promiseFn, callback) {
    const promise = promiseFn();
    if (callback == null) {
      return promise;
    }
    promise.then(
      (result) => callback(undefined, result),
      (error) => callback(error),
    );
    return;
  }
  exports.maybeCallback = maybeCallback;
  /**
   * Synchronously Generate a UUIDv4
   * @internal
   */
  function uuidV4() {
    const result = crypto.randomBytes(16);
    result[6] = (result[6] & 0x0f) | 0x40;
    result[8] = (result[8] & 0x3f) | 0x80;
    return result;
  }
  exports.uuidV4 = uuidV4;
  /**
   * A helper function for determining `maxWireVersion` between legacy and new topology instances
   * @internal
   */
  function maxWireVersion(topologyOrServer) {
    if (topologyOrServer) {
      if (topologyOrServer.loadBalanced) {
        // Since we do not have a monitor, we assume the load balanced server is always
        // pointed at the latest mongodb version. There is a risk that for on-prem
        // deployments that don't upgrade immediately that this could alert to the
        // application that a feature is available that is actually not.
        return constants_1.MAX_SUPPORTED_WIRE_VERSION;
      }
      if (topologyOrServer.hello) {
        return topologyOrServer.hello.maxWireVersion;
      }
      if (
        "lastHello" in topologyOrServer &&
        typeof topologyOrServer.lastHello === "function"
      ) {
        const lastHello = topologyOrServer.lastHello();
        if (lastHello) {
          return lastHello.maxWireVersion;
        }
      }
      if (
        topologyOrServer.description &&
        "maxWireVersion" in topologyOrServer.description &&
        topologyOrServer.description.maxWireVersion != null
      ) {
        return topologyOrServer.description.maxWireVersion;
      }
    }
    return 0;
  }
  exports.maxWireVersion = maxWireVersion;
  /**
   * Applies the function `eachFn` to each item in `arr`, in parallel.
   * @internal
   *
   * @param arr - An array of items to asynchronously iterate over
   * @param eachFn - A function to call on each item of the array. The callback signature is `(item, callback)`, where the callback indicates iteration is complete.
   * @param callback - The callback called after every item has been iterated
   */
  function eachAsync(arr, eachFn, callback) {
    arr = arr || [];
    let idx = 0;
    let awaiting = 0;
    for (idx = 0; idx < arr.length; ++idx) {
      awaiting++;
      eachFn(arr[idx], eachCallback);
    }
    if (awaiting === 0) {
      callback();
      return;
    }
    function eachCallback(err) {
      awaiting--;
      if (err) {
        callback(err);
        return;
      }
      if (idx === arr.length && awaiting <= 0) {
        callback();
      }
    }
  }
  exports.eachAsync = eachAsync;
  /** @internal */
  function arrayStrictEqual(arr, arr2) {
    if (!Array.isArray(arr) || !Array.isArray(arr2)) {
      return false;
    }
    return (
      arr.length === arr2.length && arr.every((elt, idx) => elt === arr2[idx])
    );
  }
  exports.arrayStrictEqual = arrayStrictEqual;
  /** @internal */
  function errorStrictEqual(lhs, rhs) {
    if (lhs === rhs) {
      return true;
    }
    if (!lhs || !rhs) {
      return lhs === rhs;
    }
    if ((lhs == null && rhs != null) || (lhs != null && rhs == null)) {
      return false;
    }
    if (lhs.constructor.name !== rhs.constructor.name) {
      return false;
    }
    if (lhs.message !== rhs.message) {
      return false;
    }
    return true;
  }
  exports.errorStrictEqual = errorStrictEqual;
  /** @internal */
  function makeStateMachine(stateTable) {
    return function stateTransition(target, newState) {
      const legalStates = stateTable[target.s.state];
      if (legalStates && legalStates.indexOf(newState) < 0) {
        throw new error_1.MongoRuntimeError(
          `illegal state transition from [${target.s.state}] => [${newState}], allowed: [${legalStates}]`,
        );
      }
      target.emit("stateChanged", target.s.state, newState);
      target.s.state = newState;
    };
  }
  exports.makeStateMachine = makeStateMachine;
  /** @internal */
  function now() {
    const hrtime = process.hrtime();
    return Math.floor(hrtime[0] * 1000 + hrtime[1] / 1000000);
  }
  exports.now = now;
  /** @internal */
  function calculateDurationInMs(started) {
    if (typeof started !== "number") {
      throw new error_1.MongoInvalidArgumentError(
        "Numeric value required to calculate duration",
      );
    }
    const elapsed = now() - started;
    return elapsed < 0 ? 0 : elapsed;
  }
  exports.calculateDurationInMs = calculateDurationInMs;
  /** @internal */
  function hasAtomicOperators(doc) {
    if (Array.isArray(doc)) {
      for (const document of doc) {
        if (hasAtomicOperators(document)) {
          return true;
        }
      }
      return false;
    }
    const keys = Object.keys(doc);
    return keys.length > 0 && keys[0][0] === "$";
  }
  exports.hasAtomicOperators = hasAtomicOperators;
  /**
   * Merge inherited properties from parent into options, prioritizing values from options,
   * then values from parent.
   * @internal
   */
  function resolveOptions(parent, options) {
    const result = Object.assign(
      {},
      options,
      (0, bson_1.resolveBSONOptions)(options, parent),
    );
    // Users cannot pass a readConcern/writeConcern to operations in a transaction
    const session = options?.session;
    if (!session?.inTransaction()) {
      const readConcern =
        read_concern_1.ReadConcern.fromOptions(options) ?? parent?.readConcern;
      if (readConcern) {
        result.readConcern = readConcern;
      }
      const writeConcern =
        write_concern_1.WriteConcern.fromOptions(options) ??
        parent?.writeConcern;
      if (writeConcern) {
        result.writeConcern = writeConcern;
      }
    }
    const readPreference =
      read_preference_1.ReadPreference.fromOptions(options) ??
      parent?.readPreference;
    if (readPreference) {
      result.readPreference = readPreference;
    }
    return result;
  }
  exports.resolveOptions = resolveOptions;
  function isSuperset(set, subset) {
    set = Array.isArray(set) ? new Set(set) : set;
    subset = Array.isArray(subset) ? new Set(subset) : subset;
    for (const elem of subset) {
      if (!set.has(elem)) {
        return false;
      }
    }
    return true;
  }
  exports.isSuperset = isSuperset;
  /**
   * Checks if the document is a Hello request
   * @internal
   */
  function isHello(doc) {
    return doc[constants_2.LEGACY_HELLO_COMMAND] || doc.hello ? true : false;
  }
  exports.isHello = isHello;
  /** Returns the items that are uniquely in setA */
  function setDifference(setA, setB) {
    const difference = new Set(setA);
    for (const elem of setB) {
      difference.delete(elem);
    }
    return difference;
  }
  exports.setDifference = setDifference;
  const HAS_OWN = (object, prop) =>
    Object.prototype.hasOwnProperty.call(object, prop);
  function isRecord(value, requiredKeys = undefined) {
    if (!isObject(value)) {
      return false;
    }
    const ctor = value.constructor;
    if (ctor && ctor.prototype) {
      if (!isObject(ctor.prototype)) {
        return false;
      }
      // Check to see if some method exists from the Object exists
      if (!HAS_OWN(ctor.prototype, "isPrototypeOf")) {
        return false;
      }
    }
    if (requiredKeys) {
      const keys = Object.keys(value);
      return isSuperset(keys, requiredKeys);
    }
    return true;
  }
  exports.isRecord = isRecord;
  /**
   * Make a deep copy of an object
   *
   * NOTE: This is not meant to be the perfect implementation of a deep copy,
   * but instead something that is good enough for the purposes of
   * command monitoring.
   */
  function deepCopy(value) {
    if (value == null) {
      return value;
    } else if (Array.isArray(value)) {
      return value.map((item) => deepCopy(item));
    } else if (isRecord(value)) {
      const res = {};
      for (const key in value) {
        res[key] = deepCopy(value[key]);
      }
      return res;
    }
    const ctor = value.constructor;
    if (ctor) {
      switch (ctor.name.toLowerCase()) {
        case "date":
          return new ctor(Number(value));
        case "map":
          return new Map(value);
        case "set":
          return new Set(value);
        case "buffer":
          return Buffer.from(value);
      }
    }
    return value;
  }
  exports.deepCopy = deepCopy;
  /**
   * A sequential list of items in a circularly linked list
   * @remarks
   * The head node is special, it is always defined and has a value of null.
   * It is never "included" in the list, in that, it is not returned by pop/shift or yielded by the iterator.
   * The circular linkage and always defined head node are to reduce checks for null next/prev references to zero.
   * New nodes are declared as object literals with keys always in the same order: next, prev, value.
   * @internal
   */
  class List {
    get length() {
      return this.count;
    }
    get [Symbol.toStringTag]() {
      return "List";
    }
    constructor() {
      this.count = 0;
      // this is carefully crafted:
      // declaring a complete and consistently key ordered
      // object is beneficial to the runtime optimizations
      this.head = {
        next: null,
        prev: null,
        value: null,
      };
      this.head.next = this.head;
      this.head.prev = this.head;
    }
    toArray() {
      return Array.from(this);
    }
    toString() {
      return `head <=> ${this.toArray().join(" <=> ")} <=> head`;
    }
    *[Symbol.iterator]() {
      for (const node of this.nodes()) {
        yield node.value;
      }
    }
    *nodes() {
      let ptr = this.head.next;
      while (ptr !== this.head) {
        // Save next before yielding so that we make removing within iteration safe
        const { next } = ptr;
        yield ptr;
        ptr = next;
      }
    }
    /** Insert at end of list */
    push(value) {
      this.count += 1;
      const newNode = {
        next: this.head,
        prev: this.head.prev,
        value,
      };
      this.head.prev.next = newNode;
      this.head.prev = newNode;
    }
    /** Inserts every item inside an iterable instead of the iterable itself */
    pushMany(iterable) {
      for (const value of iterable) {
        this.push(value);
      }
    }
    /** Insert at front of list */
    unshift(value) {
      this.count += 1;
      const newNode = {
        next: this.head.next,
        prev: this.head,
        value,
      };
      this.head.next.prev = newNode;
      this.head.next = newNode;
    }
    remove(node) {
      if (node === this.head || this.length === 0) {
        return null;
      }
      this.count -= 1;
      const prevNode = node.prev;
      const nextNode = node.next;
      prevNode.next = nextNode;
      nextNode.prev = prevNode;
      return node.value;
    }
    /** Removes the first node at the front of the list */
    shift() {
      return this.remove(this.head.next);
    }
    /** Removes the last node at the end of the list */
    pop() {
      return this.remove(this.head.prev);
    }
    /** Iterates through the list and removes nodes where filter returns true */
    prune(filter) {
      for (const node of this.nodes()) {
        if (filter(node.value)) {
          this.remove(node);
        }
      }
    }
    clear() {
      this.count = 0;
      this.head.next = this.head;
      this.head.prev = this.head;
    }
    /** Returns the first item in the list, does not remove */
    first() {
      // If the list is empty, value will be the head's null
      return this.head.next.value;
    }
    /** Returns the last item in the list, does not remove */
    last() {
      // If the list is empty, value will be the head's null
      return this.head.prev.value;
    }
  }
  exports.List = List;
  /**
   * A pool of Buffers which allow you to read them as if they were one
   * @internal
   */
  class BufferPool {
    constructor() {
      this.buffers = new List();
      this.totalByteLength = 0;
    }
    get length() {
      return this.totalByteLength;
    }
    /** Adds a buffer to the internal buffer pool list */
    append(buffer) {
      this.buffers.push(buffer);
      this.totalByteLength += buffer.length;
    }
    /**
     * If BufferPool contains 4 bytes or more construct an int32 from the leading bytes,
     * otherwise return null. Size can be negative, caller should error check.
     */
    getInt32() {
      if (this.totalByteLength < 4) {
        return null;
      }
      const firstBuffer = this.buffers.first();
      if (firstBuffer != null && firstBuffer.byteLength >= 4) {
        return firstBuffer.readInt32LE(0);
      }
      // Unlikely case: an int32 is split across buffers.
      // Use read and put the returned buffer back on top
      const top4Bytes = this.read(4);
      const value = top4Bytes.readInt32LE(0);
      // Put it back.
      this.totalByteLength += 4;
      this.buffers.unshift(top4Bytes);
      return value;
    }
    /** Reads the requested number of bytes, optionally consuming them */
    read(size) {
      if (typeof size !== "number" || size < 0) {
        throw new error_1.MongoInvalidArgumentError(
          'Argument "size" must be a non-negative number',
        );
      }
      // oversized request returns empty buffer
      if (size > this.totalByteLength) {
        return Buffer.alloc(0);
      }
      // We know we have enough, we just don't know how it is spread across chunks
      // TODO(NODE-4732): alloc API should change based on raw option
      const result = Buffer.allocUnsafe(size);
      for (let bytesRead = 0; bytesRead < size; ) {
        const buffer = this.buffers.shift();
        if (buffer == null) {
          break;
        }
        const bytesRemaining = size - bytesRead;
        const bytesReadable = Math.min(bytesRemaining, buffer.byteLength);
        const bytes = buffer.subarray(0, bytesReadable);
        result.set(bytes, bytesRead);
        bytesRead += bytesReadable;
        this.totalByteLength -= bytesReadable;
        if (bytesReadable < buffer.byteLength) {
          this.buffers.unshift(buffer.subarray(bytesReadable));
        }
      }
      return result;
    }
  }
  exports.BufferPool = BufferPool;
  /** @public */
  class HostAddress {
    constructor(hostString) {
      this.host = undefined;
      this.port = undefined;
      this.socketPath = undefined;
      this.isIPv6 = false;
      const escapedHost = hostString.split(" ").join("%20"); // escape spaces, for socket path hosts
      if (escapedHost.endsWith(".sock")) {
        // heuristically determine if we're working with a domain socket
        this.socketPath = decodeURIComponent(escapedHost);
        return;
      }
      const urlString = `iLoveJS://${escapedHost}`;
      let url;
      try {
        url = new url_1.URL(urlString);
      } catch (urlError) {
        const runtimeError = new error_1.MongoRuntimeError(
          `Unable to parse ${escapedHost} with URL`,
        );
        runtimeError.cause = urlError;
        throw runtimeError;
      }
      const hostname = url.hostname;
      const port = url.port;
      let normalized = decodeURIComponent(hostname).toLowerCase();
      if (normalized.startsWith("[") && normalized.endsWith("]")) {
        this.isIPv6 = true;
        normalized = normalized.substring(1, hostname.length - 1);
      }
      this.host = normalized.toLowerCase();
      if (typeof port === "number") {
        this.port = port;
      } else if (typeof port === "string" && port !== "") {
        this.port = Number.parseInt(port, 10);
      } else {
        this.port = 27017;
      }
      if (this.port === 0) {
        throw new error_1.MongoParseError("Invalid port (zero) with hostname");
      }
      Object.freeze(this);
    }
    [Symbol.for("nodejs.util.inspect.custom")]() {
      return this.inspect();
    }
    inspect() {
      return `new HostAddress('${this.toString()}')`;
    }
    toString() {
      if (typeof this.host === "string") {
        if (this.isIPv6) {
          return `[${this.host}]:${this.port}`;
        }
        return `${this.host}:${this.port}`;
      }
      return `${this.socketPath}`;
    }
    static fromString(s) {
      return new HostAddress(s);
    }
    static fromHostPort(host, port) {
      if (host.includes(":")) {
        host = `[${host}]`; // IPv6 address
      }
      return HostAddress.fromString(`${host}:${port}`);
    }
    static fromSrvRecord({ name, port }) {
      return HostAddress.fromHostPort(name, port);
    }
    toHostPort() {
      if (this.socketPath) {
        return { host: this.socketPath, port: 0 };
      }
      const host = this.host ?? "";
      const port = this.port ?? 0;
      return { host, port };
    }
  }
  exports.HostAddress = HostAddress;
  exports.DEFAULT_PK_FACTORY = {
    // We prefer not to rely on ObjectId having a createPk method
    createPk() {
      return new bson_1.ObjectId();
    },
  };
  /**
   * When the driver used emitWarning the code will be equal to this.
   * @public
   *
   * @example
   * ```ts
   * process.on('warning', (warning) => {
   *  if (warning.code === MONGODB_WARNING_CODE) console.error('Ah an important warning! :)')
   * })
   * ```
   */
  exports.MONGODB_WARNING_CODE = "MONGODB DRIVER";
  /** @internal */
  function emitWarning(message) {
    return process.emitWarning(message, { code: exports.MONGODB_WARNING_CODE });
  }
  exports.emitWarning = emitWarning;
  const emittedWarnings = new Set();
  /**
   * Will emit a warning once for the duration of the application.
   * Uses the message to identify if it has already been emitted
   * so using string interpolation can cause multiple emits
   * @internal
   */
  function emitWarningOnce(message) {
    if (!emittedWarnings.has(message)) {
      emittedWarnings.add(message);
      return emitWarning(message);
    }
  }
  exports.emitWarningOnce = emitWarningOnce;
  /**
   * Takes a JS object and joins the values into a string separated by ', '
   */
  function enumToString(en) {
    return Object.values(en).join(", ");
  }
  exports.enumToString = enumToString;
  /**
   * Determine if a server supports retryable writes.
   *
   * @internal
   */
  function supportsRetryableWrites(server) {
    if (!server) {
      return false;
    }
    if (server.loadBalanced) {
      // Loadbalanced topologies will always support retry writes
      return true;
    }
    if (server.description.logicalSessionTimeoutMinutes != null) {
      // that supports sessions
      if (server.description.type !== common_1.ServerType.Standalone) {
        // and that is not a standalone
        return true;
      }
    }
    return false;
  }
  exports.supportsRetryableWrites = supportsRetryableWrites;
  /**
   * FisherYates Shuffle
   *
   * Reference: https://bost.ocks.org/mike/shuffle/
   * @param sequence - items to be shuffled
   * @param limit - Defaults to `0`. If nonzero shuffle will slice the randomized array e.g, `.slice(0, limit)` otherwise will return the entire randomized array.
   */
  function shuffle(sequence, limit = 0) {
    const items = Array.from(sequence); // shallow copy in order to never shuffle the input
    if (limit > items.length) {
      throw new error_1.MongoRuntimeError(
        "Limit must be less than the number of items",
      );
    }
    let remainingItemsToShuffle = items.length;
    const lowerBound = limit % items.length === 0 ? 1 : items.length - limit;
    while (remainingItemsToShuffle > lowerBound) {
      // Pick a remaining element
      const randomIndex = Math.floor(Math.random() * remainingItemsToShuffle);
      remainingItemsToShuffle -= 1;
      // And swap it with the current element
      const swapHold = items[remainingItemsToShuffle];
      items[remainingItemsToShuffle] = items[randomIndex];
      items[randomIndex] = swapHold;
    }
    return limit % items.length === 0 ? items : items.slice(lowerBound);
  }
  exports.shuffle = shuffle;
  // TODO(NODE-4936): read concern eligibility for commands should be codified in command construction
  // @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.rst#read-concern
  function commandSupportsReadConcern(command) {
    if (
      command.aggregate ||
      command.count ||
      command.distinct ||
      command.find ||
      command.geoNear
    ) {
      return true;
    }
    return false;
  }
  exports.commandSupportsReadConcern = commandSupportsReadConcern;
  /**
   * Compare objectIds. `null` is always less
   * - `+1 = oid1 is greater than oid2`
   * - `-1 = oid1 is less than oid2`
   * - `+0 = oid1 is equal oid2`
   */
  function compareObjectId(oid1, oid2) {
    if (oid1 == null && oid2 == null) {
      return 0;
    }
    if (oid1 == null) {
      return -1;
    }
    if (oid2 == null) {
      return 1;
    }
    return exports.ByteUtils.compare(oid1.id, oid2.id);
  }
  exports.compareObjectId = compareObjectId;
  function parseInteger(value) {
    if (typeof value === "number") return Math.trunc(value);
    const parsedValue = Number.parseInt(String(value), 10);
    return Number.isNaN(parsedValue) ? null : parsedValue;
  }
  exports.parseInteger = parseInteger;
  function parseUnsignedInteger(value) {
    const parsedInt = parseInteger(value);
    return parsedInt != null && parsedInt >= 0 ? parsedInt : null;
  }
  exports.parseUnsignedInteger = parseUnsignedInteger;
  /**
   * Determines whether a provided address matches the provided parent domain.
   *
   * If a DNS server were to become compromised SRV records would still need to
   * advertise addresses that are under the same domain as the srvHost.
   *
   * @param address - The address to check against a domain
   * @param srvHost - The domain to check the provided address against
   * @returns Whether the provided address matches the parent domain
   */
  function matchesParentDomain(address, srvHost) {
    // Remove trailing dot if exists on either the resolved address or the srv hostname
    const normalizedAddress = address.endsWith(".")
      ? address.slice(0, address.length - 1)
      : address;
    const normalizedSrvHost = srvHost.endsWith(".")
      ? srvHost.slice(0, srvHost.length - 1)
      : srvHost;
    const allCharacterBeforeFirstDot = /^.*?\./;
    // Remove all characters before first dot
    // Add leading dot back to string so
    //   an srvHostDomain = '.trusted.site'
    //   will not satisfy an addressDomain that endsWith '.fake-trusted.site'
    const addressDomain = `.${normalizedAddress.replace(
      allCharacterBeforeFirstDot,
      "",
    )}`;
    const srvHostDomain = `.${normalizedSrvHost.replace(
      allCharacterBeforeFirstDot,
      "",
    )}`;
    return addressDomain.endsWith(srvHostDomain);
  }
  exports.matchesParentDomain = matchesParentDomain;
  async function request(uri, options = {}) {
    return new Promise((resolve, reject) => {
      const requestOptions = {
        method: "GET",
        timeout: 10000,
        json: true,
        ...url.parse(uri),
        ...options,
      };
      const req = http.request(requestOptions, (res) => {
        res.setEncoding("utf8");
        let data = "";
        res.on("data", (d) => {
          data += d;
        });
        res.once("end", () => {
          if (options.json === false) {
            resolve(data);
            return;
          }
          try {
            const parsed = JSON.parse(data);
            resolve(parsed);
          } catch {
            // TODO(NODE-3483)
            reject(
              new error_1.MongoRuntimeError(`Invalid JSON response: "${data}"`),
            );
          }
        });
      });
      req.once("timeout", () =>
        req.destroy(
          new error_1.MongoNetworkTimeoutError(
            `Network request to ${uri} timed out after ${options.timeout} ms`,
          ),
        ),
      );
      req.once("error", (error) => reject(error));
      req.end();
    });
  }
  exports.request = request;
  /**
   * A custom AbortController that aborts after a specified timeout.
   *
   * If `timeout` is undefined or \<=0, the abort controller never aborts.
   *
   * This class provides two benefits over the built-in AbortSignal.timeout() method.
   * - This class provides a mechanism for cancelling the timeout
   * - This class supports infinite timeouts by interpreting a timeout of 0 as infinite.  This is
   *    consistent with existing timeout options in the Node driver (serverSelectionTimeoutMS, for example).
   * @internal
   */
  class TimeoutController extends AbortController {
    constructor(
      timeout = 0,
      timeoutId = timeout > 0
        ? (0, timers_1.setTimeout)(() => this.abort(), timeout)
        : null,
    ) {
      super();
      this.timeoutId = timeoutId;
    }
    clear() {
      if (this.timeoutId != null) {
        (0, timers_1.clearTimeout)(this.timeoutId);
      }
      this.timeoutId = null;
    }
  }
  exports.TimeoutController = TimeoutController;
})(utils$2);

var operation = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.defineAspects = exports.AbstractOperation = exports.Aspect = void 0;
  const bson_1 = bson$2;
  const read_preference_1 = read_preference;
  exports.Aspect = {
    READ_OPERATION: Symbol("READ_OPERATION"),
    WRITE_OPERATION: Symbol("WRITE_OPERATION"),
    RETRYABLE: Symbol("RETRYABLE"),
    EXPLAINABLE: Symbol("EXPLAINABLE"),
    SKIP_COLLATION: Symbol("SKIP_COLLATION"),
    CURSOR_CREATING: Symbol("CURSOR_CREATING"),
    MUST_SELECT_SAME_SERVER: Symbol("MUST_SELECT_SAME_SERVER"),
  };
  /** @internal */
  const kSession = Symbol("session");
  /**
   * This class acts as a parent class for any operation and is responsible for setting this.options,
   * as well as setting and getting a session.
   * Additionally, this class implements `hasAspect`, which determines whether an operation has
   * a specific aspect.
   * @internal
   */
  class AbstractOperation {
    constructor(options = {}) {
      this.readPreference = this.hasAspect(exports.Aspect.WRITE_OPERATION)
        ? read_preference_1.ReadPreference.primary
        : read_preference_1.ReadPreference.fromOptions(options) ??
          read_preference_1.ReadPreference.primary;
      // Pull the BSON serialize options from the already-resolved options
      this.bsonOptions = (0, bson_1.resolveBSONOptions)(options);
      this[kSession] = options.session != null ? options.session : undefined;
      this.options = options;
      this.bypassPinningCheck = !!options.bypassPinningCheck;
      this.trySecondaryWrite = false;
    }
    hasAspect(aspect) {
      const ctor = this.constructor;
      if (ctor.aspects == null) {
        return false;
      }
      return ctor.aspects.has(aspect);
    }
    get session() {
      return this[kSession];
    }
    clearSession() {
      this[kSession] = undefined;
    }
    get canRetryRead() {
      return true;
    }
    get canRetryWrite() {
      return true;
    }
  }
  exports.AbstractOperation = AbstractOperation;
  function defineAspects(operation, aspects) {
    if (!Array.isArray(aspects) && !(aspects instanceof Set)) {
      aspects = [aspects];
    }
    aspects = new Set(aspects);
    Object.defineProperty(operation, "aspects", {
      value: aspects,
      writable: false,
    });
    return aspects;
  }
  exports.defineAspects = defineAspects;
})(operation);

Object.defineProperty(execute_operation, "__esModule", { value: true });
execute_operation.executeOperation = void 0;
const error_1$I = error;
const read_preference_1$4 = read_preference;
const server_selection_1$1 = server_selection;
const utils_1$s = utils$2;
const operation_1$n = operation;
const MMAPv1_RETRY_WRITES_ERROR_CODE =
  error_1$I.MONGODB_ERROR_CODES.IllegalOperation;
const MMAPv1_RETRY_WRITES_ERROR_MESSAGE =
  "This MongoDB deployment does not support retryable writes. Please add retryWrites=false to your connection string.";
function executeOperation(client, operation, callback) {
  return (0, utils_1$s.maybeCallback)(
    () => executeOperationAsync(client, operation),
    callback,
  );
}
execute_operation.executeOperation = executeOperation;
async function executeOperationAsync(client, operation) {
  if (!(operation instanceof operation_1$n.AbstractOperation)) {
    // TODO(NODE-3483): Extend MongoRuntimeError
    throw new error_1$I.MongoRuntimeError(
      "This method requires a valid operation instance",
    );
  }
  if (client.topology == null) {
    // Auto connect on operation
    if (client.s.hasBeenClosed) {
      throw new error_1$I.MongoNotConnectedError(
        "Client must be connected before running operations",
      );
    }
    client.s.options[Symbol.for("@@mdb.skipPingOnConnect")] = true;
    try {
      await client.connect();
    } finally {
      delete client.s.options[Symbol.for("@@mdb.skipPingOnConnect")];
    }
  }
  const { topology } = client;
  if (topology == null) {
    throw new error_1$I.MongoRuntimeError(
      "client.connect did not create a topology but also did not throw",
    );
  }
  // The driver sessions spec mandates that we implicitly create sessions for operations
  // that are not explicitly provided with a session.
  let session = operation.session;
  let owner;
  if (session == null) {
    owner = Symbol();
    session = client.startSession({ owner, explicit: false });
  } else if (session.hasEnded) {
    throw new error_1$I.MongoExpiredSessionError(
      "Use of expired sessions is not permitted",
    );
  } else if (
    session.snapshotEnabled &&
    !topology.capabilities.supportsSnapshotReads
  ) {
    throw new error_1$I.MongoCompatibilityError(
      "Snapshot reads require MongoDB 5.0 or later",
    );
  } else if (session.client !== client) {
    throw new error_1$I.MongoInvalidArgumentError(
      "ClientSession must be from the same MongoClient",
    );
  }
  const readPreference =
    operation.readPreference ?? read_preference_1$4.ReadPreference.primary;
  const inTransaction = !!session?.inTransaction();
  if (
    inTransaction &&
    !readPreference.equals(read_preference_1$4.ReadPreference.primary)
  ) {
    throw new error_1$I.MongoTransactionError(
      `Read preference in a transaction must be primary, not: ${readPreference.mode}`,
    );
  }
  if (
    session?.isPinned &&
    session.transaction.isCommitted &&
    !operation.bypassPinningCheck
  ) {
    session.unpin();
  }
  let selector;
  if (operation.hasAspect(operation_1$n.Aspect.MUST_SELECT_SAME_SERVER)) {
    // GetMore and KillCursor operations must always select the same server, but run through
    // server selection to potentially force monitor checks if the server is
    // in an unknown state.
    selector = (0, server_selection_1$1.sameServerSelector)(
      operation.server?.description,
    );
  } else if (operation.trySecondaryWrite) {
    // If operation should try to write to secondary use the custom server selector
    // otherwise provide the read preference.
    selector = (0, server_selection_1$1.secondaryWritableServerSelector)(
      topology.commonWireVersion,
      readPreference,
    );
  } else {
    selector = readPreference;
  }
  const server = await topology.selectServerAsync(selector, { session });
  if (session == null) {
    // No session also means it is not retryable, early exit
    return operation.execute(server, undefined);
  }
  if (!operation.hasAspect(operation_1$n.Aspect.RETRYABLE)) {
    // non-retryable operation, early exit
    try {
      return await operation.execute(server, session);
    } finally {
      if (session?.owner != null && session.owner === owner) {
        await session.endSession().catch(() => null);
      }
    }
  }
  const willRetryRead =
    topology.s.options.retryReads && !inTransaction && operation.canRetryRead;
  const willRetryWrite =
    topology.s.options.retryWrites &&
    !inTransaction &&
    (0, utils_1$s.supportsRetryableWrites)(server) &&
    operation.canRetryWrite;
  const hasReadAspect = operation.hasAspect(
    operation_1$n.Aspect.READ_OPERATION,
  );
  const hasWriteAspect = operation.hasAspect(
    operation_1$n.Aspect.WRITE_OPERATION,
  );
  const willRetry =
    (hasReadAspect && willRetryRead) || (hasWriteAspect && willRetryWrite);
  if (hasWriteAspect && willRetryWrite) {
    operation.options.willRetryWrite = true;
    session.incrementTransactionNumber();
  }
  try {
    return await operation.execute(server, session);
  } catch (operationError) {
    if (willRetry && operationError instanceof error_1$I.MongoError) {
      return await retryOperation(operation, operationError, {
        session,
        topology,
        selector,
      });
    }
    throw operationError;
  } finally {
    if (session?.owner != null && session.owner === owner) {
      await session.endSession().catch(() => null);
    }
  }
}
async function retryOperation(
  operation,
  originalError,
  { session, topology, selector },
) {
  const isWriteOperation = operation.hasAspect(
    operation_1$n.Aspect.WRITE_OPERATION,
  );
  const isReadOperation = operation.hasAspect(
    operation_1$n.Aspect.READ_OPERATION,
  );
  if (
    isWriteOperation &&
    originalError.code === MMAPv1_RETRY_WRITES_ERROR_CODE
  ) {
    throw new error_1$I.MongoServerError({
      message: MMAPv1_RETRY_WRITES_ERROR_MESSAGE,
      errmsg: MMAPv1_RETRY_WRITES_ERROR_MESSAGE,
      originalError,
    });
  }
  if (
    isWriteOperation &&
    !(0, error_1$I.isRetryableWriteError)(originalError)
  ) {
    throw originalError;
  }
  if (isReadOperation && !(0, error_1$I.isRetryableReadError)(originalError)) {
    throw originalError;
  }
  if (
    originalError instanceof error_1$I.MongoNetworkError &&
    session.isPinned &&
    !session.inTransaction() &&
    operation.hasAspect(operation_1$n.Aspect.CURSOR_CREATING)
  ) {
    // If we have a cursor and the initial command fails with a network error,
    // we can retry it on another connection. So we need to check it back in, clear the
    // pool for the service id, and retry again.
    session.unpin({ force: true, forceClear: true });
  }
  // select a new server, and attempt to retry the operation
  const server = await topology.selectServerAsync(selector, { session });
  if (isWriteOperation && !(0, utils_1$s.supportsRetryableWrites)(server)) {
    throw new error_1$I.MongoUnexpectedServerResponseError(
      "Selected server does not support retryable writes",
    );
  }
  try {
    return await operation.execute(server, session);
  } catch (retryError) {
    if (
      retryError instanceof error_1$I.MongoError &&
      retryError.hasErrorLabel(error_1$I.MongoErrorLabel.NoWritesPerformed)
    ) {
      throw originalError;
    }
    throw retryError;
  }
}

var list_databases = {};

var command = {};

var explain = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.Explain = exports.ExplainVerbosity = void 0;
  const error_1 = error;
  /** @public */
  exports.ExplainVerbosity = Object.freeze({
    queryPlanner: "queryPlanner",
    queryPlannerExtended: "queryPlannerExtended",
    executionStats: "executionStats",
    allPlansExecution: "allPlansExecution",
  });
  /** @internal */
  class Explain {
    constructor(verbosity) {
      if (typeof verbosity === "boolean") {
        this.verbosity = verbosity
          ? exports.ExplainVerbosity.allPlansExecution
          : exports.ExplainVerbosity.queryPlanner;
      } else {
        this.verbosity = verbosity;
      }
    }
    static fromOptions(options) {
      if (options?.explain == null) return;
      const explain = options.explain;
      if (typeof explain === "boolean" || typeof explain === "string") {
        return new Explain(explain);
      }
      throw new error_1.MongoInvalidArgumentError(
        'Field "explain" must be a string or a boolean',
      );
    }
  }
  exports.Explain = Explain;
})(explain);

Object.defineProperty(command, "__esModule", { value: true });
command.CommandOperation = void 0;
const error_1$H = error;
const explain_1 = explain;
const read_concern_1$2 = read_concern;
const server_selection_1 = server_selection;
const utils_1$r = utils$2;
const write_concern_1$4 = write_concern;
const operation_1$m = operation;
/** @internal */
class CommandOperation extends operation_1$m.AbstractOperation {
  constructor(parent, options) {
    super(options);
    this.options = options ?? {};
    // NOTE: this was explicitly added for the add/remove user operations, it's likely
    //       something we'd want to reconsider. Perhaps those commands can use `Admin`
    //       as a parent?
    const dbNameOverride = options?.dbName || options?.authdb;
    if (dbNameOverride) {
      this.ns = new utils_1$r.MongoDBNamespace(dbNameOverride, "$cmd");
    } else {
      this.ns = parent
        ? parent.s.namespace.withCollection("$cmd")
        : new utils_1$r.MongoDBNamespace("admin", "$cmd");
    }
    this.readConcern = read_concern_1$2.ReadConcern.fromOptions(options);
    this.writeConcern = write_concern_1$4.WriteConcern.fromOptions(options);
    if (this.hasAspect(operation_1$m.Aspect.EXPLAINABLE)) {
      this.explain = explain_1.Explain.fromOptions(options);
    } else if (options?.explain != null) {
      throw new error_1$H.MongoInvalidArgumentError(
        `Option "explain" is not supported on this command`,
      );
    }
  }
  get canRetryWrite() {
    if (this.hasAspect(operation_1$m.Aspect.EXPLAINABLE)) {
      return this.explain == null;
    }
    return true;
  }
  async executeCommand(server, session, cmd) {
    // TODO: consider making this a non-enumerable property
    this.server = server;
    const options = {
      ...this.options,
      ...this.bsonOptions,
      readPreference: this.readPreference,
      session,
    };
    const serverWireVersion = (0, utils_1$r.maxWireVersion)(server);
    const inTransaction = this.session && this.session.inTransaction();
    if (
      this.readConcern &&
      (0, utils_1$r.commandSupportsReadConcern)(cmd) &&
      !inTransaction
    ) {
      Object.assign(cmd, { readConcern: this.readConcern });
    }
    if (
      this.trySecondaryWrite &&
      serverWireVersion < server_selection_1.MIN_SECONDARY_WRITE_WIRE_VERSION
    ) {
      options.omitReadPreference = true;
    }
    if (
      this.writeConcern &&
      this.hasAspect(operation_1$m.Aspect.WRITE_OPERATION) &&
      !inTransaction
    ) {
      write_concern_1$4.WriteConcern.apply(cmd, this.writeConcern);
    }
    if (
      options.collation &&
      typeof options.collation === "object" &&
      !this.hasAspect(operation_1$m.Aspect.SKIP_COLLATION)
    ) {
      Object.assign(cmd, { collation: options.collation });
    }
    if (typeof options.maxTimeMS === "number") {
      cmd.maxTimeMS = options.maxTimeMS;
    }
    if (this.hasAspect(operation_1$m.Aspect.EXPLAINABLE) && this.explain) {
      cmd = (0, utils_1$r.decorateWithExplain)(cmd, this.explain);
    }
    return server.commandAsync(this.ns, cmd, options);
  }
}
command.CommandOperation = CommandOperation;

Object.defineProperty(list_databases, "__esModule", { value: true });
list_databases.ListDatabasesOperation = void 0;
const utils_1$q = utils$2;
const command_1$e = command;
const operation_1$l = operation;
/** @internal */
class ListDatabasesOperation extends command_1$e.CommandOperation {
  constructor(db, options) {
    super(db, options);
    this.options = options ?? {};
    this.ns = new utils_1$q.MongoDBNamespace("admin", "$cmd");
  }
  async execute(server, session) {
    const cmd = { listDatabases: 1 };
    if (typeof this.options.nameOnly === "boolean") {
      cmd.nameOnly = this.options.nameOnly;
    }
    if (this.options.filter) {
      cmd.filter = this.options.filter;
    }
    if (typeof this.options.authorizedDatabases === "boolean") {
      cmd.authorizedDatabases = this.options.authorizedDatabases;
    }
    // we check for undefined specifically here to allow falsy values
    // eslint-disable-next-line no-restricted-syntax
    if (
      (0, utils_1$q.maxWireVersion)(server) >= 9 &&
      this.options.comment !== undefined
    ) {
      cmd.comment = this.options.comment;
    }
    return super.executeCommand(server, session, cmd);
  }
}
list_databases.ListDatabasesOperation = ListDatabasesOperation;
(0, operation_1$l.defineAspects)(ListDatabasesOperation, [
  operation_1$l.Aspect.READ_OPERATION,
  operation_1$l.Aspect.RETRYABLE,
]);

var remove_user = {};

Object.defineProperty(remove_user, "__esModule", { value: true });
remove_user.RemoveUserOperation = void 0;
const command_1$d = command;
const operation_1$k = operation;
/** @internal */
class RemoveUserOperation extends command_1$d.CommandOperation {
  constructor(db, username, options) {
    super(db, options);
    this.options = options;
    this.username = username;
  }
  async execute(server, session) {
    await super.executeCommand(server, session, { dropUser: this.username });
    return true;
  }
}
remove_user.RemoveUserOperation = RemoveUserOperation;
(0, operation_1$k.defineAspects)(RemoveUserOperation, [
  operation_1$k.Aspect.WRITE_OPERATION,
]);

var run_command = {};

Object.defineProperty(run_command, "__esModule", { value: true });
run_command.RunAdminCommandOperation = run_command.RunCommandOperation = void 0;
const utils_1$p = utils$2;
const operation_1$j = operation;
/** @internal */
class RunCommandOperation extends operation_1$j.AbstractOperation {
  constructor(parent, command, options) {
    super(options);
    this.command = command;
    this.options = options;
    this.ns = parent.s.namespace.withCollection("$cmd");
  }
  async execute(server, session) {
    this.server = server;
    return server.commandAsync(this.ns, this.command, {
      ...this.options,
      readPreference: this.readPreference,
      session,
    });
  }
}
run_command.RunCommandOperation = RunCommandOperation;
class RunAdminCommandOperation extends operation_1$j.AbstractOperation {
  constructor(command, options) {
    super(options);
    this.command = command;
    this.options = options;
    this.ns = new utils_1$p.MongoDBNamespace("admin", "$cmd");
  }
  async execute(server, session) {
    this.server = server;
    return server.commandAsync(this.ns, this.command, {
      ...this.options,
      readPreference: this.readPreference,
      session,
    });
  }
}
run_command.RunAdminCommandOperation = RunAdminCommandOperation;

var validate_collection = {};

Object.defineProperty(validate_collection, "__esModule", { value: true });
validate_collection.ValidateCollectionOperation = void 0;
const error_1$G = error;
const command_1$c = command;
/** @internal */
class ValidateCollectionOperation extends command_1$c.CommandOperation {
  constructor(admin, collectionName, options) {
    // Decorate command with extra options
    const command = { validate: collectionName };
    const keys = Object.keys(options);
    for (let i = 0; i < keys.length; i++) {
      if (
        Object.prototype.hasOwnProperty.call(options, keys[i]) &&
        keys[i] !== "session"
      ) {
        command[keys[i]] = options[keys[i]];
      }
    }
    super(admin.s.db, options);
    this.options = options;
    this.command = command;
    this.collectionName = collectionName;
  }
  async execute(server, session) {
    const collectionName = this.collectionName;
    const doc = await super.executeCommand(server, session, this.command);
    if (doc.result != null && typeof doc.result !== "string")
      throw new error_1$G.MongoUnexpectedServerResponseError(
        "Error with validation data",
      );
    if (doc.result != null && doc.result.match(/exception|corrupt/) != null)
      throw new error_1$G.MongoUnexpectedServerResponseError(
        `Invalid collection ${collectionName}`,
      );
    if (doc.valid != null && !doc.valid)
      throw new error_1$G.MongoUnexpectedServerResponseError(
        `Invalid collection ${collectionName}`,
      );
    return doc;
  }
}
validate_collection.ValidateCollectionOperation = ValidateCollectionOperation;

Object.defineProperty(admin, "__esModule", { value: true });
admin.Admin = void 0;
const bson_1$b = bson$2;
const execute_operation_1$6 = execute_operation;
const list_databases_1 = list_databases;
const remove_user_1 = remove_user;
const run_command_1$2 = run_command;
const validate_collection_1 = validate_collection;
/**
 * The **Admin** class is an internal class that allows convenient access to
 * the admin functionality and commands for MongoDB.
 *
 * **ADMIN Cannot directly be instantiated**
 * @public
 *
 * @example
 * ```ts
 * import { MongoClient } from 'mongodb';
 *
 * const client = new MongoClient('mongodb://localhost:27017');
 * const admin = client.db().admin();
 * const dbInfo = await admin.listDatabases();
 * for (const db of dbInfo.databases) {
 *   console.log(db.name);
 * }
 * ```
 */
let Admin$1 = class Admin {
  /**
   * Create a new Admin instance
   * @internal
   */
  constructor(db) {
    this.s = { db };
  }
  /**
   * Execute a command
   *
   * The driver will ensure the following fields are attached to the command sent to the server:
   * - `lsid` - sourced from an implicit session or options.session
   * - `$readPreference` - defaults to primary or can be configured by options.readPreference
   * - `$db` - sourced from the name of this database
   *
   * If the client has a serverApi setting:
   * - `apiVersion`
   * - `apiStrict`
   * - `apiDeprecationErrors`
   *
   * When in a transaction:
   * - `readConcern` - sourced from readConcern set on the TransactionOptions
   * - `writeConcern` - sourced from writeConcern set on the TransactionOptions
   *
   * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.
   *
   * @param command - The command to execute
   * @param options - Optional settings for the command
   */
  async command(command, options) {
    return (0, execute_operation_1$6.executeOperation)(
      this.s.db.client,
      new run_command_1$2.RunAdminCommandOperation(command, {
        ...(0, bson_1$b.resolveBSONOptions)(options),
        session: options?.session,
        readPreference: options?.readPreference,
      }),
    );
  }
  /**
   * Retrieve the server build information
   *
   * @param options - Optional settings for the command
   */
  async buildInfo(options) {
    return this.command({ buildinfo: 1 }, options);
  }
  /**
   * Retrieve the server build information
   *
   * @param options - Optional settings for the command
   */
  async serverInfo(options) {
    return this.command({ buildinfo: 1 }, options);
  }
  /**
   * Retrieve this db's server status.
   *
   * @param options - Optional settings for the command
   */
  async serverStatus(options) {
    return this.command({ serverStatus: 1 }, options);
  }
  /**
   * Ping the MongoDB server and retrieve results
   *
   * @param options - Optional settings for the command
   */
  async ping(options) {
    return this.command({ ping: 1 }, options);
  }
  /**
   * Remove a user from a database
   *
   * @param username - The username to remove
   * @param options - Optional settings for the command
   */
  async removeUser(username, options) {
    return (0, execute_operation_1$6.executeOperation)(
      this.s.db.client,
      new remove_user_1.RemoveUserOperation(this.s.db, username, {
        dbName: "admin",
        ...options,
      }),
    );
  }
  /**
   * Validate an existing collection
   *
   * @param collectionName - The name of the collection to validate.
   * @param options - Optional settings for the command
   */
  async validateCollection(collectionName, options = {}) {
    return (0, execute_operation_1$6.executeOperation)(
      this.s.db.client,
      new validate_collection_1.ValidateCollectionOperation(
        this,
        collectionName,
        options,
      ),
    );
  }
  /**
   * List the available databases
   *
   * @param options - Optional settings for the command
   */
  async listDatabases(options) {
    return (0, execute_operation_1$6.executeOperation)(
      this.s.db.client,
      new list_databases_1.ListDatabasesOperation(this.s.db, options),
    );
  }
  /**
   * Get ReplicaSet status
   *
   * @param options - Optional settings for the command
   */
  async replSetGetStatus(options) {
    return this.command({ replSetGetStatus: 1 }, options);
  }
};
admin.Admin = Admin$1;

var ordered = {};

var common = {};

var _delete = {};

Object.defineProperty(_delete, "__esModule", { value: true });
_delete.makeDeleteStatement =
  _delete.DeleteManyOperation =
  _delete.DeleteOneOperation =
  _delete.DeleteOperation =
    void 0;
const error_1$F = error;
const command_1$b = command;
const operation_1$i = operation;
/** @internal */
class DeleteOperation extends command_1$b.CommandOperation {
  constructor(ns, statements, options) {
    super(undefined, options);
    this.options = options;
    this.ns = ns;
    this.statements = statements;
  }
  get canRetryWrite() {
    if (super.canRetryWrite === false) {
      return false;
    }
    return this.statements.every((op) =>
      op.limit != null ? op.limit > 0 : true,
    );
  }
  async execute(server, session) {
    const options = this.options ?? {};
    const ordered =
      typeof options.ordered === "boolean" ? options.ordered : true;
    const command = {
      delete: this.ns.collection,
      deletes: this.statements,
      ordered,
    };
    if (options.let) {
      command.let = options.let;
    }
    // we check for undefined specifically here to allow falsy values
    // eslint-disable-next-line no-restricted-syntax
    if (options.comment !== undefined) {
      command.comment = options.comment;
    }
    const unacknowledgedWrite = this.writeConcern && this.writeConcern.w === 0;
    if (unacknowledgedWrite) {
      if (this.statements.find((o) => o.hint)) {
        // TODO(NODE-3541): fix error for hint with unacknowledged writes
        throw new error_1$F.MongoCompatibilityError(
          `hint is not supported with unacknowledged writes`,
        );
      }
    }
    return super.executeCommand(server, session, command);
  }
}
_delete.DeleteOperation = DeleteOperation;
class DeleteOneOperation extends DeleteOperation {
  constructor(collection, filter, options) {
    super(
      collection.s.namespace,
      [makeDeleteStatement(filter, { ...options, limit: 1 })],
      options,
    );
  }
  async execute(server, session) {
    const res = await super.execute(server, session);
    if (this.explain) return res;
    if (res.code) throw new error_1$F.MongoServerError(res);
    if (res.writeErrors)
      throw new error_1$F.MongoServerError(res.writeErrors[0]);
    return {
      acknowledged: this.writeConcern?.w !== 0,
      deletedCount: res.n,
    };
  }
}
_delete.DeleteOneOperation = DeleteOneOperation;
class DeleteManyOperation extends DeleteOperation {
  constructor(collection, filter, options) {
    super(
      collection.s.namespace,
      [makeDeleteStatement(filter, options)],
      options,
    );
  }
  async execute(server, session) {
    const res = await super.execute(server, session);
    if (this.explain) return res;
    if (res.code) throw new error_1$F.MongoServerError(res);
    if (res.writeErrors)
      throw new error_1$F.MongoServerError(res.writeErrors[0]);
    return {
      acknowledged: this.writeConcern?.w !== 0,
      deletedCount: res.n,
    };
  }
}
_delete.DeleteManyOperation = DeleteManyOperation;
function makeDeleteStatement(filter, options) {
  const op = {
    q: filter,
    limit: typeof options.limit === "number" ? options.limit : 0,
  };
  if (options.collation) {
    op.collation = options.collation;
  }
  if (options.hint) {
    op.hint = options.hint;
  }
  return op;
}
_delete.makeDeleteStatement = makeDeleteStatement;
(0, operation_1$i.defineAspects)(DeleteOperation, [
  operation_1$i.Aspect.RETRYABLE,
  operation_1$i.Aspect.WRITE_OPERATION,
]);
(0, operation_1$i.defineAspects)(DeleteOneOperation, [
  operation_1$i.Aspect.RETRYABLE,
  operation_1$i.Aspect.WRITE_OPERATION,
  operation_1$i.Aspect.EXPLAINABLE,
  operation_1$i.Aspect.SKIP_COLLATION,
]);
(0, operation_1$i.defineAspects)(DeleteManyOperation, [
  operation_1$i.Aspect.WRITE_OPERATION,
  operation_1$i.Aspect.EXPLAINABLE,
  operation_1$i.Aspect.SKIP_COLLATION,
]);

var insert = {};

var bulk_write = {};

Object.defineProperty(bulk_write, "__esModule", { value: true });
bulk_write.BulkWriteOperation = void 0;
const operation_1$h = operation;
/** @internal */
class BulkWriteOperation extends operation_1$h.AbstractOperation {
  constructor(collection, operations, options) {
    super(options);
    this.options = options;
    this.collection = collection;
    this.operations = operations;
  }
  async execute(server, session) {
    const coll = this.collection;
    const operations = this.operations;
    const options = {
      ...this.options,
      ...this.bsonOptions,
      readPreference: this.readPreference,
    };
    // Create the bulk operation
    const bulk =
      options.ordered === false
        ? coll.initializeUnorderedBulkOp(options)
        : coll.initializeOrderedBulkOp(options);
    // for each op go through and add to the bulk
    for (let i = 0; i < operations.length; i++) {
      bulk.raw(operations[i]);
    }
    // Execute the bulk
    const result = await bulk.execute({ ...options, session });
    return result;
  }
}
bulk_write.BulkWriteOperation = BulkWriteOperation;
(0, operation_1$h.defineAspects)(BulkWriteOperation, [
  operation_1$h.Aspect.WRITE_OPERATION,
]);

var common_functions = {};

Object.defineProperty(common_functions, "__esModule", { value: true });
common_functions.prepareDocs = common_functions.indexInformation = void 0;
async function indexInformation(db, name, options) {
  if (options == null) {
    options = {};
  }
  // If we specified full information
  const full = options.full == null ? false : options.full;
  // Get the list of indexes of the specified collection
  const indexes = await db.collection(name).listIndexes(options).toArray();
  if (full) return indexes;
  const info = {};
  for (const index of indexes) {
    info[index.name] = Object.entries(index.key);
  }
  return info;
}
common_functions.indexInformation = indexInformation;
function prepareDocs(coll, docs, options) {
  const forceServerObjectId =
    typeof options.forceServerObjectId === "boolean"
      ? options.forceServerObjectId
      : coll.s.db.options?.forceServerObjectId;
  // no need to modify the docs if server sets the ObjectId
  if (forceServerObjectId === true) {
    return docs;
  }
  return docs.map((doc) => {
    if (doc._id == null) {
      doc._id = coll.s.pkFactory.createPk();
    }
    return doc;
  });
}
common_functions.prepareDocs = prepareDocs;

Object.defineProperty(insert, "__esModule", { value: true });
insert.InsertManyOperation =
  insert.InsertOneOperation =
  insert.InsertOperation =
    void 0;
const error_1$E = error;
const write_concern_1$3 = write_concern;
const bulk_write_1 = bulk_write;
const command_1$a = command;
const common_functions_1$1 = common_functions;
const operation_1$g = operation;
/** @internal */
class InsertOperation extends command_1$a.CommandOperation {
  constructor(ns, documents, options) {
    super(undefined, options);
    this.options = { ...options, checkKeys: options.checkKeys ?? false };
    this.ns = ns;
    this.documents = documents;
  }
  async execute(server, session) {
    const options = this.options ?? {};
    const ordered =
      typeof options.ordered === "boolean" ? options.ordered : true;
    const command = {
      insert: this.ns.collection,
      documents: this.documents,
      ordered,
    };
    if (typeof options.bypassDocumentValidation === "boolean") {
      command.bypassDocumentValidation = options.bypassDocumentValidation;
    }
    // we check for undefined specifically here to allow falsy values
    // eslint-disable-next-line no-restricted-syntax
    if (options.comment !== undefined) {
      command.comment = options.comment;
    }
    return super.executeCommand(server, session, command);
  }
}
insert.InsertOperation = InsertOperation;
class InsertOneOperation extends InsertOperation {
  constructor(collection, doc, options) {
    super(
      collection.s.namespace,
      (0, common_functions_1$1.prepareDocs)(collection, [doc], options),
      options,
    );
  }
  async execute(server, session) {
    const res = await super.execute(server, session);
    if (res.code) throw new error_1$E.MongoServerError(res);
    if (res.writeErrors) {
      // This should be a WriteError but we can't change it now because of error hierarchy
      throw new error_1$E.MongoServerError(res.writeErrors[0]);
    }
    return {
      acknowledged: this.writeConcern?.w !== 0,
      insertedId: this.documents[0]._id,
    };
  }
}
insert.InsertOneOperation = InsertOneOperation;
/** @internal */
class InsertManyOperation extends operation_1$g.AbstractOperation {
  constructor(collection, docs, options) {
    super(options);
    if (!Array.isArray(docs)) {
      throw new error_1$E.MongoInvalidArgumentError(
        'Argument "docs" must be an array of documents',
      );
    }
    this.options = options;
    this.collection = collection;
    this.docs = docs;
  }
  async execute(server, session) {
    const coll = this.collection;
    const options = {
      ...this.options,
      ...this.bsonOptions,
      readPreference: this.readPreference,
    };
    const writeConcern = write_concern_1$3.WriteConcern.fromOptions(options);
    const bulkWriteOperation = new bulk_write_1.BulkWriteOperation(
      coll,
      (0, common_functions_1$1.prepareDocs)(coll, this.docs, options).map(
        (document) => ({ insertOne: { document } }),
      ),
      options,
    );
    try {
      const res = await bulkWriteOperation.execute(server, session);
      return {
        acknowledged: writeConcern?.w !== 0,
        insertedCount: res.insertedCount,
        insertedIds: res.insertedIds,
      };
    } catch (err) {
      if (
        err &&
        err.message === "Operation must be an object with an operation key"
      ) {
        throw new error_1$E.MongoInvalidArgumentError(
          "Collection.insertMany() cannot be called with an array that has null/undefined values",
        );
      }
      throw err;
    }
  }
}
insert.InsertManyOperation = InsertManyOperation;
(0, operation_1$g.defineAspects)(InsertOperation, [
  operation_1$g.Aspect.RETRYABLE,
  operation_1$g.Aspect.WRITE_OPERATION,
]);
(0, operation_1$g.defineAspects)(InsertOneOperation, [
  operation_1$g.Aspect.RETRYABLE,
  operation_1$g.Aspect.WRITE_OPERATION,
]);
(0, operation_1$g.defineAspects)(InsertManyOperation, [
  operation_1$g.Aspect.WRITE_OPERATION,
]);

var update$1 = {};

Object.defineProperty(update$1, "__esModule", { value: true });
update$1.makeUpdateStatement =
  update$1.ReplaceOneOperation =
  update$1.UpdateManyOperation =
  update$1.UpdateOneOperation =
  update$1.UpdateOperation =
    void 0;
const error_1$D = error;
const utils_1$o = utils$2;
const command_1$9 = command;
const operation_1$f = operation;
/**
 * @internal
 * UpdateOperation is used in bulk write, while UpdateOneOperation and UpdateManyOperation are only used in the collections API
 */
class UpdateOperation extends command_1$9.CommandOperation {
  constructor(ns, statements, options) {
    super(undefined, options);
    this.options = options;
    this.ns = ns;
    this.statements = statements;
  }
  get canRetryWrite() {
    if (super.canRetryWrite === false) {
      return false;
    }
    return this.statements.every(
      (op) => op.multi == null || op.multi === false,
    );
  }
  async execute(server, session) {
    const options = this.options ?? {};
    const ordered =
      typeof options.ordered === "boolean" ? options.ordered : true;
    const command = {
      update: this.ns.collection,
      updates: this.statements,
      ordered,
    };
    if (typeof options.bypassDocumentValidation === "boolean") {
      command.bypassDocumentValidation = options.bypassDocumentValidation;
    }
    if (options.let) {
      command.let = options.let;
    }
    // we check for undefined specifically here to allow falsy values
    // eslint-disable-next-line no-restricted-syntax
    if (options.comment !== undefined) {
      command.comment = options.comment;
    }
    const unacknowledgedWrite = this.writeConcern && this.writeConcern.w === 0;
    if (unacknowledgedWrite) {
      if (this.statements.find((o) => o.hint)) {
        // TODO(NODE-3541): fix error for hint with unacknowledged writes
        throw new error_1$D.MongoCompatibilityError(
          `hint is not supported with unacknowledged writes`,
        );
      }
    }
    return super.executeCommand(server, session, command);
  }
}
update$1.UpdateOperation = UpdateOperation;
/** @internal */
class UpdateOneOperation extends UpdateOperation {
  constructor(collection, filter, update, options) {
    super(
      collection.s.namespace,
      [makeUpdateStatement(filter, update, { ...options, multi: false })],
      options,
    );
    if (!(0, utils_1$o.hasAtomicOperators)(update)) {
      throw new error_1$D.MongoInvalidArgumentError(
        "Update document requires atomic operators",
      );
    }
  }
  async execute(server, session) {
    const res = await super.execute(server, session);
    if (this.explain != null) return res;
    if (res.code) throw new error_1$D.MongoServerError(res);
    if (res.writeErrors)
      throw new error_1$D.MongoServerError(res.writeErrors[0]);
    return {
      acknowledged: this.writeConcern?.w !== 0,
      modifiedCount: res.nModified ?? res.n,
      upsertedId:
        Array.isArray(res.upserted) && res.upserted.length > 0
          ? res.upserted[0]._id
          : null,
      upsertedCount:
        Array.isArray(res.upserted) && res.upserted.length
          ? res.upserted.length
          : 0,
      matchedCount:
        Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n,
    };
  }
}
update$1.UpdateOneOperation = UpdateOneOperation;
/** @internal */
class UpdateManyOperation extends UpdateOperation {
  constructor(collection, filter, update, options) {
    super(
      collection.s.namespace,
      [makeUpdateStatement(filter, update, { ...options, multi: true })],
      options,
    );
    if (!(0, utils_1$o.hasAtomicOperators)(update)) {
      throw new error_1$D.MongoInvalidArgumentError(
        "Update document requires atomic operators",
      );
    }
  }
  async execute(server, session) {
    const res = await super.execute(server, session);
    if (this.explain != null) return res;
    if (res.code) throw new error_1$D.MongoServerError(res);
    if (res.writeErrors)
      throw new error_1$D.MongoServerError(res.writeErrors[0]);
    return {
      acknowledged: this.writeConcern?.w !== 0,
      modifiedCount: res.nModified ?? res.n,
      upsertedId:
        Array.isArray(res.upserted) && res.upserted.length > 0
          ? res.upserted[0]._id
          : null,
      upsertedCount:
        Array.isArray(res.upserted) && res.upserted.length
          ? res.upserted.length
          : 0,
      matchedCount:
        Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n,
    };
  }
}
update$1.UpdateManyOperation = UpdateManyOperation;
/** @internal */
class ReplaceOneOperation extends UpdateOperation {
  constructor(collection, filter, replacement, options) {
    super(
      collection.s.namespace,
      [makeUpdateStatement(filter, replacement, { ...options, multi: false })],
      options,
    );
    if ((0, utils_1$o.hasAtomicOperators)(replacement)) {
      throw new error_1$D.MongoInvalidArgumentError(
        "Replacement document must not contain atomic operators",
      );
    }
  }
  async execute(server, session) {
    const res = await super.execute(server, session);
    if (this.explain != null) return res;
    if (res.code) throw new error_1$D.MongoServerError(res);
    if (res.writeErrors)
      throw new error_1$D.MongoServerError(res.writeErrors[0]);
    return {
      acknowledged: this.writeConcern?.w !== 0,
      modifiedCount: res.nModified ?? res.n,
      upsertedId:
        Array.isArray(res.upserted) && res.upserted.length > 0
          ? res.upserted[0]._id
          : null,
      upsertedCount:
        Array.isArray(res.upserted) && res.upserted.length
          ? res.upserted.length
          : 0,
      matchedCount:
        Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n,
    };
  }
}
update$1.ReplaceOneOperation = ReplaceOneOperation;
function makeUpdateStatement(filter, update, options) {
  if (filter == null || typeof filter !== "object") {
    throw new error_1$D.MongoInvalidArgumentError(
      "Selector must be a valid JavaScript object",
    );
  }
  if (update == null || typeof update !== "object") {
    throw new error_1$D.MongoInvalidArgumentError(
      "Document must be a valid JavaScript object",
    );
  }
  const op = { q: filter, u: update };
  if (typeof options.upsert === "boolean") {
    op.upsert = options.upsert;
  }
  if (options.multi) {
    op.multi = options.multi;
  }
  if (options.hint) {
    op.hint = options.hint;
  }
  if (options.arrayFilters) {
    op.arrayFilters = options.arrayFilters;
  }
  if (options.collation) {
    op.collation = options.collation;
  }
  return op;
}
update$1.makeUpdateStatement = makeUpdateStatement;
(0, operation_1$f.defineAspects)(UpdateOperation, [
  operation_1$f.Aspect.RETRYABLE,
  operation_1$f.Aspect.WRITE_OPERATION,
  operation_1$f.Aspect.SKIP_COLLATION,
]);
(0, operation_1$f.defineAspects)(UpdateOneOperation, [
  operation_1$f.Aspect.RETRYABLE,
  operation_1$f.Aspect.WRITE_OPERATION,
  operation_1$f.Aspect.EXPLAINABLE,
  operation_1$f.Aspect.SKIP_COLLATION,
]);
(0, operation_1$f.defineAspects)(UpdateManyOperation, [
  operation_1$f.Aspect.WRITE_OPERATION,
  operation_1$f.Aspect.EXPLAINABLE,
  operation_1$f.Aspect.SKIP_COLLATION,
]);
(0, operation_1$f.defineAspects)(ReplaceOneOperation, [
  operation_1$f.Aspect.RETRYABLE,
  operation_1$f.Aspect.WRITE_OPERATION,
  operation_1$f.Aspect.SKIP_COLLATION,
]);

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.BulkOperationBase =
    exports.FindOperators =
    exports.MongoBulkWriteError =
    exports.mergeBatchResults =
    exports.WriteError =
    exports.WriteConcernError =
    exports.BulkWriteResult =
    exports.Batch =
    exports.BatchType =
      void 0;
  const util_1 = $noteUtil;
  const bson_1 = bson$2;
  const error_1 = error;
  const delete_1 = _delete;
  const execute_operation_1 = execute_operation;
  const insert_1 = insert;
  const operation_1 = operation;
  const update_1 = update$1;
  const utils_1 = utils$2;
  const write_concern_1 = write_concern;
  /** @internal */
  const kServerError = Symbol("serverError");
  /** @public */
  exports.BatchType = Object.freeze({
    INSERT: 1,
    UPDATE: 2,
    DELETE: 3,
  });
  /**
   * Keeps the state of a unordered batch so we can rewrite the results
   * correctly after command execution
   *
   * @public
   */
  class Batch {
    constructor(batchType, originalZeroIndex) {
      this.originalZeroIndex = originalZeroIndex;
      this.currentIndex = 0;
      this.originalIndexes = [];
      this.batchType = batchType;
      this.operations = [];
      this.size = 0;
      this.sizeBytes = 0;
    }
  }
  exports.Batch = Batch;
  /**
   * @public
   * The result of a bulk write.
   */
  class BulkWriteResult {
    static generateIdMap(ids) {
      const idMap = {};
      for (const doc of ids) {
        idMap[doc.index] = doc._id;
      }
      return idMap;
    }
    /**
     * Create a new BulkWriteResult instance
     * @internal
     */
    constructor(bulkResult, isOrdered) {
      this.result = bulkResult;
      this.insertedCount = this.result.nInserted ?? 0;
      this.matchedCount = this.result.nMatched ?? 0;
      this.modifiedCount = this.result.nModified ?? 0;
      this.deletedCount = this.result.nRemoved ?? 0;
      this.upsertedCount = this.result.upserted.length ?? 0;
      this.upsertedIds = BulkWriteResult.generateIdMap(this.result.upserted);
      this.insertedIds = BulkWriteResult.generateIdMap(
        this.getSuccessfullyInsertedIds(bulkResult, isOrdered),
      );
      Object.defineProperty(this, "result", {
        value: this.result,
        enumerable: false,
      });
    }
    /** Evaluates to true if the bulk operation correctly executes */
    get ok() {
      return this.result.ok;
    }
    /**
     * Returns document_ids that were actually inserted
     * @internal
     */
    getSuccessfullyInsertedIds(bulkResult, isOrdered) {
      if (bulkResult.writeErrors.length === 0) return bulkResult.insertedIds;
      if (isOrdered) {
        return bulkResult.insertedIds.slice(0, bulkResult.writeErrors[0].index);
      }
      return bulkResult.insertedIds.filter(
        ({ index }) =>
          !bulkResult.writeErrors.some(
            (writeError) => index === writeError.index,
          ),
      );
    }
    /** Returns the upserted id at the given index */
    getUpsertedIdAt(index) {
      return this.result.upserted[index];
    }
    /** Returns raw internal result */
    getRawResponse() {
      return this.result;
    }
    /** Returns true if the bulk operation contains a write error */
    hasWriteErrors() {
      return this.result.writeErrors.length > 0;
    }
    /** Returns the number of write errors off the bulk operation */
    getWriteErrorCount() {
      return this.result.writeErrors.length;
    }
    /** Returns a specific write error object */
    getWriteErrorAt(index) {
      return index < this.result.writeErrors.length
        ? this.result.writeErrors[index]
        : undefined;
    }
    /** Retrieve all write errors */
    getWriteErrors() {
      return this.result.writeErrors;
    }
    /** Retrieve the write concern error if one exists */
    getWriteConcernError() {
      if (this.result.writeConcernErrors.length === 0) {
        return;
      } else if (this.result.writeConcernErrors.length === 1) {
        // Return the error
        return this.result.writeConcernErrors[0];
      } else {
        // Combine the errors
        let errmsg = "";
        for (let i = 0; i < this.result.writeConcernErrors.length; i++) {
          const err = this.result.writeConcernErrors[i];
          errmsg = errmsg + err.errmsg;
          // TODO: Something better
          if (i === 0) errmsg = errmsg + " and ";
        }
        return new WriteConcernError({
          errmsg,
          code: error_1.MONGODB_ERROR_CODES.WriteConcernFailed,
        });
      }
    }
    toString() {
      return `BulkWriteResult(${this.result})`;
    }
    isOk() {
      return this.result.ok === 1;
    }
  }
  exports.BulkWriteResult = BulkWriteResult;
  /**
   * An error representing a failure by the server to apply the requested write concern to the bulk operation.
   * @public
   * @category Error
   */
  class WriteConcernError {
    constructor(error) {
      this[kServerError] = error;
    }
    /** Write concern error code. */
    get code() {
      return this[kServerError].code;
    }
    /** Write concern error message. */
    get errmsg() {
      return this[kServerError].errmsg;
    }
    /** Write concern error info. */
    get errInfo() {
      return this[kServerError].errInfo;
    }
    toJSON() {
      return this[kServerError];
    }
    toString() {
      return `WriteConcernError(${this.errmsg})`;
    }
  }
  exports.WriteConcernError = WriteConcernError;
  /**
   * An error that occurred during a BulkWrite on the server.
   * @public
   * @category Error
   */
  class WriteError {
    constructor(err) {
      this.err = err;
    }
    /** WriteError code. */
    get code() {
      return this.err.code;
    }
    /** WriteError original bulk operation index. */
    get index() {
      return this.err.index;
    }
    /** WriteError message. */
    get errmsg() {
      return this.err.errmsg;
    }
    /** WriteError details. */
    get errInfo() {
      return this.err.errInfo;
    }
    /** Returns the underlying operation that caused the error */
    getOperation() {
      return this.err.op;
    }
    toJSON() {
      return {
        code: this.err.code,
        index: this.err.index,
        errmsg: this.err.errmsg,
        op: this.err.op,
      };
    }
    toString() {
      return `WriteError(${JSON.stringify(this.toJSON())})`;
    }
  }
  exports.WriteError = WriteError;
  /** Merges results into shared data structure */
  function mergeBatchResults(batch, bulkResult, err, result) {
    // If we have an error set the result to be the err object
    if (err) {
      result = err;
    } else if (result && result.result) {
      result = result.result;
    }
    if (result == null) {
      return;
    }
    // Do we have a top level error stop processing and return
    if (result.ok === 0 && bulkResult.ok === 1) {
      bulkResult.ok = 0;
      const writeError = {
        index: 0,
        code: result.code || 0,
        errmsg: result.message,
        errInfo: result.errInfo,
        op: batch.operations[0],
      };
      bulkResult.writeErrors.push(new WriteError(writeError));
      return;
    } else if (result.ok === 0 && bulkResult.ok === 0) {
      return;
    }
    // If we have an insert Batch type
    if (isInsertBatch(batch) && result.n) {
      bulkResult.nInserted = bulkResult.nInserted + result.n;
    }
    // If we have an insert Batch type
    if (isDeleteBatch(batch) && result.n) {
      bulkResult.nRemoved = bulkResult.nRemoved + result.n;
    }
    let nUpserted = 0;
    // We have an array of upserted values, we need to rewrite the indexes
    if (Array.isArray(result.upserted)) {
      nUpserted = result.upserted.length;
      for (let i = 0; i < result.upserted.length; i++) {
        bulkResult.upserted.push({
          index: result.upserted[i].index + batch.originalZeroIndex,
          _id: result.upserted[i]._id,
        });
      }
    } else if (result.upserted) {
      nUpserted = 1;
      bulkResult.upserted.push({
        index: batch.originalZeroIndex,
        _id: result.upserted,
      });
    }
    // If we have an update Batch type
    if (isUpdateBatch(batch) && result.n) {
      const nModified = result.nModified;
      bulkResult.nUpserted = bulkResult.nUpserted + nUpserted;
      bulkResult.nMatched = bulkResult.nMatched + (result.n - nUpserted);
      if (typeof nModified === "number") {
        bulkResult.nModified = bulkResult.nModified + nModified;
      } else {
        bulkResult.nModified = 0;
      }
    }
    if (Array.isArray(result.writeErrors)) {
      for (let i = 0; i < result.writeErrors.length; i++) {
        const writeError = {
          index: batch.originalIndexes[result.writeErrors[i].index],
          code: result.writeErrors[i].code,
          errmsg: result.writeErrors[i].errmsg,
          errInfo: result.writeErrors[i].errInfo,
          op: batch.operations[result.writeErrors[i].index],
        };
        bulkResult.writeErrors.push(new WriteError(writeError));
      }
    }
    if (result.writeConcernError) {
      bulkResult.writeConcernErrors.push(
        new WriteConcernError(result.writeConcernError),
      );
    }
  }
  exports.mergeBatchResults = mergeBatchResults;
  function executeCommands(bulkOperation, options, callback) {
    if (bulkOperation.s.batches.length === 0) {
      return callback(
        undefined,
        new BulkWriteResult(
          bulkOperation.s.bulkResult,
          bulkOperation.isOrdered,
        ),
      );
    }
    const batch = bulkOperation.s.batches.shift();
    function resultHandler(err, result) {
      // Error is a driver related error not a bulk op error, return early
      if (
        err &&
        "message" in err &&
        !(err instanceof error_1.MongoWriteConcernError)
      ) {
        return callback(
          new MongoBulkWriteError(
            err,
            new BulkWriteResult(
              bulkOperation.s.bulkResult,
              bulkOperation.isOrdered,
            ),
          ),
        );
      }
      if (err instanceof error_1.MongoWriteConcernError) {
        return handleMongoWriteConcernError(
          batch,
          bulkOperation.s.bulkResult,
          bulkOperation.isOrdered,
          err,
          callback,
        );
      }
      // Merge the results together
      mergeBatchResults(batch, bulkOperation.s.bulkResult, err, result);
      const writeResult = new BulkWriteResult(
        bulkOperation.s.bulkResult,
        bulkOperation.isOrdered,
      );
      if (bulkOperation.handleWriteError(callback, writeResult)) return;
      // Execute the next command in line
      executeCommands(bulkOperation, options, callback);
    }
    const finalOptions = (0, utils_1.resolveOptions)(bulkOperation, {
      ...options,
      ordered: bulkOperation.isOrdered,
    });
    if (finalOptions.bypassDocumentValidation !== true) {
      delete finalOptions.bypassDocumentValidation;
    }
    // Set an operationIf if provided
    if (bulkOperation.operationId) {
      resultHandler.operationId = bulkOperation.operationId;
    }
    // Is the bypassDocumentValidation options specific
    if (bulkOperation.s.bypassDocumentValidation === true) {
      finalOptions.bypassDocumentValidation = true;
    }
    // Is the checkKeys option disabled
    if (bulkOperation.s.checkKeys === false) {
      finalOptions.checkKeys = false;
    }
    if (finalOptions.retryWrites) {
      if (isUpdateBatch(batch)) {
        finalOptions.retryWrites =
          finalOptions.retryWrites && !batch.operations.some((op) => op.multi);
      }
      if (isDeleteBatch(batch)) {
        finalOptions.retryWrites =
          finalOptions.retryWrites &&
          !batch.operations.some((op) => op.limit === 0);
      }
    }
    try {
      if (isInsertBatch(batch)) {
        (0, execute_operation_1.executeOperation)(
          bulkOperation.s.collection.client,
          new insert_1.InsertOperation(
            bulkOperation.s.namespace,
            batch.operations,
            finalOptions,
          ),
          resultHandler,
        );
      } else if (isUpdateBatch(batch)) {
        (0, execute_operation_1.executeOperation)(
          bulkOperation.s.collection.client,
          new update_1.UpdateOperation(
            bulkOperation.s.namespace,
            batch.operations,
            finalOptions,
          ),
          resultHandler,
        );
      } else if (isDeleteBatch(batch)) {
        (0, execute_operation_1.executeOperation)(
          bulkOperation.s.collection.client,
          new delete_1.DeleteOperation(
            bulkOperation.s.namespace,
            batch.operations,
            finalOptions,
          ),
          resultHandler,
        );
      }
    } catch (err) {
      // Force top level error
      err.ok = 0;
      // Merge top level error and return
      mergeBatchResults(batch, bulkOperation.s.bulkResult, err, undefined);
      callback();
    }
  }
  function handleMongoWriteConcernError(
    batch,
    bulkResult,
    isOrdered,
    err,
    callback,
  ) {
    mergeBatchResults(batch, bulkResult, undefined, err.result);
    callback(
      new MongoBulkWriteError(
        {
          message: err.result?.writeConcernError.errmsg,
          code: err.result?.writeConcernError.result,
        },
        new BulkWriteResult(bulkResult, isOrdered),
      ),
    );
  }
  /**
   * An error indicating an unsuccessful Bulk Write
   * @public
   * @category Error
   */
  class MongoBulkWriteError extends error_1.MongoServerError {
    /**
     * **Do not use this constructor!**
     *
     * Meant for internal use only.
     *
     * @remarks
     * This class is only meant to be constructed within the driver. This constructor is
     * not subject to semantic versioning compatibility guarantees and may change at any time.
     *
     * @public
     **/
    constructor(error, result) {
      super(error);
      this.writeErrors = [];
      if (error instanceof WriteConcernError) this.err = error;
      else if (!(error instanceof Error)) {
        this.message = error.message;
        this.code = error.code;
        this.writeErrors = error.writeErrors ?? [];
      }
      this.result = result;
      Object.assign(this, error);
    }
    get name() {
      return "MongoBulkWriteError";
    }
    /** Number of documents inserted. */
    get insertedCount() {
      return this.result.insertedCount;
    }
    /** Number of documents matched for update. */
    get matchedCount() {
      return this.result.matchedCount;
    }
    /** Number of documents modified. */
    get modifiedCount() {
      return this.result.modifiedCount;
    }
    /** Number of documents deleted. */
    get deletedCount() {
      return this.result.deletedCount;
    }
    /** Number of documents upserted. */
    get upsertedCount() {
      return this.result.upsertedCount;
    }
    /** Inserted document generated Id's, hash key is the index of the originating operation */
    get insertedIds() {
      return this.result.insertedIds;
    }
    /** Upserted document generated Id's, hash key is the index of the originating operation */
    get upsertedIds() {
      return this.result.upsertedIds;
    }
  }
  exports.MongoBulkWriteError = MongoBulkWriteError;
  /**
   * A builder object that is returned from {@link BulkOperationBase#find}.
   * Is used to build a write operation that involves a query filter.
   *
   * @public
   */
  class FindOperators {
    /**
     * Creates a new FindOperators object.
     * @internal
     */
    constructor(bulkOperation) {
      this.bulkOperation = bulkOperation;
    }
    /** Add a multiple update operation to the bulk operation */
    update(updateDocument) {
      const currentOp = buildCurrentOp(this.bulkOperation);
      return this.bulkOperation.addToOperationsList(
        exports.BatchType.UPDATE,
        (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, {
          ...currentOp,
          multi: true,
        }),
      );
    }
    /** Add a single update operation to the bulk operation */
    updateOne(updateDocument) {
      if (!(0, utils_1.hasAtomicOperators)(updateDocument)) {
        throw new error_1.MongoInvalidArgumentError(
          "Update document requires atomic operators",
        );
      }
      const currentOp = buildCurrentOp(this.bulkOperation);
      return this.bulkOperation.addToOperationsList(
        exports.BatchType.UPDATE,
        (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, {
          ...currentOp,
          multi: false,
        }),
      );
    }
    /** Add a replace one operation to the bulk operation */
    replaceOne(replacement) {
      if ((0, utils_1.hasAtomicOperators)(replacement)) {
        throw new error_1.MongoInvalidArgumentError(
          "Replacement document must not use atomic operators",
        );
      }
      const currentOp = buildCurrentOp(this.bulkOperation);
      return this.bulkOperation.addToOperationsList(
        exports.BatchType.UPDATE,
        (0, update_1.makeUpdateStatement)(currentOp.selector, replacement, {
          ...currentOp,
          multi: false,
        }),
      );
    }
    /** Add a delete one operation to the bulk operation */
    deleteOne() {
      const currentOp = buildCurrentOp(this.bulkOperation);
      return this.bulkOperation.addToOperationsList(
        exports.BatchType.DELETE,
        (0, delete_1.makeDeleteStatement)(currentOp.selector, {
          ...currentOp,
          limit: 1,
        }),
      );
    }
    /** Add a delete many operation to the bulk operation */
    delete() {
      const currentOp = buildCurrentOp(this.bulkOperation);
      return this.bulkOperation.addToOperationsList(
        exports.BatchType.DELETE,
        (0, delete_1.makeDeleteStatement)(currentOp.selector, {
          ...currentOp,
          limit: 0,
        }),
      );
    }
    /** Upsert modifier for update bulk operation, noting that this operation is an upsert. */
    upsert() {
      if (!this.bulkOperation.s.currentOp) {
        this.bulkOperation.s.currentOp = {};
      }
      this.bulkOperation.s.currentOp.upsert = true;
      return this;
    }
    /** Specifies the collation for the query condition. */
    collation(collation) {
      if (!this.bulkOperation.s.currentOp) {
        this.bulkOperation.s.currentOp = {};
      }
      this.bulkOperation.s.currentOp.collation = collation;
      return this;
    }
    /** Specifies arrayFilters for UpdateOne or UpdateMany bulk operations. */
    arrayFilters(arrayFilters) {
      if (!this.bulkOperation.s.currentOp) {
        this.bulkOperation.s.currentOp = {};
      }
      this.bulkOperation.s.currentOp.arrayFilters = arrayFilters;
      return this;
    }
    /** Specifies hint for the bulk operation. */
    hint(hint) {
      if (!this.bulkOperation.s.currentOp) {
        this.bulkOperation.s.currentOp = {};
      }
      this.bulkOperation.s.currentOp.hint = hint;
      return this;
    }
  }
  exports.FindOperators = FindOperators;
  const executeCommandsAsync = (0, util_1.promisify)(executeCommands);
  /**
   * TODO(NODE-4063)
   * BulkWrites merge complexity is implemented in executeCommands
   * This provides a vehicle to treat bulkOperations like any other operation (hence "shim")
   * We would like this logic to simply live inside the BulkWriteOperation class
   * @internal
   */
  class BulkWriteShimOperation extends operation_1.AbstractOperation {
    constructor(bulkOperation, options) {
      super(options);
      this.bulkOperation = bulkOperation;
    }
    execute(_server, session) {
      if (this.options.session == null) {
        // An implicit session could have been created by 'executeOperation'
        // So if we stick it on finalOptions here, each bulk operation
        // will use this same session, it'll be passed in the same way
        // an explicit session would be
        this.options.session = session;
      }
      return executeCommandsAsync(this.bulkOperation, this.options);
    }
  }
  /** @public */
  class BulkOperationBase {
    /**
     * Create a new OrderedBulkOperation or UnorderedBulkOperation instance
     * @internal
     */
    constructor(collection, options, isOrdered) {
      // determine whether bulkOperation is ordered or unordered
      this.isOrdered = isOrdered;
      const topology = (0, utils_1.getTopology)(collection);
      options = options == null ? {} : options;
      // TODO Bring from driver information in hello
      // Get the namespace for the write operations
      const namespace = collection.s.namespace;
      // Used to mark operation as executed
      const executed = false;
      // Current item
      const currentOp = undefined;
      // Set max byte size
      const hello = topology.lastHello();
      // If we have autoEncryption on, batch-splitting must be done on 2mb chunks, but single documents
      // over 2mb are still allowed
      const usingAutoEncryption = !!(
        topology.s.options && topology.s.options.autoEncrypter
      );
      const maxBsonObjectSize =
        hello && hello.maxBsonObjectSize
          ? hello.maxBsonObjectSize
          : 1024 * 1024 * 16;
      const maxBatchSizeBytes = usingAutoEncryption
        ? 1024 * 1024 * 2
        : maxBsonObjectSize;
      const maxWriteBatchSize =
        hello && hello.maxWriteBatchSize ? hello.maxWriteBatchSize : 1000;
      // Calculates the largest possible size of an Array key, represented as a BSON string
      // element. This calculation:
      //     1 byte for BSON type
      //     # of bytes = length of (string representation of (maxWriteBatchSize - 1))
      //   + 1 bytes for null terminator
      const maxKeySize = (maxWriteBatchSize - 1).toString(10).length + 2;
      // Final options for retryable writes
      let finalOptions = Object.assign({}, options);
      finalOptions = (0, utils_1.applyRetryableWrites)(
        finalOptions,
        collection.s.db,
      );
      // Final results
      const bulkResult = {
        ok: 1,
        writeErrors: [],
        writeConcernErrors: [],
        insertedIds: [],
        nInserted: 0,
        nUpserted: 0,
        nMatched: 0,
        nModified: 0,
        nRemoved: 0,
        upserted: [],
      };
      // Internal state
      this.s = {
        // Final result
        bulkResult,
        // Current batch state
        currentBatch: undefined,
        currentIndex: 0,
        // ordered specific
        currentBatchSize: 0,
        currentBatchSizeBytes: 0,
        // unordered specific
        currentInsertBatch: undefined,
        currentUpdateBatch: undefined,
        currentRemoveBatch: undefined,
        batches: [],
        // Write concern
        writeConcern: write_concern_1.WriteConcern.fromOptions(options),
        // Max batch size options
        maxBsonObjectSize,
        maxBatchSizeBytes,
        maxWriteBatchSize,
        maxKeySize,
        // Namespace
        namespace,
        // Topology
        topology,
        // Options
        options: finalOptions,
        // BSON options
        bsonOptions: (0, bson_1.resolveBSONOptions)(options),
        // Current operation
        currentOp,
        // Executed
        executed,
        // Collection
        collection,
        // Fundamental error
        err: undefined,
        // check keys
        checkKeys:
          typeof options.checkKeys === "boolean" ? options.checkKeys : false,
      };
      // bypass Validation
      if (options.bypassDocumentValidation === true) {
        this.s.bypassDocumentValidation = true;
      }
    }
    /**
     * Add a single insert document to the bulk operation
     *
     * @example
     * ```ts
     * const bulkOp = collection.initializeOrderedBulkOp();
     *
     * // Adds three inserts to the bulkOp.
     * bulkOp
     *   .insert({ a: 1 })
     *   .insert({ b: 2 })
     *   .insert({ c: 3 });
     * await bulkOp.execute();
     * ```
     */
    insert(document) {
      if (document._id == null && !shouldForceServerObjectId(this)) {
        document._id = new bson_1.ObjectId();
      }
      return this.addToOperationsList(exports.BatchType.INSERT, document);
    }
    /**
     * Builds a find operation for an update/updateOne/delete/deleteOne/replaceOne.
     * Returns a builder object used to complete the definition of the operation.
     *
     * @example
     * ```ts
     * const bulkOp = collection.initializeOrderedBulkOp();
     *
     * // Add an updateOne to the bulkOp
     * bulkOp.find({ a: 1 }).updateOne({ $set: { b: 2 } });
     *
     * // Add an updateMany to the bulkOp
     * bulkOp.find({ c: 3 }).update({ $set: { d: 4 } });
     *
     * // Add an upsert
     * bulkOp.find({ e: 5 }).upsert().updateOne({ $set: { f: 6 } });
     *
     * // Add a deletion
     * bulkOp.find({ g: 7 }).deleteOne();
     *
     * // Add a multi deletion
     * bulkOp.find({ h: 8 }).delete();
     *
     * // Add a replaceOne
     * bulkOp.find({ i: 9 }).replaceOne({writeConcern: { j: 10 }});
     *
     * // Update using a pipeline (requires Mongodb 4.2 or higher)
     * bulk.find({ k: 11, y: { $exists: true }, z: { $exists: true } }).updateOne([
     *   { $set: { total: { $sum: [ '$y', '$z' ] } } }
     * ]);
     *
     * // All of the ops will now be executed
     * await bulkOp.execute();
     * ```
     */
    find(selector) {
      if (!selector) {
        throw new error_1.MongoInvalidArgumentError(
          "Bulk find operation must specify a selector",
        );
      }
      // Save a current selector
      this.s.currentOp = {
        selector: selector,
      };
      return new FindOperators(this);
    }
    /** Specifies a raw operation to perform in the bulk write. */
    raw(op) {
      if (op == null || typeof op !== "object") {
        throw new error_1.MongoInvalidArgumentError(
          "Operation must be an object with an operation key",
        );
      }
      if ("insertOne" in op) {
        const forceServerObjectId = shouldForceServerObjectId(this);
        if (op.insertOne && op.insertOne.document == null) {
          // NOTE: provided for legacy support, but this is a malformed operation
          if (forceServerObjectId !== true && op.insertOne._id == null) {
            op.insertOne._id = new bson_1.ObjectId();
          }
          return this.addToOperationsList(
            exports.BatchType.INSERT,
            op.insertOne,
          );
        }
        if (forceServerObjectId !== true && op.insertOne.document._id == null) {
          op.insertOne.document._id = new bson_1.ObjectId();
        }
        return this.addToOperationsList(
          exports.BatchType.INSERT,
          op.insertOne.document,
        );
      }
      if ("replaceOne" in op || "updateOne" in op || "updateMany" in op) {
        if ("replaceOne" in op) {
          if ("q" in op.replaceOne) {
            throw new error_1.MongoInvalidArgumentError(
              "Raw operations are not allowed",
            );
          }
          const updateStatement = (0, update_1.makeUpdateStatement)(
            op.replaceOne.filter,
            op.replaceOne.replacement,
            { ...op.replaceOne, multi: false },
          );
          if ((0, utils_1.hasAtomicOperators)(updateStatement.u)) {
            throw new error_1.MongoInvalidArgumentError(
              "Replacement document must not use atomic operators",
            );
          }
          return this.addToOperationsList(
            exports.BatchType.UPDATE,
            updateStatement,
          );
        }
        if ("updateOne" in op) {
          if ("q" in op.updateOne) {
            throw new error_1.MongoInvalidArgumentError(
              "Raw operations are not allowed",
            );
          }
          const updateStatement = (0, update_1.makeUpdateStatement)(
            op.updateOne.filter,
            op.updateOne.update,
            {
              ...op.updateOne,
              multi: false,
            },
          );
          if (!(0, utils_1.hasAtomicOperators)(updateStatement.u)) {
            throw new error_1.MongoInvalidArgumentError(
              "Update document requires atomic operators",
            );
          }
          return this.addToOperationsList(
            exports.BatchType.UPDATE,
            updateStatement,
          );
        }
        if ("updateMany" in op) {
          if ("q" in op.updateMany) {
            throw new error_1.MongoInvalidArgumentError(
              "Raw operations are not allowed",
            );
          }
          const updateStatement = (0, update_1.makeUpdateStatement)(
            op.updateMany.filter,
            op.updateMany.update,
            {
              ...op.updateMany,
              multi: true,
            },
          );
          if (!(0, utils_1.hasAtomicOperators)(updateStatement.u)) {
            throw new error_1.MongoInvalidArgumentError(
              "Update document requires atomic operators",
            );
          }
          return this.addToOperationsList(
            exports.BatchType.UPDATE,
            updateStatement,
          );
        }
      }
      if ("deleteOne" in op) {
        if ("q" in op.deleteOne) {
          throw new error_1.MongoInvalidArgumentError(
            "Raw operations are not allowed",
          );
        }
        return this.addToOperationsList(
          exports.BatchType.DELETE,
          (0, delete_1.makeDeleteStatement)(op.deleteOne.filter, {
            ...op.deleteOne,
            limit: 1,
          }),
        );
      }
      if ("deleteMany" in op) {
        if ("q" in op.deleteMany) {
          throw new error_1.MongoInvalidArgumentError(
            "Raw operations are not allowed",
          );
        }
        return this.addToOperationsList(
          exports.BatchType.DELETE,
          (0, delete_1.makeDeleteStatement)(op.deleteMany.filter, {
            ...op.deleteMany,
            limit: 0,
          }),
        );
      }
      // otherwise an unknown operation was provided
      throw new error_1.MongoInvalidArgumentError(
        "bulkWrite only supports insertOne, updateOne, updateMany, deleteOne, deleteMany",
      );
    }
    get bsonOptions() {
      return this.s.bsonOptions;
    }
    get writeConcern() {
      return this.s.writeConcern;
    }
    get batches() {
      const batches = [...this.s.batches];
      if (this.isOrdered) {
        if (this.s.currentBatch) batches.push(this.s.currentBatch);
      } else {
        if (this.s.currentInsertBatch) batches.push(this.s.currentInsertBatch);
        if (this.s.currentUpdateBatch) batches.push(this.s.currentUpdateBatch);
        if (this.s.currentRemoveBatch) batches.push(this.s.currentRemoveBatch);
      }
      return batches;
    }
    async execute(options = {}) {
      if (this.s.executed) {
        throw new error_1.MongoBatchReExecutionError();
      }
      const writeConcern = write_concern_1.WriteConcern.fromOptions(options);
      if (writeConcern) {
        this.s.writeConcern = writeConcern;
      }
      // If we have current batch
      if (this.isOrdered) {
        if (this.s.currentBatch) this.s.batches.push(this.s.currentBatch);
      } else {
        if (this.s.currentInsertBatch)
          this.s.batches.push(this.s.currentInsertBatch);
        if (this.s.currentUpdateBatch)
          this.s.batches.push(this.s.currentUpdateBatch);
        if (this.s.currentRemoveBatch)
          this.s.batches.push(this.s.currentRemoveBatch);
      }
      // If we have no operations in the bulk raise an error
      if (this.s.batches.length === 0) {
        throw new error_1.MongoInvalidArgumentError(
          "Invalid BulkOperation, Batch cannot be empty",
        );
      }
      this.s.executed = true;
      const finalOptions = { ...this.s.options, ...options };
      const operation = new BulkWriteShimOperation(this, finalOptions);
      return (0, execute_operation_1.executeOperation)(
        this.s.collection.client,
        operation,
      );
    }
    /**
     * Handles the write error before executing commands
     * @internal
     */
    handleWriteError(callback, writeResult) {
      if (this.s.bulkResult.writeErrors.length > 0) {
        const msg = this.s.bulkResult.writeErrors[0].errmsg
          ? this.s.bulkResult.writeErrors[0].errmsg
          : "write operation failed";
        callback(
          new MongoBulkWriteError(
            {
              message: msg,
              code: this.s.bulkResult.writeErrors[0].code,
              writeErrors: this.s.bulkResult.writeErrors,
            },
            writeResult,
          ),
        );
        return true;
      }
      const writeConcernError = writeResult.getWriteConcernError();
      if (writeConcernError) {
        callback(new MongoBulkWriteError(writeConcernError, writeResult));
        return true;
      }
      return false;
    }
  }
  exports.BulkOperationBase = BulkOperationBase;
  Object.defineProperty(BulkOperationBase.prototype, "length", {
    enumerable: true,
    get() {
      return this.s.currentIndex;
    },
  });
  function shouldForceServerObjectId(bulkOperation) {
    if (typeof bulkOperation.s.options.forceServerObjectId === "boolean") {
      return bulkOperation.s.options.forceServerObjectId;
    }
    if (
      typeof bulkOperation.s.collection.s.db.options?.forceServerObjectId ===
      "boolean"
    ) {
      return bulkOperation.s.collection.s.db.options?.forceServerObjectId;
    }
    return false;
  }
  function isInsertBatch(batch) {
    return batch.batchType === exports.BatchType.INSERT;
  }
  function isUpdateBatch(batch) {
    return batch.batchType === exports.BatchType.UPDATE;
  }
  function isDeleteBatch(batch) {
    return batch.batchType === exports.BatchType.DELETE;
  }
  function buildCurrentOp(bulkOp) {
    let { currentOp } = bulkOp.s;
    bulkOp.s.currentOp = undefined;
    if (!currentOp) currentOp = {};
    return currentOp;
  }
})(common);

Object.defineProperty(ordered, "__esModule", { value: true });
ordered.OrderedBulkOperation = void 0;
const BSON$4 = bson$2;
const error_1$C = error;
const common_1$6 = common;
/** @public */
let OrderedBulkOperation$1 = class OrderedBulkOperation extends common_1$6.BulkOperationBase {
  /** @internal */
  constructor(collection, options) {
    super(collection, options, true);
  }
  addToOperationsList(batchType, document) {
    // Get the bsonSize
    const bsonSize = BSON$4.calculateObjectSize(document, {
      checkKeys: false,
      // Since we don't know what the user selected for BSON options here,
      // err on the safe side, and check the size with ignoreUndefined: false.
      ignoreUndefined: false,
    });
    // Throw error if the doc is bigger than the max BSON size
    if (bsonSize >= this.s.maxBsonObjectSize)
      // TODO(NODE-3483): Change this to MongoBSONError
      throw new error_1$C.MongoInvalidArgumentError(
        `Document is larger than the maximum size ${this.s.maxBsonObjectSize}`,
      );
    // Create a new batch object if we don't have a current one
    if (this.s.currentBatch == null) {
      this.s.currentBatch = new common_1$6.Batch(
        batchType,
        this.s.currentIndex,
      );
    }
    const maxKeySize = this.s.maxKeySize;
    // Check if we need to create a new batch
    if (
      // New batch if we exceed the max batch op size
      this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||
      // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,
      // since we can't sent an empty batch
      (this.s.currentBatchSize > 0 &&
        this.s.currentBatchSizeBytes + maxKeySize + bsonSize >=
          this.s.maxBatchSizeBytes) ||
      // New batch if the new op does not have the same op type as the current batch
      this.s.currentBatch.batchType !== batchType
    ) {
      // Save the batch to the execution stack
      this.s.batches.push(this.s.currentBatch);
      // Create a new batch
      this.s.currentBatch = new common_1$6.Batch(
        batchType,
        this.s.currentIndex,
      );
      // Reset the current size trackers
      this.s.currentBatchSize = 0;
      this.s.currentBatchSizeBytes = 0;
    }
    if (batchType === common_1$6.BatchType.INSERT) {
      this.s.bulkResult.insertedIds.push({
        index: this.s.currentIndex,
        _id: document._id,
      });
    }
    // We have an array of documents
    if (Array.isArray(document)) {
      throw new error_1$C.MongoInvalidArgumentError(
        "Operation passed in cannot be an Array",
      );
    }
    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);
    this.s.currentBatch.operations.push(document);
    this.s.currentBatchSize += 1;
    this.s.currentBatchSizeBytes += maxKeySize + bsonSize;
    this.s.currentIndex += 1;
    return this;
  }
};
ordered.OrderedBulkOperation = OrderedBulkOperation$1;

var unordered = {};

Object.defineProperty(unordered, "__esModule", { value: true });
unordered.UnorderedBulkOperation = void 0;
const BSON$3 = bson$2;
const error_1$B = error;
const common_1$5 = common;
/** @public */
let UnorderedBulkOperation$1 = class UnorderedBulkOperation extends common_1$5.BulkOperationBase {
  /** @internal */
  constructor(collection, options) {
    super(collection, options, false);
  }
  handleWriteError(callback, writeResult) {
    if (this.s.batches.length) {
      return false;
    }
    return super.handleWriteError(callback, writeResult);
  }
  addToOperationsList(batchType, document) {
    // Get the bsonSize
    const bsonSize = BSON$3.calculateObjectSize(document, {
      checkKeys: false,
      // Since we don't know what the user selected for BSON options here,
      // err on the safe side, and check the size with ignoreUndefined: false.
      ignoreUndefined: false,
    });
    // Throw error if the doc is bigger than the max BSON size
    if (bsonSize >= this.s.maxBsonObjectSize) {
      // TODO(NODE-3483): Change this to MongoBSONError
      throw new error_1$B.MongoInvalidArgumentError(
        `Document is larger than the maximum size ${this.s.maxBsonObjectSize}`,
      );
    }
    // Holds the current batch
    this.s.currentBatch = undefined;
    // Get the right type of batch
    if (batchType === common_1$5.BatchType.INSERT) {
      this.s.currentBatch = this.s.currentInsertBatch;
    } else if (batchType === common_1$5.BatchType.UPDATE) {
      this.s.currentBatch = this.s.currentUpdateBatch;
    } else if (batchType === common_1$5.BatchType.DELETE) {
      this.s.currentBatch = this.s.currentRemoveBatch;
    }
    const maxKeySize = this.s.maxKeySize;
    // Create a new batch object if we don't have a current one
    if (this.s.currentBatch == null) {
      this.s.currentBatch = new common_1$5.Batch(
        batchType,
        this.s.currentIndex,
      );
    }
    // Check if we need to create a new batch
    if (
      // New batch if we exceed the max batch op size
      this.s.currentBatch.size + 1 >= this.s.maxWriteBatchSize ||
      // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,
      // since we can't sent an empty batch
      (this.s.currentBatch.size > 0 &&
        this.s.currentBatch.sizeBytes + maxKeySize + bsonSize >=
          this.s.maxBatchSizeBytes) ||
      // New batch if the new op does not have the same op type as the current batch
      this.s.currentBatch.batchType !== batchType
    ) {
      // Save the batch to the execution stack
      this.s.batches.push(this.s.currentBatch);
      // Create a new batch
      this.s.currentBatch = new common_1$5.Batch(
        batchType,
        this.s.currentIndex,
      );
    }
    // We have an array of documents
    if (Array.isArray(document)) {
      throw new error_1$B.MongoInvalidArgumentError(
        "Operation passed in cannot be an Array",
      );
    }
    this.s.currentBatch.operations.push(document);
    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);
    this.s.currentIndex = this.s.currentIndex + 1;
    // Save back the current Batch to the right type
    if (batchType === common_1$5.BatchType.INSERT) {
      this.s.currentInsertBatch = this.s.currentBatch;
      this.s.bulkResult.insertedIds.push({
        index: this.s.bulkResult.insertedIds.length,
        _id: document._id,
      });
    } else if (batchType === common_1$5.BatchType.UPDATE) {
      this.s.currentUpdateBatch = this.s.currentBatch;
    } else if (batchType === common_1$5.BatchType.DELETE) {
      this.s.currentRemoveBatch = this.s.currentBatch;
    }
    // Update current batch size
    this.s.currentBatch.size += 1;
    this.s.currentBatch.sizeBytes += maxKeySize + bsonSize;
    return this;
  }
};
unordered.UnorderedBulkOperation = UnorderedBulkOperation$1;

var change_stream = {};

var collection = {};

var aggregation_cursor = {};

var aggregate = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.AggregateOperation = exports.DB_AGGREGATE_COLLECTION = void 0;
  const error_1 = error;
  const utils_1 = utils$2;
  const write_concern_1 = write_concern;
  const command_1 = command;
  const operation_1 = operation;
  /** @internal */
  exports.DB_AGGREGATE_COLLECTION = 1;
  const MIN_WIRE_VERSION_$OUT_READ_CONCERN_SUPPORT = 8;
  /** @internal */
  class AggregateOperation extends command_1.CommandOperation {
    constructor(ns, pipeline, options) {
      super(undefined, { ...options, dbName: ns.db });
      this.options = { ...options };
      // Covers when ns.collection is null, undefined or the empty string, use DB_AGGREGATE_COLLECTION
      this.target = ns.collection || exports.DB_AGGREGATE_COLLECTION;
      this.pipeline = pipeline;
      // determine if we have a write stage, override read preference if so
      this.hasWriteStage = false;
      if (typeof options?.out === "string") {
        this.pipeline = this.pipeline.concat({ $out: options.out });
        this.hasWriteStage = true;
      } else if (pipeline.length > 0) {
        const finalStage = pipeline[pipeline.length - 1];
        if (finalStage.$out || finalStage.$merge) {
          this.hasWriteStage = true;
        }
      }
      if (this.hasWriteStage) {
        this.trySecondaryWrite = true;
      } else {
        delete this.options.writeConcern;
      }
      if (this.explain && this.writeConcern) {
        throw new error_1.MongoInvalidArgumentError(
          'Option "explain" cannot be used on an aggregate call with writeConcern',
        );
      }
      if (options?.cursor != null && typeof options.cursor !== "object") {
        throw new error_1.MongoInvalidArgumentError(
          "Cursor options must be an object",
        );
      }
    }
    get canRetryRead() {
      return !this.hasWriteStage;
    }
    addToPipeline(stage) {
      this.pipeline.push(stage);
    }
    async execute(server, session) {
      const options = this.options;
      const serverWireVersion = (0, utils_1.maxWireVersion)(server);
      const command = { aggregate: this.target, pipeline: this.pipeline };
      if (
        this.hasWriteStage &&
        serverWireVersion < MIN_WIRE_VERSION_$OUT_READ_CONCERN_SUPPORT
      ) {
        this.readConcern = undefined;
      }
      if (this.hasWriteStage && this.writeConcern) {
        write_concern_1.WriteConcern.apply(command, this.writeConcern);
      }
      if (options.bypassDocumentValidation === true) {
        command.bypassDocumentValidation = options.bypassDocumentValidation;
      }
      if (typeof options.allowDiskUse === "boolean") {
        command.allowDiskUse = options.allowDiskUse;
      }
      if (options.hint) {
        command.hint = options.hint;
      }
      if (options.let) {
        command.let = options.let;
      }
      // we check for undefined specifically here to allow falsy values
      // eslint-disable-next-line no-restricted-syntax
      if (options.comment !== undefined) {
        command.comment = options.comment;
      }
      command.cursor = options.cursor || {};
      if (options.batchSize && !this.hasWriteStage) {
        command.cursor.batchSize = options.batchSize;
      }
      return super.executeCommand(server, session, command);
    }
  }
  exports.AggregateOperation = AggregateOperation;
  (0, operation_1.defineAspects)(AggregateOperation, [
    operation_1.Aspect.READ_OPERATION,
    operation_1.Aspect.RETRYABLE,
    operation_1.Aspect.EXPLAINABLE,
    operation_1.Aspect.CURSOR_CREATING,
  ]);
})(aggregate);

var abstract_cursor = {};

var mongo_types = {};

Object.defineProperty(mongo_types, "__esModule", { value: true });
mongo_types.CancellationToken = mongo_types.TypedEventEmitter = void 0;
const events_1 = $nodeEvents;
/**
 * Typescript type safe event emitter
 * @public
 */
class TypedEventEmitter extends events_1.EventEmitter {
  /** @internal */
  emitAndLog(event, ...args) {
    this.emit(event, ...args);
    if (this.component) this.mongoLogger?.debug(this.component, args[0]);
  }
}
mongo_types.TypedEventEmitter = TypedEventEmitter;
/** @public */
let CancellationToken$1 = class CancellationToken extends TypedEventEmitter {};
mongo_types.CancellationToken = CancellationToken$1;

var get_more = {};

Object.defineProperty(get_more, "__esModule", { value: true });
get_more.GetMoreOperation = void 0;
const error_1$A = error;
const utils_1$n = utils$2;
const operation_1$e = operation;
/** @internal */
class GetMoreOperation extends operation_1$e.AbstractOperation {
  constructor(ns, cursorId, server, options) {
    super(options);
    this.options = options;
    this.ns = ns;
    this.cursorId = cursorId;
    this.server = server;
  }
  /**
   * Although there is a server already associated with the get more operation, the signature
   * for execute passes a server so we will just use that one.
   */
  async execute(server, _session) {
    if (server !== this.server) {
      throw new error_1$A.MongoRuntimeError(
        "Getmore must run on the same server operation began on",
      );
    }
    if (this.cursorId == null || this.cursorId.isZero()) {
      throw new error_1$A.MongoRuntimeError(
        "Unable to iterate cursor with no id",
      );
    }
    const collection = this.ns.collection;
    if (collection == null) {
      // Cursors should have adopted the namespace returned by MongoDB
      // which should always defined a collection name (even a pseudo one, ex. db.aggregate())
      throw new error_1$A.MongoRuntimeError(
        "A collection name must be determined before getMore",
      );
    }
    const getMoreCmd = {
      getMore: this.cursorId,
      collection,
    };
    if (typeof this.options.batchSize === "number") {
      getMoreCmd.batchSize = Math.abs(this.options.batchSize);
    }
    if (typeof this.options.maxAwaitTimeMS === "number") {
      getMoreCmd.maxTimeMS = this.options.maxAwaitTimeMS;
    }
    // we check for undefined specifically here to allow falsy values
    // eslint-disable-next-line no-restricted-syntax
    if (
      this.options.comment !== undefined &&
      (0, utils_1$n.maxWireVersion)(server) >= 9
    ) {
      getMoreCmd.comment = this.options.comment;
    }
    const commandOptions = {
      returnFieldSelector: null,
      documentsReturnedIn: "nextBatch",
      ...this.options,
    };
    return server.commandAsync(this.ns, getMoreCmd, commandOptions);
  }
}
get_more.GetMoreOperation = GetMoreOperation;
(0, operation_1$e.defineAspects)(GetMoreOperation, [
  operation_1$e.Aspect.READ_OPERATION,
  operation_1$e.Aspect.MUST_SELECT_SAME_SERVER,
]);

var kill_cursors = {};

Object.defineProperty(kill_cursors, "__esModule", { value: true });
kill_cursors.KillCursorsOperation = void 0;
const error_1$z = error;
const operation_1$d = operation;
class KillCursorsOperation extends operation_1$d.AbstractOperation {
  constructor(cursorId, ns, server, options) {
    super(options);
    this.ns = ns;
    this.cursorId = cursorId;
    this.server = server;
  }
  async execute(server, session) {
    if (server !== this.server) {
      throw new error_1$z.MongoRuntimeError(
        "Killcursor must run on the same server operation began on",
      );
    }
    const killCursors = this.ns.collection;
    if (killCursors == null) {
      // Cursors should have adopted the namespace returned by MongoDB
      // which should always defined a collection name (even a pseudo one, ex. db.aggregate())
      throw new error_1$z.MongoRuntimeError(
        "A collection name must be determined before killCursors",
      );
    }
    const killCursorsCommand = {
      killCursors,
      cursors: [this.cursorId],
    };
    try {
      await server.commandAsync(this.ns, killCursorsCommand, { session });
    } catch {
      // The driver should never emit errors from killCursors, this is spec-ed behavior
    }
  }
}
kill_cursors.KillCursorsOperation = KillCursorsOperation;
(0, operation_1$d.defineAspects)(KillCursorsOperation, [
  operation_1$d.Aspect.MUST_SELECT_SAME_SERVER,
]);

var sessions = {};

var metrics = {};

Object.defineProperty(metrics, "__esModule", { value: true });
metrics.ConnectionPoolMetrics = void 0;
/** @internal */
class ConnectionPoolMetrics {
  constructor() {
    this.txnConnections = 0;
    this.cursorConnections = 0;
    this.otherConnections = 0;
  }
  /**
   * Mark a connection as pinned for a specific operation.
   */
  markPinned(pinType) {
    if (pinType === ConnectionPoolMetrics.TXN) {
      this.txnConnections += 1;
    } else if (pinType === ConnectionPoolMetrics.CURSOR) {
      this.cursorConnections += 1;
    } else {
      this.otherConnections += 1;
    }
  }
  /**
   * Unmark a connection as pinned for an operation.
   */
  markUnpinned(pinType) {
    if (pinType === ConnectionPoolMetrics.TXN) {
      this.txnConnections -= 1;
    } else if (pinType === ConnectionPoolMetrics.CURSOR) {
      this.cursorConnections -= 1;
    } else {
      this.otherConnections -= 1;
    }
  }
  /**
   * Return information about the cmap metrics as a string.
   */
  info(maxPoolSize) {
    return (
      "Timed out while checking out a connection from connection pool: " +
      `maxPoolSize: ${maxPoolSize}, ` +
      `connections in use by cursors: ${this.cursorConnections}, ` +
      `connections in use by transactions: ${this.txnConnections}, ` +
      `connections in use by other operations: ${this.otherConnections}`
    );
  }
  /**
   * Reset the metrics to the initial values.
   */
  reset() {
    this.txnConnections = 0;
    this.cursorConnections = 0;
    this.otherConnections = 0;
  }
}
ConnectionPoolMetrics.TXN = "txn";
ConnectionPoolMetrics.CURSOR = "cursor";
ConnectionPoolMetrics.OTHER = "other";
metrics.ConnectionPoolMetrics = ConnectionPoolMetrics;

var shared = {};

var topology_description = {};

var server_description = {};

Object.defineProperty(server_description, "__esModule", { value: true });
server_description.compareTopologyVersion =
  server_description.parseServerType =
  server_description.ServerDescription =
    void 0;
const bson_1$a = bson$2;
const error_1$y = error;
const utils_1$m = utils$2;
const common_1$4 = common$1;
const WRITABLE_SERVER_TYPES = new Set([
  common_1$4.ServerType.RSPrimary,
  common_1$4.ServerType.Standalone,
  common_1$4.ServerType.Mongos,
  common_1$4.ServerType.LoadBalancer,
]);
const DATA_BEARING_SERVER_TYPES = new Set([
  common_1$4.ServerType.RSPrimary,
  common_1$4.ServerType.RSSecondary,
  common_1$4.ServerType.Mongos,
  common_1$4.ServerType.Standalone,
  common_1$4.ServerType.LoadBalancer,
]);
/**
 * The client's view of a single server, based on the most recent hello outcome.
 *
 * Internal type, not meant to be directly instantiated
 * @public
 */
class ServerDescription {
  /**
   * Create a ServerDescription
   * @internal
   *
   * @param address - The address of the server
   * @param hello - An optional hello response for this server
   */
  constructor(address, hello, options = {}) {
    if (address == null || address === "") {
      throw new error_1$y.MongoRuntimeError(
        "ServerDescription must be provided with a non-empty address",
      );
    }
    this.address =
      typeof address === "string"
        ? utils_1$m.HostAddress.fromString(address).toString() // Use HostAddress to normalize
        : address.toString();
    this.type = parseServerType(hello, options);
    this.hosts = hello?.hosts?.map((host) => host.toLowerCase()) ?? [];
    this.passives = hello?.passives?.map((host) => host.toLowerCase()) ?? [];
    this.arbiters = hello?.arbiters?.map((host) => host.toLowerCase()) ?? [];
    this.tags = hello?.tags ?? {};
    this.minWireVersion = hello?.minWireVersion ?? 0;
    this.maxWireVersion = hello?.maxWireVersion ?? 0;
    this.roundTripTime = options?.roundTripTime ?? -1;
    this.lastUpdateTime = (0, utils_1$m.now)();
    this.lastWriteDate = hello?.lastWrite?.lastWriteDate ?? 0;
    this.error = options.error ?? null;
    // TODO(NODE-2674): Preserve int64 sent from MongoDB
    this.topologyVersion =
      this.error?.topologyVersion ?? hello?.topologyVersion ?? null;
    this.setName = hello?.setName ?? null;
    this.setVersion = hello?.setVersion ?? null;
    this.electionId = hello?.electionId ?? null;
    this.logicalSessionTimeoutMinutes =
      hello?.logicalSessionTimeoutMinutes ?? null;
    this.primary = hello?.primary ?? null;
    this.me = hello?.me?.toLowerCase() ?? null;
    this.$clusterTime = hello?.$clusterTime ?? null;
  }
  get hostAddress() {
    return utils_1$m.HostAddress.fromString(this.address);
  }
  get allHosts() {
    return this.hosts.concat(this.arbiters).concat(this.passives);
  }
  /** Is this server available for reads*/
  get isReadable() {
    return this.type === common_1$4.ServerType.RSSecondary || this.isWritable;
  }
  /** Is this server data bearing */
  get isDataBearing() {
    return DATA_BEARING_SERVER_TYPES.has(this.type);
  }
  /** Is this server available for writes */
  get isWritable() {
    return WRITABLE_SERVER_TYPES.has(this.type);
  }
  get host() {
    const chopLength = `:${this.port}`.length;
    return this.address.slice(0, -chopLength);
  }
  get port() {
    const port = this.address.split(":").pop();
    return port ? Number.parseInt(port, 10) : 27017;
  }
  /**
   * Determines if another `ServerDescription` is equal to this one per the rules defined
   * in the {@link https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#serverdescription|SDAM spec}
   */
  equals(other) {
    // Despite using the comparator that would determine a nullish topologyVersion as greater than
    // for equality we should only always perform direct equality comparison
    const topologyVersionsEqual =
      this.topologyVersion === other?.topologyVersion ||
      compareTopologyVersion(this.topologyVersion, other?.topologyVersion) ===
        0;
    const electionIdsEqual =
      this.electionId != null && other?.electionId != null
        ? (0, utils_1$m.compareObjectId)(this.electionId, other.electionId) ===
          0
        : this.electionId === other?.electionId;
    return (
      other != null &&
      (0, utils_1$m.errorStrictEqual)(this.error, other.error) &&
      this.type === other.type &&
      this.minWireVersion === other.minWireVersion &&
      (0, utils_1$m.arrayStrictEqual)(this.hosts, other.hosts) &&
      tagsStrictEqual(this.tags, other.tags) &&
      this.setName === other.setName &&
      this.setVersion === other.setVersion &&
      electionIdsEqual &&
      this.primary === other.primary &&
      this.logicalSessionTimeoutMinutes ===
        other.logicalSessionTimeoutMinutes &&
      topologyVersionsEqual
    );
  }
}
server_description.ServerDescription = ServerDescription;
// Parses a `hello` message and determines the server type
function parseServerType(hello, options) {
  if (options?.loadBalanced) {
    return common_1$4.ServerType.LoadBalancer;
  }
  if (!hello || !hello.ok) {
    return common_1$4.ServerType.Unknown;
  }
  if (hello.isreplicaset) {
    return common_1$4.ServerType.RSGhost;
  }
  if (hello.msg && hello.msg === "isdbgrid") {
    return common_1$4.ServerType.Mongos;
  }
  if (hello.setName) {
    if (hello.hidden) {
      return common_1$4.ServerType.RSOther;
    } else if (hello.isWritablePrimary) {
      return common_1$4.ServerType.RSPrimary;
    } else if (hello.secondary) {
      return common_1$4.ServerType.RSSecondary;
    } else if (hello.arbiterOnly) {
      return common_1$4.ServerType.RSArbiter;
    } else {
      return common_1$4.ServerType.RSOther;
    }
  }
  return common_1$4.ServerType.Standalone;
}
server_description.parseServerType = parseServerType;
function tagsStrictEqual(tags, tags2) {
  const tagsKeys = Object.keys(tags);
  const tags2Keys = Object.keys(tags2);
  return (
    tagsKeys.length === tags2Keys.length &&
    tagsKeys.every((key) => tags2[key] === tags[key])
  );
}
/**
 * Compares two topology versions.
 *
 * 1. If the response topologyVersion is unset or the ServerDescription's
 *    topologyVersion is null, the client MUST assume the response is more recent.
 * 1. If the response's topologyVersion.processId is not equal to the
 *    ServerDescription's, the client MUST assume the response is more recent.
 * 1. If the response's topologyVersion.processId is equal to the
 *    ServerDescription's, the client MUST use the counter field to determine
 *    which topologyVersion is more recent.
 *
 * ```ts
 * currentTv <   newTv === -1
 * currentTv === newTv === 0
 * currentTv >   newTv === 1
 * ```
 */
function compareTopologyVersion(currentTv, newTv) {
  if (currentTv == null || newTv == null) {
    return -1;
  }
  if (!currentTv.processId.equals(newTv.processId)) {
    return -1;
  }
  // TODO(NODE-2674): Preserve int64 sent from MongoDB
  const currentCounter = bson_1$a.Long.isLong(currentTv.counter)
    ? currentTv.counter
    : bson_1$a.Long.fromNumber(currentTv.counter);
  const newCounter = bson_1$a.Long.isLong(newTv.counter)
    ? newTv.counter
    : bson_1$a.Long.fromNumber(newTv.counter);
  return currentCounter.compare(newCounter);
}
server_description.compareTopologyVersion = compareTopologyVersion;

Object.defineProperty(topology_description, "__esModule", { value: true });
topology_description.TopologyDescription = void 0;
const WIRE_CONSTANTS = constants$1;
const error_1$x = error;
const utils_1$l = utils$2;
const common_1$3 = common$1;
const server_description_1$1 = server_description;
// constants related to compatibility checks
const MIN_SUPPORTED_SERVER_VERSION =
  WIRE_CONSTANTS.MIN_SUPPORTED_SERVER_VERSION;
const MAX_SUPPORTED_SERVER_VERSION =
  WIRE_CONSTANTS.MAX_SUPPORTED_SERVER_VERSION;
const MIN_SUPPORTED_WIRE_VERSION = WIRE_CONSTANTS.MIN_SUPPORTED_WIRE_VERSION;
const MAX_SUPPORTED_WIRE_VERSION = WIRE_CONSTANTS.MAX_SUPPORTED_WIRE_VERSION;
const MONGOS_OR_UNKNOWN = new Set([
  common_1$3.ServerType.Mongos,
  common_1$3.ServerType.Unknown,
]);
const MONGOS_OR_STANDALONE = new Set([
  common_1$3.ServerType.Mongos,
  common_1$3.ServerType.Standalone,
]);
const NON_PRIMARY_RS_MEMBERS = new Set([
  common_1$3.ServerType.RSSecondary,
  common_1$3.ServerType.RSArbiter,
  common_1$3.ServerType.RSOther,
]);
/**
 * Representation of a deployment of servers
 * @public
 */
class TopologyDescription {
  /**
   * Create a TopologyDescription
   */
  constructor(
    topologyType,
    serverDescriptions = null,
    setName = null,
    maxSetVersion = null,
    maxElectionId = null,
    commonWireVersion = null,
    options = null,
  ) {
    options = options ?? {};
    this.type = topologyType ?? common_1$3.TopologyType.Unknown;
    this.servers = serverDescriptions ?? new Map();
    this.stale = false;
    this.compatible = true;
    this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 0;
    this.localThresholdMS = options.localThresholdMS ?? 15;
    this.setName = setName ?? null;
    this.maxElectionId = maxElectionId ?? null;
    this.maxSetVersion = maxSetVersion ?? null;
    this.commonWireVersion = commonWireVersion ?? 0;
    // determine server compatibility
    for (const serverDescription of this.servers.values()) {
      // Load balancer mode is always compatible.
      if (
        serverDescription.type === common_1$3.ServerType.Unknown ||
        serverDescription.type === common_1$3.ServerType.LoadBalancer
      ) {
        continue;
      }
      if (serverDescription.minWireVersion > MAX_SUPPORTED_WIRE_VERSION) {
        this.compatible = false;
        this.compatibilityError = `Server at ${serverDescription.address} requires wire version ${serverDescription.minWireVersion}, but this version of the driver only supports up to ${MAX_SUPPORTED_WIRE_VERSION} (MongoDB ${MAX_SUPPORTED_SERVER_VERSION})`;
      }
      if (serverDescription.maxWireVersion < MIN_SUPPORTED_WIRE_VERSION) {
        this.compatible = false;
        this.compatibilityError = `Server at ${serverDescription.address} reports wire version ${serverDescription.maxWireVersion}, but this version of the driver requires at least ${MIN_SUPPORTED_WIRE_VERSION} (MongoDB ${MIN_SUPPORTED_SERVER_VERSION}).`;
        break;
      }
    }
    // Whenever a client updates the TopologyDescription from a hello response, it MUST set
    // TopologyDescription.logicalSessionTimeoutMinutes to the smallest logicalSessionTimeoutMinutes
    // value among ServerDescriptions of all data-bearing server types. If any have a null
    // logicalSessionTimeoutMinutes, then TopologyDescription.logicalSessionTimeoutMinutes MUST be
    // set to null.
    this.logicalSessionTimeoutMinutes = null;
    for (const [, server] of this.servers) {
      if (server.isReadable) {
        if (server.logicalSessionTimeoutMinutes == null) {
          // If any of the servers have a null logicalSessionsTimeout, then the whole topology does
          this.logicalSessionTimeoutMinutes = null;
          break;
        }
        if (this.logicalSessionTimeoutMinutes == null) {
          // First server with a non null logicalSessionsTimeout
          this.logicalSessionTimeoutMinutes =
            server.logicalSessionTimeoutMinutes;
          continue;
        }
        // Always select the smaller of the:
        // current server logicalSessionsTimeout and the topologies logicalSessionsTimeout
        this.logicalSessionTimeoutMinutes = Math.min(
          this.logicalSessionTimeoutMinutes,
          server.logicalSessionTimeoutMinutes,
        );
      }
    }
  }
  /**
   * Returns a new TopologyDescription based on the SrvPollingEvent
   * @internal
   */
  updateFromSrvPollingEvent(ev, srvMaxHosts = 0) {
    /** The SRV addresses defines the set of addresses we should be using */
    const incomingHostnames = ev.hostnames();
    const currentHostnames = new Set(this.servers.keys());
    const hostnamesToAdd = new Set(incomingHostnames);
    const hostnamesToRemove = new Set();
    for (const hostname of currentHostnames) {
      // filter hostnamesToAdd (made from incomingHostnames) down to what is *not* present in currentHostnames
      hostnamesToAdd.delete(hostname);
      if (!incomingHostnames.has(hostname)) {
        // If the SRV Records no longer include this hostname
        // we have to stop using it
        hostnamesToRemove.add(hostname);
      }
    }
    if (hostnamesToAdd.size === 0 && hostnamesToRemove.size === 0) {
      // No new hosts to add and none to remove
      return this;
    }
    const serverDescriptions = new Map(this.servers);
    for (const removedHost of hostnamesToRemove) {
      serverDescriptions.delete(removedHost);
    }
    if (hostnamesToAdd.size > 0) {
      if (srvMaxHosts === 0) {
        // Add all!
        for (const hostToAdd of hostnamesToAdd) {
          serverDescriptions.set(
            hostToAdd,
            new server_description_1$1.ServerDescription(hostToAdd),
          );
        }
      } else if (serverDescriptions.size < srvMaxHosts) {
        // Add only the amount needed to get us back to srvMaxHosts
        const selectedHosts = (0, utils_1$l.shuffle)(
          hostnamesToAdd,
          srvMaxHosts - serverDescriptions.size,
        );
        for (const selectedHostToAdd of selectedHosts) {
          serverDescriptions.set(
            selectedHostToAdd,
            new server_description_1$1.ServerDescription(selectedHostToAdd),
          );
        }
      }
    }
    return new TopologyDescription(
      this.type,
      serverDescriptions,
      this.setName,
      this.maxSetVersion,
      this.maxElectionId,
      this.commonWireVersion,
      {
        heartbeatFrequencyMS: this.heartbeatFrequencyMS,
        localThresholdMS: this.localThresholdMS,
      },
    );
  }
  /**
   * Returns a copy of this description updated with a given ServerDescription
   * @internal
   */
  update(serverDescription) {
    const address = serverDescription.address;
    // potentially mutated values
    let {
      type: topologyType,
      setName,
      maxSetVersion,
      maxElectionId,
      commonWireVersion,
    } = this;
    const serverType = serverDescription.type;
    const serverDescriptions = new Map(this.servers);
    // update common wire version
    if (serverDescription.maxWireVersion !== 0) {
      if (commonWireVersion == null) {
        commonWireVersion = serverDescription.maxWireVersion;
      } else {
        commonWireVersion = Math.min(
          commonWireVersion,
          serverDescription.maxWireVersion,
        );
      }
    }
    if (
      typeof serverDescription.setName === "string" &&
      typeof setName === "string" &&
      serverDescription.setName !== setName
    ) {
      if (topologyType === common_1$3.TopologyType.Single) {
        // "Single" Topology with setName mismatch is direct connection usage, mark unknown do not remove
        serverDescription = new server_description_1$1.ServerDescription(
          address,
        );
      } else {
        serverDescriptions.delete(address);
      }
    }
    // update the actual server description
    serverDescriptions.set(address, serverDescription);
    if (topologyType === common_1$3.TopologyType.Single) {
      // once we are defined as single, that never changes
      return new TopologyDescription(
        common_1$3.TopologyType.Single,
        serverDescriptions,
        setName,
        maxSetVersion,
        maxElectionId,
        commonWireVersion,
        {
          heartbeatFrequencyMS: this.heartbeatFrequencyMS,
          localThresholdMS: this.localThresholdMS,
        },
      );
    }
    if (topologyType === common_1$3.TopologyType.Unknown) {
      if (
        serverType === common_1$3.ServerType.Standalone &&
        this.servers.size !== 1
      ) {
        serverDescriptions.delete(address);
      } else {
        topologyType = topologyTypeForServerType(serverType);
      }
    }
    if (topologyType === common_1$3.TopologyType.Sharded) {
      if (!MONGOS_OR_UNKNOWN.has(serverType)) {
        serverDescriptions.delete(address);
      }
    }
    if (topologyType === common_1$3.TopologyType.ReplicaSetNoPrimary) {
      if (MONGOS_OR_STANDALONE.has(serverType)) {
        serverDescriptions.delete(address);
      }
      if (serverType === common_1$3.ServerType.RSPrimary) {
        const result = updateRsFromPrimary(
          serverDescriptions,
          serverDescription,
          setName,
          maxSetVersion,
          maxElectionId,
        );
        topologyType = result[0];
        setName = result[1];
        maxSetVersion = result[2];
        maxElectionId = result[3];
      } else if (NON_PRIMARY_RS_MEMBERS.has(serverType)) {
        const result = updateRsNoPrimaryFromMember(
          serverDescriptions,
          serverDescription,
          setName,
        );
        topologyType = result[0];
        setName = result[1];
      }
    }
    if (topologyType === common_1$3.TopologyType.ReplicaSetWithPrimary) {
      if (MONGOS_OR_STANDALONE.has(serverType)) {
        serverDescriptions.delete(address);
        topologyType = checkHasPrimary(serverDescriptions);
      } else if (serverType === common_1$3.ServerType.RSPrimary) {
        const result = updateRsFromPrimary(
          serverDescriptions,
          serverDescription,
          setName,
          maxSetVersion,
          maxElectionId,
        );
        topologyType = result[0];
        setName = result[1];
        maxSetVersion = result[2];
        maxElectionId = result[3];
      } else if (NON_PRIMARY_RS_MEMBERS.has(serverType)) {
        topologyType = updateRsWithPrimaryFromMember(
          serverDescriptions,
          serverDescription,
          setName,
        );
      } else {
        topologyType = checkHasPrimary(serverDescriptions);
      }
    }
    return new TopologyDescription(
      topologyType,
      serverDescriptions,
      setName,
      maxSetVersion,
      maxElectionId,
      commonWireVersion,
      {
        heartbeatFrequencyMS: this.heartbeatFrequencyMS,
        localThresholdMS: this.localThresholdMS,
      },
    );
  }
  get error() {
    const descriptionsWithError = Array.from(this.servers.values()).filter(
      (sd) => sd.error,
    );
    if (descriptionsWithError.length > 0) {
      return descriptionsWithError[0].error;
    }
    return null;
  }
  /**
   * Determines if the topology description has any known servers
   */
  get hasKnownServers() {
    return Array.from(this.servers.values()).some(
      (sd) => sd.type !== common_1$3.ServerType.Unknown,
    );
  }
  /**
   * Determines if this topology description has a data-bearing server available.
   */
  get hasDataBearingServers() {
    return Array.from(this.servers.values()).some((sd) => sd.isDataBearing);
  }
  /**
   * Determines if the topology has a definition for the provided address
   * @internal
   */
  hasServer(address) {
    return this.servers.has(address);
  }
}
topology_description.TopologyDescription = TopologyDescription;
function topologyTypeForServerType(serverType) {
  switch (serverType) {
    case common_1$3.ServerType.Standalone:
      return common_1$3.TopologyType.Single;
    case common_1$3.ServerType.Mongos:
      return common_1$3.TopologyType.Sharded;
    case common_1$3.ServerType.RSPrimary:
      return common_1$3.TopologyType.ReplicaSetWithPrimary;
    case common_1$3.ServerType.RSOther:
    case common_1$3.ServerType.RSSecondary:
      return common_1$3.TopologyType.ReplicaSetNoPrimary;
    default:
      return common_1$3.TopologyType.Unknown;
  }
}
function updateRsFromPrimary(
  serverDescriptions,
  serverDescription,
  setName = null,
  maxSetVersion = null,
  maxElectionId = null,
) {
  setName = setName || serverDescription.setName;
  if (setName !== serverDescription.setName) {
    serverDescriptions.delete(serverDescription.address);
    return [
      checkHasPrimary(serverDescriptions),
      setName,
      maxSetVersion,
      maxElectionId,
    ];
  }
  if (serverDescription.maxWireVersion >= 17) {
    const electionIdComparison = (0, utils_1$l.compareObjectId)(
      maxElectionId,
      serverDescription.electionId,
    );
    const maxElectionIdIsEqual = electionIdComparison === 0;
    const maxElectionIdIsLess = electionIdComparison === -1;
    const maxSetVersionIsLessOrEqual =
      (maxSetVersion ?? -1) <= (serverDescription.setVersion ?? -1);
    if (
      maxElectionIdIsLess ||
      (maxElectionIdIsEqual && maxSetVersionIsLessOrEqual)
    ) {
      // The reported electionId was greater
      // or the electionId was equal and reported setVersion was greater
      // Always update both values, they are a tuple
      maxElectionId = serverDescription.electionId;
      maxSetVersion = serverDescription.setVersion;
    } else {
      // Stale primary
      // replace serverDescription with a default ServerDescription of type "Unknown"
      serverDescriptions.set(
        serverDescription.address,
        new server_description_1$1.ServerDescription(serverDescription.address),
      );
      return [
        checkHasPrimary(serverDescriptions),
        setName,
        maxSetVersion,
        maxElectionId,
      ];
    }
  } else {
    const electionId = serverDescription.electionId
      ? serverDescription.electionId
      : null;
    if (serverDescription.setVersion && electionId) {
      if (maxSetVersion && maxElectionId) {
        if (
          maxSetVersion > serverDescription.setVersion ||
          (0, utils_1$l.compareObjectId)(maxElectionId, electionId) > 0
        ) {
          // this primary is stale, we must remove it
          serverDescriptions.set(
            serverDescription.address,
            new server_description_1$1.ServerDescription(
              serverDescription.address,
            ),
          );
          return [
            checkHasPrimary(serverDescriptions),
            setName,
            maxSetVersion,
            maxElectionId,
          ];
        }
      }
      maxElectionId = serverDescription.electionId;
    }
    if (
      serverDescription.setVersion != null &&
      (maxSetVersion == null || serverDescription.setVersion > maxSetVersion)
    ) {
      maxSetVersion = serverDescription.setVersion;
    }
  }
  // We've heard from the primary. Is it the same primary as before?
  for (const [address, server] of serverDescriptions) {
    if (
      server.type === common_1$3.ServerType.RSPrimary &&
      server.address !== serverDescription.address
    ) {
      // Reset old primary's type to Unknown.
      serverDescriptions.set(
        address,
        new server_description_1$1.ServerDescription(server.address),
      );
      // There can only be one primary
      break;
    }
  }
  // Discover new hosts from this primary's response.
  serverDescription.allHosts.forEach((address) => {
    if (!serverDescriptions.has(address)) {
      serverDescriptions.set(
        address,
        new server_description_1$1.ServerDescription(address),
      );
    }
  });
  // Remove hosts not in the response.
  const currentAddresses = Array.from(serverDescriptions.keys());
  const responseAddresses = serverDescription.allHosts;
  currentAddresses
    .filter((addr) => responseAddresses.indexOf(addr) === -1)
    .forEach((address) => {
      serverDescriptions.delete(address);
    });
  return [
    checkHasPrimary(serverDescriptions),
    setName,
    maxSetVersion,
    maxElectionId,
  ];
}
function updateRsWithPrimaryFromMember(
  serverDescriptions,
  serverDescription,
  setName = null,
) {
  if (setName == null) {
    // TODO(NODE-3483): should be an appropriate runtime error
    throw new error_1$x.MongoRuntimeError(
      'Argument "setName" is required if connected to a replica set',
    );
  }
  if (
    setName !== serverDescription.setName ||
    (serverDescription.me && serverDescription.address !== serverDescription.me)
  ) {
    serverDescriptions.delete(serverDescription.address);
  }
  return checkHasPrimary(serverDescriptions);
}
function updateRsNoPrimaryFromMember(
  serverDescriptions,
  serverDescription,
  setName = null,
) {
  const topologyType = common_1$3.TopologyType.ReplicaSetNoPrimary;
  setName = setName ?? serverDescription.setName;
  if (setName !== serverDescription.setName) {
    serverDescriptions.delete(serverDescription.address);
    return [topologyType, setName];
  }
  serverDescription.allHosts.forEach((address) => {
    if (!serverDescriptions.has(address)) {
      serverDescriptions.set(
        address,
        new server_description_1$1.ServerDescription(address),
      );
    }
  });
  if (
    serverDescription.me &&
    serverDescription.address !== serverDescription.me
  ) {
    serverDescriptions.delete(serverDescription.address);
  }
  return [topologyType, setName];
}
function checkHasPrimary(serverDescriptions) {
  for (const serverDescription of serverDescriptions.values()) {
    if (serverDescription.type === common_1$3.ServerType.RSPrimary) {
      return common_1$3.TopologyType.ReplicaSetWithPrimary;
    }
  }
  return common_1$3.TopologyType.ReplicaSetNoPrimary;
}

Object.defineProperty(shared, "__esModule", { value: true });
shared.isSharded = shared.getReadPreference = void 0;
const error_1$w = error;
const read_preference_1$3 = read_preference;
const common_1$2 = common$1;
const topology_description_1 = topology_description;
function getReadPreference(options) {
  // Default to command version of the readPreference
  let readPreference =
    options?.readPreference ?? read_preference_1$3.ReadPreference.primary;
  // If we have an option readPreference override the command one
  if (options?.readPreference) {
    readPreference = options.readPreference;
  }
  if (typeof readPreference === "string") {
    readPreference =
      read_preference_1$3.ReadPreference.fromString(readPreference);
  }
  if (!(readPreference instanceof read_preference_1$3.ReadPreference)) {
    throw new error_1$w.MongoInvalidArgumentError(
      'Option "readPreference" must be a ReadPreference instance',
    );
  }
  return readPreference;
}
shared.getReadPreference = getReadPreference;
function isSharded(topologyOrServer) {
  if (topologyOrServer == null) {
    return false;
  }
  if (
    topologyOrServer.description &&
    topologyOrServer.description.type === common_1$2.ServerType.Mongos
  ) {
    return true;
  }
  // NOTE: This is incredibly inefficient, and should be removed once command construction
  //       happens based on `Server` not `Topology`.
  if (
    topologyOrServer.description &&
    topologyOrServer.description instanceof
      topology_description_1.TopologyDescription
  ) {
    const servers = Array.from(topologyOrServer.description.servers.values());
    return servers.some(
      (server) => server.type === common_1$2.ServerType.Mongos,
    );
  }
  return false;
}
shared.isSharded = isSharded;

var transactions = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.isTransactionCommand =
    exports.Transaction =
    exports.TxnState =
      void 0;
  const error_1 = error;
  const read_concern_1 = read_concern;
  const read_preference_1 = read_preference;
  const write_concern_1 = write_concern;
  /** @internal */
  exports.TxnState = Object.freeze({
    NO_TRANSACTION: "NO_TRANSACTION",
    STARTING_TRANSACTION: "STARTING_TRANSACTION",
    TRANSACTION_IN_PROGRESS: "TRANSACTION_IN_PROGRESS",
    TRANSACTION_COMMITTED: "TRANSACTION_COMMITTED",
    TRANSACTION_COMMITTED_EMPTY: "TRANSACTION_COMMITTED_EMPTY",
    TRANSACTION_ABORTED: "TRANSACTION_ABORTED",
  });
  const stateMachine = {
    [exports.TxnState.NO_TRANSACTION]: [
      exports.TxnState.NO_TRANSACTION,
      exports.TxnState.STARTING_TRANSACTION,
    ],
    [exports.TxnState.STARTING_TRANSACTION]: [
      exports.TxnState.TRANSACTION_IN_PROGRESS,
      exports.TxnState.TRANSACTION_COMMITTED,
      exports.TxnState.TRANSACTION_COMMITTED_EMPTY,
      exports.TxnState.TRANSACTION_ABORTED,
    ],
    [exports.TxnState.TRANSACTION_IN_PROGRESS]: [
      exports.TxnState.TRANSACTION_IN_PROGRESS,
      exports.TxnState.TRANSACTION_COMMITTED,
      exports.TxnState.TRANSACTION_ABORTED,
    ],
    [exports.TxnState.TRANSACTION_COMMITTED]: [
      exports.TxnState.TRANSACTION_COMMITTED,
      exports.TxnState.TRANSACTION_COMMITTED_EMPTY,
      exports.TxnState.STARTING_TRANSACTION,
      exports.TxnState.NO_TRANSACTION,
    ],
    [exports.TxnState.TRANSACTION_ABORTED]: [
      exports.TxnState.STARTING_TRANSACTION,
      exports.TxnState.NO_TRANSACTION,
    ],
    [exports.TxnState.TRANSACTION_COMMITTED_EMPTY]: [
      exports.TxnState.TRANSACTION_COMMITTED_EMPTY,
      exports.TxnState.NO_TRANSACTION,
    ],
  };
  const ACTIVE_STATES = new Set([
    exports.TxnState.STARTING_TRANSACTION,
    exports.TxnState.TRANSACTION_IN_PROGRESS,
  ]);
  const COMMITTED_STATES = new Set([
    exports.TxnState.TRANSACTION_COMMITTED,
    exports.TxnState.TRANSACTION_COMMITTED_EMPTY,
    exports.TxnState.TRANSACTION_ABORTED,
  ]);
  /**
   * @public
   * A class maintaining state related to a server transaction. Internal Only
   */
  class Transaction {
    /** Create a transaction @internal */
    constructor(options) {
      options = options ?? {};
      this.state = exports.TxnState.NO_TRANSACTION;
      this.options = {};
      const writeConcern = write_concern_1.WriteConcern.fromOptions(options);
      if (writeConcern) {
        if (writeConcern.w === 0) {
          throw new error_1.MongoTransactionError(
            "Transactions do not support unacknowledged write concern",
          );
        }
        this.options.writeConcern = writeConcern;
      }
      if (options.readConcern) {
        this.options.readConcern =
          read_concern_1.ReadConcern.fromOptions(options);
      }
      if (options.readPreference) {
        this.options.readPreference =
          read_preference_1.ReadPreference.fromOptions(options);
      }
      if (options.maxCommitTimeMS) {
        this.options.maxTimeMS = options.maxCommitTimeMS;
      }
      // TODO: This isn't technically necessary
      this._pinnedServer = undefined;
      this._recoveryToken = undefined;
    }
    /** @internal */
    get server() {
      return this._pinnedServer;
    }
    get recoveryToken() {
      return this._recoveryToken;
    }
    get isPinned() {
      return !!this.server;
    }
    /** @returns Whether the transaction has started */
    get isStarting() {
      return this.state === exports.TxnState.STARTING_TRANSACTION;
    }
    /**
     * @returns Whether this session is presently in a transaction
     */
    get isActive() {
      return ACTIVE_STATES.has(this.state);
    }
    get isCommitted() {
      return COMMITTED_STATES.has(this.state);
    }
    /**
     * Transition the transaction in the state machine
     * @internal
     * @param nextState - The new state to transition to
     */
    transition(nextState) {
      const nextStates = stateMachine[this.state];
      if (nextStates && nextStates.includes(nextState)) {
        this.state = nextState;
        if (
          this.state === exports.TxnState.NO_TRANSACTION ||
          this.state === exports.TxnState.STARTING_TRANSACTION ||
          this.state === exports.TxnState.TRANSACTION_ABORTED
        ) {
          this.unpinServer();
        }
        return;
      }
      throw new error_1.MongoRuntimeError(
        `Attempted illegal state transition from [${this.state}] to [${nextState}]`,
      );
    }
    /** @internal */
    pinServer(server) {
      if (this.isActive) {
        this._pinnedServer = server;
      }
    }
    /** @internal */
    unpinServer() {
      this._pinnedServer = undefined;
    }
  }
  exports.Transaction = Transaction;
  function isTransactionCommand(command) {
    return !!(command.commitTransaction || command.abortTransaction);
  }
  exports.isTransactionCommand = isTransactionCommand;
})(transactions);

var _a;
Object.defineProperty(sessions, "__esModule", { value: true });
sessions.updateSessionFromResponse =
  sessions.applySession =
  sessions.ServerSessionPool =
  sessions.ServerSession =
  sessions.maybeClearPinnedConnection =
  sessions.ClientSession =
    void 0;
const util_1$3 = $noteUtil;
const bson_1$9 = bson$2;
const metrics_1 = metrics;
const shared_1$1 = shared;
const constants_1$4 = constants;
const error_1$v = error;
const mongo_types_1$3 = mongo_types;
const execute_operation_1$5 = execute_operation;
const run_command_1$1 = run_command;
const read_concern_1$1 = read_concern;
const read_preference_1$2 = read_preference;
const common_1$1 = common$1;
const transactions_1 = transactions;
const utils_1$k = utils$2;
const write_concern_1$2 = write_concern;
const minWireVersionForShardedTransactions = 8;
/** @internal */
const kServerSession = Symbol("serverSession");
/** @internal */
const kSnapshotTime = Symbol("snapshotTime");
/** @internal */
const kSnapshotEnabled = Symbol("snapshotEnabled");
/** @internal */
const kPinnedConnection = Symbol("pinnedConnection");
/** @internal Accumulates total number of increments to add to txnNumber when applying session to command */
const kTxnNumberIncrement = Symbol("txnNumberIncrement");
/**
 * A class representing a client session on the server
 *
 * NOTE: not meant to be instantiated directly.
 * @public
 */
let ClientSession$1 = class ClientSession extends mongo_types_1$3.TypedEventEmitter {
  /**
   * Create a client session.
   * @internal
   * @param client - The current client
   * @param sessionPool - The server session pool (Internal Class)
   * @param options - Optional settings
   * @param clientOptions - Optional settings provided when creating a MongoClient
   */
  constructor(client, sessionPool, options, clientOptions) {
    super();
    /** @internal */
    this[_a] = false;
    if (client == null) {
      // TODO(NODE-3483)
      throw new error_1$v.MongoRuntimeError(
        "ClientSession requires a MongoClient",
      );
    }
    if (sessionPool == null || !(sessionPool instanceof ServerSessionPool)) {
      // TODO(NODE-3483)
      throw new error_1$v.MongoRuntimeError(
        "ClientSession requires a ServerSessionPool",
      );
    }
    options = options ?? {};
    if (options.snapshot === true) {
      this[kSnapshotEnabled] = true;
      if (options.causalConsistency === true) {
        throw new error_1$v.MongoInvalidArgumentError(
          'Properties "causalConsistency" and "snapshot" are mutually exclusive',
        );
      }
    }
    this.client = client;
    this.sessionPool = sessionPool;
    this.hasEnded = false;
    this.clientOptions = clientOptions;
    this.explicit = !!options.explicit;
    this[kServerSession] = this.explicit ? this.sessionPool.acquire() : null;
    this[kTxnNumberIncrement] = 0;
    const defaultCausalConsistencyValue =
      this.explicit && options.snapshot !== true;
    this.supports = {
      // if we can enable causal consistency, do so by default
      causalConsistency:
        options.causalConsistency ?? defaultCausalConsistencyValue,
    };
    this.clusterTime = options.initialClusterTime;
    this.operationTime = undefined;
    this.owner = options.owner;
    this.defaultTransactionOptions = Object.assign(
      {},
      options.defaultTransactionOptions,
    );
    this.transaction = new transactions_1.Transaction();
  }
  /** The server id associated with this session */
  get id() {
    return this[kServerSession]?.id;
  }
  get serverSession() {
    let serverSession = this[kServerSession];
    if (serverSession == null) {
      if (this.explicit) {
        throw new error_1$v.MongoRuntimeError(
          "Unexpected null serverSession for an explicit session",
        );
      }
      if (this.hasEnded) {
        throw new error_1$v.MongoRuntimeError(
          "Unexpected null serverSession for an ended implicit session",
        );
      }
      serverSession = this.sessionPool.acquire();
      this[kServerSession] = serverSession;
    }
    return serverSession;
  }
  /** Whether or not this session is configured for snapshot reads */
  get snapshotEnabled() {
    return this[kSnapshotEnabled];
  }
  get loadBalanced() {
    return (
      this.client.topology?.description.type ===
      common_1$1.TopologyType.LoadBalanced
    );
  }
  /** @internal */
  get pinnedConnection() {
    return this[kPinnedConnection];
  }
  /** @internal */
  pin(conn) {
    if (this[kPinnedConnection]) {
      throw TypeError("Cannot pin multiple connections to the same session");
    }
    this[kPinnedConnection] = conn;
    conn.emit(
      constants_1$4.PINNED,
      this.inTransaction()
        ? metrics_1.ConnectionPoolMetrics.TXN
        : metrics_1.ConnectionPoolMetrics.CURSOR,
    );
  }
  /** @internal */
  unpin(options) {
    if (this.loadBalanced) {
      return maybeClearPinnedConnection(this, options);
    }
    this.transaction.unpinServer();
  }
  get isPinned() {
    return this.loadBalanced
      ? !!this[kPinnedConnection]
      : this.transaction.isPinned;
  }
  /**
   * Ends this session on the server
   *
   * @param options - Optional settings. Currently reserved for future use
   */
  async endSession(options) {
    try {
      if (this.inTransaction()) {
        await this.abortTransaction();
      }
      if (!this.hasEnded) {
        const serverSession = this[kServerSession];
        if (serverSession != null) {
          // release the server session back to the pool
          this.sessionPool.release(serverSession);
          // Make sure a new serverSession never makes it onto this ClientSession
          Object.defineProperty(this, kServerSession, {
            value: ServerSession.clone(serverSession),
            writable: false,
          });
        }
        // mark the session as ended, and emit a signal
        this.hasEnded = true;
        this.emit("ended", this);
      }
    } catch {
      // spec indicates that we should ignore all errors for `endSessions`
    } finally {
      maybeClearPinnedConnection(this, { force: true, ...options });
    }
  }
  /**
   * Advances the operationTime for a ClientSession.
   *
   * @param operationTime - the `BSON.Timestamp` of the operation type it is desired to advance to
   */
  advanceOperationTime(operationTime) {
    if (this.operationTime == null) {
      this.operationTime = operationTime;
      return;
    }
    if (operationTime.greaterThan(this.operationTime)) {
      this.operationTime = operationTime;
    }
  }
  /**
   * Advances the clusterTime for a ClientSession to the provided clusterTime of another ClientSession
   *
   * @param clusterTime - the $clusterTime returned by the server from another session in the form of a document containing the `BSON.Timestamp` clusterTime and signature
   */
  advanceClusterTime(clusterTime) {
    if (!clusterTime || typeof clusterTime !== "object") {
      throw new error_1$v.MongoInvalidArgumentError(
        "input cluster time must be an object",
      );
    }
    if (
      !clusterTime.clusterTime ||
      clusterTime.clusterTime._bsontype !== "Timestamp"
    ) {
      throw new error_1$v.MongoInvalidArgumentError(
        'input cluster time "clusterTime" property must be a valid BSON Timestamp',
      );
    }
    if (
      !clusterTime.signature ||
      clusterTime.signature.hash?._bsontype !== "Binary" ||
      (typeof clusterTime.signature.keyId !== "bigint" &&
        typeof clusterTime.signature.keyId !== "number" &&
        clusterTime.signature.keyId?._bsontype !== "Long") // apparently we decode the key to number?
    ) {
      throw new error_1$v.MongoInvalidArgumentError(
        'input cluster time must have a valid "signature" property with BSON Binary hash and BSON Long keyId',
      );
    }
    (0, common_1$1._advanceClusterTime)(this, clusterTime);
  }
  /**
   * Used to determine if this session equals another
   *
   * @param session - The session to compare to
   */
  equals(session) {
    if (!(session instanceof ClientSession)) {
      return false;
    }
    if (this.id == null || session.id == null) {
      return false;
    }
    return utils_1$k.ByteUtils.equals(this.id.id.buffer, session.id.id.buffer);
  }
  /**
   * Increment the transaction number on the internal ServerSession
   *
   * @privateRemarks
   * This helper increments a value stored on the client session that will be
   * added to the serverSession's txnNumber upon applying it to a command.
   * This is because the serverSession is lazily acquired after a connection is obtained
   */
  incrementTransactionNumber() {
    this[kTxnNumberIncrement] += 1;
  }
  /** @returns whether this session is currently in a transaction or not */
  inTransaction() {
    return this.transaction.isActive;
  }
  /**
   * Starts a new transaction with the given options.
   *
   * @param options - Options for the transaction
   */
  startTransaction(options) {
    if (this[kSnapshotEnabled]) {
      throw new error_1$v.MongoCompatibilityError(
        "Transactions are not supported in snapshot sessions",
      );
    }
    if (this.inTransaction()) {
      throw new error_1$v.MongoTransactionError(
        "Transaction already in progress",
      );
    }
    if (this.isPinned && this.transaction.isCommitted) {
      this.unpin();
    }
    const topologyMaxWireVersion = (0, utils_1$k.maxWireVersion)(
      this.client.topology,
    );
    if (
      (0, shared_1$1.isSharded)(this.client.topology) &&
      topologyMaxWireVersion != null &&
      topologyMaxWireVersion < minWireVersionForShardedTransactions
    ) {
      throw new error_1$v.MongoCompatibilityError(
        "Transactions are not supported on sharded clusters in MongoDB < 4.2.",
      );
    }
    // increment txnNumber
    this.incrementTransactionNumber();
    // create transaction state
    this.transaction = new transactions_1.Transaction({
      readConcern:
        options?.readConcern ??
        this.defaultTransactionOptions.readConcern ??
        this.clientOptions?.readConcern,
      writeConcern:
        options?.writeConcern ??
        this.defaultTransactionOptions.writeConcern ??
        this.clientOptions?.writeConcern,
      readPreference:
        options?.readPreference ??
        this.defaultTransactionOptions.readPreference ??
        this.clientOptions?.readPreference,
      maxCommitTimeMS:
        options?.maxCommitTimeMS ??
        this.defaultTransactionOptions.maxCommitTimeMS,
    });
    this.transaction.transition(transactions_1.TxnState.STARTING_TRANSACTION);
  }
  /**
   * Commits the currently active transaction in this session.
   */
  async commitTransaction() {
    return endTransactionAsync(this, "commitTransaction");
  }
  /**
   * Aborts the currently active transaction in this session.
   */
  async abortTransaction() {
    return endTransactionAsync(this, "abortTransaction");
  }
  /**
   * This is here to ensure that ClientSession is never serialized to BSON.
   */
  toBSON() {
    throw new error_1$v.MongoRuntimeError(
      "ClientSession cannot be serialized to BSON.",
    );
  }
  /**
   * Starts a transaction and runs a provided function, ensuring the commitTransaction is always attempted when all operations run in the function have completed.
   *
   * **IMPORTANT:** This method requires the user to return a Promise, and `await` all operations.
   *
   * @remarks
   * This function:
   * - If all operations successfully complete and the `commitTransaction` operation is successful, then this function will return the result of the provided function.
   * - If the transaction is unable to complete or an error is thrown from within the provided function, then this function will throw an error.
   *   - If the transaction is manually aborted within the provided function it will not throw.
   * - May be called multiple times if the driver needs to attempt to retry the operations.
   *
   * Checkout a descriptive example here:
   * @see https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-implement-transactions
   *
   * @param fn - callback to run within a transaction
   * @param options - optional settings for the transaction
   * @returns A raw command response or undefined
   */
  async withTransaction(fn, options) {
    const startTime = (0, utils_1$k.now)();
    return attemptTransaction(this, startTime, fn, options);
  }
};
sessions.ClientSession = ClientSession$1;
_a = kSnapshotEnabled;
const MAX_WITH_TRANSACTION_TIMEOUT = 120000;
const NON_DETERMINISTIC_WRITE_CONCERN_ERRORS = new Set([
  "CannotSatisfyWriteConcern",
  "UnknownReplWriteConcern",
  "UnsatisfiableWriteConcern",
]);
function hasNotTimedOut(startTime, max) {
  return (0, utils_1$k.calculateDurationInMs)(startTime) < max;
}
function isUnknownTransactionCommitResult(err) {
  const isNonDeterministicWriteConcernError =
    err instanceof error_1$v.MongoServerError &&
    err.codeName &&
    NON_DETERMINISTIC_WRITE_CONCERN_ERRORS.has(err.codeName);
  return (
    isMaxTimeMSExpiredError(err) ||
    (!isNonDeterministicWriteConcernError &&
      err.code !== error_1$v.MONGODB_ERROR_CODES.UnsatisfiableWriteConcern &&
      err.code !== error_1$v.MONGODB_ERROR_CODES.UnknownReplWriteConcern)
  );
}
function maybeClearPinnedConnection(session, options) {
  // unpin a connection if it has been pinned
  const conn = session[kPinnedConnection];
  const error = options?.error;
  if (
    session.inTransaction() &&
    error &&
    error instanceof error_1$v.MongoError &&
    error.hasErrorLabel(error_1$v.MongoErrorLabel.TransientTransactionError)
  ) {
    return;
  }
  const topology = session.client.topology;
  // NOTE: the spec talks about what to do on a network error only, but the tests seem to
  //       to validate that we don't unpin on _all_ errors?
  if (conn && topology != null) {
    const servers = Array.from(topology.s.servers.values());
    const loadBalancer = servers[0];
    if (options?.error == null || options?.force) {
      loadBalancer.pool.checkIn(conn);
      conn.emit(
        constants_1$4.UNPINNED,
        session.transaction.state !== transactions_1.TxnState.NO_TRANSACTION
          ? metrics_1.ConnectionPoolMetrics.TXN
          : metrics_1.ConnectionPoolMetrics.CURSOR,
      );
      if (options?.forceClear) {
        loadBalancer.pool.clear({ serviceId: conn.serviceId });
      }
    }
    session[kPinnedConnection] = undefined;
  }
}
sessions.maybeClearPinnedConnection = maybeClearPinnedConnection;
function isMaxTimeMSExpiredError(err) {
  if (err == null || !(err instanceof error_1$v.MongoServerError)) {
    return false;
  }
  return (
    err.code === error_1$v.MONGODB_ERROR_CODES.MaxTimeMSExpired ||
    (err.writeConcernError &&
      err.writeConcernError.code ===
        error_1$v.MONGODB_ERROR_CODES.MaxTimeMSExpired)
  );
}
function attemptTransactionCommit(session, startTime, fn, result, options) {
  return session.commitTransaction().then(
    () => result,
    (err) => {
      if (
        err instanceof error_1$v.MongoError &&
        hasNotTimedOut(startTime, MAX_WITH_TRANSACTION_TIMEOUT) &&
        !isMaxTimeMSExpiredError(err)
      ) {
        if (
          err.hasErrorLabel(
            error_1$v.MongoErrorLabel.UnknownTransactionCommitResult,
          )
        ) {
          return attemptTransactionCommit(
            session,
            startTime,
            fn,
            result,
            options,
          );
        }
        if (
          err.hasErrorLabel(error_1$v.MongoErrorLabel.TransientTransactionError)
        ) {
          return attemptTransaction(session, startTime, fn, options);
        }
      }
      throw err;
    },
  );
}
const USER_EXPLICIT_TXN_END_STATES = new Set([
  transactions_1.TxnState.NO_TRANSACTION,
  transactions_1.TxnState.TRANSACTION_COMMITTED,
  transactions_1.TxnState.TRANSACTION_ABORTED,
]);
function userExplicitlyEndedTransaction(session) {
  return USER_EXPLICIT_TXN_END_STATES.has(session.transaction.state);
}
function attemptTransaction(session, startTime, fn, options = {}) {
  session.startTransaction(options);
  let promise;
  try {
    promise = fn(session);
  } catch (err) {
    promise = Promise.reject(err);
  }
  if (!(0, utils_1$k.isPromiseLike)(promise)) {
    session.abortTransaction().catch(() => null);
    return Promise.reject(
      new error_1$v.MongoInvalidArgumentError(
        "Function provided to `withTransaction` must return a Promise",
      ),
    );
  }
  return promise.then(
    (result) => {
      if (userExplicitlyEndedTransaction(session)) {
        return result;
      }
      return attemptTransactionCommit(session, startTime, fn, result, options);
    },
    (err) => {
      function maybeRetryOrThrow(err) {
        if (
          err instanceof error_1$v.MongoError &&
          err.hasErrorLabel(
            error_1$v.MongoErrorLabel.TransientTransactionError,
          ) &&
          hasNotTimedOut(startTime, MAX_WITH_TRANSACTION_TIMEOUT)
        ) {
          return attemptTransaction(session, startTime, fn, options);
        }
        if (isMaxTimeMSExpiredError(err)) {
          err.addErrorLabel(
            error_1$v.MongoErrorLabel.UnknownTransactionCommitResult,
          );
        }
        throw err;
      }
      if (session.inTransaction()) {
        return session.abortTransaction().then(() => maybeRetryOrThrow(err));
      }
      return maybeRetryOrThrow(err);
    },
  );
}
const endTransactionAsync = (0, util_1$3.promisify)(endTransaction);
function endTransaction(session, commandName, callback) {
  // handle any initial problematic cases
  const txnState = session.transaction.state;
  if (txnState === transactions_1.TxnState.NO_TRANSACTION) {
    callback(new error_1$v.MongoTransactionError("No transaction started"));
    return;
  }
  if (commandName === "commitTransaction") {
    if (
      txnState === transactions_1.TxnState.STARTING_TRANSACTION ||
      txnState === transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY
    ) {
      // the transaction was never started, we can safely exit here
      session.transaction.transition(
        transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY,
      );
      callback();
      return;
    }
    if (txnState === transactions_1.TxnState.TRANSACTION_ABORTED) {
      callback(
        new error_1$v.MongoTransactionError(
          "Cannot call commitTransaction after calling abortTransaction",
        ),
      );
      return;
    }
  } else {
    if (txnState === transactions_1.TxnState.STARTING_TRANSACTION) {
      // the transaction was never started, we can safely exit here
      session.transaction.transition(
        transactions_1.TxnState.TRANSACTION_ABORTED,
      );
      callback();
      return;
    }
    if (txnState === transactions_1.TxnState.TRANSACTION_ABORTED) {
      callback(
        new error_1$v.MongoTransactionError(
          "Cannot call abortTransaction twice",
        ),
      );
      return;
    }
    if (
      txnState === transactions_1.TxnState.TRANSACTION_COMMITTED ||
      txnState === transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY
    ) {
      callback(
        new error_1$v.MongoTransactionError(
          "Cannot call abortTransaction after calling commitTransaction",
        ),
      );
      return;
    }
  }
  // construct and send the command
  const command = { [commandName]: 1 };
  // apply a writeConcern if specified
  let writeConcern;
  if (session.transaction.options.writeConcern) {
    writeConcern = Object.assign({}, session.transaction.options.writeConcern);
  } else if (session.clientOptions && session.clientOptions.writeConcern) {
    writeConcern = { w: session.clientOptions.writeConcern.w };
  }
  if (txnState === transactions_1.TxnState.TRANSACTION_COMMITTED) {
    writeConcern = Object.assign({ wtimeoutMS: 10000 }, writeConcern, {
      w: "majority",
    });
  }
  if (writeConcern) {
    write_concern_1$2.WriteConcern.apply(command, writeConcern);
  }
  if (
    commandName === "commitTransaction" &&
    session.transaction.options.maxTimeMS
  ) {
    Object.assign(command, {
      maxTimeMS: session.transaction.options.maxTimeMS,
    });
  }
  function commandHandler(error) {
    if (commandName !== "commitTransaction") {
      session.transaction.transition(
        transactions_1.TxnState.TRANSACTION_ABORTED,
      );
      if (session.loadBalanced) {
        maybeClearPinnedConnection(session, { force: false });
      }
      // The spec indicates that we should ignore all errors on `abortTransaction`
      return callback();
    }
    session.transaction.transition(
      transactions_1.TxnState.TRANSACTION_COMMITTED,
    );
    if (error instanceof error_1$v.MongoError) {
      if (
        error.hasErrorLabel(error_1$v.MongoErrorLabel.RetryableWriteError) ||
        error instanceof error_1$v.MongoWriteConcernError ||
        isMaxTimeMSExpiredError(error)
      ) {
        if (isUnknownTransactionCommitResult(error)) {
          error.addErrorLabel(
            error_1$v.MongoErrorLabel.UnknownTransactionCommitResult,
          );
          // per txns spec, must unpin session in this case
          session.unpin({ error });
        }
      } else if (
        error.hasErrorLabel(error_1$v.MongoErrorLabel.TransientTransactionError)
      ) {
        session.unpin({ error });
      }
    }
    callback(error);
  }
  if (session.transaction.recoveryToken) {
    command.recoveryToken = session.transaction.recoveryToken;
  }
  // send the command
  (0, execute_operation_1$5.executeOperation)(
    session.client,
    new run_command_1$1.RunAdminCommandOperation(command, {
      session,
      readPreference: read_preference_1$2.ReadPreference.primary,
      bypassPinningCheck: true,
    }),
    (error) => {
      if (command.abortTransaction) {
        // always unpin on abort regardless of command outcome
        session.unpin();
      }
      if (
        error instanceof error_1$v.MongoError &&
        error.hasErrorLabel(error_1$v.MongoErrorLabel.RetryableWriteError)
      ) {
        // SPEC-1185: apply majority write concern when retrying commitTransaction
        if (command.commitTransaction) {
          // per txns spec, must unpin session in this case
          session.unpin({ force: true });
          command.writeConcern = Object.assign(
            { wtimeout: 10000 },
            command.writeConcern,
            {
              w: "majority",
            },
          );
        }
        return (0, execute_operation_1$5.executeOperation)(
          session.client,
          new run_command_1$1.RunAdminCommandOperation(command, {
            session,
            readPreference: read_preference_1$2.ReadPreference.primary,
            bypassPinningCheck: true,
          }),
          commandHandler,
        );
      }
      commandHandler(error);
    },
  );
}
/**
 * Reflects the existence of a session on the server. Can be reused by the session pool.
 * WARNING: not meant to be instantiated directly. For internal use only.
 * @public
 */
class ServerSession {
  /** @internal */
  constructor() {
    this.id = {
      id: new bson_1$9.Binary(
        (0, utils_1$k.uuidV4)(),
        bson_1$9.Binary.SUBTYPE_UUID,
      ),
    };
    this.lastUse = (0, utils_1$k.now)();
    this.txnNumber = 0;
    this.isDirty = false;
  }
  /**
   * Determines if the server session has timed out.
   *
   * @param sessionTimeoutMinutes - The server's "logicalSessionTimeoutMinutes"
   */
  hasTimedOut(sessionTimeoutMinutes) {
    // Take the difference of the lastUse timestamp and now, which will result in a value in
    // milliseconds, and then convert milliseconds to minutes to compare to `sessionTimeoutMinutes`
    const idleTimeMinutes = Math.round(
      (((0, utils_1$k.calculateDurationInMs)(this.lastUse) % 86400000) %
        3600000) /
        60000,
    );
    return idleTimeMinutes > sessionTimeoutMinutes - 1;
  }
  /**
   * @internal
   * Cloning meant to keep a readable reference to the server session data
   * after ClientSession has ended
   */
  static clone(serverSession) {
    const arrayBuffer = new ArrayBuffer(16);
    const idBytes = Buffer.from(arrayBuffer);
    idBytes.set(serverSession.id.id.buffer);
    const id = new bson_1$9.Binary(idBytes, serverSession.id.id.sub_type);
    // Manual prototype construction to avoid modifying the constructor of this class
    return Object.setPrototypeOf(
      {
        id: { id },
        lastUse: serverSession.lastUse,
        txnNumber: serverSession.txnNumber,
        isDirty: serverSession.isDirty,
      },
      ServerSession.prototype,
    );
  }
}
sessions.ServerSession = ServerSession;
/**
 * Maintains a pool of Server Sessions.
 * For internal use only
 * @internal
 */
class ServerSessionPool {
  constructor(client) {
    if (client == null) {
      throw new error_1$v.MongoRuntimeError(
        "ServerSessionPool requires a MongoClient",
      );
    }
    this.client = client;
    this.sessions = new utils_1$k.List();
  }
  /**
   * Acquire a Server Session from the pool.
   * Iterates through each session in the pool, removing any stale sessions
   * along the way. The first non-stale session found is removed from the
   * pool and returned. If no non-stale session is found, a new ServerSession is created.
   */
  acquire() {
    const sessionTimeoutMinutes =
      this.client.topology?.logicalSessionTimeoutMinutes ?? 10;
    let session = null;
    // Try to obtain from session pool
    while (this.sessions.length > 0) {
      const potentialSession = this.sessions.shift();
      if (
        potentialSession != null &&
        (!!this.client.topology?.loadBalanced ||
          !potentialSession.hasTimedOut(sessionTimeoutMinutes))
      ) {
        session = potentialSession;
        break;
      }
    }
    // If nothing valid came from the pool make a new one
    if (session == null) {
      session = new ServerSession();
    }
    return session;
  }
  /**
   * Release a session to the session pool
   * Adds the session back to the session pool if the session has not timed out yet.
   * This method also removes any stale sessions from the pool.
   *
   * @param session - The session to release to the pool
   */
  release(session) {
    const sessionTimeoutMinutes =
      this.client.topology?.logicalSessionTimeoutMinutes ?? 10;
    if (this.client.topology?.loadBalanced && !sessionTimeoutMinutes) {
      this.sessions.unshift(session);
    }
    if (!sessionTimeoutMinutes) {
      return;
    }
    this.sessions.prune((session) =>
      session.hasTimedOut(sessionTimeoutMinutes),
    );
    if (!session.hasTimedOut(sessionTimeoutMinutes)) {
      if (session.isDirty) {
        return;
      }
      // otherwise, readd this session to the session pool
      this.sessions.unshift(session);
    }
  }
}
sessions.ServerSessionPool = ServerSessionPool;
/**
 * Optionally decorate a command with sessions specific keys
 *
 * @param session - the session tracking transaction state
 * @param command - the command to decorate
 * @param options - Optional settings passed to calling operation
 *
 * @internal
 */
function applySession(session, command, options) {
  if (session.hasEnded) {
    return new error_1$v.MongoExpiredSessionError();
  }
  // May acquire serverSession here
  const serverSession = session.serverSession;
  if (serverSession == null) {
    return new error_1$v.MongoRuntimeError("Unable to acquire server session");
  }
  if (options.writeConcern?.w === 0) {
    if (session && session.explicit) {
      // Error if user provided an explicit session to an unacknowledged write (SPEC-1019)
      return new error_1$v.MongoAPIError(
        "Cannot have explicit session with unacknowledged writes",
      );
    }
    return;
  }
  // mark the last use of this session, and apply the `lsid`
  serverSession.lastUse = (0, utils_1$k.now)();
  command.lsid = serverSession.id;
  const inTxnOrTxnCommand =
    session.inTransaction() ||
    (0, transactions_1.isTransactionCommand)(command);
  const isRetryableWrite = !!options.willRetryWrite;
  if (isRetryableWrite || inTxnOrTxnCommand) {
    serverSession.txnNumber += session[kTxnNumberIncrement];
    session[kTxnNumberIncrement] = 0;
    // TODO(NODE-2674): Preserve int64 sent from MongoDB
    command.txnNumber = bson_1$9.Long.fromNumber(serverSession.txnNumber);
  }
  if (!inTxnOrTxnCommand) {
    if (session.transaction.state !== transactions_1.TxnState.NO_TRANSACTION) {
      session.transaction.transition(transactions_1.TxnState.NO_TRANSACTION);
    }
    if (
      session.supports.causalConsistency &&
      session.operationTime &&
      (0, utils_1$k.commandSupportsReadConcern)(command)
    ) {
      command.readConcern = command.readConcern || {};
      Object.assign(command.readConcern, {
        afterClusterTime: session.operationTime,
      });
    } else if (session[kSnapshotEnabled]) {
      command.readConcern = command.readConcern || {
        level: read_concern_1$1.ReadConcernLevel.snapshot,
      };
      if (session[kSnapshotTime] != null) {
        Object.assign(command.readConcern, {
          atClusterTime: session[kSnapshotTime],
        });
      }
    }
    return;
  }
  // now attempt to apply transaction-specific sessions data
  // `autocommit` must always be false to differentiate from retryable writes
  command.autocommit = false;
  if (
    session.transaction.state === transactions_1.TxnState.STARTING_TRANSACTION
  ) {
    session.transaction.transition(
      transactions_1.TxnState.TRANSACTION_IN_PROGRESS,
    );
    command.startTransaction = true;
    const readConcern =
      session.transaction.options.readConcern ||
      session?.clientOptions?.readConcern;
    if (readConcern) {
      command.readConcern = readConcern;
    }
    if (session.supports.causalConsistency && session.operationTime) {
      command.readConcern = command.readConcern || {};
      Object.assign(command.readConcern, {
        afterClusterTime: session.operationTime,
      });
    }
  }
  return;
}
sessions.applySession = applySession;
function updateSessionFromResponse(session, document) {
  if (document.$clusterTime) {
    (0, common_1$1._advanceClusterTime)(session, document.$clusterTime);
  }
  if (document.operationTime && session && session.supports.causalConsistency) {
    session.advanceOperationTime(document.operationTime);
  }
  if (document.recoveryToken && session && session.inTransaction()) {
    session.transaction._recoveryToken = document.recoveryToken;
  }
  if (session?.[kSnapshotEnabled] && session[kSnapshotTime] == null) {
    // find and aggregate commands return atClusterTime on the cursor
    // distinct includes it in the response body
    const atClusterTime =
      document.cursor?.atClusterTime || document.atClusterTime;
    if (atClusterTime) {
      session[kSnapshotTime] = atClusterTime;
    }
  }
}
sessions.updateSessionFromResponse = updateSessionFromResponse;

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.assertUninitialized =
    exports.AbstractCursor =
    exports.CURSOR_FLAGS =
      void 0;
  const stream_1 = $nodeStream;
  const bson_1 = bson$2;
  const error_1 = error;
  const mongo_types_1 = mongo_types;
  const execute_operation_1 = execute_operation;
  const get_more_1 = get_more;
  const kill_cursors_1 = kill_cursors;
  const read_concern_1 = read_concern;
  const read_preference_1 = read_preference;
  const sessions_1 = sessions;
  const utils_1 = utils$2;
  /** @internal */
  const kId = Symbol("id");
  /** @internal */
  const kDocuments = Symbol("documents");
  /** @internal */
  const kServer = Symbol("server");
  /** @internal */
  const kNamespace = Symbol("namespace");
  /** @internal */
  const kClient = Symbol("client");
  /** @internal */
  const kSession = Symbol("session");
  /** @internal */
  const kOptions = Symbol("options");
  /** @internal */
  const kTransform = Symbol("transform");
  /** @internal */
  const kInitialized = Symbol("initialized");
  /** @internal */
  const kClosed = Symbol("closed");
  /** @internal */
  const kKilled = Symbol("killed");
  /** @internal */
  const kInit = Symbol("kInit");
  /** @public */
  exports.CURSOR_FLAGS = [
    "tailable",
    "oplogReplay",
    "noCursorTimeout",
    "awaitData",
    "exhaust",
    "partial",
  ];
  /** @public */
  class AbstractCursor extends mongo_types_1.TypedEventEmitter {
    /** @internal */
    constructor(client, namespace, options = {}) {
      super();
      if (!client.s.isMongoClient) {
        throw new error_1.MongoRuntimeError(
          "Cursor must be constructed with MongoClient",
        );
      }
      this[kClient] = client;
      this[kNamespace] = namespace;
      this[kId] = null;
      this[kDocuments] = new utils_1.List();
      this[kInitialized] = false;
      this[kClosed] = false;
      this[kKilled] = false;
      this[kOptions] = {
        readPreference:
          options.readPreference &&
          options.readPreference instanceof read_preference_1.ReadPreference
            ? options.readPreference
            : read_preference_1.ReadPreference.primary,
        ...(0, bson_1.pluckBSONSerializeOptions)(options),
      };
      const readConcern = read_concern_1.ReadConcern.fromOptions(options);
      if (readConcern) {
        this[kOptions].readConcern = readConcern;
      }
      if (typeof options.batchSize === "number") {
        this[kOptions].batchSize = options.batchSize;
      }
      // we check for undefined specifically here to allow falsy values
      // eslint-disable-next-line no-restricted-syntax
      if (options.comment !== undefined) {
        this[kOptions].comment = options.comment;
      }
      if (typeof options.maxTimeMS === "number") {
        this[kOptions].maxTimeMS = options.maxTimeMS;
      }
      if (typeof options.maxAwaitTimeMS === "number") {
        this[kOptions].maxAwaitTimeMS = options.maxAwaitTimeMS;
      }
      if (options.session instanceof sessions_1.ClientSession) {
        this[kSession] = options.session;
      } else {
        this[kSession] = this[kClient].startSession({
          owner: this,
          explicit: false,
        });
      }
    }
    get id() {
      return this[kId] ?? undefined;
    }
    /** @internal */
    get isDead() {
      return (this[kId]?.isZero() ?? false) || this[kClosed] || this[kKilled];
    }
    /** @internal */
    get client() {
      return this[kClient];
    }
    /** @internal */
    get server() {
      return this[kServer];
    }
    get namespace() {
      return this[kNamespace];
    }
    get readPreference() {
      return this[kOptions].readPreference;
    }
    get readConcern() {
      return this[kOptions].readConcern;
    }
    /** @internal */
    get session() {
      return this[kSession];
    }
    set session(clientSession) {
      this[kSession] = clientSession;
    }
    /** @internal */
    get cursorOptions() {
      return this[kOptions];
    }
    get closed() {
      return this[kClosed];
    }
    get killed() {
      return this[kKilled];
    }
    get loadBalanced() {
      return !!this[kClient].topology?.loadBalanced;
    }
    /** Returns current buffered documents length */
    bufferedCount() {
      return this[kDocuments].length;
    }
    /** Returns current buffered documents */
    readBufferedDocuments(number) {
      const bufferedDocs = [];
      const documentsToRead = Math.min(
        number ?? this[kDocuments].length,
        this[kDocuments].length,
      );
      for (let count = 0; count < documentsToRead; count++) {
        const document = this[kDocuments].shift();
        if (document != null) {
          bufferedDocs.push(document);
        }
      }
      return bufferedDocs;
    }
    async *[Symbol.asyncIterator]() {
      if (this.closed) {
        return;
      }
      try {
        while (true) {
          const document = await this.next();
          // Intentional strict null check, because users can map cursors to falsey values.
          // We allow mapping to all values except for null.
          // eslint-disable-next-line no-restricted-syntax
          if (document === null) {
            if (!this.closed) {
              const message =
                "Cursor returned a `null` document, but the cursor is not exhausted.  Mapping documents to `null` is not supported in the cursor transform.";
              await cleanupCursor(this, { needsToEmitClosed: true }).catch(
                () => null,
              );
              throw new error_1.MongoAPIError(message);
            }
            break;
          }
          yield document;
          if (this[kId] === bson_1.Long.ZERO) {
            // Cursor exhausted
            break;
          }
        }
      } finally {
        // Only close the cursor if it has not already been closed. This finally clause handles
        // the case when a user would break out of a for await of loop early.
        if (!this.closed) {
          await this.close().catch(() => null);
        }
      }
    }
    stream(options) {
      if (options?.transform) {
        const transform = options.transform;
        const readable = new ReadableCursorStream(this);
        return readable.pipe(
          new stream_1.Transform({
            objectMode: true,
            highWaterMark: 1,
            transform(chunk, _, callback) {
              try {
                const transformed = transform(chunk);
                callback(undefined, transformed);
              } catch (err) {
                callback(err);
              }
            },
          }),
        );
      }
      return new ReadableCursorStream(this);
    }
    async hasNext() {
      if (this[kId] === bson_1.Long.ZERO) {
        return false;
      }
      if (this[kDocuments].length !== 0) {
        return true;
      }
      const doc = await next(this, { blocking: true, transform: false });
      if (doc) {
        this[kDocuments].unshift(doc);
        return true;
      }
      return false;
    }
    /** Get the next available document from the cursor, returns null if no more documents are available. */
    async next() {
      if (this[kId] === bson_1.Long.ZERO) {
        throw new error_1.MongoCursorExhaustedError();
      }
      return next(this, { blocking: true, transform: true });
    }
    /**
     * Try to get the next available document from the cursor or `null` if an empty batch is returned
     */
    async tryNext() {
      if (this[kId] === bson_1.Long.ZERO) {
        throw new error_1.MongoCursorExhaustedError();
      }
      return next(this, { blocking: false, transform: true });
    }
    /**
     * Iterates over all the documents for this cursor using the iterator, callback pattern.
     *
     * If the iterator returns `false`, iteration will stop.
     *
     * @param iterator - The iteration callback.
     * @deprecated - Will be removed in a future release. Use for await...of instead.
     */
    async forEach(iterator) {
      if (typeof iterator !== "function") {
        throw new error_1.MongoInvalidArgumentError(
          'Argument "iterator" must be a function',
        );
      }
      for await (const document of this) {
        const result = iterator(document);
        if (result === false) {
          break;
        }
      }
    }
    async close() {
      const needsToEmitClosed = !this[kClosed];
      this[kClosed] = true;
      await cleanupCursor(this, { needsToEmitClosed });
    }
    /**
     * Returns an array of documents. The caller is responsible for making sure that there
     * is enough memory to store the results. Note that the array only contains partial
     * results when this cursor had been previously accessed. In that case,
     * cursor.rewind() can be used to reset the cursor.
     */
    async toArray() {
      const array = [];
      for await (const document of this) {
        array.push(document);
      }
      return array;
    }
    /**
     * Add a cursor flag to the cursor
     *
     * @param flag - The flag to set, must be one of following ['tailable', 'oplogReplay', 'noCursorTimeout', 'awaitData', 'partial' -.
     * @param value - The flag boolean value.
     */
    addCursorFlag(flag, value) {
      assertUninitialized(this);
      if (!exports.CURSOR_FLAGS.includes(flag)) {
        throw new error_1.MongoInvalidArgumentError(
          `Flag ${flag} is not one of ${exports.CURSOR_FLAGS}`,
        );
      }
      if (typeof value !== "boolean") {
        throw new error_1.MongoInvalidArgumentError(
          `Flag ${flag} must be a boolean value`,
        );
      }
      this[kOptions][flag] = value;
      return this;
    }
    /**
     * Map all documents using the provided function
     * If there is a transform set on the cursor, that will be called first and the result passed to
     * this function's transform.
     *
     * @remarks
     *
     * **Note** Cursors use `null` internally to indicate that there are no more documents in the cursor. Providing a mapping
     * function that maps values to `null` will result in the cursor closing itself before it has finished iterating
     * all documents.  This will **not** result in a memory leak, just surprising behavior.  For example:
     *
     * ```typescript
     * const cursor = collection.find({});
     * cursor.map(() => null);
     *
     * const documents = await cursor.toArray();
     * // documents is always [], regardless of how many documents are in the collection.
     * ```
     *
     * Other falsey values are allowed:
     *
     * ```typescript
     * const cursor = collection.find({});
     * cursor.map(() => '');
     *
     * const documents = await cursor.toArray();
     * // documents is now an array of empty strings
     * ```
     *
     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,
     * it **does not** return a new instance of a cursor. This means when calling map,
     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.
     * Take note of the following example:
     *
     * @example
     * ```typescript
     * const cursor: FindCursor<Document> = coll.find();
     * const mappedCursor: FindCursor<number> = cursor.map(doc => Object.keys(doc).length);
     * const keyCounts: number[] = await mappedCursor.toArray(); // cursor.toArray() still returns Document[]
     * ```
     * @param transform - The mapping transformation method.
     */
    map(transform) {
      assertUninitialized(this);
      const oldTransform = this[kTransform]; // TODO(NODE-3283): Improve transform typing
      if (oldTransform) {
        this[kTransform] = (doc) => {
          return transform(oldTransform(doc));
        };
      } else {
        this[kTransform] = transform;
      }
      return this;
    }
    /**
     * Set the ReadPreference for the cursor.
     *
     * @param readPreference - The new read preference for the cursor.
     */
    withReadPreference(readPreference) {
      assertUninitialized(this);
      if (readPreference instanceof read_preference_1.ReadPreference) {
        this[kOptions].readPreference = readPreference;
      } else if (typeof readPreference === "string") {
        this[kOptions].readPreference =
          read_preference_1.ReadPreference.fromString(readPreference);
      } else {
        throw new error_1.MongoInvalidArgumentError(
          `Invalid read preference: ${readPreference}`,
        );
      }
      return this;
    }
    /**
     * Set the ReadPreference for the cursor.
     *
     * @param readPreference - The new read preference for the cursor.
     */
    withReadConcern(readConcern) {
      assertUninitialized(this);
      const resolvedReadConcern = read_concern_1.ReadConcern.fromOptions({
        readConcern,
      });
      if (resolvedReadConcern) {
        this[kOptions].readConcern = resolvedReadConcern;
      }
      return this;
    }
    /**
     * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)
     *
     * @param value - Number of milliseconds to wait before aborting the query.
     */
    maxTimeMS(value) {
      assertUninitialized(this);
      if (typeof value !== "number") {
        throw new error_1.MongoInvalidArgumentError(
          "Argument for maxTimeMS must be a number",
        );
      }
      this[kOptions].maxTimeMS = value;
      return this;
    }
    /**
     * Set the batch size for the cursor.
     *
     * @param value - The number of documents to return per batch. See {@link https://www.mongodb.com/docs/manual/reference/command/find/|find command documentation}.
     */
    batchSize(value) {
      assertUninitialized(this);
      if (this[kOptions].tailable) {
        throw new error_1.MongoTailableCursorError(
          "Tailable cursor does not support batchSize",
        );
      }
      if (typeof value !== "number") {
        throw new error_1.MongoInvalidArgumentError(
          'Operation "batchSize" requires an integer',
        );
      }
      this[kOptions].batchSize = value;
      return this;
    }
    /**
     * Rewind this cursor to its uninitialized state. Any options that are present on the cursor will
     * remain in effect. Iterating this cursor will cause new queries to be sent to the server, even
     * if the resultant data has already been retrieved by this cursor.
     */
    rewind() {
      if (!this[kInitialized]) {
        return;
      }
      this[kId] = null;
      this[kDocuments].clear();
      this[kClosed] = false;
      this[kKilled] = false;
      this[kInitialized] = false;
      const session = this[kSession];
      if (session) {
        // We only want to end this session if we created it, and it hasn't ended yet
        if (session.explicit === false) {
          if (!session.hasEnded) {
            session.endSession().catch(() => null);
          }
          this[kSession] = this.client.startSession({
            owner: this,
            explicit: false,
          });
        }
      }
    }
    /** @internal */
    async getMore(batchSize) {
      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
      const getMoreOperation = new get_more_1.GetMoreOperation(
        this[kNamespace],
        this[kId],
        this[kServer],
        {
          ...this[kOptions],
          session: this[kSession],
          batchSize,
        },
      );
      return (0, execute_operation_1.executeOperation)(
        this[kClient],
        getMoreOperation,
      );
    }
    /**
     * @internal
     *
     * This function is exposed for the unified test runner's createChangeStream
     * operation.  We cannot refactor to use the abstract _initialize method without
     * a significant refactor.
     */
    async [kInit]() {
      try {
        const state = await this._initialize(this[kSession]);
        const response = state.response;
        this[kServer] = state.server;
        if (response.cursor) {
          // TODO(NODE-2674): Preserve int64 sent from MongoDB
          this[kId] =
            typeof response.cursor.id === "number"
              ? bson_1.Long.fromNumber(response.cursor.id)
              : typeof response.cursor.id === "bigint"
              ? bson_1.Long.fromBigInt(response.cursor.id)
              : response.cursor.id;
          if (response.cursor.ns) {
            this[kNamespace] = (0, utils_1.ns)(response.cursor.ns);
          }
          this[kDocuments].pushMany(response.cursor.firstBatch);
        }
        // When server responses return without a cursor document, we close this cursor
        // and return the raw server response. This is often the case for explain commands
        // for example
        if (this[kId] == null) {
          this[kId] = bson_1.Long.ZERO;
          // TODO(NODE-3286): ExecutionResult needs to accept a generic parameter
          this[kDocuments].push(state.response);
        }
        // the cursor is now initialized, even if it is dead
        this[kInitialized] = true;
      } catch (error) {
        // the cursor is now initialized, even if an error occurred
        this[kInitialized] = true;
        await cleanupCursor(this, { error });
        throw error;
      }
      if (this.isDead) {
        await cleanupCursor(this, undefined);
      }
      return;
    }
  }
  /** @event */
  AbstractCursor.CLOSE = "close";
  exports.AbstractCursor = AbstractCursor;
  /**
   * @param cursor - the cursor on which to call `next`
   * @param blocking - a boolean indicating whether or not the cursor should `block` until data
   *     is available.  Generally, this flag is set to `false` because if the getMore returns no documents,
   *     the cursor has been exhausted.  In certain scenarios (ChangeStreams, tailable await cursors and
   *     `tryNext`, for example) blocking is necessary because a getMore returning no documents does
   *     not indicate the end of the cursor.
   * @param transform - if true, the cursor's transform function is applied to the result document (if the transform exists)
   * @returns the next document in the cursor, or `null`.  When `blocking` is `true`, a `null` document means
   * the cursor has been exhausted.  Otherwise, it means that there is no document available in the cursor's buffer.
   */
  async function next(cursor, { blocking, transform }) {
    if (cursor.closed) {
      return null;
    }
    do {
      if (cursor[kId] == null) {
        // All cursors must operate within a session, one must be made implicitly if not explicitly provided
        await cursor[kInit]();
      }
      if (cursor[kDocuments].length !== 0) {
        const doc = cursor[kDocuments].shift();
        if (doc != null && transform && cursor[kTransform]) {
          try {
            return cursor[kTransform](doc);
          } catch (error) {
            // `cleanupCursorAsync` should never throw, but if it does we want to throw the original
            // error instead.
            await cleanupCursor(cursor, {
              error,
              needsToEmitClosed: true,
            }).catch(() => null);
            throw error;
          }
        }
        return doc;
      }
      if (cursor.isDead) {
        // if the cursor is dead, we clean it up
        // cleanupCursorAsync should never throw, but if it does it indicates a bug in the driver
        // and we should surface the error
        await cleanupCursor(cursor, {});
        return null;
      }
      // otherwise need to call getMore
      const batchSize = cursor[kOptions].batchSize || 1000;
      try {
        const response = await cursor.getMore(batchSize);
        if (response) {
          const cursorId =
            typeof response.cursor.id === "number"
              ? bson_1.Long.fromNumber(response.cursor.id)
              : typeof response.cursor.id === "bigint"
              ? bson_1.Long.fromBigInt(response.cursor.id)
              : response.cursor.id;
          cursor[kDocuments].pushMany(response.cursor.nextBatch);
          cursor[kId] = cursorId;
        }
      } catch (error) {
        // `cleanupCursorAsync` should never throw, but if it does we want to throw the original
        // error instead.
        await cleanupCursor(cursor, { error }).catch(() => null);
        throw error;
      }
      if (cursor.isDead) {
        // If we successfully received a response from a cursor BUT the cursor indicates that it is exhausted,
        // we intentionally clean up the cursor to release its session back into the pool before the cursor
        // is iterated.  This prevents a cursor that is exhausted on the server from holding
        // onto a session indefinitely until the AbstractCursor is iterated.
        //
        // cleanupCursorAsync should never throw, but if it does it indicates a bug in the driver
        // and we should surface the error
        await cleanupCursor(cursor, {});
      }
      if (cursor[kDocuments].length === 0 && blocking === false) {
        return null;
      }
    } while (!cursor.isDead || cursor[kDocuments].length !== 0);
    return null;
  }
  async function cleanupCursor(cursor, options) {
    const cursorId = cursor[kId];
    const cursorNs = cursor[kNamespace];
    const server = cursor[kServer];
    const session = cursor[kSession];
    const error = options?.error;
    // Cursors only emit closed events once the client-side cursor has been exhausted fully or there
    // was an error.  Notably, when the server returns a cursor id of 0 and a non-empty batch, we
    // cleanup the cursor but don't emit a `close` event.
    const needsToEmitClosed =
      options?.needsToEmitClosed ?? cursor[kDocuments].length === 0;
    if (error) {
      if (cursor.loadBalanced && error instanceof error_1.MongoNetworkError) {
        return completeCleanup();
      }
    }
    if (
      cursorId == null ||
      server == null ||
      cursorId.isZero() ||
      cursorNs == null
    ) {
      if (needsToEmitClosed) {
        cursor[kClosed] = true;
        cursor[kId] = bson_1.Long.ZERO;
        cursor.emit(AbstractCursor.CLOSE);
      }
      if (session) {
        if (session.owner === cursor) {
          await session.endSession({ error });
          return;
        }
        if (!session.inTransaction()) {
          (0, sessions_1.maybeClearPinnedConnection)(session, { error });
        }
      }
      return;
    }
    async function completeCleanup() {
      if (session) {
        if (session.owner === cursor) {
          try {
            await session.endSession({ error });
          } finally {
            cursor.emit(AbstractCursor.CLOSE);
          }
          return;
        }
        if (!session.inTransaction()) {
          (0, sessions_1.maybeClearPinnedConnection)(session, { error });
        }
      }
      cursor.emit(AbstractCursor.CLOSE);
      return;
    }
    cursor[kKilled] = true;
    if (session.hasEnded) {
      return completeCleanup();
    }
    try {
      await (0, execute_operation_1.executeOperation)(
        cursor[kClient],
        new kill_cursors_1.KillCursorsOperation(cursorId, cursorNs, server, {
          session,
        }),
      ).catch(() => null);
    } finally {
      await completeCleanup();
    }
  }
  /** @internal */
  function assertUninitialized(cursor) {
    if (cursor[kInitialized]) {
      throw new error_1.MongoCursorInUseError();
    }
  }
  exports.assertUninitialized = assertUninitialized;
  class ReadableCursorStream extends stream_1.Readable {
    constructor(cursor) {
      super({
        objectMode: true,
        autoDestroy: false,
        highWaterMark: 1,
      });
      this._readInProgress = false;
      this._cursor = cursor;
    }
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _read(size) {
      if (!this._readInProgress) {
        this._readInProgress = true;
        this._readNext();
      }
    }
    _destroy(error, callback) {
      this._cursor.close().then(
        () => callback(error),
        (closeError) => callback(closeError),
      );
    }
    _readNext() {
      next(this._cursor, { blocking: true, transform: true }).then(
        (result) => {
          if (result == null) {
            this.push(null);
          } else if (this.destroyed) {
            this._cursor.close().catch(() => null);
          } else {
            if (this.push(result)) {
              return this._readNext();
            }
            this._readInProgress = false;
          }
        },
        (err) => {
          // NOTE: This is questionable, but we have a test backing the behavior. It seems the
          //       desired behavior is that a stream ends cleanly when a user explicitly closes
          //       a client during iteration. Alternatively, we could do the "right" thing and
          //       propagate the error message by removing this special case.
          if (err.message.match(/server is closed/)) {
            this._cursor.close().catch(() => null);
            return this.push(null);
          }
          // NOTE: This is also perhaps questionable. The rationale here is that these errors tend
          //       to be "operation was interrupted", where a cursor has been closed but there is an
          //       active getMore in-flight. This used to check if the cursor was killed but once
          //       that changed to happen in cleanup legitimate errors would not destroy the
          //       stream. There are change streams test specifically test these cases.
          if (err.message.match(/operation was interrupted/)) {
            return this.push(null);
          }
          // NOTE: The two above checks on the message of the error will cause a null to be pushed
          //       to the stream, thus closing the stream before the destroy call happens. This means
          //       that either of those error messages on a change stream will not get a proper
          //       'error' event to be emitted (the error passed to destroy). Change stream resumability
          //       relies on that error event to be emitted to create its new cursor and thus was not
          //       working on 4.4 servers because the error emitted on failover was "interrupted at
          //       shutdown" while on 5.0+ it is "The server is in quiesce mode and will shut down".
          //       See NODE-4475.
          return this.destroy(err);
        },
      );
    }
  }
})(abstract_cursor);

Object.defineProperty(aggregation_cursor, "__esModule", { value: true });
aggregation_cursor.AggregationCursor = void 0;
const aggregate_1$1 = aggregate;
const execute_operation_1$4 = execute_operation;
const utils_1$j = utils$2;
const abstract_cursor_1$4 = abstract_cursor;
/** @internal */
const kPipeline = Symbol("pipeline");
/** @internal */
const kOptions = Symbol("options");
/**
 * The **AggregationCursor** class is an internal class that embodies an aggregation cursor on MongoDB
 * allowing for iteration over the results returned from the underlying query. It supports
 * one by one document iteration, conversion to an array or can be iterated as a Node 4.X
 * or higher stream
 * @public
 */
let AggregationCursor$1 = class AggregationCursor extends abstract_cursor_1$4.AbstractCursor {
  /** @internal */
  constructor(client, namespace, pipeline = [], options = {}) {
    super(client, namespace, options);
    this[kPipeline] = pipeline;
    this[kOptions] = options;
  }
  get pipeline() {
    return this[kPipeline];
  }
  clone() {
    const clonedOptions = (0, utils_1$j.mergeOptions)({}, this[kOptions]);
    delete clonedOptions.session;
    return new AggregationCursor(this.client, this.namespace, this[kPipeline], {
      ...clonedOptions,
    });
  }
  map(transform) {
    return super.map(transform);
  }
  /** @internal */
  async _initialize(session) {
    const aggregateOperation = new aggregate_1$1.AggregateOperation(
      this.namespace,
      this[kPipeline],
      {
        ...this[kOptions],
        ...this.cursorOptions,
        session,
      },
    );
    const response = await (0, execute_operation_1$4.executeOperation)(
      this.client,
      aggregateOperation,
    );
    // TODO: NODE-2882
    return { server: aggregateOperation.server, session, response };
  }
  /** Execute the explain for the cursor */
  async explain(verbosity) {
    return (0, execute_operation_1$4.executeOperation)(
      this.client,
      new aggregate_1$1.AggregateOperation(this.namespace, this[kPipeline], {
        ...this[kOptions],
        ...this.cursorOptions,
        explain: verbosity ?? true,
      }),
    );
  }
  group($group) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $group });
    return this;
  }
  /** Add a limit stage to the aggregation pipeline */
  limit($limit) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $limit });
    return this;
  }
  /** Add a match stage to the aggregation pipeline */
  match($match) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $match });
    return this;
  }
  /** Add an out stage to the aggregation pipeline */
  out($out) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $out });
    return this;
  }
  /**
   * Add a project stage to the aggregation pipeline
   *
   * @remarks
   * In order to strictly type this function you must provide an interface
   * that represents the effect of your projection on the result documents.
   *
   * By default chaining a projection to your cursor changes the returned type to the generic {@link Document} type.
   * You should specify a parameterized type to have assertions on your final results.
   *
   * @example
   * ```typescript
   * // Best way
   * const docs: AggregationCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });
   * // Flexible way
   * const docs: AggregationCursor<Document> = cursor.project({ _id: 0, a: true });
   * ```
   *
   * @remarks
   * In order to strictly type this function you must provide an interface
   * that represents the effect of your projection on the result documents.
   *
   * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,
   * it **does not** return a new instance of a cursor. This means when calling project,
   * you should always assign the result to a new variable in order to get a correctly typed cursor variable.
   * Take note of the following example:
   *
   * @example
   * ```typescript
   * const cursor: AggregationCursor<{ a: number; b: string }> = coll.aggregate([]);
   * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });
   * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();
   *
   * // or always use chaining and save the final cursor
   *
   * const cursor = coll.aggregate().project<{ a: string }>({
   *   _id: 0,
   *   a: { $convert: { input: '$a', to: 'string' }
   * }});
   * ```
   */
  project($project) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $project });
    return this;
  }
  /** Add a lookup stage to the aggregation pipeline */
  lookup($lookup) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $lookup });
    return this;
  }
  /** Add a redact stage to the aggregation pipeline */
  redact($redact) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $redact });
    return this;
  }
  /** Add a skip stage to the aggregation pipeline */
  skip($skip) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $skip });
    return this;
  }
  /** Add a sort stage to the aggregation pipeline */
  sort($sort) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $sort });
    return this;
  }
  /** Add a unwind stage to the aggregation pipeline */
  unwind($unwind) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $unwind });
    return this;
  }
  /** Add a geoNear stage to the aggregation pipeline */
  geoNear($geoNear) {
    (0, abstract_cursor_1$4.assertUninitialized)(this);
    this[kPipeline].push({ $geoNear });
    return this;
  }
};
aggregation_cursor.AggregationCursor = AggregationCursor$1;

var find_cursor = {};

var count = {};

Object.defineProperty(count, "__esModule", { value: true });
count.CountOperation = void 0;
const command_1$8 = command;
const operation_1$c = operation;
/** @internal */
class CountOperation extends command_1$8.CommandOperation {
  constructor(namespace, filter, options) {
    super({ s: { namespace: namespace } }, options);
    this.options = options;
    this.collectionName = namespace.collection;
    this.query = filter;
  }
  async execute(server, session) {
    const options = this.options;
    const cmd = {
      count: this.collectionName,
      query: this.query,
    };
    if (typeof options.limit === "number") {
      cmd.limit = options.limit;
    }
    if (typeof options.skip === "number") {
      cmd.skip = options.skip;
    }
    if (options.hint != null) {
      cmd.hint = options.hint;
    }
    if (typeof options.maxTimeMS === "number") {
      cmd.maxTimeMS = options.maxTimeMS;
    }
    const result = await super.executeCommand(server, session, cmd);
    return result ? result.n : 0;
  }
}
count.CountOperation = CountOperation;
(0, operation_1$c.defineAspects)(CountOperation, [
  operation_1$c.Aspect.READ_OPERATION,
  operation_1$c.Aspect.RETRYABLE,
]);

var find = {};

var sort = {};

Object.defineProperty(sort, "__esModule", { value: true });
sort.formatSort = void 0;
const error_1$u = error;
/** @internal */
function prepareDirection(direction = 1) {
  const value = `${direction}`.toLowerCase();
  if (isMeta(direction)) return direction;
  switch (value) {
    case "ascending":
    case "asc":
    case "1":
      return 1;
    case "descending":
    case "desc":
    case "-1":
      return -1;
    default:
      throw new error_1$u.MongoInvalidArgumentError(
        `Invalid sort direction: ${JSON.stringify(direction)}`,
      );
  }
}
/** @internal */
function isMeta(t) {
  return (
    typeof t === "object" &&
    t != null &&
    "$meta" in t &&
    typeof t.$meta === "string"
  );
}
/** @internal */
function isPair(t) {
  if (Array.isArray(t) && t.length === 2) {
    try {
      prepareDirection(t[1]);
      return true;
    } catch (e) {
      return false;
    }
  }
  return false;
}
function isDeep(t) {
  return Array.isArray(t) && Array.isArray(t[0]);
}
function isMap(t) {
  return t instanceof Map && t.size > 0;
}
/** @internal */
function pairToMap(v) {
  return new Map([[`${v[0]}`, prepareDirection([v[1]])]]);
}
/** @internal */
function deepToMap(t) {
  const sortEntries = t.map(([k, v]) => [`${k}`, prepareDirection(v)]);
  return new Map(sortEntries);
}
/** @internal */
function stringsToMap(t) {
  const sortEntries = t.map((key) => [`${key}`, 1]);
  return new Map(sortEntries);
}
/** @internal */
function objectToMap(t) {
  const sortEntries = Object.entries(t).map(([k, v]) => [
    `${k}`,
    prepareDirection(v),
  ]);
  return new Map(sortEntries);
}
/** @internal */
function mapToMap(t) {
  const sortEntries = Array.from(t).map(([k, v]) => [
    `${k}`,
    prepareDirection(v),
  ]);
  return new Map(sortEntries);
}
/** converts a Sort type into a type that is valid for the server (SortForCmd) */
function formatSort(sort, direction) {
  if (sort == null) return undefined;
  if (typeof sort === "string")
    return new Map([[sort, prepareDirection(direction)]]);
  if (typeof sort !== "object") {
    throw new error_1$u.MongoInvalidArgumentError(
      `Invalid sort format: ${JSON.stringify(
        sort,
      )} Sort must be a valid object`,
    );
  }
  if (!Array.isArray(sort)) {
    return isMap(sort)
      ? mapToMap(sort)
      : Object.keys(sort).length
      ? objectToMap(sort)
      : undefined;
  }
  if (!sort.length) return undefined;
  if (isDeep(sort)) return deepToMap(sort);
  if (isPair(sort)) return pairToMap(sort);
  return stringsToMap(sort);
}
sort.formatSort = formatSort;

Object.defineProperty(find, "__esModule", { value: true });
find.FindOperation = void 0;
const error_1$t = error;
const read_concern_1 = read_concern;
const sort_1$1 = sort;
const utils_1$i = utils$2;
const command_1$7 = command;
const operation_1$b = operation;
/** @internal */
class FindOperation extends command_1$7.CommandOperation {
  constructor(collection, ns, filter = {}, options = {}) {
    super(collection, options);
    this.options = { ...options };
    delete this.options.writeConcern;
    this.ns = ns;
    if (typeof filter !== "object" || Array.isArray(filter)) {
      throw new error_1$t.MongoInvalidArgumentError(
        "Query filter must be a plain object or ObjectId",
      );
    }
    // special case passing in an ObjectId as a filter
    this.filter =
      filter != null && filter._bsontype === "ObjectId"
        ? { _id: filter }
        : filter;
  }
  async execute(server, session) {
    this.server = server;
    const options = this.options;
    let findCommand = makeFindCommand(this.ns, this.filter, options);
    if (this.explain) {
      findCommand = (0, utils_1$i.decorateWithExplain)(
        findCommand,
        this.explain,
      );
    }
    return server.commandAsync(this.ns, findCommand, {
      ...this.options,
      ...this.bsonOptions,
      documentsReturnedIn: "firstBatch",
      session,
    });
  }
}
find.FindOperation = FindOperation;
function makeFindCommand(ns, filter, options) {
  const findCommand = {
    find: ns.collection,
    filter,
  };
  if (options.sort) {
    findCommand.sort = (0, sort_1$1.formatSort)(options.sort);
  }
  if (options.projection) {
    let projection = options.projection;
    if (projection && Array.isArray(projection)) {
      projection = projection.length
        ? projection.reduce((result, field) => {
            result[field] = 1;
            return result;
          }, {})
        : { _id: 1 };
    }
    findCommand.projection = projection;
  }
  if (options.hint) {
    findCommand.hint = (0, utils_1$i.normalizeHintField)(options.hint);
  }
  if (typeof options.skip === "number") {
    findCommand.skip = options.skip;
  }
  if (typeof options.limit === "number") {
    if (options.limit < 0) {
      findCommand.limit = -options.limit;
      findCommand.singleBatch = true;
    } else {
      findCommand.limit = options.limit;
    }
  }
  if (typeof options.batchSize === "number") {
    if (options.batchSize < 0) {
      if (
        options.limit &&
        options.limit !== 0 &&
        Math.abs(options.batchSize) < Math.abs(options.limit)
      ) {
        findCommand.limit = -options.batchSize;
      }
      findCommand.singleBatch = true;
    } else {
      findCommand.batchSize = options.batchSize;
    }
  }
  if (typeof options.singleBatch === "boolean") {
    findCommand.singleBatch = options.singleBatch;
  }
  // we check for undefined specifically here to allow falsy values
  // eslint-disable-next-line no-restricted-syntax
  if (options.comment !== undefined) {
    findCommand.comment = options.comment;
  }
  if (typeof options.maxTimeMS === "number") {
    findCommand.maxTimeMS = options.maxTimeMS;
  }
  const readConcern = read_concern_1.ReadConcern.fromOptions(options);
  if (readConcern) {
    findCommand.readConcern = readConcern.toJSON();
  }
  if (options.max) {
    findCommand.max = options.max;
  }
  if (options.min) {
    findCommand.min = options.min;
  }
  if (typeof options.returnKey === "boolean") {
    findCommand.returnKey = options.returnKey;
  }
  if (typeof options.showRecordId === "boolean") {
    findCommand.showRecordId = options.showRecordId;
  }
  if (typeof options.tailable === "boolean") {
    findCommand.tailable = options.tailable;
  }
  if (typeof options.oplogReplay === "boolean") {
    findCommand.oplogReplay = options.oplogReplay;
  }
  if (typeof options.timeout === "boolean") {
    findCommand.noCursorTimeout = !options.timeout;
  } else if (typeof options.noCursorTimeout === "boolean") {
    findCommand.noCursorTimeout = options.noCursorTimeout;
  }
  if (typeof options.awaitData === "boolean") {
    findCommand.awaitData = options.awaitData;
  }
  if (typeof options.allowPartialResults === "boolean") {
    findCommand.allowPartialResults = options.allowPartialResults;
  }
  if (options.collation) {
    findCommand.collation = options.collation;
  }
  if (typeof options.allowDiskUse === "boolean") {
    findCommand.allowDiskUse = options.allowDiskUse;
  }
  if (options.let) {
    findCommand.let = options.let;
  }
  return findCommand;
}
(0, operation_1$b.defineAspects)(FindOperation, [
  operation_1$b.Aspect.READ_OPERATION,
  operation_1$b.Aspect.RETRYABLE,
  operation_1$b.Aspect.EXPLAINABLE,
  operation_1$b.Aspect.CURSOR_CREATING,
]);

Object.defineProperty(find_cursor, "__esModule", { value: true });
find_cursor.FindCursor = find_cursor.FLAGS = void 0;
const bson_1$8 = bson$2;
const error_1$s = error;
const count_1 = count;
const execute_operation_1$3 = execute_operation;
const find_1 = find;
const sort_1 = sort;
const utils_1$h = utils$2;
const abstract_cursor_1$3 = abstract_cursor;
/** @internal */
const kFilter = Symbol("filter");
/** @internal */
const kNumReturned = Symbol("numReturned");
/** @internal */
const kBuiltOptions = Symbol("builtOptions");
/** @public Flags allowed for cursor */
find_cursor.FLAGS = [
  "tailable",
  "oplogReplay",
  "noCursorTimeout",
  "awaitData",
  "exhaust",
  "partial",
];
/** @public */
let FindCursor$1 = class FindCursor extends abstract_cursor_1$3.AbstractCursor {
  /** @internal */
  constructor(client, namespace, filter = {}, options = {}) {
    super(client, namespace, options);
    this[kFilter] = filter;
    this[kBuiltOptions] = options;
    if (options.sort != null) {
      this[kBuiltOptions].sort = (0, sort_1.formatSort)(options.sort);
    }
  }
  clone() {
    const clonedOptions = (0, utils_1$h.mergeOptions)({}, this[kBuiltOptions]);
    delete clonedOptions.session;
    return new FindCursor(this.client, this.namespace, this[kFilter], {
      ...clonedOptions,
    });
  }
  map(transform) {
    return super.map(transform);
  }
  /** @internal */
  async _initialize(session) {
    const findOperation = new find_1.FindOperation(
      undefined,
      this.namespace,
      this[kFilter],
      {
        ...this[kBuiltOptions],
        ...this.cursorOptions,
        session,
      },
    );
    const response = await (0, execute_operation_1$3.executeOperation)(
      this.client,
      findOperation,
    );
    // the response is not a cursor when `explain` is enabled
    this[kNumReturned] = response.cursor?.firstBatch?.length;
    // TODO: NODE-2882
    return { server: findOperation.server, session, response };
  }
  /** @internal */
  async getMore(batchSize) {
    const numReturned = this[kNumReturned];
    if (numReturned) {
      // TODO(DRIVERS-1448): Remove logic to enforce `limit` in the driver
      const limit = this[kBuiltOptions].limit;
      batchSize =
        limit && limit > 0 && numReturned + batchSize > limit
          ? limit - numReturned
          : batchSize;
      if (batchSize <= 0) {
        // this is an optimization for the special case of a limit for a find command to avoid an
        // extra getMore when the limit has been reached and the limit is a multiple of the batchSize.
        // This is a consequence of the new query engine in 5.0 having no knowledge of the limit as it
        // produces results for the find command.  Once a batch is filled up, it is returned and only
        // on the subsequent getMore will the query framework consider the limit, determine the cursor
        // is exhausted and return a cursorId of zero.
        // instead, if we determine there are no more documents to request from the server, we preemptively
        // close the cursor
        await this.close().catch(() => null);
        return { cursor: { id: bson_1$8.Long.ZERO, nextBatch: [] } };
      }
    }
    const response = await super.getMore(batchSize);
    // TODO: wrap this in some logic to prevent it from happening if we don't need this support
    if (response) {
      this[kNumReturned] =
        this[kNumReturned] + response.cursor.nextBatch.length;
    }
    return response;
  }
  /**
   * Get the count of documents for this cursor
   * @deprecated Use `collection.estimatedDocumentCount` or `collection.countDocuments` instead
   */
  async count(options) {
    (0, utils_1$h.emitWarningOnce)(
      "cursor.count is deprecated and will be removed in the next major version, please use `collection.estimatedDocumentCount` or `collection.countDocuments` instead ",
    );
    if (typeof options === "boolean") {
      throw new error_1$s.MongoInvalidArgumentError(
        "Invalid first parameter to count",
      );
    }
    return (0, execute_operation_1$3.executeOperation)(
      this.client,
      new count_1.CountOperation(this.namespace, this[kFilter], {
        ...this[kBuiltOptions],
        ...this.cursorOptions,
        ...options,
      }),
    );
  }
  /** Execute the explain for the cursor */
  async explain(verbosity) {
    return (0, execute_operation_1$3.executeOperation)(
      this.client,
      new find_1.FindOperation(undefined, this.namespace, this[kFilter], {
        ...this[kBuiltOptions],
        ...this.cursorOptions,
        explain: verbosity ?? true,
      }),
    );
  }
  /** Set the cursor query */
  filter(filter) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    this[kFilter] = filter;
    return this;
  }
  /**
   * Set the cursor hint
   *
   * @param hint - If specified, then the query system will only consider plans using the hinted index.
   */
  hint(hint) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    this[kBuiltOptions].hint = hint;
    return this;
  }
  /**
   * Set the cursor min
   *
   * @param min - Specify a $min value to specify the inclusive lower bound for a specific index in order to constrain the results of find(). The $min specifies the lower bound for all keys of a specific index in order.
   */
  min(min) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    this[kBuiltOptions].min = min;
    return this;
  }
  /**
   * Set the cursor max
   *
   * @param max - Specify a $max value to specify the exclusive upper bound for a specific index in order to constrain the results of find(). The $max specifies the upper bound for all keys of a specific index in order.
   */
  max(max) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    this[kBuiltOptions].max = max;
    return this;
  }
  /**
   * Set the cursor returnKey.
   * If set to true, modifies the cursor to only return the index field or fields for the results of the query, rather than documents.
   * If set to true and the query does not use an index to perform the read operation, the returned documents will not contain any fields.
   *
   * @param value - the returnKey value.
   */
  returnKey(value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    this[kBuiltOptions].returnKey = value;
    return this;
  }
  /**
   * Modifies the output of a query by adding a field $recordId to matching documents. $recordId is the internal key which uniquely identifies a document in a collection.
   *
   * @param value - The $showDiskLoc option has now been deprecated and replaced with the showRecordId field. $showDiskLoc will still be accepted for OP_QUERY stye find.
   */
  showRecordId(value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    this[kBuiltOptions].showRecordId = value;
    return this;
  }
  /**
   * Add a query modifier to the cursor query
   *
   * @param name - The query modifier (must start with $, such as $orderby etc)
   * @param value - The modifier value.
   */
  addQueryModifier(name, value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    if (name[0] !== "$") {
      throw new error_1$s.MongoInvalidArgumentError(
        `${name} is not a valid query modifier`,
      );
    }
    // Strip of the $
    const field = name.substr(1);
    // NOTE: consider some TS magic for this
    switch (field) {
      case "comment":
        this[kBuiltOptions].comment = value;
        break;
      case "explain":
        this[kBuiltOptions].explain = value;
        break;
      case "hint":
        this[kBuiltOptions].hint = value;
        break;
      case "max":
        this[kBuiltOptions].max = value;
        break;
      case "maxTimeMS":
        this[kBuiltOptions].maxTimeMS = value;
        break;
      case "min":
        this[kBuiltOptions].min = value;
        break;
      case "orderby":
        this[kBuiltOptions].sort = (0, sort_1.formatSort)(value);
        break;
      case "query":
        this[kFilter] = value;
        break;
      case "returnKey":
        this[kBuiltOptions].returnKey = value;
        break;
      case "showDiskLoc":
        this[kBuiltOptions].showRecordId = value;
        break;
      default:
        throw new error_1$s.MongoInvalidArgumentError(
          `Invalid query modifier: ${name}`,
        );
    }
    return this;
  }
  /**
   * Add a comment to the cursor query allowing for tracking the comment in the log.
   *
   * @param value - The comment attached to this query.
   */
  comment(value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    this[kBuiltOptions].comment = value;
    return this;
  }
  /**
   * Set a maxAwaitTimeMS on a tailing cursor query to allow to customize the timeout value for the option awaitData (Only supported on MongoDB 3.2 or higher, ignored otherwise)
   *
   * @param value - Number of milliseconds to wait before aborting the tailed query.
   */
  maxAwaitTimeMS(value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    if (typeof value !== "number") {
      throw new error_1$s.MongoInvalidArgumentError(
        "Argument for maxAwaitTimeMS must be a number",
      );
    }
    this[kBuiltOptions].maxAwaitTimeMS = value;
    return this;
  }
  /**
   * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)
   *
   * @param value - Number of milliseconds to wait before aborting the query.
   */
  maxTimeMS(value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    if (typeof value !== "number") {
      throw new error_1$s.MongoInvalidArgumentError(
        "Argument for maxTimeMS must be a number",
      );
    }
    this[kBuiltOptions].maxTimeMS = value;
    return this;
  }
  /**
   * Add a project stage to the aggregation pipeline
   *
   * @remarks
   * In order to strictly type this function you must provide an interface
   * that represents the effect of your projection on the result documents.
   *
   * By default chaining a projection to your cursor changes the returned type to the generic
   * {@link Document} type.
   * You should specify a parameterized type to have assertions on your final results.
   *
   * @example
   * ```typescript
   * // Best way
   * const docs: FindCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });
   * // Flexible way
   * const docs: FindCursor<Document> = cursor.project({ _id: 0, a: true });
   * ```
   *
   * @remarks
   *
   * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,
   * it **does not** return a new instance of a cursor. This means when calling project,
   * you should always assign the result to a new variable in order to get a correctly typed cursor variable.
   * Take note of the following example:
   *
   * @example
   * ```typescript
   * const cursor: FindCursor<{ a: number; b: string }> = coll.find();
   * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });
   * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();
   *
   * // or always use chaining and save the final cursor
   *
   * const cursor = coll.find().project<{ a: string }>({
   *   _id: 0,
   *   a: { $convert: { input: '$a', to: 'string' }
   * }});
   * ```
   */
  project(value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    this[kBuiltOptions].projection = value;
    return this;
  }
  /**
   * Sets the sort order of the cursor query.
   *
   * @param sort - The key or keys set for the sort.
   * @param direction - The direction of the sorting (1 or -1).
   */
  sort(sort, direction) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    if (this[kBuiltOptions].tailable) {
      throw new error_1$s.MongoTailableCursorError(
        "Tailable cursor does not support sorting",
      );
    }
    this[kBuiltOptions].sort = (0, sort_1.formatSort)(sort, direction);
    return this;
  }
  /**
   * Allows disk use for blocking sort operations exceeding 100MB memory. (MongoDB 3.2 or higher)
   *
   * @remarks
   * {@link https://www.mongodb.com/docs/manual/reference/command/find/#find-cmd-allowdiskuse | find command allowDiskUse documentation}
   */
  allowDiskUse(allow = true) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    if (!this[kBuiltOptions].sort) {
      throw new error_1$s.MongoInvalidArgumentError(
        'Option "allowDiskUse" requires a sort specification',
      );
    }
    // As of 6.0 the default is true. This allows users to get back to the old behavior.
    if (!allow) {
      this[kBuiltOptions].allowDiskUse = false;
      return this;
    }
    this[kBuiltOptions].allowDiskUse = true;
    return this;
  }
  /**
   * Set the collation options for the cursor.
   *
   * @param value - The cursor collation options (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).
   */
  collation(value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    this[kBuiltOptions].collation = value;
    return this;
  }
  /**
   * Set the limit for the cursor.
   *
   * @param value - The limit for the cursor query.
   */
  limit(value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    if (this[kBuiltOptions].tailable) {
      throw new error_1$s.MongoTailableCursorError(
        "Tailable cursor does not support limit",
      );
    }
    if (typeof value !== "number") {
      throw new error_1$s.MongoInvalidArgumentError(
        'Operation "limit" requires an integer',
      );
    }
    this[kBuiltOptions].limit = value;
    return this;
  }
  /**
   * Set the skip for the cursor.
   *
   * @param value - The skip for the cursor query.
   */
  skip(value) {
    (0, abstract_cursor_1$3.assertUninitialized)(this);
    if (this[kBuiltOptions].tailable) {
      throw new error_1$s.MongoTailableCursorError(
        "Tailable cursor does not support skip",
      );
    }
    if (typeof value !== "number") {
      throw new error_1$s.MongoInvalidArgumentError(
        'Operation "skip" requires an integer',
      );
    }
    this[kBuiltOptions].skip = value;
    return this;
  }
};
find_cursor.FindCursor = FindCursor$1;

var list_indexes_cursor = {};

var indexes = {};

Object.defineProperty(indexes, "__esModule", { value: true });
indexes.IndexInformationOperation =
  indexes.IndexExistsOperation =
  indexes.ListIndexesOperation =
  indexes.DropIndexOperation =
  indexes.EnsureIndexOperation =
  indexes.CreateIndexOperation =
  indexes.CreateIndexesOperation =
  indexes.IndexesOperation =
    void 0;
const error_1$r = error;
const read_preference_1$1 = read_preference;
const utils_1$g = utils$2;
const command_1$6 = command;
const common_functions_1 = common_functions;
const operation_1$a = operation;
const VALID_INDEX_OPTIONS = new Set([
  "background",
  "unique",
  "name",
  "partialFilterExpression",
  "sparse",
  "hidden",
  "expireAfterSeconds",
  "storageEngine",
  "collation",
  "version",
  // text indexes
  "weights",
  "default_language",
  "language_override",
  "textIndexVersion",
  // 2d-sphere indexes
  "2dsphereIndexVersion",
  // 2d indexes
  "bits",
  "min",
  "max",
  // geoHaystack Indexes
  "bucketSize",
  // wildcard indexes
  "wildcardProjection",
]);
function isIndexDirection(x) {
  return (
    typeof x === "number" ||
    x === "2d" ||
    x === "2dsphere" ||
    x === "text" ||
    x === "geoHaystack"
  );
}
function isSingleIndexTuple(t) {
  return Array.isArray(t) && t.length === 2 && isIndexDirection(t[1]);
}
function makeIndexSpec(indexSpec, options) {
  const key = new Map();
  const indexSpecs =
    !Array.isArray(indexSpec) || isSingleIndexTuple(indexSpec)
      ? [indexSpec]
      : indexSpec;
  // Iterate through array and handle different types
  for (const spec of indexSpecs) {
    if (typeof spec === "string") {
      key.set(spec, 1);
    } else if (Array.isArray(spec)) {
      key.set(spec[0], spec[1] ?? 1);
    } else if (spec instanceof Map) {
      for (const [property, value] of spec) {
        key.set(property, value);
      }
    } else if ((0, utils_1$g.isObject)(spec)) {
      for (const [property, value] of Object.entries(spec)) {
        key.set(property, value);
      }
    }
  }
  return { ...options, key };
}
/** @internal */
class IndexesOperation extends operation_1$a.AbstractOperation {
  constructor(collection, options) {
    super(options);
    this.options = options;
    this.collection = collection;
  }
  async execute(_server, session) {
    const coll = this.collection;
    const options = this.options;
    return (0, common_functions_1.indexInformation)(
      coll.s.db,
      coll.collectionName,
      {
        full: true,
        ...options,
        readPreference: this.readPreference,
        session,
      },
    );
  }
}
indexes.IndexesOperation = IndexesOperation;
/** @internal */
class CreateIndexesOperation extends command_1$6.CommandOperation {
  constructor(parent, collectionName, indexes, options) {
    super(parent, options);
    this.options = options ?? {};
    this.collectionName = collectionName;
    this.indexes = indexes.map((userIndex) => {
      // Ensure the key is a Map to preserve index key ordering
      const key =
        userIndex.key instanceof Map
          ? userIndex.key
          : new Map(Object.entries(userIndex.key));
      const name =
        userIndex.name != null
          ? userIndex.name
          : Array.from(key).flat().join("_");
      const validIndexOptions = Object.fromEntries(
        Object.entries({ ...userIndex }).filter(([optionName]) =>
          VALID_INDEX_OPTIONS.has(optionName),
        ),
      );
      return {
        ...validIndexOptions,
        name,
        key,
      };
    });
  }
  async execute(server, session) {
    const options = this.options;
    const indexes = this.indexes;
    const serverWireVersion = (0, utils_1$g.maxWireVersion)(server);
    const cmd = { createIndexes: this.collectionName, indexes };
    if (options.commitQuorum != null) {
      if (serverWireVersion < 9) {
        throw new error_1$r.MongoCompatibilityError(
          "Option `commitQuorum` for `createIndexes` not supported on servers < 4.4",
        );
      }
      cmd.commitQuorum = options.commitQuorum;
    }
    // collation is set on each index, it should not be defined at the root
    this.options.collation = undefined;
    await super.executeCommand(server, session, cmd);
    const indexNames = indexes.map((index) => index.name || "");
    return indexNames;
  }
}
indexes.CreateIndexesOperation = CreateIndexesOperation;
/** @internal */
class CreateIndexOperation extends CreateIndexesOperation {
  constructor(parent, collectionName, indexSpec, options) {
    super(parent, collectionName, [makeIndexSpec(indexSpec, options)], options);
  }
  async execute(server, session) {
    const indexNames = await super.execute(server, session);
    return indexNames[0];
  }
}
indexes.CreateIndexOperation = CreateIndexOperation;
/** @internal */
class EnsureIndexOperation extends CreateIndexOperation {
  constructor(db, collectionName, indexSpec, options) {
    super(db, collectionName, indexSpec, options);
    this.readPreference = read_preference_1$1.ReadPreference.primary;
    this.db = db;
    this.collectionName = collectionName;
  }
  async execute(server, session) {
    const indexName = this.indexes[0].name;
    const indexes = await this.db
      .collection(this.collectionName)
      .listIndexes({ session })
      .toArray()
      .catch((error) => {
        if (
          error instanceof error_1$r.MongoError &&
          error.code === error_1$r.MONGODB_ERROR_CODES.NamespaceNotFound
        )
          return [];
        throw error;
      });
    if (indexName && indexes.some((index) => index.name === indexName))
      return indexName;
    return super.execute(server, session);
  }
}
indexes.EnsureIndexOperation = EnsureIndexOperation;
/** @internal */
class DropIndexOperation extends command_1$6.CommandOperation {
  constructor(collection, indexName, options) {
    super(collection, options);
    this.options = options ?? {};
    this.collection = collection;
    this.indexName = indexName;
  }
  async execute(server, session) {
    const cmd = {
      dropIndexes: this.collection.collectionName,
      index: this.indexName,
    };
    return super.executeCommand(server, session, cmd);
  }
}
indexes.DropIndexOperation = DropIndexOperation;
/** @internal */
class ListIndexesOperation extends command_1$6.CommandOperation {
  constructor(collection, options) {
    super(collection, options);
    this.options = { ...options };
    delete this.options.writeConcern;
    this.collectionNamespace = collection.s.namespace;
  }
  async execute(server, session) {
    const serverWireVersion = (0, utils_1$g.maxWireVersion)(server);
    const cursor = this.options.batchSize
      ? { batchSize: this.options.batchSize }
      : {};
    const command = {
      listIndexes: this.collectionNamespace.collection,
      cursor,
    };
    // we check for undefined specifically here to allow falsy values
    // eslint-disable-next-line no-restricted-syntax
    if (serverWireVersion >= 9 && this.options.comment !== undefined) {
      command.comment = this.options.comment;
    }
    return super.executeCommand(server, session, command);
  }
}
indexes.ListIndexesOperation = ListIndexesOperation;
/** @internal */
class IndexExistsOperation extends operation_1$a.AbstractOperation {
  constructor(collection, indexes, options) {
    super(options);
    this.options = options;
    this.collection = collection;
    this.indexes = indexes;
  }
  async execute(server, session) {
    const coll = this.collection;
    const indexes = this.indexes;
    const info = await (0, common_functions_1.indexInformation)(
      coll.s.db,
      coll.collectionName,
      {
        ...this.options,
        readPreference: this.readPreference,
        session,
      },
    );
    // Let's check for the index names
    if (!Array.isArray(indexes)) return info[indexes] != null;
    // All keys found return true
    return indexes.every((indexName) => info[indexName] != null);
  }
}
indexes.IndexExistsOperation = IndexExistsOperation;
/** @internal */
class IndexInformationOperation extends operation_1$a.AbstractOperation {
  constructor(db, name, options) {
    super(options);
    this.options = options ?? {};
    this.db = db;
    this.name = name;
  }
  async execute(server, session) {
    const db = this.db;
    const name = this.name;
    return (0, common_functions_1.indexInformation)(db, name, {
      ...this.options,
      readPreference: this.readPreference,
      session,
    });
  }
}
indexes.IndexInformationOperation = IndexInformationOperation;
(0, operation_1$a.defineAspects)(ListIndexesOperation, [
  operation_1$a.Aspect.READ_OPERATION,
  operation_1$a.Aspect.RETRYABLE,
  operation_1$a.Aspect.CURSOR_CREATING,
]);
(0, operation_1$a.defineAspects)(CreateIndexesOperation, [
  operation_1$a.Aspect.WRITE_OPERATION,
]);
(0, operation_1$a.defineAspects)(CreateIndexOperation, [
  operation_1$a.Aspect.WRITE_OPERATION,
]);
(0, operation_1$a.defineAspects)(EnsureIndexOperation, [
  operation_1$a.Aspect.WRITE_OPERATION,
]);
(0, operation_1$a.defineAspects)(DropIndexOperation, [
  operation_1$a.Aspect.WRITE_OPERATION,
]);

Object.defineProperty(list_indexes_cursor, "__esModule", { value: true });
list_indexes_cursor.ListIndexesCursor = void 0;
const execute_operation_1$2 = execute_operation;
const indexes_1 = indexes;
const abstract_cursor_1$2 = abstract_cursor;
/** @public */
let ListIndexesCursor$1 = class ListIndexesCursor extends abstract_cursor_1$2.AbstractCursor {
  constructor(collection, options) {
    super(collection.client, collection.s.namespace, options);
    this.parent = collection;
    this.options = options;
  }
  clone() {
    return new ListIndexesCursor(this.parent, {
      ...this.options,
      ...this.cursorOptions,
    });
  }
  /** @internal */
  async _initialize(session) {
    const operation = new indexes_1.ListIndexesOperation(this.parent, {
      ...this.cursorOptions,
      ...this.options,
      session,
    });
    const response = await (0, execute_operation_1$2.executeOperation)(
      this.parent.client,
      operation,
    );
    // TODO: NODE-2882
    return { server: operation.server, session, response };
  }
};
list_indexes_cursor.ListIndexesCursor = ListIndexesCursor$1;

var list_search_indexes_cursor = {};

Object.defineProperty(list_search_indexes_cursor, "__esModule", {
  value: true,
});
list_search_indexes_cursor.ListSearchIndexesCursor = void 0;
const aggregation_cursor_1 = aggregation_cursor;
/** @public */
class ListSearchIndexesCursor extends aggregation_cursor_1.AggregationCursor {
  /** @internal */
  constructor({ fullNamespace: ns, client }, name, options = {}) {
    const pipeline =
      name == null
        ? [{ $listSearchIndexes: {} }]
        : [{ $listSearchIndexes: { name } }];
    super(client, ns, pipeline, options);
  }
}
list_search_indexes_cursor.ListSearchIndexesCursor = ListSearchIndexesCursor;

var count_documents = {};

Object.defineProperty(count_documents, "__esModule", { value: true });
count_documents.CountDocumentsOperation = void 0;
const aggregate_1 = aggregate;
/** @internal */
class CountDocumentsOperation extends aggregate_1.AggregateOperation {
  constructor(collection, query, options) {
    const pipeline = [];
    pipeline.push({ $match: query });
    if (typeof options.skip === "number") {
      pipeline.push({ $skip: options.skip });
    }
    if (typeof options.limit === "number") {
      pipeline.push({ $limit: options.limit });
    }
    pipeline.push({ $group: { _id: 1, n: { $sum: 1 } } });
    super(collection.s.namespace, pipeline, options);
  }
  async execute(server, session) {
    const result = await super.execute(server, session);
    // NOTE: We're avoiding creating a cursor here to reduce the callstack.
    const response = result;
    if (response.cursor == null || response.cursor.firstBatch == null) {
      return 0;
    }
    const docs = response.cursor.firstBatch;
    return docs.length ? docs[0].n : 0;
  }
}
count_documents.CountDocumentsOperation = CountDocumentsOperation;

var distinct = {};

Object.defineProperty(distinct, "__esModule", { value: true });
distinct.DistinctOperation = void 0;
const utils_1$f = utils$2;
const command_1$5 = command;
const operation_1$9 = operation;
/**
 * Return a list of distinct values for the given key across a collection.
 * @internal
 */
class DistinctOperation extends command_1$5.CommandOperation {
  /**
   * Construct a Distinct operation.
   *
   * @param collection - Collection instance.
   * @param key - Field of the document to find distinct values for.
   * @param query - The query for filtering the set of documents to which we apply the distinct filter.
   * @param options - Optional settings. See Collection.prototype.distinct for a list of options.
   */
  constructor(collection, key, query, options) {
    super(collection, options);
    this.options = options ?? {};
    this.collection = collection;
    this.key = key;
    this.query = query;
  }
  async execute(server, session) {
    const coll = this.collection;
    const key = this.key;
    const query = this.query;
    const options = this.options;
    // Distinct command
    const cmd = {
      distinct: coll.collectionName,
      key: key,
      query: query,
    };
    // Add maxTimeMS if defined
    if (typeof options.maxTimeMS === "number") {
      cmd.maxTimeMS = options.maxTimeMS;
    }
    // we check for undefined specifically here to allow falsy values
    // eslint-disable-next-line no-restricted-syntax
    if (typeof options.comment !== "undefined") {
      cmd.comment = options.comment;
    }
    // Do we have a readConcern specified
    (0, utils_1$f.decorateWithReadConcern)(cmd, coll, options);
    // Have we specified collation
    (0, utils_1$f.decorateWithCollation)(cmd, coll, options);
    const result = await super.executeCommand(server, session, cmd);
    return this.explain ? result : result.values;
  }
}
distinct.DistinctOperation = DistinctOperation;
(0, operation_1$9.defineAspects)(DistinctOperation, [
  operation_1$9.Aspect.READ_OPERATION,
  operation_1$9.Aspect.RETRYABLE,
  operation_1$9.Aspect.EXPLAINABLE,
]);

var drop$1 = {};

Object.defineProperty(drop$1, "__esModule", { value: true });
drop$1.DropDatabaseOperation = drop$1.DropCollectionOperation = void 0;
const error_1$q = error;
const command_1$4 = command;
const operation_1$8 = operation;
/** @internal */
class DropCollectionOperation extends command_1$4.CommandOperation {
  constructor(db, name, options = {}) {
    super(db, options);
    this.db = db;
    this.options = options;
    this.name = name;
  }
  async execute(server, session) {
    const db = this.db;
    const options = this.options;
    const name = this.name;
    const encryptedFieldsMap =
      db.client.options.autoEncryption?.encryptedFieldsMap;
    let encryptedFields =
      options.encryptedFields ??
      encryptedFieldsMap?.[`${db.databaseName}.${name}`];
    if (!encryptedFields && encryptedFieldsMap) {
      // If the MongoClient was configured with an encryptedFieldsMap,
      // and no encryptedFields config was available in it or explicitly
      // passed as an argument, the spec tells us to look one up using
      // listCollections().
      const listCollectionsResult = await db
        .listCollections({ name }, { nameOnly: false })
        .toArray();
      encryptedFields = listCollectionsResult?.[0]?.options?.encryptedFields;
    }
    if (encryptedFields) {
      const escCollection =
        encryptedFields.escCollection || `enxcol_.${name}.esc`;
      const ecocCollection =
        encryptedFields.ecocCollection || `enxcol_.${name}.ecoc`;
      for (const collectionName of [escCollection, ecocCollection]) {
        // Drop auxilliary collections, ignoring potential NamespaceNotFound errors.
        const dropOp = new DropCollectionOperation(db, collectionName);
        try {
          await dropOp.executeWithoutEncryptedFieldsCheck(server, session);
        } catch (err) {
          if (
            !(err instanceof error_1$q.MongoServerError) ||
            err.code !== error_1$q.MONGODB_ERROR_CODES.NamespaceNotFound
          ) {
            throw err;
          }
        }
      }
    }
    return this.executeWithoutEncryptedFieldsCheck(server, session);
  }
  async executeWithoutEncryptedFieldsCheck(server, session) {
    await super.executeCommand(server, session, { drop: this.name });
    return true;
  }
}
drop$1.DropCollectionOperation = DropCollectionOperation;
/** @internal */
class DropDatabaseOperation extends command_1$4.CommandOperation {
  constructor(db, options) {
    super(db, options);
    this.options = options;
  }
  async execute(server, session) {
    await super.executeCommand(server, session, { dropDatabase: 1 });
    return true;
  }
}
drop$1.DropDatabaseOperation = DropDatabaseOperation;
(0, operation_1$8.defineAspects)(DropCollectionOperation, [
  operation_1$8.Aspect.WRITE_OPERATION,
]);
(0, operation_1$8.defineAspects)(DropDatabaseOperation, [
  operation_1$8.Aspect.WRITE_OPERATION,
]);

var estimated_document_count = {};

Object.defineProperty(estimated_document_count, "__esModule", { value: true });
estimated_document_count.EstimatedDocumentCountOperation = void 0;
const command_1$3 = command;
const operation_1$7 = operation;
/** @internal */
class EstimatedDocumentCountOperation extends command_1$3.CommandOperation {
  constructor(collection, options = {}) {
    super(collection, options);
    this.options = options;
    this.collectionName = collection.collectionName;
  }
  async execute(server, session) {
    const cmd = { count: this.collectionName };
    if (typeof this.options.maxTimeMS === "number") {
      cmd.maxTimeMS = this.options.maxTimeMS;
    }
    // we check for undefined specifically here to allow falsy values
    // eslint-disable-next-line no-restricted-syntax
    if (this.options.comment !== undefined) {
      cmd.comment = this.options.comment;
    }
    const response = await super.executeCommand(server, session, cmd);
    return response?.n || 0;
  }
}
estimated_document_count.EstimatedDocumentCountOperation =
  EstimatedDocumentCountOperation;
(0, operation_1$7.defineAspects)(EstimatedDocumentCountOperation, [
  operation_1$7.Aspect.READ_OPERATION,
  operation_1$7.Aspect.RETRYABLE,
  operation_1$7.Aspect.CURSOR_CREATING,
]);

var find_and_modify = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.FindOneAndUpdateOperation =
    exports.FindOneAndReplaceOperation =
    exports.FindOneAndDeleteOperation =
    exports.ReturnDocument =
      void 0;
  const error_1 = error;
  const read_preference_1 = read_preference;
  const sort_1 = sort;
  const utils_1 = utils$2;
  const command_1 = command;
  const operation_1 = operation;
  /** @public */
  exports.ReturnDocument = Object.freeze({
    BEFORE: "before",
    AFTER: "after",
  });
  function configureFindAndModifyCmdBaseUpdateOpts(cmdBase, options) {
    cmdBase.new = options.returnDocument === exports.ReturnDocument.AFTER;
    cmdBase.upsert = options.upsert === true;
    if (options.bypassDocumentValidation === true) {
      cmdBase.bypassDocumentValidation = options.bypassDocumentValidation;
    }
    return cmdBase;
  }
  /** @internal */
  class FindAndModifyOperation extends command_1.CommandOperation {
    constructor(collection, query, options) {
      super(collection, options);
      this.options = options ?? {};
      this.cmdBase = {
        remove: false,
        new: false,
        upsert: false,
      };
      options.includeResultMetadata ??= false;
      const sort = (0, sort_1.formatSort)(options.sort);
      if (sort) {
        this.cmdBase.sort = sort;
      }
      if (options.projection) {
        this.cmdBase.fields = options.projection;
      }
      if (options.maxTimeMS) {
        this.cmdBase.maxTimeMS = options.maxTimeMS;
      }
      // Decorate the findAndModify command with the write Concern
      if (options.writeConcern) {
        this.cmdBase.writeConcern = options.writeConcern;
      }
      if (options.let) {
        this.cmdBase.let = options.let;
      }
      // we check for undefined specifically here to allow falsy values
      // eslint-disable-next-line no-restricted-syntax
      if (options.comment !== undefined) {
        this.cmdBase.comment = options.comment;
      }
      // force primary read preference
      this.readPreference = read_preference_1.ReadPreference.primary;
      this.collection = collection;
      this.query = query;
    }
    async execute(server, session) {
      const coll = this.collection;
      const query = this.query;
      const options = { ...this.options, ...this.bsonOptions };
      // Create findAndModify command object
      const cmd = {
        findAndModify: coll.collectionName,
        query: query,
        ...this.cmdBase,
      };
      // Have we specified collation
      try {
        (0, utils_1.decorateWithCollation)(cmd, coll, options);
      } catch (err) {
        return err;
      }
      if (options.hint) {
        // TODO: once this method becomes a CommandOperation we will have the server
        // in place to check.
        const unacknowledgedWrite = this.writeConcern?.w === 0;
        if (unacknowledgedWrite || (0, utils_1.maxWireVersion)(server) < 8) {
          throw new error_1.MongoCompatibilityError(
            "The current topology does not support a hint on findAndModify commands",
          );
        }
        cmd.hint = options.hint;
      }
      // Execute the command
      const result = await super.executeCommand(server, session, cmd);
      return options.includeResultMetadata ? result : result.value ?? null;
    }
  }
  /** @internal */
  class FindOneAndDeleteOperation extends FindAndModifyOperation {
    constructor(collection, filter, options) {
      // Basic validation
      if (filter == null || typeof filter !== "object") {
        throw new error_1.MongoInvalidArgumentError(
          'Argument "filter" must be an object',
        );
      }
      super(collection, filter, options);
      this.cmdBase.remove = true;
    }
  }
  exports.FindOneAndDeleteOperation = FindOneAndDeleteOperation;
  /** @internal */
  class FindOneAndReplaceOperation extends FindAndModifyOperation {
    constructor(collection, filter, replacement, options) {
      if (filter == null || typeof filter !== "object") {
        throw new error_1.MongoInvalidArgumentError(
          'Argument "filter" must be an object',
        );
      }
      if (replacement == null || typeof replacement !== "object") {
        throw new error_1.MongoInvalidArgumentError(
          'Argument "replacement" must be an object',
        );
      }
      if ((0, utils_1.hasAtomicOperators)(replacement)) {
        throw new error_1.MongoInvalidArgumentError(
          "Replacement document must not contain atomic operators",
        );
      }
      super(collection, filter, options);
      this.cmdBase.update = replacement;
      configureFindAndModifyCmdBaseUpdateOpts(this.cmdBase, options);
    }
  }
  exports.FindOneAndReplaceOperation = FindOneAndReplaceOperation;
  /** @internal */
  class FindOneAndUpdateOperation extends FindAndModifyOperation {
    constructor(collection, filter, update, options) {
      if (filter == null || typeof filter !== "object") {
        throw new error_1.MongoInvalidArgumentError(
          'Argument "filter" must be an object',
        );
      }
      if (update == null || typeof update !== "object") {
        throw new error_1.MongoInvalidArgumentError(
          'Argument "update" must be an object',
        );
      }
      if (!(0, utils_1.hasAtomicOperators)(update)) {
        throw new error_1.MongoInvalidArgumentError(
          "Update document requires atomic operators",
        );
      }
      super(collection, filter, options);
      this.cmdBase.update = update;
      configureFindAndModifyCmdBaseUpdateOpts(this.cmdBase, options);
      if (options.arrayFilters) {
        this.cmdBase.arrayFilters = options.arrayFilters;
      }
    }
  }
  exports.FindOneAndUpdateOperation = FindOneAndUpdateOperation;
  (0, operation_1.defineAspects)(FindAndModifyOperation, [
    operation_1.Aspect.WRITE_OPERATION,
    operation_1.Aspect.RETRYABLE,
    operation_1.Aspect.EXPLAINABLE,
  ]);
})(find_and_modify);

var is_capped = {};

Object.defineProperty(is_capped, "__esModule", { value: true });
is_capped.IsCappedOperation = void 0;
const error_1$p = error;
const operation_1$6 = operation;
/** @internal */
class IsCappedOperation extends operation_1$6.AbstractOperation {
  constructor(collection, options) {
    super(options);
    this.options = options;
    this.collection = collection;
  }
  async execute(server, session) {
    const coll = this.collection;
    const [collection] = await coll.s.db
      .listCollections(
        { name: coll.collectionName },
        {
          ...this.options,
          nameOnly: false,
          readPreference: this.readPreference,
          session,
        },
      )
      .toArray();
    if (collection == null || collection.options == null) {
      throw new error_1$p.MongoAPIError(
        `collection ${coll.namespace} not found`,
      );
    }
    return !!collection.options?.capped;
  }
}
is_capped.IsCappedOperation = IsCappedOperation;

var options_operation = {};

Object.defineProperty(options_operation, "__esModule", { value: true });
options_operation.OptionsOperation = void 0;
const error_1$o = error;
const operation_1$5 = operation;
/** @internal */
class OptionsOperation extends operation_1$5.AbstractOperation {
  constructor(collection, options) {
    super(options);
    this.options = options;
    this.collection = collection;
  }
  async execute(server, session) {
    const coll = this.collection;
    const [collection] = await coll.s.db
      .listCollections(
        { name: coll.collectionName },
        {
          ...this.options,
          nameOnly: false,
          readPreference: this.readPreference,
          session,
        },
      )
      .toArray();
    if (collection == null || collection.options == null) {
      throw new error_1$o.MongoAPIError(
        `collection ${coll.namespace} not found`,
      );
    }
    return collection.options;
  }
}
options_operation.OptionsOperation = OptionsOperation;

var rename = {};

var hasRequiredRename;

function requireRename() {
  if (hasRequiredRename) return rename;
  hasRequiredRename = 1;
  Object.defineProperty(rename, "__esModule", { value: true });
  rename.RenameOperation = void 0;
  const collection_1 = requireCollection();
  const utils_1 = utils$2;
  const command_1 = command;
  const operation_1 = operation;
  /** @internal */
  class RenameOperation extends command_1.CommandOperation {
    constructor(collection, newName, options) {
      super(collection, options);
      this.collection = collection;
      this.newName = newName;
      this.options = options;
      this.ns = new utils_1.MongoDBNamespace("admin", "$cmd");
    }
    async execute(server, session) {
      // Build the command
      const renameCollection = this.collection.namespace;
      const toCollection = this.collection.s.namespace
        .withCollection(this.newName)
        .toString();
      const dropTarget =
        typeof this.options.dropTarget === "boolean"
          ? this.options.dropTarget
          : false;
      const command = {
        renameCollection: renameCollection,
        to: toCollection,
        dropTarget: dropTarget,
      };
      await super.executeCommand(server, session, command);
      return new collection_1.Collection(
        this.collection.s.db,
        this.newName,
        this.collection.s.options,
      );
    }
  }
  rename.RenameOperation = RenameOperation;
  (0, operation_1.defineAspects)(RenameOperation, [
    operation_1.Aspect.WRITE_OPERATION,
  ]);

  return rename;
}

var create = {};

Object.defineProperty(create, "__esModule", { value: true });
create.CreateSearchIndexesOperation = void 0;
const operation_1$4 = operation;
/** @internal */
class CreateSearchIndexesOperation extends operation_1$4.AbstractOperation {
  constructor(collection, descriptions) {
    super();
    this.collection = collection;
    this.descriptions = descriptions;
  }
  async execute(server, session) {
    const namespace = this.collection.fullNamespace;
    const command = {
      createSearchIndexes: namespace.collection,
      indexes: this.descriptions,
    };
    const res = await server.commandAsync(namespace, command, { session });
    const indexesCreated = res?.indexesCreated ?? [];
    return indexesCreated.map(({ name }) => name);
  }
}
create.CreateSearchIndexesOperation = CreateSearchIndexesOperation;

var drop = {};

Object.defineProperty(drop, "__esModule", { value: true });
drop.DropSearchIndexOperation = void 0;
const error_1$n = error;
const operation_1$3 = operation;
/** @internal */
class DropSearchIndexOperation extends operation_1$3.AbstractOperation {
  constructor(collection, name) {
    super();
    this.collection = collection;
    this.name = name;
  }
  async execute(server, session) {
    const namespace = this.collection.fullNamespace;
    const command = {
      dropSearchIndex: namespace.collection,
    };
    if (typeof this.name === "string") {
      command.name = this.name;
    }
    try {
      await server.commandAsync(namespace, command, { session });
    } catch (error) {
      const isNamespaceNotFoundError =
        error instanceof error_1$n.MongoServerError &&
        error.code === error_1$n.MONGODB_ERROR_CODES.NamespaceNotFound;
      if (!isNamespaceNotFoundError) {
        throw error;
      }
    }
  }
}
drop.DropSearchIndexOperation = DropSearchIndexOperation;

var update = {};

Object.defineProperty(update, "__esModule", { value: true });
update.UpdateSearchIndexOperation = void 0;
const operation_1$2 = operation;
/** @internal */
class UpdateSearchIndexOperation extends operation_1$2.AbstractOperation {
  constructor(collection, name, definition) {
    super();
    this.collection = collection;
    this.name = name;
    this.definition = definition;
  }
  async execute(server, session) {
    const namespace = this.collection.fullNamespace;
    const command = {
      updateSearchIndex: namespace.collection,
      name: this.name,
      definition: this.definition,
    };
    await server.commandAsync(namespace, command, { session });
    return;
  }
}
update.UpdateSearchIndexOperation = UpdateSearchIndexOperation;

var hasRequiredCollection;

function requireCollection() {
  if (hasRequiredCollection) return collection;
  hasRequiredCollection = 1;
  Object.defineProperty(collection, "__esModule", { value: true });
  collection.Collection = void 0;
  const bson_1 = bson$2;
  const ordered_1 = ordered;
  const unordered_1 = unordered;
  const change_stream_1 = requireChange_stream();
  const aggregation_cursor_1 = aggregation_cursor;
  const find_cursor_1 = find_cursor;
  const list_indexes_cursor_1 = list_indexes_cursor;
  const list_search_indexes_cursor_1 = list_search_indexes_cursor;
  const error_1 = error;
  const bulk_write_1 = bulk_write;
  const count_1 = count;
  const count_documents_1 = count_documents;
  const delete_1 = _delete;
  const distinct_1 = distinct;
  const drop_1 = drop$1;
  const estimated_document_count_1 = estimated_document_count;
  const execute_operation_1 = execute_operation;
  const find_and_modify_1 = find_and_modify;
  const indexes_1 = indexes;
  const insert_1 = insert;
  const is_capped_1 = is_capped;
  const options_operation_1 = options_operation;
  const rename_1 = requireRename();
  const create_1 = create;
  const drop_2 = drop;
  const update_1 = update;
  const update_2 = update$1;
  const read_concern_1 = read_concern;
  const read_preference_1 = read_preference;
  const utils_1 = utils$2;
  const write_concern_1 = write_concern;
  /**
   * The **Collection** class is an internal class that embodies a MongoDB collection
   * allowing for insert/find/update/delete and other command operation on that MongoDB collection.
   *
   * **COLLECTION Cannot directly be instantiated**
   * @public
   *
   * @example
   * ```ts
   * import { MongoClient } from 'mongodb';
   *
   * interface Pet {
   *   name: string;
   *   kind: 'dog' | 'cat' | 'fish';
   * }
   *
   * const client = new MongoClient('mongodb://localhost:27017');
   * const pets = client.db().collection<Pet>('pets');
   *
   * const petCursor = pets.find();
   *
   * for await (const pet of petCursor) {
   *   console.log(`${pet.name} is a ${pet.kind}!`);
   * }
   * ```
   */
  class Collection {
    /**
     * Create a new Collection instance
     * @internal
     */
    constructor(db, name, options) {
      // Internal state
      this.s = {
        db,
        options,
        namespace: new utils_1.MongoDBCollectionNamespace(
          db.databaseName,
          name,
        ),
        pkFactory: db.options?.pkFactory ?? utils_1.DEFAULT_PK_FACTORY,
        readPreference: read_preference_1.ReadPreference.fromOptions(options),
        bsonOptions: (0, bson_1.resolveBSONOptions)(options, db),
        readConcern: read_concern_1.ReadConcern.fromOptions(options),
        writeConcern: write_concern_1.WriteConcern.fromOptions(options),
      };
      this.client = db.client;
    }
    /**
     * The name of the database this collection belongs to
     */
    get dbName() {
      return this.s.namespace.db;
    }
    /**
     * The name of this collection
     */
    get collectionName() {
      return this.s.namespace.collection;
    }
    /**
     * The namespace of this collection, in the format `${this.dbName}.${this.collectionName}`
     */
    get namespace() {
      return this.fullNamespace.toString();
    }
    /**
     *  @internal
     *
     * The `MongoDBNamespace` for the collection.
     */
    get fullNamespace() {
      return this.s.namespace;
    }
    /**
     * The current readConcern of the collection. If not explicitly defined for
     * this collection, will be inherited from the parent DB
     */
    get readConcern() {
      if (this.s.readConcern == null) {
        return this.s.db.readConcern;
      }
      return this.s.readConcern;
    }
    /**
     * The current readPreference of the collection. If not explicitly defined for
     * this collection, will be inherited from the parent DB
     */
    get readPreference() {
      if (this.s.readPreference == null) {
        return this.s.db.readPreference;
      }
      return this.s.readPreference;
    }
    get bsonOptions() {
      return this.s.bsonOptions;
    }
    /**
     * The current writeConcern of the collection. If not explicitly defined for
     * this collection, will be inherited from the parent DB
     */
    get writeConcern() {
      if (this.s.writeConcern == null) {
        return this.s.db.writeConcern;
      }
      return this.s.writeConcern;
    }
    /** The current index hint for the collection */
    get hint() {
      return this.s.collectionHint;
    }
    set hint(v) {
      this.s.collectionHint = (0, utils_1.normalizeHintField)(v);
    }
    /**
     * Inserts a single document into MongoDB. If documents passed in do not contain the **_id** field,
     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior
     * can be overridden by setting the **forceServerObjectId** flag.
     *
     * @param doc - The document to insert
     * @param options - Optional settings for the command
     */
    async insertOne(doc, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new insert_1.InsertOneOperation(
          this,
          doc,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Inserts an array of documents into MongoDB. If documents passed in do not contain the **_id** field,
     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior
     * can be overridden by setting the **forceServerObjectId** flag.
     *
     * @param docs - The documents to insert
     * @param options - Optional settings for the command
     */
    async insertMany(docs, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new insert_1.InsertManyOperation(
          this,
          docs,
          (0, utils_1.resolveOptions)(this, options ?? { ordered: true }),
        ),
      );
    }
    /**
     * Perform a bulkWrite operation without a fluent API
     *
     * Legal operation types are
     * - `insertOne`
     * - `replaceOne`
     * - `updateOne`
     * - `updateMany`
     * - `deleteOne`
     * - `deleteMany`
     *
     * If documents passed in do not contain the **_id** field,
     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior
     * can be overridden by setting the **forceServerObjectId** flag.
     *
     * @param operations - Bulk operations to perform
     * @param options - Optional settings for the command
     * @throws MongoDriverError if operations is not an array
     */
    async bulkWrite(operations, options) {
      if (!Array.isArray(operations)) {
        throw new error_1.MongoInvalidArgumentError(
          'Argument "operations" must be an array of documents',
        );
      }
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new bulk_write_1.BulkWriteOperation(
          this,
          operations,
          (0, utils_1.resolveOptions)(this, options ?? { ordered: true }),
        ),
      );
    }
    /**
     * Update a single document in a collection
     *
     * @param filter - The filter used to select the document to update
     * @param update - The update operations to be applied to the document
     * @param options - Optional settings for the command
     */
    async updateOne(filter, update, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new update_2.UpdateOneOperation(
          this,
          filter,
          update,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Replace a document in a collection with another document
     *
     * @param filter - The filter used to select the document to replace
     * @param replacement - The Document that replaces the matching document
     * @param options - Optional settings for the command
     */
    async replaceOne(filter, replacement, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new update_2.ReplaceOneOperation(
          this,
          filter,
          replacement,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Update multiple documents in a collection
     *
     * @param filter - The filter used to select the documents to update
     * @param update - The update operations to be applied to the documents
     * @param options - Optional settings for the command
     */
    async updateMany(filter, update, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new update_2.UpdateManyOperation(
          this,
          filter,
          update,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Delete a document from a collection
     *
     * @param filter - The filter used to select the document to remove
     * @param options - Optional settings for the command
     */
    async deleteOne(filter = {}, options = {}) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new delete_1.DeleteOneOperation(
          this,
          filter,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Delete multiple documents from a collection
     *
     * @param filter - The filter used to select the documents to remove
     * @param options - Optional settings for the command
     */
    async deleteMany(filter = {}, options = {}) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new delete_1.DeleteManyOperation(
          this,
          filter,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Rename the collection.
     *
     * @remarks
     * This operation does not inherit options from the Db or MongoClient.
     *
     * @param newName - New name of of the collection.
     * @param options - Optional settings for the command
     */
    async rename(newName, options) {
      // Intentionally, we do not inherit options from parent for this operation.
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new rename_1.RenameOperation(this, newName, {
          ...options,
          readPreference: read_preference_1.ReadPreference.PRIMARY,
        }),
      );
    }
    /**
     * Drop the collection from the database, removing it permanently. New accesses will create a new collection.
     *
     * @param options - Optional settings for the command
     */
    async drop(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new drop_1.DropCollectionOperation(
          this.s.db,
          this.collectionName,
          options,
        ),
      );
    }
    async findOne(filter = {}, options = {}) {
      const cursor = this.find(filter, options).limit(-1).batchSize(1);
      const res = await cursor.next();
      await cursor.close();
      return res;
    }
    find(filter = {}, options = {}) {
      return new find_cursor_1.FindCursor(
        this.client,
        this.s.namespace,
        filter,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /**
     * Returns the options of the collection.
     *
     * @param options - Optional settings for the command
     */
    async options(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new options_operation_1.OptionsOperation(
          this,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Returns if the collection is a capped collection
     *
     * @param options - Optional settings for the command
     */
    async isCapped(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new is_capped_1.IsCappedOperation(
          this,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Creates an index on the db and collection collection.
     *
     * @param indexSpec - The field name or index specification to create an index for
     * @param options - Optional settings for the command
     *
     * @example
     * ```ts
     * const collection = client.db('foo').collection('bar');
     *
     * await collection.createIndex({ a: 1, b: -1 });
     *
     * // Alternate syntax for { c: 1, d: -1 } that ensures order of indexes
     * await collection.createIndex([ [c, 1], [d, -1] ]);
     *
     * // Equivalent to { e: 1 }
     * await collection.createIndex('e');
     *
     * // Equivalent to { f: 1, g: 1 }
     * await collection.createIndex(['f', 'g'])
     *
     * // Equivalent to { h: 1, i: -1 }
     * await collection.createIndex([ { h: 1 }, { i: -1 } ]);
     *
     * // Equivalent to { j: 1, k: -1, l: 2d }
     * await collection.createIndex(['j', ['k', -1], { l: '2d' }])
     * ```
     */
    async createIndex(indexSpec, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new indexes_1.CreateIndexOperation(
          this,
          this.collectionName,
          indexSpec,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Creates multiple indexes in the collection, this method is only supported for
     * MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported
     * error.
     *
     * **Note**: Unlike {@link Collection#createIndex| createIndex}, this function takes in raw index specifications.
     * Index specifications are defined {@link https://www.mongodb.com/docs/manual/reference/command/createIndexes/| here}.
     *
     * @param indexSpecs - An array of index specifications to be created
     * @param options - Optional settings for the command
     *
     * @example
     * ```ts
     * const collection = client.db('foo').collection('bar');
     * await collection.createIndexes([
     *   // Simple index on field fizz
     *   {
     *     key: { fizz: 1 },
     *   }
     *   // wildcard index
     *   {
     *     key: { '$**': 1 }
     *   },
     *   // named index on darmok and jalad
     *   {
     *     key: { darmok: 1, jalad: -1 }
     *     name: 'tanagra'
     *   }
     * ]);
     * ```
     */
    async createIndexes(indexSpecs, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new indexes_1.CreateIndexesOperation(
          this,
          this.collectionName,
          indexSpecs,
          (0, utils_1.resolveOptions)(this, {
            ...options,
            maxTimeMS: undefined,
          }),
        ),
      );
    }
    /**
     * Drops an index from this collection.
     *
     * @param indexName - Name of the index to drop.
     * @param options - Optional settings for the command
     */
    async dropIndex(indexName, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new indexes_1.DropIndexOperation(this, indexName, {
          ...(0, utils_1.resolveOptions)(this, options),
          readPreference: read_preference_1.ReadPreference.primary,
        }),
      );
    }
    /**
     * Drops all indexes from this collection.
     *
     * @param options - Optional settings for the command
     */
    async dropIndexes(options) {
      try {
        await (0, execute_operation_1.executeOperation)(
          this.client,
          new indexes_1.DropIndexOperation(
            this,
            "*",
            (0, utils_1.resolveOptions)(this, options),
          ),
        );
        return true;
      } catch {
        return false;
      }
    }
    /**
     * Get the list of all indexes information for the collection.
     *
     * @param options - Optional settings for the command
     */
    listIndexes(options) {
      return new list_indexes_cursor_1.ListIndexesCursor(
        this,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /**
     * Checks if one or more indexes exist on the collection, fails on first non-existing index
     *
     * @param indexes - One or more index names to check.
     * @param options - Optional settings for the command
     */
    async indexExists(indexes, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new indexes_1.IndexExistsOperation(
          this,
          indexes,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Retrieves this collections index info.
     *
     * @param options - Optional settings for the command
     */
    async indexInformation(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new indexes_1.IndexInformationOperation(
          this.s.db,
          this.collectionName,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Gets an estimate of the count of documents in a collection using collection metadata.
     * This will always run a count command on all server versions.
     *
     * due to an oversight in versions 5.0.0-5.0.8 of MongoDB, the count command,
     * which estimatedDocumentCount uses in its implementation, was not included in v1 of
     * the Stable API, and so users of the Stable API with estimatedDocumentCount are
     * recommended to upgrade their server version to 5.0.9+ or set apiStrict: false to avoid
     * encountering errors.
     *
     * @see {@link https://www.mongodb.com/docs/manual/reference/command/count/#behavior|Count: Behavior}
     * @param options - Optional settings for the command
     */
    async estimatedDocumentCount(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new estimated_document_count_1.EstimatedDocumentCountOperation(
          this,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Gets the number of documents matching the filter.
     * For a fast count of the total documents in a collection see {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.
     * **Note**: When migrating from {@link Collection#count| count} to {@link Collection#countDocuments| countDocuments}
     * the following query operators must be replaced:
     *
     * | Operator | Replacement |
     * | -------- | ----------- |
     * | `$where`   | [`$expr`][1] |
     * | `$near`    | [`$geoWithin`][2] with [`$center`][3] |
     * | `$nearSphere` | [`$geoWithin`][2] with [`$centerSphere`][4] |
     *
     * [1]: https://www.mongodb.com/docs/manual/reference/operator/query/expr/
     * [2]: https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/
     * [3]: https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center
     * [4]: https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere
     *
     * @param filter - The filter for the count
     * @param options - Optional settings for the command
     *
     * @see https://www.mongodb.com/docs/manual/reference/operator/query/expr/
     * @see https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/
     * @see https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center
     * @see https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere
     */
    async countDocuments(filter = {}, options = {}) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new count_documents_1.CountDocumentsOperation(
          this,
          filter,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    async distinct(key, filter = {}, options = {}) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new distinct_1.DistinctOperation(
          this,
          key,
          filter,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Retrieve all the indexes on the collection.
     *
     * @param options - Optional settings for the command
     */
    async indexes(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new indexes_1.IndexesOperation(
          this,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    async findOneAndDelete(filter, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new find_and_modify_1.FindOneAndDeleteOperation(
          this,
          filter,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    async findOneAndReplace(filter, replacement, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new find_and_modify_1.FindOneAndReplaceOperation(
          this,
          filter,
          replacement,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    async findOneAndUpdate(filter, update, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new find_and_modify_1.FindOneAndUpdateOperation(
          this,
          filter,
          update,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Execute an aggregation framework pipeline against the collection, needs MongoDB \>= 2.2
     *
     * @param pipeline - An array of aggregation pipelines to execute
     * @param options - Optional settings for the command
     */
    aggregate(pipeline = [], options) {
      if (!Array.isArray(pipeline)) {
        throw new error_1.MongoInvalidArgumentError(
          'Argument "pipeline" must be an array of aggregation stages',
        );
      }
      return new aggregation_cursor_1.AggregationCursor(
        this.client,
        this.s.namespace,
        pipeline,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /**
     * Create a new Change Stream, watching for new changes (insertions, updates, replacements, deletions, and invalidations) in this collection.
     *
     * @remarks
     * watch() accepts two generic arguments for distinct use cases:
     * - The first is to override the schema that may be defined for this specific collection
     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument
     * @example
     * By just providing the first argument I can type the change to be `ChangeStreamDocument<{ _id: number }>`
     * ```ts
     * collection.watch<{ _id: number }>()
     *   .on('change', change => console.log(change._id.toFixed(4)));
     * ```
     *
     * @example
     * Passing a second argument provides a way to reflect the type changes caused by an advanced pipeline.
     * Here, we are using a pipeline to have MongoDB filter for insert changes only and add a comment.
     * No need start from scratch on the ChangeStreamInsertDocument type!
     * By using an intersection we can save time and ensure defaults remain the same type!
     * ```ts
     * collection
     *   .watch<Schema, ChangeStreamInsertDocument<Schema> & { comment: string }>([
     *     { $addFields: { comment: 'big changes' } },
     *     { $match: { operationType: 'insert' } }
     *   ])
     *   .on('change', change => {
     *     change.comment.startsWith('big');
     *     change.operationType === 'insert';
     *     // No need to narrow in code because the generics did that for us!
     *     expectType<Schema>(change.fullDocument);
     *   });
     * ```
     *
     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.
     * @param options - Optional settings for the command
     * @typeParam TLocal - Type of the data being detected by the change stream
     * @typeParam TChange - Type of the whole change stream document emitted
     */
    watch(pipeline = [], options = {}) {
      // Allow optionally not specifying a pipeline
      if (!Array.isArray(pipeline)) {
        options = pipeline;
        pipeline = [];
      }
      return new change_stream_1.ChangeStream(
        this,
        pipeline,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /**
     * Initiate an Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.
     *
     * @throws MongoNotConnectedError
     * @remarks
     * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.
     * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.
     */
    initializeUnorderedBulkOp(options) {
      return new unordered_1.UnorderedBulkOperation(
        this,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /**
     * Initiate an In order bulk write operation. Operations will be serially executed in the order they are added, creating a new operation for each switch in types.
     *
     * @throws MongoNotConnectedError
     * @remarks
     * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.
     * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.
     */
    initializeOrderedBulkOp(options) {
      return new ordered_1.OrderedBulkOperation(
        this,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /**
     * An estimated count of matching documents in the db to a filter.
     *
     * **NOTE:** This method has been deprecated, since it does not provide an accurate count of the documents
     * in a collection. To obtain an accurate count of documents in the collection, use {@link Collection#countDocuments| countDocuments}.
     * To obtain an estimated count of all documents in the collection, use {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.
     *
     * @deprecated use {@link Collection#countDocuments| countDocuments} or {@link Collection#estimatedDocumentCount| estimatedDocumentCount} instead
     *
     * @param filter - The filter for the count.
     * @param options - Optional settings for the command
     */
    async count(filter = {}, options = {}) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new count_1.CountOperation(
          this.fullNamespace,
          filter,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    listSearchIndexes(indexNameOrOptions, options) {
      options =
        typeof indexNameOrOptions === "object"
          ? indexNameOrOptions
          : options == null
          ? {}
          : options;
      const indexName =
        indexNameOrOptions == null
          ? null
          : typeof indexNameOrOptions === "object"
          ? null
          : indexNameOrOptions;
      return new list_search_indexes_cursor_1.ListSearchIndexesCursor(
        this,
        indexName,
        options,
      );
    }
    /**
     * Creates a single search index for the collection.
     *
     * @param description - The index description for the new search index.
     * @returns A promise that resolves to the name of the new search index.
     *
     * @remarks Only available when used against a 7.0+ Atlas cluster.
     */
    async createSearchIndex(description) {
      const [index] = await this.createSearchIndexes([description]);
      return index;
    }
    /**
     * Creates multiple search indexes for the current collection.
     *
     * @param descriptions - An array of `SearchIndexDescription`s for the new search indexes.
     * @returns A promise that resolves to an array of the newly created search index names.
     *
     * @remarks Only available when used against a 7.0+ Atlas cluster.
     * @returns
     */
    async createSearchIndexes(descriptions) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new create_1.CreateSearchIndexesOperation(this, descriptions),
      );
    }
    /**
     * Deletes a search index by index name.
     *
     * @param name - The name of the search index to be deleted.
     *
     * @remarks Only available when used against a 7.0+ Atlas cluster.
     */
    async dropSearchIndex(name) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new drop_2.DropSearchIndexOperation(this, name),
      );
    }
    /**
     * Updates a search index by replacing the existing index definition with the provided definition.
     *
     * @param name - The name of the search index to update.
     * @param definition - The new search index definition.
     *
     * @remarks Only available when used against a 7.0+ Atlas cluster.
     */
    async updateSearchIndex(name, definition) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new update_1.UpdateSearchIndexOperation(this, name, definition),
      );
    }
  }
  collection.Collection = Collection;

  return collection;
}

var change_stream_cursor = {};

var hasRequiredChange_stream_cursor;

function requireChange_stream_cursor() {
  if (hasRequiredChange_stream_cursor) return change_stream_cursor;
  hasRequiredChange_stream_cursor = 1;
  Object.defineProperty(change_stream_cursor, "__esModule", { value: true });
  change_stream_cursor.ChangeStreamCursor = void 0;
  const change_stream_1 = requireChange_stream();
  const constants_1 = constants;
  const aggregate_1 = aggregate;
  const execute_operation_1 = execute_operation;
  const utils_1 = utils$2;
  const abstract_cursor_1 = abstract_cursor;
  /** @internal */
  class ChangeStreamCursor extends abstract_cursor_1.AbstractCursor {
    constructor(client, namespace, pipeline = [], options = {}) {
      super(client, namespace, options);
      this.pipeline = pipeline;
      this.options = options;
      this._resumeToken = null;
      this.startAtOperationTime = options.startAtOperationTime;
      if (options.startAfter) {
        this.resumeToken = options.startAfter;
      } else if (options.resumeAfter) {
        this.resumeToken = options.resumeAfter;
      }
    }
    set resumeToken(token) {
      this._resumeToken = token;
      this.emit(change_stream_1.ChangeStream.RESUME_TOKEN_CHANGED, token);
    }
    get resumeToken() {
      return this._resumeToken;
    }
    get resumeOptions() {
      const options = {
        ...this.options,
      };
      for (const key of ["resumeAfter", "startAfter", "startAtOperationTime"]) {
        delete options[key];
      }
      if (this.resumeToken != null) {
        if (this.options.startAfter && !this.hasReceived) {
          options.startAfter = this.resumeToken;
        } else {
          options.resumeAfter = this.resumeToken;
        }
      } else if (
        this.startAtOperationTime != null &&
        (0, utils_1.maxWireVersion)(this.server) >= 7
      ) {
        options.startAtOperationTime = this.startAtOperationTime;
      }
      return options;
    }
    cacheResumeToken(resumeToken) {
      if (this.bufferedCount() === 0 && this.postBatchResumeToken) {
        this.resumeToken = this.postBatchResumeToken;
      } else {
        this.resumeToken = resumeToken;
      }
      this.hasReceived = true;
    }
    _processBatch(response) {
      const cursor = response.cursor;
      if (cursor.postBatchResumeToken) {
        this.postBatchResumeToken = response.cursor.postBatchResumeToken;
        const batch =
          "firstBatch" in response.cursor
            ? response.cursor.firstBatch
            : response.cursor.nextBatch;
        if (batch.length === 0) {
          this.resumeToken = cursor.postBatchResumeToken;
        }
      }
    }
    clone() {
      return new ChangeStreamCursor(
        this.client,
        this.namespace,
        this.pipeline,
        {
          ...this.cursorOptions,
        },
      );
    }
    async _initialize(session) {
      const aggregateOperation = new aggregate_1.AggregateOperation(
        this.namespace,
        this.pipeline,
        {
          ...this.cursorOptions,
          ...this.options,
          session,
        },
      );
      const response = await (0, execute_operation_1.executeOperation)(
        session.client,
        aggregateOperation,
      );
      const server = aggregateOperation.server;
      this.maxWireVersion = (0, utils_1.maxWireVersion)(server);
      if (
        this.startAtOperationTime == null &&
        this.resumeAfter == null &&
        this.startAfter == null &&
        this.maxWireVersion >= 7
      ) {
        this.startAtOperationTime = response.operationTime;
      }
      this._processBatch(response);
      this.emit(constants_1.INIT, response);
      this.emit(constants_1.RESPONSE);
      // TODO: NODE-2882
      return { server, session, response };
    }
    async getMore(batchSize) {
      const response = await super.getMore(batchSize);
      this.maxWireVersion = (0, utils_1.maxWireVersion)(this.server);
      this._processBatch(response);
      this.emit(change_stream_1.ChangeStream.MORE, response);
      this.emit(change_stream_1.ChangeStream.RESPONSE);
      return response;
    }
  }
  change_stream_cursor.ChangeStreamCursor = ChangeStreamCursor;

  return change_stream_cursor;
}

var db = {};

var list_collections_cursor = {};

var list_collections = {};

Object.defineProperty(list_collections, "__esModule", { value: true });
list_collections.ListCollectionsOperation = void 0;
const utils_1$e = utils$2;
const command_1$2 = command;
const operation_1$1 = operation;
/** @internal */
class ListCollectionsOperation extends command_1$2.CommandOperation {
  constructor(db, filter, options) {
    super(db, options);
    this.options = { ...options };
    delete this.options.writeConcern;
    this.db = db;
    this.filter = filter;
    this.nameOnly = !!this.options.nameOnly;
    this.authorizedCollections = !!this.options.authorizedCollections;
    if (typeof this.options.batchSize === "number") {
      this.batchSize = this.options.batchSize;
    }
  }
  async execute(server, session) {
    return super.executeCommand(
      server,
      session,
      this.generateCommand((0, utils_1$e.maxWireVersion)(server)),
    );
  }
  /* This is here for the purpose of unit testing the final command that gets sent. */
  generateCommand(wireVersion) {
    const command = {
      listCollections: 1,
      filter: this.filter,
      cursor: this.batchSize ? { batchSize: this.batchSize } : {},
      nameOnly: this.nameOnly,
      authorizedCollections: this.authorizedCollections,
    };
    // we check for undefined specifically here to allow falsy values
    // eslint-disable-next-line no-restricted-syntax
    if (wireVersion >= 9 && this.options.comment !== undefined) {
      command.comment = this.options.comment;
    }
    return command;
  }
}
list_collections.ListCollectionsOperation = ListCollectionsOperation;
(0, operation_1$1.defineAspects)(ListCollectionsOperation, [
  operation_1$1.Aspect.READ_OPERATION,
  operation_1$1.Aspect.RETRYABLE,
  operation_1$1.Aspect.CURSOR_CREATING,
]);

Object.defineProperty(list_collections_cursor, "__esModule", { value: true });
list_collections_cursor.ListCollectionsCursor = void 0;
const execute_operation_1$1 = execute_operation;
const list_collections_1 = list_collections;
const abstract_cursor_1$1 = abstract_cursor;
/** @public */
let ListCollectionsCursor$1 = class ListCollectionsCursor extends abstract_cursor_1$1.AbstractCursor {
  constructor(db, filter, options) {
    super(db.client, db.s.namespace, options);
    this.parent = db;
    this.filter = filter;
    this.options = options;
  }
  clone() {
    return new ListCollectionsCursor(this.parent, this.filter, {
      ...this.options,
      ...this.cursorOptions,
    });
  }
  /** @internal */
  async _initialize(session) {
    const operation = new list_collections_1.ListCollectionsOperation(
      this.parent,
      this.filter,
      {
        ...this.cursorOptions,
        ...this.options,
        session,
      },
    );
    const response = await (0, execute_operation_1$1.executeOperation)(
      this.parent.client,
      operation,
    );
    // TODO: NODE-2882
    return { server: operation.server, session, response };
  }
};
list_collections_cursor.ListCollectionsCursor = ListCollectionsCursor$1;

var run_command_cursor = {};

Object.defineProperty(run_command_cursor, "__esModule", { value: true });
run_command_cursor.RunCommandCursor = void 0;
const error_1$m = error;
const execute_operation_1 = execute_operation;
const get_more_1 = get_more;
const run_command_1 = run_command;
const utils_1$d = utils$2;
const abstract_cursor_1 = abstract_cursor;
/** @public */
class RunCommandCursor extends abstract_cursor_1.AbstractCursor {
  /**
   * Controls the `getMore.comment` field
   * @param comment - any BSON value
   */
  setComment(comment) {
    this.getMoreOptions.comment = comment;
    return this;
  }
  /**
   * Controls the `getMore.maxTimeMS` field. Only valid when cursor is tailable await
   * @param maxTimeMS - the number of milliseconds to wait for new data
   */
  setMaxTimeMS(maxTimeMS) {
    this.getMoreOptions.maxAwaitTimeMS = maxTimeMS;
    return this;
  }
  /**
   * Controls the `getMore.batchSize` field
   * @param maxTimeMS - the number documents to return in the `nextBatch`
   */
  setBatchSize(batchSize) {
    this.getMoreOptions.batchSize = batchSize;
    return this;
  }
  /** Unsupported for RunCommandCursor */
  clone() {
    throw new error_1$m.MongoAPIError(
      "Clone not supported, create a new cursor with db.runCursorCommand",
    );
  }
  /** Unsupported for RunCommandCursor: readConcern must be configured directly on command document */
  withReadConcern(_) {
    throw new error_1$m.MongoAPIError(
      "RunCommandCursor does not support readConcern it must be attached to the command being run",
    );
  }
  /** Unsupported for RunCommandCursor: various cursor flags must be configured directly on command document */
  addCursorFlag(_, __) {
    throw new error_1$m.MongoAPIError(
      "RunCommandCursor does not support cursor flags, they must be attached to the command being run",
    );
  }
  /** Unsupported for RunCommandCursor: maxTimeMS must be configured directly on command document */
  maxTimeMS(_) {
    throw new error_1$m.MongoAPIError(
      "maxTimeMS must be configured on the command document directly, to configure getMore.maxTimeMS use cursor.setMaxTimeMS()",
    );
  }
  /** Unsupported for RunCommandCursor: batchSize must be configured directly on command document */
  batchSize(_) {
    throw new error_1$m.MongoAPIError(
      "batchSize must be configured on the command document directly, to configure getMore.batchSize use cursor.setBatchSize()",
    );
  }
  /** @internal */
  constructor(db, command, options = {}) {
    super(db.client, (0, utils_1$d.ns)(db.namespace), options);
    this.getMoreOptions = {};
    this.db = db;
    this.command = Object.freeze({ ...command });
  }
  /** @internal */
  async _initialize(session) {
    const operation = new run_command_1.RunCommandOperation(
      this.db,
      this.command,
      {
        ...this.cursorOptions,
        session: session,
        readPreference: this.cursorOptions.readPreference,
      },
    );
    const response = await (0, execute_operation_1.executeOperation)(
      this.client,
      operation,
    );
    if (response.cursor == null) {
      throw new error_1$m.MongoUnexpectedServerResponseError(
        "Expected server to respond with cursor",
      );
    }
    return {
      server: operation.server,
      session,
      response,
    };
  }
  /** @internal */
  async getMore(_batchSize) {
    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
    const getMoreOperation = new get_more_1.GetMoreOperation(
      this.namespace,
      this.id,
      this.server,
      {
        ...this.cursorOptions,
        session: this.session,
        ...this.getMoreOptions,
      },
    );
    return (0, execute_operation_1.executeOperation)(
      this.client,
      getMoreOperation,
    );
  }
}
run_command_cursor.RunCommandCursor = RunCommandCursor;

var collections = {};

var hasRequiredCollections;

function requireCollections() {
  if (hasRequiredCollections) return collections;
  hasRequiredCollections = 1;
  Object.defineProperty(collections, "__esModule", { value: true });
  collections.CollectionsOperation = void 0;
  const collection_1 = requireCollection();
  const operation_1 = operation;
  /** @internal */
  class CollectionsOperation extends operation_1.AbstractOperation {
    constructor(db, options) {
      super(options);
      this.options = options;
      this.db = db;
    }
    async execute(server, session) {
      // Let's get the collection names
      const documents = await this.db
        .listCollections(
          {},
          {
            ...this.options,
            nameOnly: true,
            readPreference: this.readPreference,
            session,
          },
        )
        .toArray();
      const collections = [];
      for (const { name } of documents) {
        if (!name.includes("$")) {
          // Filter collections removing any illegal ones
          collections.push(
            new collection_1.Collection(this.db, name, this.db.s.options),
          );
        }
      }
      // Return the collection objects
      return collections;
    }
  }
  collections.CollectionsOperation = CollectionsOperation;

  return collections;
}

var create_collection = {};

var hasRequiredCreate_collection;

function requireCreate_collection() {
  if (hasRequiredCreate_collection) return create_collection;
  hasRequiredCreate_collection = 1;
  Object.defineProperty(create_collection, "__esModule", { value: true });
  create_collection.CreateCollectionOperation = void 0;
  const constants_1 = constants$1;
  const collection_1 = requireCollection();
  const error_1 = error;
  const command_1 = command;
  const indexes_1 = indexes;
  const operation_1 = operation;
  const ILLEGAL_COMMAND_FIELDS = new Set([
    "w",
    "wtimeout",
    "j",
    "fsync",
    "autoIndexId",
    "pkFactory",
    "raw",
    "readPreference",
    "session",
    "readConcern",
    "writeConcern",
    "raw",
    "fieldsAsRaw",
    "useBigInt64",
    "promoteLongs",
    "promoteValues",
    "promoteBuffers",
    "bsonRegExp",
    "serializeFunctions",
    "ignoreUndefined",
    "enableUtf8Validation",
  ]);
  /* @internal */
  const INVALID_QE_VERSION =
    "Driver support of Queryable Encryption is incompatible with server. Upgrade server to use Queryable Encryption.";
  /** @internal */
  class CreateCollectionOperation extends command_1.CommandOperation {
    constructor(db, name, options = {}) {
      super(db, options);
      this.options = options;
      this.db = db;
      this.name = name;
    }
    async execute(server, session) {
      const db = this.db;
      const name = this.name;
      const options = this.options;
      const encryptedFields =
        options.encryptedFields ??
        db.client.options.autoEncryption?.encryptedFieldsMap?.[
          `${db.databaseName}.${name}`
        ];
      if (encryptedFields) {
        // Creating a QE collection required min server of 7.0.0
        // TODO(NODE-5353): Get wire version information from connection.
        if (
          !server.loadBalanced &&
          server.description.maxWireVersion <
            constants_1.MIN_SUPPORTED_QE_WIRE_VERSION
        ) {
          throw new error_1.MongoCompatibilityError(
            `${INVALID_QE_VERSION} The minimum server version required is ${constants_1.MIN_SUPPORTED_QE_SERVER_VERSION}`,
          );
        }
        // Create auxilliary collections for queryable encryption support.
        const escCollection =
          encryptedFields.escCollection ?? `enxcol_.${name}.esc`;
        const ecocCollection =
          encryptedFields.ecocCollection ?? `enxcol_.${name}.ecoc`;
        for (const collectionName of [escCollection, ecocCollection]) {
          const createOp = new CreateCollectionOperation(db, collectionName, {
            clusteredIndex: {
              key: { _id: 1 },
              unique: true,
            },
          });
          await createOp.executeWithoutEncryptedFieldsCheck(server, session);
        }
        if (!options.encryptedFields) {
          this.options = { ...this.options, encryptedFields };
        }
      }
      const coll = await this.executeWithoutEncryptedFieldsCheck(
        server,
        session,
      );
      if (encryptedFields) {
        // Create the required index for queryable encryption support.
        const createIndexOp = new indexes_1.CreateIndexOperation(
          db,
          name,
          { __safeContent__: 1 },
          {},
        );
        await createIndexOp.execute(server, session);
      }
      return coll;
    }
    async executeWithoutEncryptedFieldsCheck(server, session) {
      const db = this.db;
      const name = this.name;
      const options = this.options;
      const cmd = { create: name };
      for (const n in options) {
        if (
          options[n] != null &&
          typeof options[n] !== "function" &&
          !ILLEGAL_COMMAND_FIELDS.has(n)
        ) {
          cmd[n] = options[n];
        }
      }
      // otherwise just execute the command
      await super.executeCommand(server, session, cmd);
      return new collection_1.Collection(db, name, options);
    }
  }
  create_collection.CreateCollectionOperation = CreateCollectionOperation;
  (0, operation_1.defineAspects)(CreateCollectionOperation, [
    operation_1.Aspect.WRITE_OPERATION,
  ]);

  return create_collection;
}

var profiling_level = {};

Object.defineProperty(profiling_level, "__esModule", { value: true });
profiling_level.ProfilingLevelOperation = void 0;
const error_1$l = error;
const command_1$1 = command;
/** @internal */
class ProfilingLevelOperation extends command_1$1.CommandOperation {
  constructor(db, options) {
    super(db, options);
    this.options = options;
  }
  async execute(server, session) {
    const doc = await super.executeCommand(server, session, { profile: -1 });
    if (doc.ok === 1) {
      const was = doc.was;
      if (was === 0) return "off";
      if (was === 1) return "slow_only";
      if (was === 2) return "all";
      throw new error_1$l.MongoUnexpectedServerResponseError(
        `Illegal profiling level value ${was}`,
      );
    } else {
      throw new error_1$l.MongoUnexpectedServerResponseError(
        "Error with profile command",
      );
    }
  }
}
profiling_level.ProfilingLevelOperation = ProfilingLevelOperation;

var set_profiling_level = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.SetProfilingLevelOperation = exports.ProfilingLevel = void 0;
  const error_1 = error;
  const utils_1 = utils$2;
  const command_1 = command;
  const levelValues = new Set(["off", "slow_only", "all"]);
  /** @public */
  exports.ProfilingLevel = Object.freeze({
    off: "off",
    slowOnly: "slow_only",
    all: "all",
  });
  /** @internal */
  class SetProfilingLevelOperation extends command_1.CommandOperation {
    constructor(db, level, options) {
      super(db, options);
      this.options = options;
      switch (level) {
        case exports.ProfilingLevel.off:
          this.profile = 0;
          break;
        case exports.ProfilingLevel.slowOnly:
          this.profile = 1;
          break;
        case exports.ProfilingLevel.all:
          this.profile = 2;
          break;
        default:
          this.profile = 0;
          break;
      }
      this.level = level;
    }
    async execute(server, session) {
      const level = this.level;
      if (!levelValues.has(level)) {
        throw new error_1.MongoInvalidArgumentError(
          `Profiling level must be one of "${(0, utils_1.enumToString)(
            exports.ProfilingLevel,
          )}"`,
        );
      }
      // TODO(NODE-3483): Determine error to put here
      await super.executeCommand(server, session, { profile: this.profile });
      return level;
    }
  }
  exports.SetProfilingLevelOperation = SetProfilingLevelOperation;
})(set_profiling_level);

var stats = {};

Object.defineProperty(stats, "__esModule", { value: true });
stats.DbStatsOperation = void 0;
const command_1 = command;
const operation_1 = operation;
/** @internal */
class DbStatsOperation extends command_1.CommandOperation {
  constructor(db, options) {
    super(db, options);
    this.options = options;
  }
  async execute(server, session) {
    const command = { dbStats: true };
    if (this.options.scale != null) {
      command.scale = this.options.scale;
    }
    return super.executeCommand(server, session, command);
  }
}
stats.DbStatsOperation = DbStatsOperation;
(0, operation_1.defineAspects)(DbStatsOperation, [
  operation_1.Aspect.READ_OPERATION,
]);

var hasRequiredDb;

function requireDb() {
  if (hasRequiredDb) return db;
  hasRequiredDb = 1;
  Object.defineProperty(db, "__esModule", { value: true });
  db.Db = void 0;
  const admin_1 = admin;
  const bson_1 = bson$2;
  const change_stream_1 = requireChange_stream();
  const collection_1 = requireCollection();
  const CONSTANTS = constants;
  const aggregation_cursor_1 = aggregation_cursor;
  const list_collections_cursor_1 = list_collections_cursor;
  const run_command_cursor_1 = run_command_cursor;
  const error_1 = error;
  const collections_1 = requireCollections();
  const create_collection_1 = requireCreate_collection();
  const drop_1 = drop$1;
  const execute_operation_1 = execute_operation;
  const indexes_1 = indexes;
  const profiling_level_1 = profiling_level;
  const remove_user_1 = remove_user;
  const rename_1 = requireRename();
  const run_command_1 = run_command;
  const set_profiling_level_1 = set_profiling_level;
  const stats_1 = stats;
  const read_concern_1 = read_concern;
  const read_preference_1 = read_preference;
  const utils_1 = utils$2;
  const write_concern_1 = write_concern;
  // Allowed parameters
  const DB_OPTIONS_ALLOW_LIST = [
    "writeConcern",
    "readPreference",
    "readPreferenceTags",
    "native_parser",
    "forceServerObjectId",
    "pkFactory",
    "serializeFunctions",
    "raw",
    "authSource",
    "ignoreUndefined",
    "readConcern",
    "retryMiliSeconds",
    "numberOfRetries",
    "useBigInt64",
    "promoteBuffers",
    "promoteLongs",
    "bsonRegExp",
    "enableUtf8Validation",
    "promoteValues",
    "compression",
    "retryWrites",
  ];
  /**
   * The **Db** class is a class that represents a MongoDB Database.
   * @public
   *
   * @example
   * ```ts
   * import { MongoClient } from 'mongodb';
   *
   * interface Pet {
   *   name: string;
   *   kind: 'dog' | 'cat' | 'fish';
   * }
   *
   * const client = new MongoClient('mongodb://localhost:27017');
   * const db = client.db();
   *
   * // Create a collection that validates our union
   * await db.createCollection<Pet>('pets', {
   *   validator: { $expr: { $in: ['$kind', ['dog', 'cat', 'fish']] } }
   * })
   * ```
   */
  class Db {
    /**
     * Creates a new Db instance.
     *
     * Db name cannot contain a dot, the server may apply more restrictions when an operation is run.
     *
     * @param client - The MongoClient for the database.
     * @param databaseName - The name of the database this instance represents.
     * @param options - Optional settings for Db construction.
     */
    constructor(client, databaseName, options) {
      options = options ?? {};
      // Filter the options
      options = (0, utils_1.filterOptions)(options, DB_OPTIONS_ALLOW_LIST);
      // Ensure there are no dots in database name
      if (typeof databaseName === "string" && databaseName.includes(".")) {
        throw new error_1.MongoInvalidArgumentError(
          `Database names cannot contain the character '.'`,
        );
      }
      // Internal state of the db object
      this.s = {
        // Options
        options,
        // Unpack read preference
        readPreference: read_preference_1.ReadPreference.fromOptions(options),
        // Merge bson options
        bsonOptions: (0, bson_1.resolveBSONOptions)(options, client),
        // Set up the primary key factory or fallback to ObjectId
        pkFactory: options?.pkFactory ?? utils_1.DEFAULT_PK_FACTORY,
        // ReadConcern
        readConcern: read_concern_1.ReadConcern.fromOptions(options),
        writeConcern: write_concern_1.WriteConcern.fromOptions(options),
        // Namespace
        namespace: new utils_1.MongoDBNamespace(databaseName),
      };
      this.client = client;
    }
    get databaseName() {
      return this.s.namespace.db;
    }
    // Options
    get options() {
      return this.s.options;
    }
    /**
     * Check if a secondary can be used (because the read preference is *not* set to primary)
     */
    get secondaryOk() {
      return this.s.readPreference?.preference !== "primary" || false;
    }
    get readConcern() {
      return this.s.readConcern;
    }
    /**
     * The current readPreference of the Db. If not explicitly defined for
     * this Db, will be inherited from the parent MongoClient
     */
    get readPreference() {
      if (this.s.readPreference == null) {
        return this.client.readPreference;
      }
      return this.s.readPreference;
    }
    get bsonOptions() {
      return this.s.bsonOptions;
    }
    // get the write Concern
    get writeConcern() {
      return this.s.writeConcern;
    }
    get namespace() {
      return this.s.namespace.toString();
    }
    /**
     * Create a new collection on a server with the specified options. Use this to create capped collections.
     * More information about command options available at https://www.mongodb.com/docs/manual/reference/command/create/
     *
     * Collection namespace validation is performed server-side.
     *
     * @param name - The name of the collection to create
     * @param options - Optional settings for the command
     */
    async createCollection(name, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new create_collection_1.CreateCollectionOperation(
          this,
          name,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Execute a command
     *
     * @remarks
     * This command does not inherit options from the MongoClient.
     *
     * The driver will ensure the following fields are attached to the command sent to the server:
     * - `lsid` - sourced from an implicit session or options.session
     * - `$readPreference` - defaults to primary or can be configured by options.readPreference
     * - `$db` - sourced from the name of this database
     *
     * If the client has a serverApi setting:
     * - `apiVersion`
     * - `apiStrict`
     * - `apiDeprecationErrors`
     *
     * When in a transaction:
     * - `readConcern` - sourced from readConcern set on the TransactionOptions
     * - `writeConcern` - sourced from writeConcern set on the TransactionOptions
     *
     * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.
     *
     * @param command - The command to run
     * @param options - Optional settings for the command
     */
    async command(command, options) {
      // Intentionally, we do not inherit options from parent for this operation.
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new run_command_1.RunCommandOperation(this, command, {
          ...(0, bson_1.resolveBSONOptions)(options),
          session: options?.session,
          readPreference: options?.readPreference,
        }),
      );
    }
    /**
     * Execute an aggregation framework pipeline against the database, needs MongoDB \>= 3.6
     *
     * @param pipeline - An array of aggregation stages to be executed
     * @param options - Optional settings for the command
     */
    aggregate(pipeline = [], options) {
      return new aggregation_cursor_1.AggregationCursor(
        this.client,
        this.s.namespace,
        pipeline,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /** Return the Admin db instance */
    admin() {
      return new admin_1.Admin(this);
    }
    /**
     * Returns a reference to a MongoDB Collection. If it does not exist it will be created implicitly.
     *
     * Collection namespace validation is performed server-side.
     *
     * @param name - the collection name we wish to access.
     * @returns return the new Collection instance
     */
    collection(name, options = {}) {
      if (typeof options === "function") {
        throw new error_1.MongoInvalidArgumentError(
          "The callback form of this helper has been removed.",
        );
      }
      return new collection_1.Collection(
        this,
        name,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /**
     * Get all the db statistics.
     *
     * @param options - Optional settings for the command
     */
    async stats(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new stats_1.DbStatsOperation(
          this,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    listCollections(filter = {}, options = {}) {
      return new list_collections_cursor_1.ListCollectionsCursor(
        this,
        filter,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /**
     * Rename a collection.
     *
     * @remarks
     * This operation does not inherit options from the MongoClient.
     *
     * @param fromCollection - Name of current collection to rename
     * @param toCollection - New name of of the collection
     * @param options - Optional settings for the command
     */
    async renameCollection(fromCollection, toCollection, options) {
      // Intentionally, we do not inherit options from parent for this operation.
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new rename_1.RenameOperation(
          this.collection(fromCollection),
          toCollection,
          {
            ...options,
            new_collection: true,
            readPreference: read_preference_1.ReadPreference.primary,
          },
        ),
      );
    }
    /**
     * Drop a collection from the database, removing it permanently. New accesses will create a new collection.
     *
     * @param name - Name of collection to drop
     * @param options - Optional settings for the command
     */
    async dropCollection(name, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new drop_1.DropCollectionOperation(
          this,
          name,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Drop a database, removing it permanently from the server.
     *
     * @param options - Optional settings for the command
     */
    async dropDatabase(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new drop_1.DropDatabaseOperation(
          this,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Fetch all collections for the current db.
     *
     * @param options - Optional settings for the command
     */
    async collections(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new collections_1.CollectionsOperation(
          this,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Creates an index on the db and collection.
     *
     * @param name - Name of the collection to create the index on.
     * @param indexSpec - Specify the field to index, or an index specification
     * @param options - Optional settings for the command
     */
    async createIndex(name, indexSpec, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new indexes_1.CreateIndexOperation(
          this,
          name,
          indexSpec,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Remove a user from a database
     *
     * @param username - The username to remove
     * @param options - Optional settings for the command
     */
    async removeUser(username, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new remove_user_1.RemoveUserOperation(
          this,
          username,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Set the current profiling level of MongoDB
     *
     * @param level - The new profiling level (off, slow_only, all).
     * @param options - Optional settings for the command
     */
    async setProfilingLevel(level, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new set_profiling_level_1.SetProfilingLevelOperation(
          this,
          level,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Retrieve the current profiling Level for MongoDB
     *
     * @param options - Optional settings for the command
     */
    async profilingLevel(options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new profiling_level_1.ProfilingLevelOperation(
          this,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Retrieves this collections index info.
     *
     * @param name - The name of the collection.
     * @param options - Optional settings for the command
     */
    async indexInformation(name, options) {
      return (0, execute_operation_1.executeOperation)(
        this.client,
        new indexes_1.IndexInformationOperation(
          this,
          name,
          (0, utils_1.resolveOptions)(this, options),
        ),
      );
    }
    /**
     * Create a new Change Stream, watching for new changes (insertions, updates,
     * replacements, deletions, and invalidations) in this database. Will ignore all
     * changes to system collections.
     *
     * @remarks
     * watch() accepts two generic arguments for distinct use cases:
     * - The first is to provide the schema that may be defined for all the collections within this database
     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument
     *
     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.
     * @param options - Optional settings for the command
     * @typeParam TSchema - Type of the data being detected by the change stream
     * @typeParam TChange - Type of the whole change stream document emitted
     */
    watch(pipeline = [], options = {}) {
      // Allow optionally not specifying a pipeline
      if (!Array.isArray(pipeline)) {
        options = pipeline;
        pipeline = [];
      }
      return new change_stream_1.ChangeStream(
        this,
        pipeline,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
    /**
     * A low level cursor API providing basic driver functionality:
     * - ClientSession management
     * - ReadPreference for server selection
     * - Running getMores automatically when a local batch is exhausted
     *
     * @param command - The command that will start a cursor on the server.
     * @param options - Configurations for running the command, bson options will apply to getMores
     */
    runCursorCommand(command, options) {
      return new run_command_cursor_1.RunCommandCursor(this, command, options);
    }
  }
  Db.SYSTEM_NAMESPACE_COLLECTION = CONSTANTS.SYSTEM_NAMESPACE_COLLECTION;
  Db.SYSTEM_INDEX_COLLECTION = CONSTANTS.SYSTEM_INDEX_COLLECTION;
  Db.SYSTEM_PROFILE_COLLECTION = CONSTANTS.SYSTEM_PROFILE_COLLECTION;
  Db.SYSTEM_USER_COLLECTION = CONSTANTS.SYSTEM_USER_COLLECTION;
  Db.SYSTEM_COMMAND_COLLECTION = CONSTANTS.SYSTEM_COMMAND_COLLECTION;
  Db.SYSTEM_JS_COLLECTION = CONSTANTS.SYSTEM_JS_COLLECTION;
  db.Db = Db;

  return db;
}

var mongo_client = {};

var mongo_credentials = {};

var gssapi = {};

var deps = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.getMongoDBClientEncryption =
    exports.aws4 =
    exports.getSocks =
    exports.getSnappy =
    exports.getGcpMetadata =
    exports.getAwsCredentialProvider =
    exports.getZstdLibrary =
    exports.ZStandard =
    exports.getKerberos =
    exports.Kerberos =
      void 0;
  const error_1 = error;
  function makeErrorModule(error) {
    const props = error ? { kModuleError: error } : {};
    return new Proxy(props, {
      get: (_, key) => {
        if (key === "kModuleError") {
          return error;
        }
        throw error;
      },
      set: () => {
        throw error;
      },
    });
  }
  exports.Kerberos = makeErrorModule(
    new error_1.MongoMissingDependencyError(
      "Optional module `kerberos` not found. Please install it to enable kerberos authentication",
    ),
  );
  function getKerberos() {
    try {
      // Ensure you always wrap an optional require in the try block NODE-3199
      exports.Kerberos = require("kerberos");
      return exports.Kerberos;
    } catch {
      return exports.Kerberos;
    }
  }
  exports.getKerberos = getKerberos;
  exports.ZStandard = makeErrorModule(
    new error_1.MongoMissingDependencyError(
      "Optional module `@mongodb-js/zstd` not found. Please install it to enable zstd compression",
    ),
  );
  function getZstdLibrary() {
    try {
      exports.ZStandard = require("@mongodb-js/zstd");
      return exports.ZStandard;
    } catch {
      return exports.ZStandard;
    }
  }
  exports.getZstdLibrary = getZstdLibrary;
  function getAwsCredentialProvider() {
    try {
      // Ensure you always wrap an optional require in the try block NODE-3199
      const credentialProvider = require("@aws-sdk/credential-providers");
      return credentialProvider;
    } catch {
      return makeErrorModule(
        new error_1.MongoMissingDependencyError(
          "Optional module `@aws-sdk/credential-providers` not found." +
            " Please install it to enable getting aws credentials via the official sdk.",
        ),
      );
    }
  }
  exports.getAwsCredentialProvider = getAwsCredentialProvider;
  function getGcpMetadata() {
    try {
      // Ensure you always wrap an optional require in the try block NODE-3199
      const credentialProvider = require("gcp-metadata");
      return credentialProvider;
    } catch {
      return makeErrorModule(
        new error_1.MongoMissingDependencyError(
          "Optional module `gcp-metadata` not found." +
            " Please install it to enable getting gcp credentials via the official sdk.",
        ),
      );
    }
  }
  exports.getGcpMetadata = getGcpMetadata;
  function getSnappy() {
    try {
      // Ensure you always wrap an optional require in the try block NODE-3199
      const value = require("snappy");
      return value;
    } catch (cause) {
      const kModuleError = new error_1.MongoMissingDependencyError(
        "Optional module `snappy` not found. Please install it to enable snappy compression",
        { cause },
      );
      return { kModuleError };
    }
  }
  exports.getSnappy = getSnappy;
  function getSocks() {
    try {
      // Ensure you always wrap an optional require in the try block NODE-3199
      const value = require("socks");
      return value;
    } catch (cause) {
      const kModuleError = new error_1.MongoMissingDependencyError(
        "Optional module `socks` not found. Please install it to connections over a SOCKS5 proxy",
        { cause },
      );
      return { kModuleError };
    }
  }
  exports.getSocks = getSocks;
  exports.aws4 = makeErrorModule(
    new error_1.MongoMissingDependencyError(
      "Optional module `aws4` not found. Please install it to enable AWS authentication",
    ),
  );
  try {
    // Ensure you always wrap an optional require in the try block NODE-3199
    exports.aws4 = require("aws4");
  } catch {} // eslint-disable-line
  /** A utility function to get the instance of mongodb-client-encryption, if it exists. */
  function getMongoDBClientEncryption() {
    let mongodbClientEncryption = null;
    try {
      // NOTE(NODE-3199): Ensure you always wrap an optional require literally in the try block
      // Cannot be moved to helper utility function, bundlers search and replace the actual require call
      // in a way that makes this line throw at bundle time, not runtime, catching here will make bundling succeed
      mongodbClientEncryption = require("mongodb-client-encryption");
    } catch (cause) {
      const kModuleError = new error_1.MongoMissingDependencyError(
        "Optional module `mongodb-client-encryption` not found. Please install it to use auto encryption or ClientEncryption.",
        { cause },
      );
      return { kModuleError };
    }
    return mongodbClientEncryption;
  }
  exports.getMongoDBClientEncryption = getMongoDBClientEncryption;
})(deps);

var auth_provider = {};

Object.defineProperty(auth_provider, "__esModule", { value: true });
auth_provider.AuthProvider = auth_provider.AuthContext = void 0;
const error_1$k = error;
/**
 * Context used during authentication
 * @internal
 */
class AuthContext {
  constructor(connection, credentials, options) {
    /** If the context is for reauthentication. */
    this.reauthenticating = false;
    this.connection = connection;
    this.credentials = credentials;
    this.options = options;
  }
}
auth_provider.AuthContext = AuthContext;
class AuthProvider {
  /**
   * Prepare the handshake document before the initial handshake.
   *
   * @param handshakeDoc - The document used for the initial handshake on a connection
   * @param authContext - Context for authentication flow
   */
  async prepare(handshakeDoc, _authContext) {
    return handshakeDoc;
  }
  /**
   * Reauthenticate.
   * @param context - The shared auth context.
   */
  async reauth(context) {
    if (context.reauthenticating) {
      throw new error_1$k.MongoRuntimeError(
        "Reauthentication already in progress.",
      );
    }
    try {
      context.reauthenticating = true;
      await this.auth(context);
    } finally {
      context.reauthenticating = false;
    }
  }
}
auth_provider.AuthProvider = AuthProvider;

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.resolveCname =
    exports.performGSSAPICanonicalizeHostName =
    exports.GSSAPI =
    exports.GSSAPICanonicalizationValue =
      void 0;
  const dns = $nodeDns;
  const deps_1 = deps;
  const error_1 = error;
  const utils_1 = utils$2;
  const auth_provider_1 = auth_provider;
  /** @public */
  exports.GSSAPICanonicalizationValue = Object.freeze({
    on: true,
    off: false,
    none: "none",
    forward: "forward",
    forwardAndReverse: "forwardAndReverse",
  });
  async function externalCommand(connection, command) {
    return connection.commandAsync(
      (0, utils_1.ns)("$external.$cmd"),
      command,
      undefined,
    );
  }
  let krb;
  class GSSAPI extends auth_provider_1.AuthProvider {
    async auth(authContext) {
      const { connection, credentials } = authContext;
      if (credentials == null) {
        throw new error_1.MongoMissingCredentialsError(
          "Credentials required for GSSAPI authentication",
        );
      }
      const { username } = credentials;
      const client = await makeKerberosClient(authContext);
      const payload = await client.step("");
      const saslStartResponse = await externalCommand(
        connection,
        saslStart(payload),
      );
      const negotiatedPayload = await negotiate(
        client,
        10,
        saslStartResponse.payload,
      );
      const saslContinueResponse = await externalCommand(
        connection,
        saslContinue(negotiatedPayload, saslStartResponse.conversationId),
      );
      const finalizePayload = await finalize(
        client,
        username,
        saslContinueResponse.payload,
      );
      await externalCommand(connection, {
        saslContinue: 1,
        conversationId: saslContinueResponse.conversationId,
        payload: finalizePayload,
      });
    }
  }
  exports.GSSAPI = GSSAPI;
  async function makeKerberosClient(authContext) {
    const { hostAddress } = authContext.options;
    const { credentials } = authContext;
    if (!hostAddress || typeof hostAddress.host !== "string" || !credentials) {
      throw new error_1.MongoInvalidArgumentError(
        "Connection must have host and port and credentials defined.",
      );
    }
    loadKrb();
    if ("kModuleError" in krb) {
      throw krb["kModuleError"];
    }
    const { initializeClient } = krb;
    const { username, password } = credentials;
    const mechanismProperties = credentials.mechanismProperties;
    const serviceName = mechanismProperties.SERVICE_NAME ?? "mongodb";
    const host = await performGSSAPICanonicalizeHostName(
      hostAddress.host,
      mechanismProperties,
    );
    const initOptions = {};
    if (password != null) {
      // TODO(NODE-5139): These do not match the typescript options in initializeClient
      Object.assign(initOptions, { user: username, password: password });
    }
    const spnHost = mechanismProperties.SERVICE_HOST ?? host;
    let spn = `${serviceName}${
      process.platform === "win32" ? "/" : "@"
    }${spnHost}`;
    if ("SERVICE_REALM" in mechanismProperties) {
      spn = `${spn}@${mechanismProperties.SERVICE_REALM}`;
    }
    return initializeClient(spn, initOptions);
  }
  function saslStart(payload) {
    return {
      saslStart: 1,
      mechanism: "GSSAPI",
      payload,
      autoAuthorize: 1,
    };
  }
  function saslContinue(payload, conversationId) {
    return {
      saslContinue: 1,
      conversationId,
      payload,
    };
  }
  async function negotiate(client, retries, payload) {
    try {
      const response = await client.step(payload);
      return response || "";
    } catch (error) {
      if (retries === 0) {
        // Retries exhausted, raise error
        throw error;
      }
      // Adjust number of retries and call step again
      return negotiate(client, retries - 1, payload);
    }
  }
  async function finalize(client, user, payload) {
    // GSS Client Unwrap
    const response = await client.unwrap(payload);
    return client.wrap(response || "", { user });
  }
  async function performGSSAPICanonicalizeHostName(host, mechanismProperties) {
    const mode = mechanismProperties.CANONICALIZE_HOST_NAME;
    if (!mode || mode === exports.GSSAPICanonicalizationValue.none) {
      return host;
    }
    // If forward and reverse or true
    if (
      mode === exports.GSSAPICanonicalizationValue.on ||
      mode === exports.GSSAPICanonicalizationValue.forwardAndReverse
    ) {
      // Perform the lookup of the ip address.
      const { address } = await dns.promises.lookup(host);
      try {
        // Perform a reverse ptr lookup on the ip address.
        const results = await dns.promises.resolvePtr(address);
        // If the ptr did not error but had no results, return the host.
        return results.length > 0 ? results[0] : host;
      } catch (error) {
        // This can error as ptr records may not exist for all ips. In this case
        // fallback to a cname lookup as dns.lookup() does not return the
        // cname.
        return resolveCname(host);
      }
    } else {
      // The case for forward is just to resolve the cname as dns.lookup()
      // will not return it.
      return resolveCname(host);
    }
  }
  exports.performGSSAPICanonicalizeHostName = performGSSAPICanonicalizeHostName;
  async function resolveCname(host) {
    // Attempt to resolve the host name
    try {
      const results = await dns.promises.resolveCname(host);
      // Get the first resolved host id
      return results.length > 0 ? results[0] : host;
    } catch {
      return host;
    }
  }
  exports.resolveCname = resolveCname;
  /**
   * Load the Kerberos library.
   */
  function loadKrb() {
    if (!krb) {
      krb = (0, deps_1.getKerberos)();
    }
  }
})(gssapi);

var providers$1 = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.AUTH_MECHS_AUTH_SRC_EXTERNAL = exports.AuthMechanism = void 0;
  /** @public */
  exports.AuthMechanism = Object.freeze({
    MONGODB_AWS: "MONGODB-AWS",
    MONGODB_CR: "MONGODB-CR",
    MONGODB_DEFAULT: "DEFAULT",
    MONGODB_GSSAPI: "GSSAPI",
    MONGODB_PLAIN: "PLAIN",
    MONGODB_SCRAM_SHA1: "SCRAM-SHA-1",
    MONGODB_SCRAM_SHA256: "SCRAM-SHA-256",
    MONGODB_X509: "MONGODB-X509",
    /** @experimental */
    MONGODB_OIDC: "MONGODB-OIDC",
  });
  /** @internal */
  exports.AUTH_MECHS_AUTH_SRC_EXTERNAL = new Set([
    exports.AuthMechanism.MONGODB_GSSAPI,
    exports.AuthMechanism.MONGODB_AWS,
    exports.AuthMechanism.MONGODB_OIDC,
    exports.AuthMechanism.MONGODB_X509,
  ]);
})(providers$1);

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.MongoCredentials = exports.DEFAULT_ALLOWED_HOSTS = void 0;
  const error_1 = error;
  const gssapi_1 = gssapi;
  const providers_1 = providers$1;
  // https://github.com/mongodb/specifications/blob/master/source/auth/auth.rst
  function getDefaultAuthMechanism(hello) {
    if (hello) {
      // If hello contains saslSupportedMechs, use scram-sha-256
      // if it is available, else scram-sha-1
      if (Array.isArray(hello.saslSupportedMechs)) {
        return hello.saslSupportedMechs.includes(
          providers_1.AuthMechanism.MONGODB_SCRAM_SHA256,
        )
          ? providers_1.AuthMechanism.MONGODB_SCRAM_SHA256
          : providers_1.AuthMechanism.MONGODB_SCRAM_SHA1;
      }
      // Fallback to legacy selection method. If wire version >= 3, use scram-sha-1
      if (hello.maxWireVersion >= 3) {
        return providers_1.AuthMechanism.MONGODB_SCRAM_SHA1;
      }
    }
    // Default for wireprotocol < 3
    return providers_1.AuthMechanism.MONGODB_CR;
  }
  const ALLOWED_PROVIDER_NAMES = ["aws", "azure"];
  const ALLOWED_HOSTS_ERROR =
    "Auth mechanism property ALLOWED_HOSTS must be an array of strings.";
  /** @internal */
  exports.DEFAULT_ALLOWED_HOSTS = [
    "*.mongodb.net",
    "*.mongodb-dev.net",
    "*.mongodbgov.net",
    "localhost",
    "127.0.0.1",
    "::1",
  ];
  /** Error for when the token audience is missing in the environment. */
  const TOKEN_AUDIENCE_MISSING_ERROR =
    "TOKEN_AUDIENCE must be set in the auth mechanism properties when PROVIDER_NAME is azure.";
  /**
   * A representation of the credentials used by MongoDB
   * @public
   */
  class MongoCredentials {
    constructor(options) {
      this.username = options.username ?? "";
      this.password = options.password;
      this.source = options.source;
      if (!this.source && options.db) {
        this.source = options.db;
      }
      this.mechanism =
        options.mechanism || providers_1.AuthMechanism.MONGODB_DEFAULT;
      this.mechanismProperties = options.mechanismProperties || {};
      if (this.mechanism.match(/MONGODB-AWS/i)) {
        if (!this.username && process.env.AWS_ACCESS_KEY_ID) {
          this.username = process.env.AWS_ACCESS_KEY_ID;
        }
        if (!this.password && process.env.AWS_SECRET_ACCESS_KEY) {
          this.password = process.env.AWS_SECRET_ACCESS_KEY;
        }
        if (
          this.mechanismProperties.AWS_SESSION_TOKEN == null &&
          process.env.AWS_SESSION_TOKEN != null
        ) {
          this.mechanismProperties = {
            ...this.mechanismProperties,
            AWS_SESSION_TOKEN: process.env.AWS_SESSION_TOKEN,
          };
        }
      }
      if (
        this.mechanism === providers_1.AuthMechanism.MONGODB_OIDC &&
        !this.mechanismProperties.ALLOWED_HOSTS
      ) {
        this.mechanismProperties = {
          ...this.mechanismProperties,
          ALLOWED_HOSTS: exports.DEFAULT_ALLOWED_HOSTS,
        };
      }
      Object.freeze(this.mechanismProperties);
      Object.freeze(this);
    }
    /** Determines if two MongoCredentials objects are equivalent */
    equals(other) {
      return (
        this.mechanism === other.mechanism &&
        this.username === other.username &&
        this.password === other.password &&
        this.source === other.source
      );
    }
    /**
     * If the authentication mechanism is set to "default", resolves the authMechanism
     * based on the server version and server supported sasl mechanisms.
     *
     * @param hello - A hello response from the server
     */
    resolveAuthMechanism(hello) {
      // If the mechanism is not "default", then it does not need to be resolved
      if (this.mechanism.match(/DEFAULT/i)) {
        return new MongoCredentials({
          username: this.username,
          password: this.password,
          source: this.source,
          mechanism: getDefaultAuthMechanism(hello),
          mechanismProperties: this.mechanismProperties,
        });
      }
      return this;
    }
    validate() {
      if (
        (this.mechanism === providers_1.AuthMechanism.MONGODB_GSSAPI ||
          this.mechanism === providers_1.AuthMechanism.MONGODB_CR ||
          this.mechanism === providers_1.AuthMechanism.MONGODB_PLAIN ||
          this.mechanism === providers_1.AuthMechanism.MONGODB_SCRAM_SHA1 ||
          this.mechanism === providers_1.AuthMechanism.MONGODB_SCRAM_SHA256) &&
        !this.username
      ) {
        throw new error_1.MongoMissingCredentialsError(
          `Username required for mechanism '${this.mechanism}'`,
        );
      }
      if (this.mechanism === providers_1.AuthMechanism.MONGODB_OIDC) {
        if (this.username && this.mechanismProperties.PROVIDER_NAME) {
          throw new error_1.MongoInvalidArgumentError(
            `username and PROVIDER_NAME may not be used together for mechanism '${this.mechanism}'.`,
          );
        }
        if (
          this.mechanismProperties.PROVIDER_NAME === "azure" &&
          !this.mechanismProperties.TOKEN_AUDIENCE
        ) {
          throw new error_1.MongoAzureError(TOKEN_AUDIENCE_MISSING_ERROR);
        }
        if (
          this.mechanismProperties.PROVIDER_NAME &&
          !ALLOWED_PROVIDER_NAMES.includes(
            this.mechanismProperties.PROVIDER_NAME,
          )
        ) {
          throw new error_1.MongoInvalidArgumentError(
            `Currently only a PROVIDER_NAME in ${ALLOWED_PROVIDER_NAMES.join(
              ",",
            )} is supported for mechanism '${this.mechanism}'.`,
          );
        }
        if (
          this.mechanismProperties.REFRESH_TOKEN_CALLBACK &&
          !this.mechanismProperties.REQUEST_TOKEN_CALLBACK
        ) {
          throw new error_1.MongoInvalidArgumentError(
            `A REQUEST_TOKEN_CALLBACK must be provided when using a REFRESH_TOKEN_CALLBACK for mechanism '${this.mechanism}'`,
          );
        }
        if (
          !this.mechanismProperties.PROVIDER_NAME &&
          !this.mechanismProperties.REQUEST_TOKEN_CALLBACK
        ) {
          throw new error_1.MongoInvalidArgumentError(
            `Either a PROVIDER_NAME or a REQUEST_TOKEN_CALLBACK must be specified for mechanism '${this.mechanism}'.`,
          );
        }
        if (this.mechanismProperties.ALLOWED_HOSTS) {
          const hosts = this.mechanismProperties.ALLOWED_HOSTS;
          if (!Array.isArray(hosts)) {
            throw new error_1.MongoInvalidArgumentError(ALLOWED_HOSTS_ERROR);
          }
          for (const host of hosts) {
            if (typeof host !== "string") {
              throw new error_1.MongoInvalidArgumentError(ALLOWED_HOSTS_ERROR);
            }
          }
        }
      }
      if (providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(this.mechanism)) {
        if (this.source != null && this.source !== "$external") {
          // TODO(NODE-3485): Replace this with a MongoAuthValidationError
          throw new error_1.MongoAPIError(
            `Invalid source '${this.source}' for mechanism '${this.mechanism}' specified.`,
          );
        }
      }
      if (
        this.mechanism === providers_1.AuthMechanism.MONGODB_PLAIN &&
        this.source == null
      ) {
        // TODO(NODE-3485): Replace this with a MongoAuthValidationError
        throw new error_1.MongoAPIError(
          "PLAIN Authentication Mechanism needs an auth source",
        );
      }
      if (
        this.mechanism === providers_1.AuthMechanism.MONGODB_X509 &&
        this.password != null
      ) {
        if (this.password === "") {
          Reflect.set(this, "password", undefined);
          return;
        }
        // TODO(NODE-3485): Replace this with a MongoAuthValidationError
        throw new error_1.MongoAPIError(
          `Password not allowed for mechanism MONGODB-X509`,
        );
      }
      const canonicalization =
        this.mechanismProperties.CANONICALIZE_HOST_NAME ?? false;
      if (
        !Object.values(gssapi_1.GSSAPICanonicalizationValue).includes(
          canonicalization,
        )
      ) {
        throw new error_1.MongoAPIError(
          `Invalid CANONICALIZE_HOST_NAME value: ${canonicalization}`,
        );
      }
    }
    static merge(creds, options) {
      return new MongoCredentials({
        username: options.username ?? creds?.username ?? "",
        password: options.password ?? creds?.password ?? "",
        mechanism:
          options.mechanism ??
          creds?.mechanism ??
          providers_1.AuthMechanism.MONGODB_DEFAULT,
        mechanismProperties:
          options.mechanismProperties ?? creds?.mechanismProperties ?? {},
        source: options.source ?? options.db ?? creds?.source ?? "admin",
      });
    }
  }
  exports.MongoCredentials = MongoCredentials;
})(mongo_credentials);

var connection_string = {};

var lib$1 = {};

var whatwgUrl = {};

var webidl2jsWrapper = {};

var URL$1 = {};

var lib = {};

var hasRequiredLib$1;

function requireLib$1() {
  if (hasRequiredLib$1) return lib;
  hasRequiredLib$1 = 1;
  (function (exports) {
    function makeException(ErrorType, message, options) {
      if (options.globals) {
        ErrorType = options.globals[ErrorType.name];
      }
      return new ErrorType(
        `${options.context ? options.context : "Value"} ${message}.`,
      );
    }

    function toNumber(value, options) {
      if (typeof value === "bigint") {
        throw makeException(
          TypeError,
          "is a BigInt which cannot be converted to a number",
          options,
        );
      }
      if (!options.globals) {
        return Number(value);
      }
      return options.globals.Number(value);
    }

    // Round x to the nearest integer, choosing the even integer if it lies halfway between two.
    function evenRound(x) {
      // There are four cases for numbers with fractional part being .5:
      //
      // case |     x     | floor(x) | round(x) | expected | x <> 0 | x % 1 | x & 1 |   example
      //   1  |  2n + 0.5 |  2n      |  2n + 1  |  2n      |   >    |  0.5  |   0   |  0.5 ->  0
      //   2  |  2n + 1.5 |  2n + 1  |  2n + 2  |  2n + 2  |   >    |  0.5  |   1   |  1.5 ->  2
      //   3  | -2n - 0.5 | -2n - 1  | -2n      | -2n      |   <    | -0.5  |   0   | -0.5 ->  0
      //   4  | -2n - 1.5 | -2n - 2  | -2n - 1  | -2n - 2  |   <    | -0.5  |   1   | -1.5 -> -2
      // (where n is a non-negative integer)
      //
      // Branch here for cases 1 and 4
      if (
        (x > 0 && x % 1 === +0.5 && (x & 1) === 0) ||
        (x < 0 && x % 1 === -0.5 && (x & 1) === 1)
      ) {
        return censorNegativeZero(Math.floor(x));
      }

      return censorNegativeZero(Math.round(x));
    }

    function integerPart(n) {
      return censorNegativeZero(Math.trunc(n));
    }

    function sign(x) {
      return x < 0 ? -1 : 1;
    }

    function modulo(x, y) {
      // https://tc39.github.io/ecma262/#eqn-modulo
      // Note that http://stackoverflow.com/a/4467559/3191 does NOT work for large modulos
      const signMightNotMatch = x % y;
      if (sign(y) !== sign(signMightNotMatch)) {
        return signMightNotMatch + y;
      }
      return signMightNotMatch;
    }

    function censorNegativeZero(x) {
      return x === 0 ? 0 : x;
    }

    function createIntegerConversion(bitLength, { unsigned }) {
      let lowerBound, upperBound;
      if (unsigned) {
        lowerBound = 0;
        upperBound = 2 ** bitLength - 1;
      } else {
        lowerBound = -(2 ** (bitLength - 1));
        upperBound = 2 ** (bitLength - 1) - 1;
      }

      const twoToTheBitLength = 2 ** bitLength;
      const twoToOneLessThanTheBitLength = 2 ** (bitLength - 1);

      return (value, options = {}) => {
        let x = toNumber(value, options);
        x = censorNegativeZero(x);

        if (options.enforceRange) {
          if (!Number.isFinite(x)) {
            throw makeException(TypeError, "is not a finite number", options);
          }

          x = integerPart(x);

          if (x < lowerBound || x > upperBound) {
            throw makeException(
              TypeError,
              `is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`,
              options,
            );
          }

          return x;
        }

        if (!Number.isNaN(x) && options.clamp) {
          x = Math.min(Math.max(x, lowerBound), upperBound);
          x = evenRound(x);
          return x;
        }

        if (!Number.isFinite(x) || x === 0) {
          return 0;
        }
        x = integerPart(x);

        // Math.pow(2, 64) is not accurately representable in JavaScript, so try to avoid these per-spec operations if
        // possible. Hopefully it's an optimization for the non-64-bitLength cases too.
        if (x >= lowerBound && x <= upperBound) {
          return x;
        }

        // These will not work great for bitLength of 64, but oh well. See the README for more details.
        x = modulo(x, twoToTheBitLength);
        if (!unsigned && x >= twoToOneLessThanTheBitLength) {
          return x - twoToTheBitLength;
        }
        return x;
      };
    }

    function createLongLongConversion(bitLength, { unsigned }) {
      const upperBound = Number.MAX_SAFE_INTEGER;
      const lowerBound = unsigned ? 0 : Number.MIN_SAFE_INTEGER;
      const asBigIntN = unsigned ? BigInt.asUintN : BigInt.asIntN;

      return (value, options = {}) => {
        let x = toNumber(value, options);
        x = censorNegativeZero(x);

        if (options.enforceRange) {
          if (!Number.isFinite(x)) {
            throw makeException(TypeError, "is not a finite number", options);
          }

          x = integerPart(x);

          if (x < lowerBound || x > upperBound) {
            throw makeException(
              TypeError,
              `is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`,
              options,
            );
          }

          return x;
        }

        if (!Number.isNaN(x) && options.clamp) {
          x = Math.min(Math.max(x, lowerBound), upperBound);
          x = evenRound(x);
          return x;
        }

        if (!Number.isFinite(x) || x === 0) {
          return 0;
        }

        let xBigInt = BigInt(integerPart(x));
        xBigInt = asBigIntN(bitLength, xBigInt);
        return Number(xBigInt);
      };
    }

    exports.any = (value) => {
      return value;
    };

    exports.undefined = () => {
      return undefined;
    };

    exports.boolean = (value) => {
      return Boolean(value);
    };

    exports.byte = createIntegerConversion(8, { unsigned: false });
    exports.octet = createIntegerConversion(8, { unsigned: true });

    exports.short = createIntegerConversion(16, { unsigned: false });
    exports["unsigned short"] = createIntegerConversion(16, { unsigned: true });

    exports.long = createIntegerConversion(32, { unsigned: false });
    exports["unsigned long"] = createIntegerConversion(32, { unsigned: true });

    exports["long long"] = createLongLongConversion(64, { unsigned: false });
    exports["unsigned long long"] = createLongLongConversion(64, {
      unsigned: true,
    });

    exports.double = (value, options = {}) => {
      const x = toNumber(value, options);

      if (!Number.isFinite(x)) {
        throw makeException(
          TypeError,
          "is not a finite floating-point value",
          options,
        );
      }

      return x;
    };

    exports["unrestricted double"] = (value, options = {}) => {
      const x = toNumber(value, options);

      return x;
    };

    exports.float = (value, options = {}) => {
      const x = toNumber(value, options);

      if (!Number.isFinite(x)) {
        throw makeException(
          TypeError,
          "is not a finite floating-point value",
          options,
        );
      }

      if (Object.is(x, -0)) {
        return x;
      }

      const y = Math.fround(x);

      if (!Number.isFinite(y)) {
        throw makeException(
          TypeError,
          "is outside the range of a single-precision floating-point value",
          options,
        );
      }

      return y;
    };

    exports["unrestricted float"] = (value, options = {}) => {
      const x = toNumber(value, options);

      if (isNaN(x)) {
        return x;
      }

      if (Object.is(x, -0)) {
        return x;
      }

      return Math.fround(x);
    };

    exports.DOMString = (value, options = {}) => {
      if (options.treatNullAsEmptyString && value === null) {
        return "";
      }

      if (typeof value === "symbol") {
        throw makeException(
          TypeError,
          "is a symbol, which cannot be converted to a string",
          options,
        );
      }

      const StringCtor = options.globals ? options.globals.String : String;
      return StringCtor(value);
    };

    exports.ByteString = (value, options = {}) => {
      const x = exports.DOMString(value, options);
      let c;
      for (let i = 0; (c = x.codePointAt(i)) !== undefined; ++i) {
        if (c > 255) {
          throw makeException(TypeError, "is not a valid ByteString", options);
        }
      }

      return x;
    };

    exports.USVString = (value, options = {}) => {
      const S = exports.DOMString(value, options);
      const n = S.length;
      const U = [];
      for (let i = 0; i < n; ++i) {
        const c = S.charCodeAt(i);
        if (c < 0xd800 || c > 0xdfff) {
          U.push(String.fromCodePoint(c));
        } else if (0xdc00 <= c && c <= 0xdfff) {
          U.push(String.fromCodePoint(0xfffd));
        } else if (i === n - 1) {
          U.push(String.fromCodePoint(0xfffd));
        } else {
          const d = S.charCodeAt(i + 1);
          if (0xdc00 <= d && d <= 0xdfff) {
            const a = c & 0x3ff;
            const b = d & 0x3ff;
            U.push(String.fromCodePoint((2 << 15) + (2 << 9) * a + b));
            ++i;
          } else {
            U.push(String.fromCodePoint(0xfffd));
          }
        }
      }

      return U.join("");
    };

    exports.object = (value, options = {}) => {
      if (
        value === null ||
        (typeof value !== "object" && typeof value !== "function")
      ) {
        throw makeException(TypeError, "is not an object", options);
      }

      return value;
    };

    const abByteLengthGetter = Object.getOwnPropertyDescriptor(
      ArrayBuffer.prototype,
      "byteLength",
    ).get;
    const sabByteLengthGetter =
      typeof SharedArrayBuffer === "function"
        ? Object.getOwnPropertyDescriptor(
            SharedArrayBuffer.prototype,
            "byteLength",
          ).get
        : null;

    function isNonSharedArrayBuffer(value) {
      try {
        // This will throw on SharedArrayBuffers, but not detached ArrayBuffers.
        // (The spec says it should throw, but the spec conflicts with implementations: https://github.com/tc39/ecma262/issues/678)
        abByteLengthGetter.call(value);

        return true;
      } catch {
        return false;
      }
    }

    function isSharedArrayBuffer(value) {
      try {
        sabByteLengthGetter.call(value);
        return true;
      } catch {
        return false;
      }
    }

    function isArrayBufferDetached(value) {
      try {
        return false;
      } catch {
        return true;
      }
    }

    exports.ArrayBuffer = (value, options = {}) => {
      if (!isNonSharedArrayBuffer(value)) {
        if (options.allowShared && !isSharedArrayBuffer(value)) {
          throw makeException(
            TypeError,
            "is not an ArrayBuffer or SharedArrayBuffer",
            options,
          );
        }
        throw makeException(TypeError, "is not an ArrayBuffer", options);
      }
      if (isArrayBufferDetached()) {
        throw makeException(TypeError, "is a detached ArrayBuffer", options);
      }

      return value;
    };

    const dvByteLengthGetter = Object.getOwnPropertyDescriptor(
      DataView.prototype,
      "byteLength",
    ).get;
    exports.DataView = (value, options = {}) => {
      try {
        dvByteLengthGetter.call(value);
      } catch (e) {
        throw makeException(TypeError, "is not a DataView", options);
      }

      if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {
        throw makeException(
          TypeError,
          "is backed by a SharedArrayBuffer, which is not allowed",
          options,
        );
      }
      if (isArrayBufferDetached()) {
        throw makeException(
          TypeError,
          "is backed by a detached ArrayBuffer",
          options,
        );
      }

      return value;
    };

    // Returns the unforgeable `TypedArray` constructor name or `undefined`,
    // if the `this` value isn't a valid `TypedArray` object.
    //
    // https://tc39.es/ecma262/#sec-get-%typedarray%.prototype-@@tostringtag
    const typedArrayNameGetter = Object.getOwnPropertyDescriptor(
      Object.getPrototypeOf(Uint8Array).prototype,
      Symbol.toStringTag,
    ).get;
    [
      Int8Array,
      Int16Array,
      Int32Array,
      Uint8Array,
      Uint16Array,
      Uint32Array,
      Uint8ClampedArray,
      Float32Array,
      Float64Array,
    ].forEach((func) => {
      const { name } = func;
      const article = /^[AEIOU]/u.test(name) ? "an" : "a";
      exports[name] = (value, options = {}) => {
        if (
          !ArrayBuffer.isView(value) ||
          typedArrayNameGetter.call(value) !== name
        ) {
          throw makeException(
            TypeError,
            `is not ${article} ${name} object`,
            options,
          );
        }
        if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {
          throw makeException(
            TypeError,
            "is a view on a SharedArrayBuffer, which is not allowed",
            options,
          );
        }
        if (isArrayBufferDetached()) {
          throw makeException(
            TypeError,
            "is a view on a detached ArrayBuffer",
            options,
          );
        }

        return value;
      };
    });

    // Common definitions

    exports.ArrayBufferView = (value, options = {}) => {
      if (!ArrayBuffer.isView(value)) {
        throw makeException(
          TypeError,
          "is not a view on an ArrayBuffer or SharedArrayBuffer",
          options,
        );
      }

      if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {
        throw makeException(
          TypeError,
          "is a view on a SharedArrayBuffer, which is not allowed",
          options,
        );
      }

      if (isArrayBufferDetached()) {
        throw makeException(
          TypeError,
          "is a view on a detached ArrayBuffer",
          options,
        );
      }
      return value;
    };

    exports.BufferSource = (value, options = {}) => {
      if (ArrayBuffer.isView(value)) {
        if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {
          throw makeException(
            TypeError,
            "is a view on a SharedArrayBuffer, which is not allowed",
            options,
          );
        }

        if (isArrayBufferDetached()) {
          throw makeException(
            TypeError,
            "is a view on a detached ArrayBuffer",
            options,
          );
        }
        return value;
      }

      if (!options.allowShared && !isNonSharedArrayBuffer(value)) {
        throw makeException(
          TypeError,
          "is not an ArrayBuffer or a view on one",
          options,
        );
      }
      if (
        options.allowShared &&
        !isSharedArrayBuffer(value) &&
        !isNonSharedArrayBuffer(value)
      ) {
        throw makeException(
          TypeError,
          "is not an ArrayBuffer, SharedArrayBuffer, or a view on one",
          options,
        );
      }
      if (isArrayBufferDetached()) {
        throw makeException(TypeError, "is a detached ArrayBuffer", options);
      }

      return value;
    };

    exports.DOMTimeStamp = exports["unsigned long long"];
  })(lib);
  return lib;
}

var utils$1 = { exports: {} };

var hasRequiredUtils;

function requireUtils() {
  if (hasRequiredUtils) return utils$1.exports;
  hasRequiredUtils = 1;
  (function (module, exports) {
    // Returns "Type(value) is Object" in ES terminology.
    function isObject(value) {
      return (
        (typeof value === "object" && value !== null) ||
        typeof value === "function"
      );
    }

    const hasOwn = Function.prototype.call.bind(
      Object.prototype.hasOwnProperty,
    );

    // Like `Object.assign`, but using `[[GetOwnProperty]]` and `[[DefineOwnProperty]]`
    // instead of `[[Get]]` and `[[Set]]` and only allowing objects
    function define(target, source) {
      for (const key of Reflect.ownKeys(source)) {
        const descriptor = Reflect.getOwnPropertyDescriptor(source, key);
        if (descriptor && !Reflect.defineProperty(target, key, descriptor)) {
          throw new TypeError(`Cannot redefine property: ${String(key)}`);
        }
      }
    }

    function newObjectInRealm(globalObject, object) {
      const ctorRegistry = initCtorRegistry(globalObject);
      return Object.defineProperties(
        Object.create(ctorRegistry["%Object.prototype%"]),
        Object.getOwnPropertyDescriptors(object),
      );
    }

    const wrapperSymbol = Symbol("wrapper");
    const implSymbol = Symbol("impl");
    const sameObjectCaches = Symbol("SameObject caches");
    const ctorRegistrySymbol = Symbol.for("[webidl2js] constructor registry");

    const AsyncIteratorPrototype = Object.getPrototypeOf(
      Object.getPrototypeOf(async function* () {}).prototype,
    );

    function initCtorRegistry(globalObject) {
      if (hasOwn(globalObject, ctorRegistrySymbol)) {
        return globalObject[ctorRegistrySymbol];
      }

      const ctorRegistry = Object.create(null);

      // In addition to registering all the WebIDL2JS-generated types in the constructor registry,
      // we also register a few intrinsics that we make use of in generated code, since they are not
      // easy to grab from the globalObject variable.
      ctorRegistry["%Object.prototype%"] = globalObject.Object.prototype;
      ctorRegistry["%IteratorPrototype%"] = Object.getPrototypeOf(
        Object.getPrototypeOf(new globalObject.Array()[Symbol.iterator]()),
      );

      try {
        ctorRegistry["%AsyncIteratorPrototype%"] = Object.getPrototypeOf(
          Object.getPrototypeOf(
            globalObject.eval("(async function* () {})").prototype,
          ),
        );
      } catch {
        ctorRegistry["%AsyncIteratorPrototype%"] = AsyncIteratorPrototype;
      }

      globalObject[ctorRegistrySymbol] = ctorRegistry;
      return ctorRegistry;
    }

    function getSameObject(wrapper, prop, creator) {
      if (!wrapper[sameObjectCaches]) {
        wrapper[sameObjectCaches] = Object.create(null);
      }

      if (prop in wrapper[sameObjectCaches]) {
        return wrapper[sameObjectCaches][prop];
      }

      wrapper[sameObjectCaches][prop] = creator();
      return wrapper[sameObjectCaches][prop];
    }

    function wrapperForImpl(impl) {
      return impl ? impl[wrapperSymbol] : null;
    }

    function implForWrapper(wrapper) {
      return wrapper ? wrapper[implSymbol] : null;
    }

    function tryWrapperForImpl(impl) {
      const wrapper = wrapperForImpl(impl);
      return wrapper ? wrapper : impl;
    }

    function tryImplForWrapper(wrapper) {
      const impl = implForWrapper(wrapper);
      return impl ? impl : wrapper;
    }

    const iterInternalSymbol = Symbol("internal");

    function isArrayIndexPropName(P) {
      if (typeof P !== "string") {
        return false;
      }
      const i = P >>> 0;
      if (i === 2 ** 32 - 1) {
        return false;
      }
      const s = `${i}`;
      if (P !== s) {
        return false;
      }
      return true;
    }

    const byteLengthGetter = Object.getOwnPropertyDescriptor(
      ArrayBuffer.prototype,
      "byteLength",
    ).get;
    function isArrayBuffer(value) {
      try {
        byteLengthGetter.call(value);
        return true;
      } catch (e) {
        return false;
      }
    }

    function iteratorResult([key, value], kind) {
      let result;
      switch (kind) {
        case "key":
          result = key;
          break;
        case "value":
          result = value;
          break;
        case "key+value":
          result = [key, value];
          break;
      }
      return { value: result, done: false };
    }

    const supportsPropertyIndex = Symbol("supports property index");
    const supportedPropertyIndices = Symbol("supported property indices");
    const supportsPropertyName = Symbol("supports property name");
    const supportedPropertyNames = Symbol("supported property names");
    const indexedGet = Symbol("indexed property get");
    const indexedSetNew = Symbol("indexed property set new");
    const indexedSetExisting = Symbol("indexed property set existing");
    const namedGet = Symbol("named property get");
    const namedSetNew = Symbol("named property set new");
    const namedSetExisting = Symbol("named property set existing");
    const namedDelete = Symbol("named property delete");

    const asyncIteratorNext = Symbol(
      "async iterator get the next iteration result",
    );
    const asyncIteratorReturn = Symbol("async iterator return steps");
    const asyncIteratorInit = Symbol("async iterator initialization steps");
    const asyncIteratorEOI = Symbol("async iterator end of iteration");

    module.exports = {
      isObject,
      hasOwn,
      define,
      newObjectInRealm,
      wrapperSymbol,
      implSymbol,
      getSameObject,
      ctorRegistrySymbol,
      initCtorRegistry,
      wrapperForImpl,
      implForWrapper,
      tryWrapperForImpl,
      tryImplForWrapper,
      iterInternalSymbol,
      isArrayBuffer,
      isArrayIndexPropName,
      supportsPropertyIndex,
      supportedPropertyIndices,
      supportsPropertyName,
      supportedPropertyNames,
      indexedGet,
      indexedSetNew,
      indexedSetExisting,
      namedGet,
      namedSetNew,
      namedSetExisting,
      namedDelete,
      asyncIteratorNext,
      asyncIteratorReturn,
      asyncIteratorInit,
      asyncIteratorEOI,
      iteratorResult,
    };
  })(utils$1);
  return utils$1.exports;
}

var URLImpl = {};

var urlStateMachine = { exports: {} };

var regexes;
var hasRequiredRegexes;

function requireRegexes() {
  if (hasRequiredRegexes) return regexes;
  hasRequiredRegexes = 1;

  const combiningMarks =
    /[\u0300-\u036F\u0483-\u0489\u0591-\u05BD\u05BF\u05C1\u05C2\u05C4\u05C5\u05C7\u0610-\u061A\u064B-\u065F\u0670\u06D6-\u06DC\u06DF-\u06E4\u06E7\u06E8\u06EA-\u06ED\u0711\u0730-\u074A\u07A6-\u07B0\u07EB-\u07F3\u07FD\u0816-\u0819\u081B-\u0823\u0825-\u0827\u0829-\u082D\u0859-\u085B\u0898-\u089F\u08CA-\u08E1\u08E3-\u0903\u093A-\u093C\u093E-\u094F\u0951-\u0957\u0962\u0963\u0981-\u0983\u09BC\u09BE-\u09C4\u09C7\u09C8\u09CB-\u09CD\u09D7\u09E2\u09E3\u09FE\u0A01-\u0A03\u0A3C\u0A3E-\u0A42\u0A47\u0A48\u0A4B-\u0A4D\u0A51\u0A70\u0A71\u0A75\u0A81-\u0A83\u0ABC\u0ABE-\u0AC5\u0AC7-\u0AC9\u0ACB-\u0ACD\u0AE2\u0AE3\u0AFA-\u0AFF\u0B01-\u0B03\u0B3C\u0B3E-\u0B44\u0B47\u0B48\u0B4B-\u0B4D\u0B55-\u0B57\u0B62\u0B63\u0B82\u0BBE-\u0BC2\u0BC6-\u0BC8\u0BCA-\u0BCD\u0BD7\u0C00-\u0C04\u0C3C\u0C3E-\u0C44\u0C46-\u0C48\u0C4A-\u0C4D\u0C55\u0C56\u0C62\u0C63\u0C81-\u0C83\u0CBC\u0CBE-\u0CC4\u0CC6-\u0CC8\u0CCA-\u0CCD\u0CD5\u0CD6\u0CE2\u0CE3\u0D00-\u0D03\u0D3B\u0D3C\u0D3E-\u0D44\u0D46-\u0D48\u0D4A-\u0D4D\u0D57\u0D62\u0D63\u0D81-\u0D83\u0DCA\u0DCF-\u0DD4\u0DD6\u0DD8-\u0DDF\u0DF2\u0DF3\u0E31\u0E34-\u0E3A\u0E47-\u0E4E\u0EB1\u0EB4-\u0EBC\u0EC8-\u0ECD\u0F18\u0F19\u0F35\u0F37\u0F39\u0F3E\u0F3F\u0F71-\u0F84\u0F86\u0F87\u0F8D-\u0F97\u0F99-\u0FBC\u0FC6\u102B-\u103E\u1056-\u1059\u105E-\u1060\u1062-\u1064\u1067-\u106D\u1071-\u1074\u1082-\u108D\u108F\u109A-\u109D\u135D-\u135F\u1712-\u1715\u1732-\u1734\u1752\u1753\u1772\u1773\u17B4-\u17D3\u17DD\u180B-\u180D\u180F\u1885\u1886\u18A9\u1920-\u192B\u1930-\u193B\u1A17-\u1A1B\u1A55-\u1A5E\u1A60-\u1A7C\u1A7F\u1AB0-\u1ACE\u1B00-\u1B04\u1B34-\u1B44\u1B6B-\u1B73\u1B80-\u1B82\u1BA1-\u1BAD\u1BE6-\u1BF3\u1C24-\u1C37\u1CD0-\u1CD2\u1CD4-\u1CE8\u1CED\u1CF4\u1CF7-\u1CF9\u1DC0-\u1DFF\u20D0-\u20F0\u2CEF-\u2CF1\u2D7F\u2DE0-\u2DFF\u302A-\u302F\u3099\u309A\uA66F-\uA672\uA674-\uA67D\uA69E\uA69F\uA6F0\uA6F1\uA802\uA806\uA80B\uA823-\uA827\uA82C\uA880\uA881\uA8B4-\uA8C5\uA8E0-\uA8F1\uA8FF\uA926-\uA92D\uA947-\uA953\uA980-\uA983\uA9B3-\uA9C0\uA9E5\uAA29-\uAA36\uAA43\uAA4C\uAA4D\uAA7B-\uAA7D\uAAB0\uAAB2-\uAAB4\uAAB7\uAAB8\uAABE\uAABF\uAAC1\uAAEB-\uAAEF\uAAF5\uAAF6\uABE3-\uABEA\uABEC\uABED\uFB1E\uFE00-\uFE0F\uFE20-\uFE2F\u{101FD}\u{102E0}\u{10376}-\u{1037A}\u{10A01}-\u{10A03}\u{10A05}\u{10A06}\u{10A0C}-\u{10A0F}\u{10A38}-\u{10A3A}\u{10A3F}\u{10AE5}\u{10AE6}\u{10D24}-\u{10D27}\u{10EAB}\u{10EAC}\u{10F46}-\u{10F50}\u{10F82}-\u{10F85}\u{11000}-\u{11002}\u{11038}-\u{11046}\u{11070}\u{11073}\u{11074}\u{1107F}-\u{11082}\u{110B0}-\u{110BA}\u{110C2}\u{11100}-\u{11102}\u{11127}-\u{11134}\u{11145}\u{11146}\u{11173}\u{11180}-\u{11182}\u{111B3}-\u{111C0}\u{111C9}-\u{111CC}\u{111CE}\u{111CF}\u{1122C}-\u{11237}\u{1123E}\u{112DF}-\u{112EA}\u{11300}-\u{11303}\u{1133B}\u{1133C}\u{1133E}-\u{11344}\u{11347}\u{11348}\u{1134B}-\u{1134D}\u{11357}\u{11362}\u{11363}\u{11366}-\u{1136C}\u{11370}-\u{11374}\u{11435}-\u{11446}\u{1145E}\u{114B0}-\u{114C3}\u{115AF}-\u{115B5}\u{115B8}-\u{115C0}\u{115DC}\u{115DD}\u{11630}-\u{11640}\u{116AB}-\u{116B7}\u{1171D}-\u{1172B}\u{1182C}-\u{1183A}\u{11930}-\u{11935}\u{11937}\u{11938}\u{1193B}-\u{1193E}\u{11940}\u{11942}\u{11943}\u{119D1}-\u{119D7}\u{119DA}-\u{119E0}\u{119E4}\u{11A01}-\u{11A0A}\u{11A33}-\u{11A39}\u{11A3B}-\u{11A3E}\u{11A47}\u{11A51}-\u{11A5B}\u{11A8A}-\u{11A99}\u{11C2F}-\u{11C36}\u{11C38}-\u{11C3F}\u{11C92}-\u{11CA7}\u{11CA9}-\u{11CB6}\u{11D31}-\u{11D36}\u{11D3A}\u{11D3C}\u{11D3D}\u{11D3F}-\u{11D45}\u{11D47}\u{11D8A}-\u{11D8E}\u{11D90}\u{11D91}\u{11D93}-\u{11D97}\u{11EF3}-\u{11EF6}\u{16AF0}-\u{16AF4}\u{16B30}-\u{16B36}\u{16F4F}\u{16F51}-\u{16F87}\u{16F8F}-\u{16F92}\u{16FE4}\u{16FF0}\u{16FF1}\u{1BC9D}\u{1BC9E}\u{1CF00}-\u{1CF2D}\u{1CF30}-\u{1CF46}\u{1D165}-\u{1D169}\u{1D16D}-\u{1D172}\u{1D17B}-\u{1D182}\u{1D185}-\u{1D18B}\u{1D1AA}-\u{1D1AD}\u{1D242}-\u{1D244}\u{1DA00}-\u{1DA36}\u{1DA3B}-\u{1DA6C}\u{1DA75}\u{1DA84}\u{1DA9B}-\u{1DA9F}\u{1DAA1}-\u{1DAAF}\u{1E000}-\u{1E006}\u{1E008}-\u{1E018}\u{1E01B}-\u{1E021}\u{1E023}\u{1E024}\u{1E026}-\u{1E02A}\u{1E130}-\u{1E136}\u{1E2AE}\u{1E2EC}-\u{1E2EF}\u{1E8D0}-\u{1E8D6}\u{1E944}-\u{1E94A}\u{E0100}-\u{E01EF}]/u;
  const combiningClassVirama =
    /[\u094D\u09CD\u0A4D\u0ACD\u0B4D\u0BCD\u0C4D\u0CCD\u0D3B\u0D3C\u0D4D\u0DCA\u0E3A\u0EBA\u0F84\u1039\u103A\u1714\u1734\u17D2\u1A60\u1B44\u1BAA\u1BAB\u1BF2\u1BF3\u2D7F\uA806\uA8C4\uA953\uA9C0\uAAF6\uABED\u{10A3F}\u{11046}\u{1107F}\u{110B9}\u{11133}\u{11134}\u{111C0}\u{11235}\u{112EA}\u{1134D}\u{11442}\u{114C2}\u{115BF}\u{1163F}\u{116B6}\u{1172B}\u{11839}\u{119E0}\u{11A34}\u{11A47}\u{11A99}\u{11C3F}\u{11D44}\u{11D45}\u{11D97}]/u;
  const validZWNJ =
    /[\u0620\u0626\u0628\u062A-\u062E\u0633-\u063F\u0641-\u0647\u0649\u064A\u066E\u066F\u0678-\u0687\u069A-\u06BF\u06C1\u06C2\u06CC\u06CE\u06D0\u06D1\u06FA-\u06FC\u06FF\u0712-\u0714\u071A-\u071D\u071F-\u0727\u0729\u072B\u072D\u072E\u074E-\u0758\u075C-\u076A\u076D-\u0770\u0772\u0775-\u0777\u077A-\u077F\u07CA-\u07EA\u0841-\u0845\u0848\u084A-\u0853\u0855\u0860\u0862-\u0865\u0868\u08A0-\u08A9\u08AF\u08B0\u08B3\u08B4\u08B6-\u08B8\u08BA-\u08BD\u1807\u1820-\u1878\u1887-\u18A8\u18AA\uA840-\uA872\u{10AC0}-\u{10AC4}\u{10ACD}\u{10AD3}-\u{10ADC}\u{10ADE}-\u{10AE0}\u{10AEB}-\u{10AEE}\u{10B80}\u{10B82}\u{10B86}-\u{10B88}\u{10B8A}\u{10B8B}\u{10B8D}\u{10B90}\u{10BAD}\u{10BAE}\u{10D00}-\u{10D21}\u{10D23}\u{10F30}-\u{10F32}\u{10F34}-\u{10F44}\u{10F51}-\u{10F53}\u{1E900}-\u{1E943}][\xAD\u0300-\u036F\u0483-\u0489\u0591-\u05BD\u05BF\u05C1\u05C2\u05C4\u05C5\u05C7\u0610-\u061A\u061C\u064B-\u065F\u0670\u06D6-\u06DC\u06DF-\u06E4\u06E7\u06E8\u06EA-\u06ED\u070F\u0711\u0730-\u074A\u07A6-\u07B0\u07EB-\u07F3\u07FD\u0816-\u0819\u081B-\u0823\u0825-\u0827\u0829-\u082D\u0859-\u085B\u08D3-\u08E1\u08E3-\u0902\u093A\u093C\u0941-\u0948\u094D\u0951-\u0957\u0962\u0963\u0981\u09BC\u09C1-\u09C4\u09CD\u09E2\u09E3\u09FE\u0A01\u0A02\u0A3C\u0A41\u0A42\u0A47\u0A48\u0A4B-\u0A4D\u0A51\u0A70\u0A71\u0A75\u0A81\u0A82\u0ABC\u0AC1-\u0AC5\u0AC7\u0AC8\u0ACD\u0AE2\u0AE3\u0AFA-\u0AFF\u0B01\u0B3C\u0B3F\u0B41-\u0B44\u0B4D\u0B56\u0B62\u0B63\u0B82\u0BC0\u0BCD\u0C00\u0C04\u0C3E-\u0C40\u0C46-\u0C48\u0C4A-\u0C4D\u0C55\u0C56\u0C62\u0C63\u0C81\u0CBC\u0CBF\u0CC6\u0CCC\u0CCD\u0CE2\u0CE3\u0D00\u0D01\u0D3B\u0D3C\u0D41-\u0D44\u0D4D\u0D62\u0D63\u0DCA\u0DD2-\u0DD4\u0DD6\u0E31\u0E34-\u0E3A\u0E47-\u0E4E\u0EB1\u0EB4-\u0EBC\u0EC8-\u0ECD\u0F18\u0F19\u0F35\u0F37\u0F39\u0F71-\u0F7E\u0F80-\u0F84\u0F86\u0F87\u0F8D-\u0F97\u0F99-\u0FBC\u0FC6\u102D-\u1030\u1032-\u1037\u1039\u103A\u103D\u103E\u1058\u1059\u105E-\u1060\u1071-\u1074\u1082\u1085\u1086\u108D\u109D\u135D-\u135F\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17B4\u17B5\u17B7-\u17BD\u17C6\u17C9-\u17D3\u17DD\u180B-\u180D\u1885\u1886\u18A9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193B\u1A17\u1A18\u1A1B\u1A56\u1A58-\u1A5E\u1A60\u1A62\u1A65-\u1A6C\u1A73-\u1A7C\u1A7F\u1AB0-\u1ABE\u1B00-\u1B03\u1B34\u1B36-\u1B3A\u1B3C\u1B42\u1B6B-\u1B73\u1B80\u1B81\u1BA2-\u1BA5\u1BA8\u1BA9\u1BAB-\u1BAD\u1BE6\u1BE8\u1BE9\u1BED\u1BEF-\u1BF1\u1C2C-\u1C33\u1C36\u1C37\u1CD0-\u1CD2\u1CD4-\u1CE0\u1CE2-\u1CE8\u1CED\u1CF4\u1CF8\u1CF9\u1DC0-\u1DF9\u1DFB-\u1DFF\u200B\u200E\u200F\u202A-\u202E\u2060-\u2064\u206A-\u206F\u20D0-\u20F0\u2CEF-\u2CF1\u2D7F\u2DE0-\u2DFF\u302A-\u302D\u3099\u309A\uA66F-\uA672\uA674-\uA67D\uA69E\uA69F\uA6F0\uA6F1\uA802\uA806\uA80B\uA825\uA826\uA8C4\uA8C5\uA8E0-\uA8F1\uA8FF\uA926-\uA92D\uA947-\uA951\uA980-\uA982\uA9B3\uA9B6-\uA9B9\uA9BC\uA9BD\uA9E5\uAA29-\uAA2E\uAA31\uAA32\uAA35\uAA36\uAA43\uAA4C\uAA7C\uAAB0\uAAB2-\uAAB4\uAAB7\uAAB8\uAABE\uAABF\uAAC1\uAAEC\uAAED\uAAF6\uABE5\uABE8\uABED\uFB1E\uFE00-\uFE0F\uFE20-\uFE2F\uFEFF\uFFF9-\uFFFB\u{101FD}\u{102E0}\u{10376}-\u{1037A}\u{10A01}-\u{10A03}\u{10A05}\u{10A06}\u{10A0C}-\u{10A0F}\u{10A38}-\u{10A3A}\u{10A3F}\u{10AE5}\u{10AE6}\u{10D24}-\u{10D27}\u{10F46}-\u{10F50}\u{11001}\u{11038}-\u{11046}\u{1107F}-\u{11081}\u{110B3}-\u{110B6}\u{110B9}\u{110BA}\u{11100}-\u{11102}\u{11127}-\u{1112B}\u{1112D}-\u{11134}\u{11173}\u{11180}\u{11181}\u{111B6}-\u{111BE}\u{111C9}-\u{111CC}\u{1122F}-\u{11231}\u{11234}\u{11236}\u{11237}\u{1123E}\u{112DF}\u{112E3}-\u{112EA}\u{11300}\u{11301}\u{1133B}\u{1133C}\u{11340}\u{11366}-\u{1136C}\u{11370}-\u{11374}\u{11438}-\u{1143F}\u{11442}-\u{11444}\u{11446}\u{1145E}\u{114B3}-\u{114B8}\u{114BA}\u{114BF}\u{114C0}\u{114C2}\u{114C3}\u{115B2}-\u{115B5}\u{115BC}\u{115BD}\u{115BF}\u{115C0}\u{115DC}\u{115DD}\u{11633}-\u{1163A}\u{1163D}\u{1163F}\u{11640}\u{116AB}\u{116AD}\u{116B0}-\u{116B5}\u{116B7}\u{1171D}-\u{1171F}\u{11722}-\u{11725}\u{11727}-\u{1172B}\u{1182F}-\u{11837}\u{11839}\u{1183A}\u{119D4}-\u{119D7}\u{119DA}\u{119DB}\u{119E0}\u{11A01}-\u{11A0A}\u{11A33}-\u{11A38}\u{11A3B}-\u{11A3E}\u{11A47}\u{11A51}-\u{11A56}\u{11A59}-\u{11A5B}\u{11A8A}-\u{11A96}\u{11A98}\u{11A99}\u{11C30}-\u{11C36}\u{11C38}-\u{11C3D}\u{11C3F}\u{11C92}-\u{11CA7}\u{11CAA}-\u{11CB0}\u{11CB2}\u{11CB3}\u{11CB5}\u{11CB6}\u{11D31}-\u{11D36}\u{11D3A}\u{11D3C}\u{11D3D}\u{11D3F}-\u{11D45}\u{11D47}\u{11D90}\u{11D91}\u{11D95}\u{11D97}\u{11EF3}\u{11EF4}\u{13430}-\u{13438}\u{16AF0}-\u{16AF4}\u{16B30}-\u{16B36}\u{16F4F}\u{16F8F}-\u{16F92}\u{1BC9D}\u{1BC9E}\u{1BCA0}-\u{1BCA3}\u{1D167}-\u{1D169}\u{1D173}-\u{1D182}\u{1D185}-\u{1D18B}\u{1D1AA}-\u{1D1AD}\u{1D242}-\u{1D244}\u{1DA00}-\u{1DA36}\u{1DA3B}-\u{1DA6C}\u{1DA75}\u{1DA84}\u{1DA9B}-\u{1DA9F}\u{1DAA1}-\u{1DAAF}\u{1E000}-\u{1E006}\u{1E008}-\u{1E018}\u{1E01B}-\u{1E021}\u{1E023}\u{1E024}\u{1E026}-\u{1E02A}\u{1E130}-\u{1E136}\u{1E2EC}-\u{1E2EF}\u{1E8D0}-\u{1E8D6}\u{1E944}-\u{1E94B}\u{E0001}\u{E0020}-\u{E007F}\u{E0100}-\u{E01EF}]*\u200C[\xAD\u0300-\u036F\u0483-\u0489\u0591-\u05BD\u05BF\u05C1\u05C2\u05C4\u05C5\u05C7\u0610-\u061A\u061C\u064B-\u065F\u0670\u06D6-\u06DC\u06DF-\u06E4\u06E7\u06E8\u06EA-\u06ED\u070F\u0711\u0730-\u074A\u07A6-\u07B0\u07EB-\u07F3\u07FD\u0816-\u0819\u081B-\u0823\u0825-\u0827\u0829-\u082D\u0859-\u085B\u08D3-\u08E1\u08E3-\u0902\u093A\u093C\u0941-\u0948\u094D\u0951-\u0957\u0962\u0963\u0981\u09BC\u09C1-\u09C4\u09CD\u09E2\u09E3\u09FE\u0A01\u0A02\u0A3C\u0A41\u0A42\u0A47\u0A48\u0A4B-\u0A4D\u0A51\u0A70\u0A71\u0A75\u0A81\u0A82\u0ABC\u0AC1-\u0AC5\u0AC7\u0AC8\u0ACD\u0AE2\u0AE3\u0AFA-\u0AFF\u0B01\u0B3C\u0B3F\u0B41-\u0B44\u0B4D\u0B56\u0B62\u0B63\u0B82\u0BC0\u0BCD\u0C00\u0C04\u0C3E-\u0C40\u0C46-\u0C48\u0C4A-\u0C4D\u0C55\u0C56\u0C62\u0C63\u0C81\u0CBC\u0CBF\u0CC6\u0CCC\u0CCD\u0CE2\u0CE3\u0D00\u0D01\u0D3B\u0D3C\u0D41-\u0D44\u0D4D\u0D62\u0D63\u0DCA\u0DD2-\u0DD4\u0DD6\u0E31\u0E34-\u0E3A\u0E47-\u0E4E\u0EB1\u0EB4-\u0EBC\u0EC8-\u0ECD\u0F18\u0F19\u0F35\u0F37\u0F39\u0F71-\u0F7E\u0F80-\u0F84\u0F86\u0F87\u0F8D-\u0F97\u0F99-\u0FBC\u0FC6\u102D-\u1030\u1032-\u1037\u1039\u103A\u103D\u103E\u1058\u1059\u105E-\u1060\u1071-\u1074\u1082\u1085\u1086\u108D\u109D\u135D-\u135F\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17B4\u17B5\u17B7-\u17BD\u17C6\u17C9-\u17D3\u17DD\u180B-\u180D\u1885\u1886\u18A9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193B\u1A17\u1A18\u1A1B\u1A56\u1A58-\u1A5E\u1A60\u1A62\u1A65-\u1A6C\u1A73-\u1A7C\u1A7F\u1AB0-\u1ABE\u1B00-\u1B03\u1B34\u1B36-\u1B3A\u1B3C\u1B42\u1B6B-\u1B73\u1B80\u1B81\u1BA2-\u1BA5\u1BA8\u1BA9\u1BAB-\u1BAD\u1BE6\u1BE8\u1BE9\u1BED\u1BEF-\u1BF1\u1C2C-\u1C33\u1C36\u1C37\u1CD0-\u1CD2\u1CD4-\u1CE0\u1CE2-\u1CE8\u1CED\u1CF4\u1CF8\u1CF9\u1DC0-\u1DF9\u1DFB-\u1DFF\u200B\u200E\u200F\u202A-\u202E\u2060-\u2064\u206A-\u206F\u20D0-\u20F0\u2CEF-\u2CF1\u2D7F\u2DE0-\u2DFF\u302A-\u302D\u3099\u309A\uA66F-\uA672\uA674-\uA67D\uA69E\uA69F\uA6F0\uA6F1\uA802\uA806\uA80B\uA825\uA826\uA8C4\uA8C5\uA8E0-\uA8F1\uA8FF\uA926-\uA92D\uA947-\uA951\uA980-\uA982\uA9B3\uA9B6-\uA9B9\uA9BC\uA9BD\uA9E5\uAA29-\uAA2E\uAA31\uAA32\uAA35\uAA36\uAA43\uAA4C\uAA7C\uAAB0\uAAB2-\uAAB4\uAAB7\uAAB8\uAABE\uAABF\uAAC1\uAAEC\uAAED\uAAF6\uABE5\uABE8\uABED\uFB1E\uFE00-\uFE0F\uFE20-\uFE2F\uFEFF\uFFF9-\uFFFB\u{101FD}\u{102E0}\u{10376}-\u{1037A}\u{10A01}-\u{10A03}\u{10A05}\u{10A06}\u{10A0C}-\u{10A0F}\u{10A38}-\u{10A3A}\u{10A3F}\u{10AE5}\u{10AE6}\u{10D24}-\u{10D27}\u{10F46}-\u{10F50}\u{11001}\u{11038}-\u{11046}\u{1107F}-\u{11081}\u{110B3}-\u{110B6}\u{110B9}\u{110BA}\u{11100}-\u{11102}\u{11127}-\u{1112B}\u{1112D}-\u{11134}\u{11173}\u{11180}\u{11181}\u{111B6}-\u{111BE}\u{111C9}-\u{111CC}\u{1122F}-\u{11231}\u{11234}\u{11236}\u{11237}\u{1123E}\u{112DF}\u{112E3}-\u{112EA}\u{11300}\u{11301}\u{1133B}\u{1133C}\u{11340}\u{11366}-\u{1136C}\u{11370}-\u{11374}\u{11438}-\u{1143F}\u{11442}-\u{11444}\u{11446}\u{1145E}\u{114B3}-\u{114B8}\u{114BA}\u{114BF}\u{114C0}\u{114C2}\u{114C3}\u{115B2}-\u{115B5}\u{115BC}\u{115BD}\u{115BF}\u{115C0}\u{115DC}\u{115DD}\u{11633}-\u{1163A}\u{1163D}\u{1163F}\u{11640}\u{116AB}\u{116AD}\u{116B0}-\u{116B5}\u{116B7}\u{1171D}-\u{1171F}\u{11722}-\u{11725}\u{11727}-\u{1172B}\u{1182F}-\u{11837}\u{11839}\u{1183A}\u{119D4}-\u{119D7}\u{119DA}\u{119DB}\u{119E0}\u{11A01}-\u{11A0A}\u{11A33}-\u{11A38}\u{11A3B}-\u{11A3E}\u{11A47}\u{11A51}-\u{11A56}\u{11A59}-\u{11A5B}\u{11A8A}-\u{11A96}\u{11A98}\u{11A99}\u{11C30}-\u{11C36}\u{11C38}-\u{11C3D}\u{11C3F}\u{11C92}-\u{11CA7}\u{11CAA}-\u{11CB0}\u{11CB2}\u{11CB3}\u{11CB5}\u{11CB6}\u{11D31}-\u{11D36}\u{11D3A}\u{11D3C}\u{11D3D}\u{11D3F}-\u{11D45}\u{11D47}\u{11D90}\u{11D91}\u{11D95}\u{11D97}\u{11EF3}\u{11EF4}\u{13430}-\u{13438}\u{16AF0}-\u{16AF4}\u{16B30}-\u{16B36}\u{16F4F}\u{16F8F}-\u{16F92}\u{1BC9D}\u{1BC9E}\u{1BCA0}-\u{1BCA3}\u{1D167}-\u{1D169}\u{1D173}-\u{1D182}\u{1D185}-\u{1D18B}\u{1D1AA}-\u{1D1AD}\u{1D242}-\u{1D244}\u{1DA00}-\u{1DA36}\u{1DA3B}-\u{1DA6C}\u{1DA75}\u{1DA84}\u{1DA9B}-\u{1DA9F}\u{1DAA1}-\u{1DAAF}\u{1E000}-\u{1E006}\u{1E008}-\u{1E018}\u{1E01B}-\u{1E021}\u{1E023}\u{1E024}\u{1E026}-\u{1E02A}\u{1E130}-\u{1E136}\u{1E2EC}-\u{1E2EF}\u{1E8D0}-\u{1E8D6}\u{1E944}-\u{1E94B}\u{E0001}\u{E0020}-\u{E007F}\u{E0100}-\u{E01EF}]*[\u0620\u0622-\u063F\u0641-\u064A\u066E\u066F\u0671-\u0673\u0675-\u06D3\u06D5\u06EE\u06EF\u06FA-\u06FC\u06FF\u0710\u0712-\u072F\u074D-\u077F\u07CA-\u07EA\u0840-\u0855\u0860\u0862-\u0865\u0867-\u086A\u08A0-\u08AC\u08AE-\u08B4\u08B6-\u08BD\u1807\u1820-\u1878\u1887-\u18A8\u18AA\uA840-\uA871\u{10AC0}-\u{10AC5}\u{10AC7}\u{10AC9}\u{10ACA}\u{10ACE}-\u{10AD6}\u{10AD8}-\u{10AE1}\u{10AE4}\u{10AEB}-\u{10AEF}\u{10B80}-\u{10B91}\u{10BA9}-\u{10BAE}\u{10D01}-\u{10D23}\u{10F30}-\u{10F44}\u{10F51}-\u{10F54}\u{1E900}-\u{1E943}]/u;
  const bidiDomain =
    /[\u05BE\u05C0\u05C3\u05C6\u05D0-\u05EA\u05EF-\u05F4\u0600-\u0605\u0608\u060B\u060D\u061B-\u064A\u0660-\u0669\u066B-\u066F\u0671-\u06D5\u06DD\u06E5\u06E6\u06EE\u06EF\u06FA-\u070D\u070F\u0710\u0712-\u072F\u074D-\u07A5\u07B1\u07C0-\u07EA\u07F4\u07F5\u07FA\u07FE-\u0815\u081A\u0824\u0828\u0830-\u083E\u0840-\u0858\u085E\u0860-\u086A\u0870-\u088E\u0890\u0891\u08A0-\u08C9\u08E2\u200F\uFB1D\uFB1F-\uFB28\uFB2A-\uFB36\uFB38-\uFB3C\uFB3E\uFB40\uFB41\uFB43\uFB44\uFB46-\uFBC2\uFBD3-\uFD3D\uFD50-\uFD8F\uFD92-\uFDC7\uFDF0-\uFDFC\uFE70-\uFE74\uFE76-\uFEFC\u{10800}-\u{10805}\u{10808}\u{1080A}-\u{10835}\u{10837}\u{10838}\u{1083C}\u{1083F}-\u{10855}\u{10857}-\u{1089E}\u{108A7}-\u{108AF}\u{108E0}-\u{108F2}\u{108F4}\u{108F5}\u{108FB}-\u{1091B}\u{10920}-\u{10939}\u{1093F}\u{10980}-\u{109B7}\u{109BC}-\u{109CF}\u{109D2}-\u{10A00}\u{10A10}-\u{10A13}\u{10A15}-\u{10A17}\u{10A19}-\u{10A35}\u{10A40}-\u{10A48}\u{10A50}-\u{10A58}\u{10A60}-\u{10A9F}\u{10AC0}-\u{10AE4}\u{10AEB}-\u{10AF6}\u{10B00}-\u{10B35}\u{10B40}-\u{10B55}\u{10B58}-\u{10B72}\u{10B78}-\u{10B91}\u{10B99}-\u{10B9C}\u{10BA9}-\u{10BAF}\u{10C00}-\u{10C48}\u{10C80}-\u{10CB2}\u{10CC0}-\u{10CF2}\u{10CFA}-\u{10D23}\u{10D30}-\u{10D39}\u{10E60}-\u{10E7E}\u{10E80}-\u{10EA9}\u{10EAD}\u{10EB0}\u{10EB1}\u{10F00}-\u{10F27}\u{10F30}-\u{10F45}\u{10F51}-\u{10F59}\u{10F70}-\u{10F81}\u{10F86}-\u{10F89}\u{10FB0}-\u{10FCB}\u{10FE0}-\u{10FF6}\u{1E800}-\u{1E8C4}\u{1E8C7}-\u{1E8CF}\u{1E900}-\u{1E943}\u{1E94B}\u{1E950}-\u{1E959}\u{1E95E}\u{1E95F}\u{1EC71}-\u{1ECB4}\u{1ED01}-\u{1ED3D}\u{1EE00}-\u{1EE03}\u{1EE05}-\u{1EE1F}\u{1EE21}\u{1EE22}\u{1EE24}\u{1EE27}\u{1EE29}-\u{1EE32}\u{1EE34}-\u{1EE37}\u{1EE39}\u{1EE3B}\u{1EE42}\u{1EE47}\u{1EE49}\u{1EE4B}\u{1EE4D}-\u{1EE4F}\u{1EE51}\u{1EE52}\u{1EE54}\u{1EE57}\u{1EE59}\u{1EE5B}\u{1EE5D}\u{1EE5F}\u{1EE61}\u{1EE62}\u{1EE64}\u{1EE67}-\u{1EE6A}\u{1EE6C}-\u{1EE72}\u{1EE74}-\u{1EE77}\u{1EE79}-\u{1EE7C}\u{1EE7E}\u{1EE80}-\u{1EE89}\u{1EE8B}-\u{1EE9B}\u{1EEA1}-\u{1EEA3}\u{1EEA5}-\u{1EEA9}\u{1EEAB}-\u{1EEBB}]/u;
  const bidiS1LTR =
    /[A-Za-z\xAA\xB5\xBA\xC0-\xD6\xD8-\xF6\xF8-\u02B8\u02BB-\u02C1\u02D0\u02D1\u02E0-\u02E4\u02EE\u0370-\u0373\u0376\u0377\u037A-\u037D\u037F\u0386\u0388-\u038A\u038C\u038E-\u03A1\u03A3-\u03F5\u03F7-\u0482\u048A-\u052F\u0531-\u0556\u0559-\u0589\u0903-\u0939\u093B\u093D-\u0940\u0949-\u094C\u094E-\u0950\u0958-\u0961\u0964-\u0980\u0982\u0983\u0985-\u098C\u098F\u0990\u0993-\u09A8\u09AA-\u09B0\u09B2\u09B6-\u09B9\u09BD-\u09C0\u09C7\u09C8\u09CB\u09CC\u09CE\u09D7\u09DC\u09DD\u09DF-\u09E1\u09E6-\u09F1\u09F4-\u09FA\u09FC\u09FD\u0A03\u0A05-\u0A0A\u0A0F\u0A10\u0A13-\u0A28\u0A2A-\u0A30\u0A32\u0A33\u0A35\u0A36\u0A38\u0A39\u0A3E-\u0A40\u0A59-\u0A5C\u0A5E\u0A66-\u0A6F\u0A72-\u0A74\u0A76\u0A83\u0A85-\u0A8D\u0A8F-\u0A91\u0A93-\u0AA8\u0AAA-\u0AB0\u0AB2\u0AB3\u0AB5-\u0AB9\u0ABD-\u0AC0\u0AC9\u0ACB\u0ACC\u0AD0\u0AE0\u0AE1\u0AE6-\u0AF0\u0AF9\u0B02\u0B03\u0B05-\u0B0C\u0B0F\u0B10\u0B13-\u0B28\u0B2A-\u0B30\u0B32\u0B33\u0B35-\u0B39\u0B3D\u0B3E\u0B40\u0B47\u0B48\u0B4B\u0B4C\u0B57\u0B5C\u0B5D\u0B5F-\u0B61\u0B66-\u0B77\u0B83\u0B85-\u0B8A\u0B8E-\u0B90\u0B92-\u0B95\u0B99\u0B9A\u0B9C\u0B9E\u0B9F\u0BA3\u0BA4\u0BA8-\u0BAA\u0BAE-\u0BB9\u0BBE\u0BBF\u0BC1\u0BC2\u0BC6-\u0BC8\u0BCA-\u0BCC\u0BD0\u0BD7\u0BE6-\u0BF2\u0C01-\u0C03\u0C05-\u0C0C\u0C0E-\u0C10\u0C12-\u0C28\u0C2A-\u0C39\u0C3D\u0C41-\u0C44\u0C58-\u0C5A\u0C5D\u0C60\u0C61\u0C66-\u0C6F\u0C77\u0C7F\u0C80\u0C82-\u0C8C\u0C8E-\u0C90\u0C92-\u0CA8\u0CAA-\u0CB3\u0CB5-\u0CB9\u0CBD-\u0CC4\u0CC6-\u0CC8\u0CCA\u0CCB\u0CD5\u0CD6\u0CDD\u0CDE\u0CE0\u0CE1\u0CE6-\u0CEF\u0CF1\u0CF2\u0D02-\u0D0C\u0D0E-\u0D10\u0D12-\u0D3A\u0D3D-\u0D40\u0D46-\u0D48\u0D4A-\u0D4C\u0D4E\u0D4F\u0D54-\u0D61\u0D66-\u0D7F\u0D82\u0D83\u0D85-\u0D96\u0D9A-\u0DB1\u0DB3-\u0DBB\u0DBD\u0DC0-\u0DC6\u0DCF-\u0DD1\u0DD8-\u0DDF\u0DE6-\u0DEF\u0DF2-\u0DF4\u0E01-\u0E30\u0E32\u0E33\u0E40-\u0E46\u0E4F-\u0E5B\u0E81\u0E82\u0E84\u0E86-\u0E8A\u0E8C-\u0EA3\u0EA5\u0EA7-\u0EB0\u0EB2\u0EB3\u0EBD\u0EC0-\u0EC4\u0EC6\u0ED0-\u0ED9\u0EDC-\u0EDF\u0F00-\u0F17\u0F1A-\u0F34\u0F36\u0F38\u0F3E-\u0F47\u0F49-\u0F6C\u0F7F\u0F85\u0F88-\u0F8C\u0FBE-\u0FC5\u0FC7-\u0FCC\u0FCE-\u0FDA\u1000-\u102C\u1031\u1038\u103B\u103C\u103F-\u1057\u105A-\u105D\u1061-\u1070\u1075-\u1081\u1083\u1084\u1087-\u108C\u108E-\u109C\u109E-\u10C5\u10C7\u10CD\u10D0-\u1248\u124A-\u124D\u1250-\u1256\u1258\u125A-\u125D\u1260-\u1288\u128A-\u128D\u1290-\u12B0\u12B2-\u12B5\u12B8-\u12BE\u12C0\u12C2-\u12C5\u12C8-\u12D6\u12D8-\u1310\u1312-\u1315\u1318-\u135A\u1360-\u137C\u1380-\u138F\u13A0-\u13F5\u13F8-\u13FD\u1401-\u167F\u1681-\u169A\u16A0-\u16F8\u1700-\u1711\u1715\u171F-\u1731\u1734-\u1736\u1740-\u1751\u1760-\u176C\u176E-\u1770\u1780-\u17B3\u17B6\u17BE-\u17C5\u17C7\u17C8\u17D4-\u17DA\u17DC\u17E0-\u17E9\u1810-\u1819\u1820-\u1878\u1880-\u1884\u1887-\u18A8\u18AA\u18B0-\u18F5\u1900-\u191E\u1923-\u1926\u1929-\u192B\u1930\u1931\u1933-\u1938\u1946-\u196D\u1970-\u1974\u1980-\u19AB\u19B0-\u19C9\u19D0-\u19DA\u1A00-\u1A16\u1A19\u1A1A\u1A1E-\u1A55\u1A57\u1A61\u1A63\u1A64\u1A6D-\u1A72\u1A80-\u1A89\u1A90-\u1A99\u1AA0-\u1AAD\u1B04-\u1B33\u1B35\u1B3B\u1B3D-\u1B41\u1B43-\u1B4C\u1B50-\u1B6A\u1B74-\u1B7E\u1B82-\u1BA1\u1BA6\u1BA7\u1BAA\u1BAE-\u1BE5\u1BE7\u1BEA-\u1BEC\u1BEE\u1BF2\u1BF3\u1BFC-\u1C2B\u1C34\u1C35\u1C3B-\u1C49\u1C4D-\u1C88\u1C90-\u1CBA\u1CBD-\u1CC7\u1CD3\u1CE1\u1CE9-\u1CEC\u1CEE-\u1CF3\u1CF5-\u1CF7\u1CFA\u1D00-\u1DBF\u1E00-\u1F15\u1F18-\u1F1D\u1F20-\u1F45\u1F48-\u1F4D\u1F50-\u1F57\u1F59\u1F5B\u1F5D\u1F5F-\u1F7D\u1F80-\u1FB4\u1FB6-\u1FBC\u1FBE\u1FC2-\u1FC4\u1FC6-\u1FCC\u1FD0-\u1FD3\u1FD6-\u1FDB\u1FE0-\u1FEC\u1FF2-\u1FF4\u1FF6-\u1FFC\u200E\u2071\u207F\u2090-\u209C\u2102\u2107\u210A-\u2113\u2115\u2119-\u211D\u2124\u2126\u2128\u212A-\u212D\u212F-\u2139\u213C-\u213F\u2145-\u2149\u214E\u214F\u2160-\u2188\u2336-\u237A\u2395\u249C-\u24E9\u26AC\u2800-\u28FF\u2C00-\u2CE4\u2CEB-\u2CEE\u2CF2\u2CF3\u2D00-\u2D25\u2D27\u2D2D\u2D30-\u2D67\u2D6F\u2D70\u2D80-\u2D96\u2DA0-\u2DA6\u2DA8-\u2DAE\u2DB0-\u2DB6\u2DB8-\u2DBE\u2DC0-\u2DC6\u2DC8-\u2DCE\u2DD0-\u2DD6\u2DD8-\u2DDE\u3005-\u3007\u3021-\u3029\u302E\u302F\u3031-\u3035\u3038-\u303C\u3041-\u3096\u309D-\u309F\u30A1-\u30FA\u30FC-\u30FF\u3105-\u312F\u3131-\u318E\u3190-\u31BF\u31F0-\u321C\u3220-\u324F\u3260-\u327B\u327F-\u32B0\u32C0-\u32CB\u32D0-\u3376\u337B-\u33DD\u33E0-\u33FE\u3400-\u4DBF\u4E00-\uA48C\uA4D0-\uA60C\uA610-\uA62B\uA640-\uA66E\uA680-\uA69D\uA6A0-\uA6EF\uA6F2-\uA6F7\uA722-\uA787\uA789-\uA7CA\uA7D0\uA7D1\uA7D3\uA7D5-\uA7D9\uA7F2-\uA801\uA803-\uA805\uA807-\uA80A\uA80C-\uA824\uA827\uA830-\uA837\uA840-\uA873\uA880-\uA8C3\uA8CE-\uA8D9\uA8F2-\uA8FE\uA900-\uA925\uA92E-\uA946\uA952\uA953\uA95F-\uA97C\uA983-\uA9B2\uA9B4\uA9B5\uA9BA\uA9BB\uA9BE-\uA9CD\uA9CF-\uA9D9\uA9DE-\uA9E4\uA9E6-\uA9FE\uAA00-\uAA28\uAA2F\uAA30\uAA33\uAA34\uAA40-\uAA42\uAA44-\uAA4B\uAA4D\uAA50-\uAA59\uAA5C-\uAA7B\uAA7D-\uAAAF\uAAB1\uAAB5\uAAB6\uAAB9-\uAABD\uAAC0\uAAC2\uAADB-\uAAEB\uAAEE-\uAAF5\uAB01-\uAB06\uAB09-\uAB0E\uAB11-\uAB16\uAB20-\uAB26\uAB28-\uAB2E\uAB30-\uAB69\uAB70-\uABE4\uABE6\uABE7\uABE9-\uABEC\uABF0-\uABF9\uAC00-\uD7A3\uD7B0-\uD7C6\uD7CB-\uD7FB\uD800-\uFA6D\uFA70-\uFAD9\uFB00-\uFB06\uFB13-\uFB17\uFF21-\uFF3A\uFF41-\uFF5A\uFF66-\uFFBE\uFFC2-\uFFC7\uFFCA-\uFFCF\uFFD2-\uFFD7\uFFDA-\uFFDC\u{10000}-\u{1000B}\u{1000D}-\u{10026}\u{10028}-\u{1003A}\u{1003C}\u{1003D}\u{1003F}-\u{1004D}\u{10050}-\u{1005D}\u{10080}-\u{100FA}\u{10100}\u{10102}\u{10107}-\u{10133}\u{10137}-\u{1013F}\u{1018D}\u{1018E}\u{101D0}-\u{101FC}\u{10280}-\u{1029C}\u{102A0}-\u{102D0}\u{10300}-\u{10323}\u{1032D}-\u{1034A}\u{10350}-\u{10375}\u{10380}-\u{1039D}\u{1039F}-\u{103C3}\u{103C8}-\u{103D5}\u{10400}-\u{1049D}\u{104A0}-\u{104A9}\u{104B0}-\u{104D3}\u{104D8}-\u{104FB}\u{10500}-\u{10527}\u{10530}-\u{10563}\u{1056F}-\u{1057A}\u{1057C}-\u{1058A}\u{1058C}-\u{10592}\u{10594}\u{10595}\u{10597}-\u{105A1}\u{105A3}-\u{105B1}\u{105B3}-\u{105B9}\u{105BB}\u{105BC}\u{10600}-\u{10736}\u{10740}-\u{10755}\u{10760}-\u{10767}\u{10780}-\u{10785}\u{10787}-\u{107B0}\u{107B2}-\u{107BA}\u{11000}\u{11002}-\u{11037}\u{11047}-\u{1104D}\u{11066}-\u{1106F}\u{11071}\u{11072}\u{11075}\u{11082}-\u{110B2}\u{110B7}\u{110B8}\u{110BB}-\u{110C1}\u{110CD}\u{110D0}-\u{110E8}\u{110F0}-\u{110F9}\u{11103}-\u{11126}\u{1112C}\u{11136}-\u{11147}\u{11150}-\u{11172}\u{11174}-\u{11176}\u{11182}-\u{111B5}\u{111BF}-\u{111C8}\u{111CD}\u{111CE}\u{111D0}-\u{111DF}\u{111E1}-\u{111F4}\u{11200}-\u{11211}\u{11213}-\u{1122E}\u{11232}\u{11233}\u{11235}\u{11238}-\u{1123D}\u{11280}-\u{11286}\u{11288}\u{1128A}-\u{1128D}\u{1128F}-\u{1129D}\u{1129F}-\u{112A9}\u{112B0}-\u{112DE}\u{112E0}-\u{112E2}\u{112F0}-\u{112F9}\u{11302}\u{11303}\u{11305}-\u{1130C}\u{1130F}\u{11310}\u{11313}-\u{11328}\u{1132A}-\u{11330}\u{11332}\u{11333}\u{11335}-\u{11339}\u{1133D}-\u{1133F}\u{11341}-\u{11344}\u{11347}\u{11348}\u{1134B}-\u{1134D}\u{11350}\u{11357}\u{1135D}-\u{11363}\u{11400}-\u{11437}\u{11440}\u{11441}\u{11445}\u{11447}-\u{1145B}\u{1145D}\u{1145F}-\u{11461}\u{11480}-\u{114B2}\u{114B9}\u{114BB}-\u{114BE}\u{114C1}\u{114C4}-\u{114C7}\u{114D0}-\u{114D9}\u{11580}-\u{115B1}\u{115B8}-\u{115BB}\u{115BE}\u{115C1}-\u{115DB}\u{11600}-\u{11632}\u{1163B}\u{1163C}\u{1163E}\u{11641}-\u{11644}\u{11650}-\u{11659}\u{11680}-\u{116AA}\u{116AC}\u{116AE}\u{116AF}\u{116B6}\u{116B8}\u{116B9}\u{116C0}-\u{116C9}\u{11700}-\u{1171A}\u{11720}\u{11721}\u{11726}\u{11730}-\u{11746}\u{11800}-\u{1182E}\u{11838}\u{1183B}\u{118A0}-\u{118F2}\u{118FF}-\u{11906}\u{11909}\u{1190C}-\u{11913}\u{11915}\u{11916}\u{11918}-\u{11935}\u{11937}\u{11938}\u{1193D}\u{1193F}-\u{11942}\u{11944}-\u{11946}\u{11950}-\u{11959}\u{119A0}-\u{119A7}\u{119AA}-\u{119D3}\u{119DC}-\u{119DF}\u{119E1}-\u{119E4}\u{11A00}\u{11A07}\u{11A08}\u{11A0B}-\u{11A32}\u{11A39}\u{11A3A}\u{11A3F}-\u{11A46}\u{11A50}\u{11A57}\u{11A58}\u{11A5C}-\u{11A89}\u{11A97}\u{11A9A}-\u{11AA2}\u{11AB0}-\u{11AF8}\u{11C00}-\u{11C08}\u{11C0A}-\u{11C2F}\u{11C3E}-\u{11C45}\u{11C50}-\u{11C6C}\u{11C70}-\u{11C8F}\u{11CA9}\u{11CB1}\u{11CB4}\u{11D00}-\u{11D06}\u{11D08}\u{11D09}\u{11D0B}-\u{11D30}\u{11D46}\u{11D50}-\u{11D59}\u{11D60}-\u{11D65}\u{11D67}\u{11D68}\u{11D6A}-\u{11D8E}\u{11D93}\u{11D94}\u{11D96}\u{11D98}\u{11DA0}-\u{11DA9}\u{11EE0}-\u{11EF2}\u{11EF5}-\u{11EF8}\u{11FB0}\u{11FC0}-\u{11FD4}\u{11FFF}-\u{12399}\u{12400}-\u{1246E}\u{12470}-\u{12474}\u{12480}-\u{12543}\u{12F90}-\u{12FF2}\u{13000}-\u{1342E}\u{13430}-\u{13438}\u{14400}-\u{14646}\u{16800}-\u{16A38}\u{16A40}-\u{16A5E}\u{16A60}-\u{16A69}\u{16A6E}-\u{16ABE}\u{16AC0}-\u{16AC9}\u{16AD0}-\u{16AED}\u{16AF5}\u{16B00}-\u{16B2F}\u{16B37}-\u{16B45}\u{16B50}-\u{16B59}\u{16B5B}-\u{16B61}\u{16B63}-\u{16B77}\u{16B7D}-\u{16B8F}\u{16E40}-\u{16E9A}\u{16F00}-\u{16F4A}\u{16F50}-\u{16F87}\u{16F93}-\u{16F9F}\u{16FE0}\u{16FE1}\u{16FE3}\u{16FF0}\u{16FF1}\u{17000}-\u{187F7}\u{18800}-\u{18CD5}\u{18D00}-\u{18D08}\u{1AFF0}-\u{1AFF3}\u{1AFF5}-\u{1AFFB}\u{1AFFD}\u{1AFFE}\u{1B000}-\u{1B122}\u{1B150}-\u{1B152}\u{1B164}-\u{1B167}\u{1B170}-\u{1B2FB}\u{1BC00}-\u{1BC6A}\u{1BC70}-\u{1BC7C}\u{1BC80}-\u{1BC88}\u{1BC90}-\u{1BC99}\u{1BC9C}\u{1BC9F}\u{1CF50}-\u{1CFC3}\u{1D000}-\u{1D0F5}\u{1D100}-\u{1D126}\u{1D129}-\u{1D166}\u{1D16A}-\u{1D172}\u{1D183}\u{1D184}\u{1D18C}-\u{1D1A9}\u{1D1AE}-\u{1D1E8}\u{1D2E0}-\u{1D2F3}\u{1D360}-\u{1D378}\u{1D400}-\u{1D454}\u{1D456}-\u{1D49C}\u{1D49E}\u{1D49F}\u{1D4A2}\u{1D4A5}\u{1D4A6}\u{1D4A9}-\u{1D4AC}\u{1D4AE}-\u{1D4B9}\u{1D4BB}\u{1D4BD}-\u{1D4C3}\u{1D4C5}-\u{1D505}\u{1D507}-\u{1D50A}\u{1D50D}-\u{1D514}\u{1D516}-\u{1D51C}\u{1D51E}-\u{1D539}\u{1D53B}-\u{1D53E}\u{1D540}-\u{1D544}\u{1D546}\u{1D54A}-\u{1D550}\u{1D552}-\u{1D6A5}\u{1D6A8}-\u{1D6DA}\u{1D6DC}-\u{1D714}\u{1D716}-\u{1D74E}\u{1D750}-\u{1D788}\u{1D78A}-\u{1D7C2}\u{1D7C4}-\u{1D7CB}\u{1D800}-\u{1D9FF}\u{1DA37}-\u{1DA3A}\u{1DA6D}-\u{1DA74}\u{1DA76}-\u{1DA83}\u{1DA85}-\u{1DA8B}\u{1DF00}-\u{1DF1E}\u{1E100}-\u{1E12C}\u{1E137}-\u{1E13D}\u{1E140}-\u{1E149}\u{1E14E}\u{1E14F}\u{1E290}-\u{1E2AD}\u{1E2C0}-\u{1E2EB}\u{1E2F0}-\u{1E2F9}\u{1E7E0}-\u{1E7E6}\u{1E7E8}-\u{1E7EB}\u{1E7ED}\u{1E7EE}\u{1E7F0}-\u{1E7FE}\u{1F110}-\u{1F12E}\u{1F130}-\u{1F169}\u{1F170}-\u{1F1AC}\u{1F1E6}-\u{1F202}\u{1F210}-\u{1F23B}\u{1F240}-\u{1F248}\u{1F250}\u{1F251}\u{20000}-\u{2A6DF}\u{2A700}-\u{2B738}\u{2B740}-\u{2B81D}\u{2B820}-\u{2CEA1}\u{2CEB0}-\u{2EBE0}\u{2F800}-\u{2FA1D}\u{30000}-\u{3134A}\u{F0000}-\u{FFFFD}\u{100000}-\u{10FFFD}]/u;
  const bidiS1RTL =
    /[\u05BE\u05C0\u05C3\u05C6\u05D0-\u05EA\u05EF-\u05F4\u0608\u060B\u060D\u061B-\u064A\u066D-\u066F\u0671-\u06D5\u06E5\u06E6\u06EE\u06EF\u06FA-\u070D\u070F\u0710\u0712-\u072F\u074D-\u07A5\u07B1\u07C0-\u07EA\u07F4\u07F5\u07FA\u07FE-\u0815\u081A\u0824\u0828\u0830-\u083E\u0840-\u0858\u085E\u0860-\u086A\u0870-\u088E\u08A0-\u08C9\u200F\uFB1D\uFB1F-\uFB28\uFB2A-\uFB36\uFB38-\uFB3C\uFB3E\uFB40\uFB41\uFB43\uFB44\uFB46-\uFBC2\uFBD3-\uFD3D\uFD50-\uFD8F\uFD92-\uFDC7\uFDF0-\uFDFC\uFE70-\uFE74\uFE76-\uFEFC\u{10800}-\u{10805}\u{10808}\u{1080A}-\u{10835}\u{10837}\u{10838}\u{1083C}\u{1083F}-\u{10855}\u{10857}-\u{1089E}\u{108A7}-\u{108AF}\u{108E0}-\u{108F2}\u{108F4}\u{108F5}\u{108FB}-\u{1091B}\u{10920}-\u{10939}\u{1093F}\u{10980}-\u{109B7}\u{109BC}-\u{109CF}\u{109D2}-\u{10A00}\u{10A10}-\u{10A13}\u{10A15}-\u{10A17}\u{10A19}-\u{10A35}\u{10A40}-\u{10A48}\u{10A50}-\u{10A58}\u{10A60}-\u{10A9F}\u{10AC0}-\u{10AE4}\u{10AEB}-\u{10AF6}\u{10B00}-\u{10B35}\u{10B40}-\u{10B55}\u{10B58}-\u{10B72}\u{10B78}-\u{10B91}\u{10B99}-\u{10B9C}\u{10BA9}-\u{10BAF}\u{10C00}-\u{10C48}\u{10C80}-\u{10CB2}\u{10CC0}-\u{10CF2}\u{10CFA}-\u{10D23}\u{10E80}-\u{10EA9}\u{10EAD}\u{10EB0}\u{10EB1}\u{10F00}-\u{10F27}\u{10F30}-\u{10F45}\u{10F51}-\u{10F59}\u{10F70}-\u{10F81}\u{10F86}-\u{10F89}\u{10FB0}-\u{10FCB}\u{10FE0}-\u{10FF6}\u{1E800}-\u{1E8C4}\u{1E8C7}-\u{1E8CF}\u{1E900}-\u{1E943}\u{1E94B}\u{1E950}-\u{1E959}\u{1E95E}\u{1E95F}\u{1EC71}-\u{1ECB4}\u{1ED01}-\u{1ED3D}\u{1EE00}-\u{1EE03}\u{1EE05}-\u{1EE1F}\u{1EE21}\u{1EE22}\u{1EE24}\u{1EE27}\u{1EE29}-\u{1EE32}\u{1EE34}-\u{1EE37}\u{1EE39}\u{1EE3B}\u{1EE42}\u{1EE47}\u{1EE49}\u{1EE4B}\u{1EE4D}-\u{1EE4F}\u{1EE51}\u{1EE52}\u{1EE54}\u{1EE57}\u{1EE59}\u{1EE5B}\u{1EE5D}\u{1EE5F}\u{1EE61}\u{1EE62}\u{1EE64}\u{1EE67}-\u{1EE6A}\u{1EE6C}-\u{1EE72}\u{1EE74}-\u{1EE77}\u{1EE79}-\u{1EE7C}\u{1EE7E}\u{1EE80}-\u{1EE89}\u{1EE8B}-\u{1EE9B}\u{1EEA1}-\u{1EEA3}\u{1EEA5}-\u{1EEA9}\u{1EEAB}-\u{1EEBB}]/u;
  const bidiS2 =
    /^[\0-\x08\x0E-\x1B!-@\[-`\{-\x84\x86-\xA9\xAB-\xB4\xB6-\xB9\xBB-\xBF\xD7\xF7\u02B9\u02BA\u02C2-\u02CF\u02D2-\u02DF\u02E5-\u02ED\u02EF-\u036F\u0374\u0375\u037E\u0384\u0385\u0387\u03F6\u0483-\u0489\u058A\u058D-\u058F\u0591-\u05C7\u05D0-\u05EA\u05EF-\u05F4\u0600-\u070D\u070F-\u074A\u074D-\u07B1\u07C0-\u07FA\u07FD-\u082D\u0830-\u083E\u0840-\u085B\u085E\u0860-\u086A\u0870-\u088E\u0890\u0891\u0898-\u0902\u093A\u093C\u0941-\u0948\u094D\u0951-\u0957\u0962\u0963\u0981\u09BC\u09C1-\u09C4\u09CD\u09E2\u09E3\u09F2\u09F3\u09FB\u09FE\u0A01\u0A02\u0A3C\u0A41\u0A42\u0A47\u0A48\u0A4B-\u0A4D\u0A51\u0A70\u0A71\u0A75\u0A81\u0A82\u0ABC\u0AC1-\u0AC5\u0AC7\u0AC8\u0ACD\u0AE2\u0AE3\u0AF1\u0AFA-\u0AFF\u0B01\u0B3C\u0B3F\u0B41-\u0B44\u0B4D\u0B55\u0B56\u0B62\u0B63\u0B82\u0BC0\u0BCD\u0BF3-\u0BFA\u0C00\u0C04\u0C3C\u0C3E-\u0C40\u0C46-\u0C48\u0C4A-\u0C4D\u0C55\u0C56\u0C62\u0C63\u0C78-\u0C7E\u0C81\u0CBC\u0CCC\u0CCD\u0CE2\u0CE3\u0D00\u0D01\u0D3B\u0D3C\u0D41-\u0D44\u0D4D\u0D62\u0D63\u0D81\u0DCA\u0DD2-\u0DD4\u0DD6\u0E31\u0E34-\u0E3A\u0E3F\u0E47-\u0E4E\u0EB1\u0EB4-\u0EBC\u0EC8-\u0ECD\u0F18\u0F19\u0F35\u0F37\u0F39-\u0F3D\u0F71-\u0F7E\u0F80-\u0F84\u0F86\u0F87\u0F8D-\u0F97\u0F99-\u0FBC\u0FC6\u102D-\u1030\u1032-\u1037\u1039\u103A\u103D\u103E\u1058\u1059\u105E-\u1060\u1071-\u1074\u1082\u1085\u1086\u108D\u109D\u135D-\u135F\u1390-\u1399\u1400\u169B\u169C\u1712-\u1714\u1732\u1733\u1752\u1753\u1772\u1773\u17B4\u17B5\u17B7-\u17BD\u17C6\u17C9-\u17D3\u17DB\u17DD\u17F0-\u17F9\u1800-\u180F\u1885\u1886\u18A9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193B\u1940\u1944\u1945\u19DE-\u19FF\u1A17\u1A18\u1A1B\u1A56\u1A58-\u1A5E\u1A60\u1A62\u1A65-\u1A6C\u1A73-\u1A7C\u1A7F\u1AB0-\u1ACE\u1B00-\u1B03\u1B34\u1B36-\u1B3A\u1B3C\u1B42\u1B6B-\u1B73\u1B80\u1B81\u1BA2-\u1BA5\u1BA8\u1BA9\u1BAB-\u1BAD\u1BE6\u1BE8\u1BE9\u1BED\u1BEF-\u1BF1\u1C2C-\u1C33\u1C36\u1C37\u1CD0-\u1CD2\u1CD4-\u1CE0\u1CE2-\u1CE8\u1CED\u1CF4\u1CF8\u1CF9\u1DC0-\u1DFF\u1FBD\u1FBF-\u1FC1\u1FCD-\u1FCF\u1FDD-\u1FDF\u1FED-\u1FEF\u1FFD\u1FFE\u200B-\u200D\u200F-\u2027\u202F-\u205E\u2060-\u2064\u206A-\u2070\u2074-\u207E\u2080-\u208E\u20A0-\u20C0\u20D0-\u20F0\u2100\u2101\u2103-\u2106\u2108\u2109\u2114\u2116-\u2118\u211E-\u2123\u2125\u2127\u2129\u212E\u213A\u213B\u2140-\u2144\u214A-\u214D\u2150-\u215F\u2189-\u218B\u2190-\u2335\u237B-\u2394\u2396-\u2426\u2440-\u244A\u2460-\u249B\u24EA-\u26AB\u26AD-\u27FF\u2900-\u2B73\u2B76-\u2B95\u2B97-\u2BFF\u2CE5-\u2CEA\u2CEF-\u2CF1\u2CF9-\u2CFF\u2D7F\u2DE0-\u2E5D\u2E80-\u2E99\u2E9B-\u2EF3\u2F00-\u2FD5\u2FF0-\u2FFB\u3001-\u3004\u3008-\u3020\u302A-\u302D\u3030\u3036\u3037\u303D-\u303F\u3099-\u309C\u30A0\u30FB\u31C0-\u31E3\u321D\u321E\u3250-\u325F\u327C-\u327E\u32B1-\u32BF\u32CC-\u32CF\u3377-\u337A\u33DE\u33DF\u33FF\u4DC0-\u4DFF\uA490-\uA4C6\uA60D-\uA60F\uA66F-\uA67F\uA69E\uA69F\uA6F0\uA6F1\uA700-\uA721\uA788\uA802\uA806\uA80B\uA825\uA826\uA828-\uA82C\uA838\uA839\uA874-\uA877\uA8C4\uA8C5\uA8E0-\uA8F1\uA8FF\uA926-\uA92D\uA947-\uA951\uA980-\uA982\uA9B3\uA9B6-\uA9B9\uA9BC\uA9BD\uA9E5\uAA29-\uAA2E\uAA31\uAA32\uAA35\uAA36\uAA43\uAA4C\uAA7C\uAAB0\uAAB2-\uAAB4\uAAB7\uAAB8\uAABE\uAABF\uAAC1\uAAEC\uAAED\uAAF6\uAB6A\uAB6B\uABE5\uABE8\uABED\uFB1D-\uFB36\uFB38-\uFB3C\uFB3E\uFB40\uFB41\uFB43\uFB44\uFB46-\uFBC2\uFBD3-\uFD8F\uFD92-\uFDC7\uFDCF\uFDF0-\uFE19\uFE20-\uFE52\uFE54-\uFE66\uFE68-\uFE6B\uFE70-\uFE74\uFE76-\uFEFC\uFEFF\uFF01-\uFF20\uFF3B-\uFF40\uFF5B-\uFF65\uFFE0-\uFFE6\uFFE8-\uFFEE\uFFF9-\uFFFD\u{10101}\u{10140}-\u{1018C}\u{10190}-\u{1019C}\u{101A0}\u{101FD}\u{102E0}-\u{102FB}\u{10376}-\u{1037A}\u{10800}-\u{10805}\u{10808}\u{1080A}-\u{10835}\u{10837}\u{10838}\u{1083C}\u{1083F}-\u{10855}\u{10857}-\u{1089E}\u{108A7}-\u{108AF}\u{108E0}-\u{108F2}\u{108F4}\u{108F5}\u{108FB}-\u{1091B}\u{1091F}-\u{10939}\u{1093F}\u{10980}-\u{109B7}\u{109BC}-\u{109CF}\u{109D2}-\u{10A03}\u{10A05}\u{10A06}\u{10A0C}-\u{10A13}\u{10A15}-\u{10A17}\u{10A19}-\u{10A35}\u{10A38}-\u{10A3A}\u{10A3F}-\u{10A48}\u{10A50}-\u{10A58}\u{10A60}-\u{10A9F}\u{10AC0}-\u{10AE6}\u{10AEB}-\u{10AF6}\u{10B00}-\u{10B35}\u{10B39}-\u{10B55}\u{10B58}-\u{10B72}\u{10B78}-\u{10B91}\u{10B99}-\u{10B9C}\u{10BA9}-\u{10BAF}\u{10C00}-\u{10C48}\u{10C80}-\u{10CB2}\u{10CC0}-\u{10CF2}\u{10CFA}-\u{10D27}\u{10D30}-\u{10D39}\u{10E60}-\u{10E7E}\u{10E80}-\u{10EA9}\u{10EAB}-\u{10EAD}\u{10EB0}\u{10EB1}\u{10F00}-\u{10F27}\u{10F30}-\u{10F59}\u{10F70}-\u{10F89}\u{10FB0}-\u{10FCB}\u{10FE0}-\u{10FF6}\u{11001}\u{11038}-\u{11046}\u{11052}-\u{11065}\u{11070}\u{11073}\u{11074}\u{1107F}-\u{11081}\u{110B3}-\u{110B6}\u{110B9}\u{110BA}\u{110C2}\u{11100}-\u{11102}\u{11127}-\u{1112B}\u{1112D}-\u{11134}\u{11173}\u{11180}\u{11181}\u{111B6}-\u{111BE}\u{111C9}-\u{111CC}\u{111CF}\u{1122F}-\u{11231}\u{11234}\u{11236}\u{11237}\u{1123E}\u{112DF}\u{112E3}-\u{112EA}\u{11300}\u{11301}\u{1133B}\u{1133C}\u{11340}\u{11366}-\u{1136C}\u{11370}-\u{11374}\u{11438}-\u{1143F}\u{11442}-\u{11444}\u{11446}\u{1145E}\u{114B3}-\u{114B8}\u{114BA}\u{114BF}\u{114C0}\u{114C2}\u{114C3}\u{115B2}-\u{115B5}\u{115BC}\u{115BD}\u{115BF}\u{115C0}\u{115DC}\u{115DD}\u{11633}-\u{1163A}\u{1163D}\u{1163F}\u{11640}\u{11660}-\u{1166C}\u{116AB}\u{116AD}\u{116B0}-\u{116B5}\u{116B7}\u{1171D}-\u{1171F}\u{11722}-\u{11725}\u{11727}-\u{1172B}\u{1182F}-\u{11837}\u{11839}\u{1183A}\u{1193B}\u{1193C}\u{1193E}\u{11943}\u{119D4}-\u{119D7}\u{119DA}\u{119DB}\u{119E0}\u{11A01}-\u{11A06}\u{11A09}\u{11A0A}\u{11A33}-\u{11A38}\u{11A3B}-\u{11A3E}\u{11A47}\u{11A51}-\u{11A56}\u{11A59}-\u{11A5B}\u{11A8A}-\u{11A96}\u{11A98}\u{11A99}\u{11C30}-\u{11C36}\u{11C38}-\u{11C3D}\u{11C92}-\u{11CA7}\u{11CAA}-\u{11CB0}\u{11CB2}\u{11CB3}\u{11CB5}\u{11CB6}\u{11D31}-\u{11D36}\u{11D3A}\u{11D3C}\u{11D3D}\u{11D3F}-\u{11D45}\u{11D47}\u{11D90}\u{11D91}\u{11D95}\u{11D97}\u{11EF3}\u{11EF4}\u{11FD5}-\u{11FF1}\u{16AF0}-\u{16AF4}\u{16B30}-\u{16B36}\u{16F4F}\u{16F8F}-\u{16F92}\u{16FE2}\u{16FE4}\u{1BC9D}\u{1BC9E}\u{1BCA0}-\u{1BCA3}\u{1CF00}-\u{1CF2D}\u{1CF30}-\u{1CF46}\u{1D167}-\u{1D169}\u{1D173}-\u{1D182}\u{1D185}-\u{1D18B}\u{1D1AA}-\u{1D1AD}\u{1D1E9}\u{1D1EA}\u{1D200}-\u{1D245}\u{1D300}-\u{1D356}\u{1D6DB}\u{1D715}\u{1D74F}\u{1D789}\u{1D7C3}\u{1D7CE}-\u{1D7FF}\u{1DA00}-\u{1DA36}\u{1DA3B}-\u{1DA6C}\u{1DA75}\u{1DA84}\u{1DA9B}-\u{1DA9F}\u{1DAA1}-\u{1DAAF}\u{1E000}-\u{1E006}\u{1E008}-\u{1E018}\u{1E01B}-\u{1E021}\u{1E023}\u{1E024}\u{1E026}-\u{1E02A}\u{1E130}-\u{1E136}\u{1E2AE}\u{1E2EC}-\u{1E2EF}\u{1E2FF}\u{1E800}-\u{1E8C4}\u{1E8C7}-\u{1E8D6}\u{1E900}-\u{1E94B}\u{1E950}-\u{1E959}\u{1E95E}\u{1E95F}\u{1EC71}-\u{1ECB4}\u{1ED01}-\u{1ED3D}\u{1EE00}-\u{1EE03}\u{1EE05}-\u{1EE1F}\u{1EE21}\u{1EE22}\u{1EE24}\u{1EE27}\u{1EE29}-\u{1EE32}\u{1EE34}-\u{1EE37}\u{1EE39}\u{1EE3B}\u{1EE42}\u{1EE47}\u{1EE49}\u{1EE4B}\u{1EE4D}-\u{1EE4F}\u{1EE51}\u{1EE52}\u{1EE54}\u{1EE57}\u{1EE59}\u{1EE5B}\u{1EE5D}\u{1EE5F}\u{1EE61}\u{1EE62}\u{1EE64}\u{1EE67}-\u{1EE6A}\u{1EE6C}-\u{1EE72}\u{1EE74}-\u{1EE77}\u{1EE79}-\u{1EE7C}\u{1EE7E}\u{1EE80}-\u{1EE89}\u{1EE8B}-\u{1EE9B}\u{1EEA1}-\u{1EEA3}\u{1EEA5}-\u{1EEA9}\u{1EEAB}-\u{1EEBB}\u{1EEF0}\u{1EEF1}\u{1F000}-\u{1F02B}\u{1F030}-\u{1F093}\u{1F0A0}-\u{1F0AE}\u{1F0B1}-\u{1F0BF}\u{1F0C1}-\u{1F0CF}\u{1F0D1}-\u{1F0F5}\u{1F100}-\u{1F10F}\u{1F12F}\u{1F16A}-\u{1F16F}\u{1F1AD}\u{1F260}-\u{1F265}\u{1F300}-\u{1F6D7}\u{1F6DD}-\u{1F6EC}\u{1F6F0}-\u{1F6FC}\u{1F700}-\u{1F773}\u{1F780}-\u{1F7D8}\u{1F7E0}-\u{1F7EB}\u{1F7F0}\u{1F800}-\u{1F80B}\u{1F810}-\u{1F847}\u{1F850}-\u{1F859}\u{1F860}-\u{1F887}\u{1F890}-\u{1F8AD}\u{1F8B0}\u{1F8B1}\u{1F900}-\u{1FA53}\u{1FA60}-\u{1FA6D}\u{1FA70}-\u{1FA74}\u{1FA78}-\u{1FA7C}\u{1FA80}-\u{1FA86}\u{1FA90}-\u{1FAAC}\u{1FAB0}-\u{1FABA}\u{1FAC0}-\u{1FAC5}\u{1FAD0}-\u{1FAD9}\u{1FAE0}-\u{1FAE7}\u{1FAF0}-\u{1FAF6}\u{1FB00}-\u{1FB92}\u{1FB94}-\u{1FBCA}\u{1FBF0}-\u{1FBF9}\u{E0001}\u{E0020}-\u{E007F}\u{E0100}-\u{E01EF}]*$/u;
  const bidiS3 =
    /[0-9\xB2\xB3\xB9\u05BE\u05C0\u05C3\u05C6\u05D0-\u05EA\u05EF-\u05F4\u0600-\u0605\u0608\u060B\u060D\u061B-\u064A\u0660-\u0669\u066B-\u066F\u0671-\u06D5\u06DD\u06E5\u06E6\u06EE-\u070D\u070F\u0710\u0712-\u072F\u074D-\u07A5\u07B1\u07C0-\u07EA\u07F4\u07F5\u07FA\u07FE-\u0815\u081A\u0824\u0828\u0830-\u083E\u0840-\u0858\u085E\u0860-\u086A\u0870-\u088E\u0890\u0891\u08A0-\u08C9\u08E2\u200F\u2070\u2074-\u2079\u2080-\u2089\u2488-\u249B\uFB1D\uFB1F-\uFB28\uFB2A-\uFB36\uFB38-\uFB3C\uFB3E\uFB40\uFB41\uFB43\uFB44\uFB46-\uFBC2\uFBD3-\uFD3D\uFD50-\uFD8F\uFD92-\uFDC7\uFDF0-\uFDFC\uFE70-\uFE74\uFE76-\uFEFC\uFF10-\uFF19\u{102E1}-\u{102FB}\u{10800}-\u{10805}\u{10808}\u{1080A}-\u{10835}\u{10837}\u{10838}\u{1083C}\u{1083F}-\u{10855}\u{10857}-\u{1089E}\u{108A7}-\u{108AF}\u{108E0}-\u{108F2}\u{108F4}\u{108F5}\u{108FB}-\u{1091B}\u{10920}-\u{10939}\u{1093F}\u{10980}-\u{109B7}\u{109BC}-\u{109CF}\u{109D2}-\u{10A00}\u{10A10}-\u{10A13}\u{10A15}-\u{10A17}\u{10A19}-\u{10A35}\u{10A40}-\u{10A48}\u{10A50}-\u{10A58}\u{10A60}-\u{10A9F}\u{10AC0}-\u{10AE4}\u{10AEB}-\u{10AF6}\u{10B00}-\u{10B35}\u{10B40}-\u{10B55}\u{10B58}-\u{10B72}\u{10B78}-\u{10B91}\u{10B99}-\u{10B9C}\u{10BA9}-\u{10BAF}\u{10C00}-\u{10C48}\u{10C80}-\u{10CB2}\u{10CC0}-\u{10CF2}\u{10CFA}-\u{10D23}\u{10D30}-\u{10D39}\u{10E60}-\u{10E7E}\u{10E80}-\u{10EA9}\u{10EAD}\u{10EB0}\u{10EB1}\u{10F00}-\u{10F27}\u{10F30}-\u{10F45}\u{10F51}-\u{10F59}\u{10F70}-\u{10F81}\u{10F86}-\u{10F89}\u{10FB0}-\u{10FCB}\u{10FE0}-\u{10FF6}\u{1D7CE}-\u{1D7FF}\u{1E800}-\u{1E8C4}\u{1E8C7}-\u{1E8CF}\u{1E900}-\u{1E943}\u{1E94B}\u{1E950}-\u{1E959}\u{1E95E}\u{1E95F}\u{1EC71}-\u{1ECB4}\u{1ED01}-\u{1ED3D}\u{1EE00}-\u{1EE03}\u{1EE05}-\u{1EE1F}\u{1EE21}\u{1EE22}\u{1EE24}\u{1EE27}\u{1EE29}-\u{1EE32}\u{1EE34}-\u{1EE37}\u{1EE39}\u{1EE3B}\u{1EE42}\u{1EE47}\u{1EE49}\u{1EE4B}\u{1EE4D}-\u{1EE4F}\u{1EE51}\u{1EE52}\u{1EE54}\u{1EE57}\u{1EE59}\u{1EE5B}\u{1EE5D}\u{1EE5F}\u{1EE61}\u{1EE62}\u{1EE64}\u{1EE67}-\u{1EE6A}\u{1EE6C}-\u{1EE72}\u{1EE74}-\u{1EE77}\u{1EE79}-\u{1EE7C}\u{1EE7E}\u{1EE80}-\u{1EE89}\u{1EE8B}-\u{1EE9B}\u{1EEA1}-\u{1EEA3}\u{1EEA5}-\u{1EEA9}\u{1EEAB}-\u{1EEBB}\u{1F100}-\u{1F10A}\u{1FBF0}-\u{1FBF9}][\u0300-\u036F\u0483-\u0489\u0591-\u05BD\u05BF\u05C1\u05C2\u05C4\u05C5\u05C7\u0610-\u061A\u064B-\u065F\u0670\u06D6-\u06DC\u06DF-\u06E4\u06E7\u06E8\u06EA-\u06ED\u0711\u0730-\u074A\u07A6-\u07B0\u07EB-\u07F3\u07FD\u0816-\u0819\u081B-\u0823\u0825-\u0827\u0829-\u082D\u0859-\u085B\u0898-\u089F\u08CA-\u08E1\u08E3-\u0902\u093A\u093C\u0941-\u0948\u094D\u0951-\u0957\u0962\u0963\u0981\u09BC\u09C1-\u09C4\u09CD\u09E2\u09E3\u09FE\u0A01\u0A02\u0A3C\u0A41\u0A42\u0A47\u0A48\u0A4B-\u0A4D\u0A51\u0A70\u0A71\u0A75\u0A81\u0A82\u0ABC\u0AC1-\u0AC5\u0AC7\u0AC8\u0ACD\u0AE2\u0AE3\u0AFA-\u0AFF\u0B01\u0B3C\u0B3F\u0B41-\u0B44\u0B4D\u0B55\u0B56\u0B62\u0B63\u0B82\u0BC0\u0BCD\u0C00\u0C04\u0C3C\u0C3E-\u0C40\u0C46-\u0C48\u0C4A-\u0C4D\u0C55\u0C56\u0C62\u0C63\u0C81\u0CBC\u0CCC\u0CCD\u0CE2\u0CE3\u0D00\u0D01\u0D3B\u0D3C\u0D41-\u0D44\u0D4D\u0D62\u0D63\u0D81\u0DCA\u0DD2-\u0DD4\u0DD6\u0E31\u0E34-\u0E3A\u0E47-\u0E4E\u0EB1\u0EB4-\u0EBC\u0EC8-\u0ECD\u0F18\u0F19\u0F35\u0F37\u0F39\u0F71-\u0F7E\u0F80-\u0F84\u0F86\u0F87\u0F8D-\u0F97\u0F99-\u0FBC\u0FC6\u102D-\u1030\u1032-\u1037\u1039\u103A\u103D\u103E\u1058\u1059\u105E-\u1060\u1071-\u1074\u1082\u1085\u1086\u108D\u109D\u135D-\u135F\u1712-\u1714\u1732\u1733\u1752\u1753\u1772\u1773\u17B4\u17B5\u17B7-\u17BD\u17C6\u17C9-\u17D3\u17DD\u180B-\u180D\u180F\u1885\u1886\u18A9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193B\u1A17\u1A18\u1A1B\u1A56\u1A58-\u1A5E\u1A60\u1A62\u1A65-\u1A6C\u1A73-\u1A7C\u1A7F\u1AB0-\u1ACE\u1B00-\u1B03\u1B34\u1B36-\u1B3A\u1B3C\u1B42\u1B6B-\u1B73\u1B80\u1B81\u1BA2-\u1BA5\u1BA8\u1BA9\u1BAB-\u1BAD\u1BE6\u1BE8\u1BE9\u1BED\u1BEF-\u1BF1\u1C2C-\u1C33\u1C36\u1C37\u1CD0-\u1CD2\u1CD4-\u1CE0\u1CE2-\u1CE8\u1CED\u1CF4\u1CF8\u1CF9\u1DC0-\u1DFF\u20D0-\u20F0\u2CEF-\u2CF1\u2D7F\u2DE0-\u2DFF\u302A-\u302D\u3099\u309A\uA66F-\uA672\uA674-\uA67D\uA69E\uA69F\uA6F0\uA6F1\uA802\uA806\uA80B\uA825\uA826\uA82C\uA8C4\uA8C5\uA8E0-\uA8F1\uA8FF\uA926-\uA92D\uA947-\uA951\uA980-\uA982\uA9B3\uA9B6-\uA9B9\uA9BC\uA9BD\uA9E5\uAA29-\uAA2E\uAA31\uAA32\uAA35\uAA36\uAA43\uAA4C\uAA7C\uAAB0\uAAB2-\uAAB4\uAAB7\uAAB8\uAABE\uAABF\uAAC1\uAAEC\uAAED\uAAF6\uABE5\uABE8\uABED\uFB1E\uFE00-\uFE0F\uFE20-\uFE2F\u{101FD}\u{102E0}\u{10376}-\u{1037A}\u{10A01}-\u{10A03}\u{10A05}\u{10A06}\u{10A0C}-\u{10A0F}\u{10A38}-\u{10A3A}\u{10A3F}\u{10AE5}\u{10AE6}\u{10D24}-\u{10D27}\u{10EAB}\u{10EAC}\u{10F46}-\u{10F50}\u{10F82}-\u{10F85}\u{11001}\u{11038}-\u{11046}\u{11070}\u{11073}\u{11074}\u{1107F}-\u{11081}\u{110B3}-\u{110B6}\u{110B9}\u{110BA}\u{110C2}\u{11100}-\u{11102}\u{11127}-\u{1112B}\u{1112D}-\u{11134}\u{11173}\u{11180}\u{11181}\u{111B6}-\u{111BE}\u{111C9}-\u{111CC}\u{111CF}\u{1122F}-\u{11231}\u{11234}\u{11236}\u{11237}\u{1123E}\u{112DF}\u{112E3}-\u{112EA}\u{11300}\u{11301}\u{1133B}\u{1133C}\u{11340}\u{11366}-\u{1136C}\u{11370}-\u{11374}\u{11438}-\u{1143F}\u{11442}-\u{11444}\u{11446}\u{1145E}\u{114B3}-\u{114B8}\u{114BA}\u{114BF}\u{114C0}\u{114C2}\u{114C3}\u{115B2}-\u{115B5}\u{115BC}\u{115BD}\u{115BF}\u{115C0}\u{115DC}\u{115DD}\u{11633}-\u{1163A}\u{1163D}\u{1163F}\u{11640}\u{116AB}\u{116AD}\u{116B0}-\u{116B5}\u{116B7}\u{1171D}-\u{1171F}\u{11722}-\u{11725}\u{11727}-\u{1172B}\u{1182F}-\u{11837}\u{11839}\u{1183A}\u{1193B}\u{1193C}\u{1193E}\u{11943}\u{119D4}-\u{119D7}\u{119DA}\u{119DB}\u{119E0}\u{11A01}-\u{11A06}\u{11A09}\u{11A0A}\u{11A33}-\u{11A38}\u{11A3B}-\u{11A3E}\u{11A47}\u{11A51}-\u{11A56}\u{11A59}-\u{11A5B}\u{11A8A}-\u{11A96}\u{11A98}\u{11A99}\u{11C30}-\u{11C36}\u{11C38}-\u{11C3D}\u{11C92}-\u{11CA7}\u{11CAA}-\u{11CB0}\u{11CB2}\u{11CB3}\u{11CB5}\u{11CB6}\u{11D31}-\u{11D36}\u{11D3A}\u{11D3C}\u{11D3D}\u{11D3F}-\u{11D45}\u{11D47}\u{11D90}\u{11D91}\u{11D95}\u{11D97}\u{11EF3}\u{11EF4}\u{16AF0}-\u{16AF4}\u{16B30}-\u{16B36}\u{16F4F}\u{16F8F}-\u{16F92}\u{16FE4}\u{1BC9D}\u{1BC9E}\u{1CF00}-\u{1CF2D}\u{1CF30}-\u{1CF46}\u{1D167}-\u{1D169}\u{1D17B}-\u{1D182}\u{1D185}-\u{1D18B}\u{1D1AA}-\u{1D1AD}\u{1D242}-\u{1D244}\u{1DA00}-\u{1DA36}\u{1DA3B}-\u{1DA6C}\u{1DA75}\u{1DA84}\u{1DA9B}-\u{1DA9F}\u{1DAA1}-\u{1DAAF}\u{1E000}-\u{1E006}\u{1E008}-\u{1E018}\u{1E01B}-\u{1E021}\u{1E023}\u{1E024}\u{1E026}-\u{1E02A}\u{1E130}-\u{1E136}\u{1E2AE}\u{1E2EC}-\u{1E2EF}\u{1E8D0}-\u{1E8D6}\u{1E944}-\u{1E94A}\u{E0100}-\u{E01EF}]*$/u;
  const bidiS4EN =
    /[0-9\xB2\xB3\xB9\u06F0-\u06F9\u2070\u2074-\u2079\u2080-\u2089\u2488-\u249B\uFF10-\uFF19\u{102E1}-\u{102FB}\u{1D7CE}-\u{1D7FF}\u{1F100}-\u{1F10A}\u{1FBF0}-\u{1FBF9}]/u;
  const bidiS4AN =
    /[\u0600-\u0605\u0660-\u0669\u066B\u066C\u06DD\u0890\u0891\u08E2\u{10D30}-\u{10D39}\u{10E60}-\u{10E7E}]/u;
  const bidiS5 =
    /^[\0-\x08\x0E-\x1B!-\x84\x86-\u0377\u037A-\u037F\u0384-\u038A\u038C\u038E-\u03A1\u03A3-\u052F\u0531-\u0556\u0559-\u058A\u058D-\u058F\u0591-\u05BD\u05BF\u05C1\u05C2\u05C4\u05C5\u05C7\u0606\u0607\u0609\u060A\u060C\u060E-\u061A\u064B-\u065F\u066A\u0670\u06D6-\u06DC\u06DE-\u06E4\u06E7-\u06ED\u06F0-\u06F9\u0711\u0730-\u074A\u07A6-\u07B0\u07EB-\u07F3\u07F6-\u07F9\u07FD\u0816-\u0819\u081B-\u0823\u0825-\u0827\u0829-\u082D\u0859-\u085B\u0898-\u089F\u08CA-\u08E1\u08E3-\u0983\u0985-\u098C\u098F\u0990\u0993-\u09A8\u09AA-\u09B0\u09B2\u09B6-\u09B9\u09BC-\u09C4\u09C7\u09C8\u09CB-\u09CE\u09D7\u09DC\u09DD\u09DF-\u09E3\u09E6-\u09FE\u0A01-\u0A03\u0A05-\u0A0A\u0A0F\u0A10\u0A13-\u0A28\u0A2A-\u0A30\u0A32\u0A33\u0A35\u0A36\u0A38\u0A39\u0A3C\u0A3E-\u0A42\u0A47\u0A48\u0A4B-\u0A4D\u0A51\u0A59-\u0A5C\u0A5E\u0A66-\u0A76\u0A81-\u0A83\u0A85-\u0A8D\u0A8F-\u0A91\u0A93-\u0AA8\u0AAA-\u0AB0\u0AB2\u0AB3\u0AB5-\u0AB9\u0ABC-\u0AC5\u0AC7-\u0AC9\u0ACB-\u0ACD\u0AD0\u0AE0-\u0AE3\u0AE6-\u0AF1\u0AF9-\u0AFF\u0B01-\u0B03\u0B05-\u0B0C\u0B0F\u0B10\u0B13-\u0B28\u0B2A-\u0B30\u0B32\u0B33\u0B35-\u0B39\u0B3C-\u0B44\u0B47\u0B48\u0B4B-\u0B4D\u0B55-\u0B57\u0B5C\u0B5D\u0B5F-\u0B63\u0B66-\u0B77\u0B82\u0B83\u0B85-\u0B8A\u0B8E-\u0B90\u0B92-\u0B95\u0B99\u0B9A\u0B9C\u0B9E\u0B9F\u0BA3\u0BA4\u0BA8-\u0BAA\u0BAE-\u0BB9\u0BBE-\u0BC2\u0BC6-\u0BC8\u0BCA-\u0BCD\u0BD0\u0BD7\u0BE6-\u0BFA\u0C00-\u0C0C\u0C0E-\u0C10\u0C12-\u0C28\u0C2A-\u0C39\u0C3C-\u0C44\u0C46-\u0C48\u0C4A-\u0C4D\u0C55\u0C56\u0C58-\u0C5A\u0C5D\u0C60-\u0C63\u0C66-\u0C6F\u0C77-\u0C8C\u0C8E-\u0C90\u0C92-\u0CA8\u0CAA-\u0CB3\u0CB5-\u0CB9\u0CBC-\u0CC4\u0CC6-\u0CC8\u0CCA-\u0CCD\u0CD5\u0CD6\u0CDD\u0CDE\u0CE0-\u0CE3\u0CE6-\u0CEF\u0CF1\u0CF2\u0D00-\u0D0C\u0D0E-\u0D10\u0D12-\u0D44\u0D46-\u0D48\u0D4A-\u0D4F\u0D54-\u0D63\u0D66-\u0D7F\u0D81-\u0D83\u0D85-\u0D96\u0D9A-\u0DB1\u0DB3-\u0DBB\u0DBD\u0DC0-\u0DC6\u0DCA\u0DCF-\u0DD4\u0DD6\u0DD8-\u0DDF\u0DE6-\u0DEF\u0DF2-\u0DF4\u0E01-\u0E3A\u0E3F-\u0E5B\u0E81\u0E82\u0E84\u0E86-\u0E8A\u0E8C-\u0EA3\u0EA5\u0EA7-\u0EBD\u0EC0-\u0EC4\u0EC6\u0EC8-\u0ECD\u0ED0-\u0ED9\u0EDC-\u0EDF\u0F00-\u0F47\u0F49-\u0F6C\u0F71-\u0F97\u0F99-\u0FBC\u0FBE-\u0FCC\u0FCE-\u0FDA\u1000-\u10C5\u10C7\u10CD\u10D0-\u1248\u124A-\u124D\u1250-\u1256\u1258\u125A-\u125D\u1260-\u1288\u128A-\u128D\u1290-\u12B0\u12B2-\u12B5\u12B8-\u12BE\u12C0\u12C2-\u12C5\u12C8-\u12D6\u12D8-\u1310\u1312-\u1315\u1318-\u135A\u135D-\u137C\u1380-\u1399\u13A0-\u13F5\u13F8-\u13FD\u1400-\u167F\u1681-\u169C\u16A0-\u16F8\u1700-\u1715\u171F-\u1736\u1740-\u1753\u1760-\u176C\u176E-\u1770\u1772\u1773\u1780-\u17DD\u17E0-\u17E9\u17F0-\u17F9\u1800-\u1819\u1820-\u1878\u1880-\u18AA\u18B0-\u18F5\u1900-\u191E\u1920-\u192B\u1930-\u193B\u1940\u1944-\u196D\u1970-\u1974\u1980-\u19AB\u19B0-\u19C9\u19D0-\u19DA\u19DE-\u1A1B\u1A1E-\u1A5E\u1A60-\u1A7C\u1A7F-\u1A89\u1A90-\u1A99\u1AA0-\u1AAD\u1AB0-\u1ACE\u1B00-\u1B4C\u1B50-\u1B7E\u1B80-\u1BF3\u1BFC-\u1C37\u1C3B-\u1C49\u1C4D-\u1C88\u1C90-\u1CBA\u1CBD-\u1CC7\u1CD0-\u1CFA\u1D00-\u1F15\u1F18-\u1F1D\u1F20-\u1F45\u1F48-\u1F4D\u1F50-\u1F57\u1F59\u1F5B\u1F5D\u1F5F-\u1F7D\u1F80-\u1FB4\u1FB6-\u1FC4\u1FC6-\u1FD3\u1FD6-\u1FDB\u1FDD-\u1FEF\u1FF2-\u1FF4\u1FF6-\u1FFE\u200B-\u200E\u2010-\u2027\u202F-\u205E\u2060-\u2064\u206A-\u2071\u2074-\u208E\u2090-\u209C\u20A0-\u20C0\u20D0-\u20F0\u2100-\u218B\u2190-\u2426\u2440-\u244A\u2460-\u2B73\u2B76-\u2B95\u2B97-\u2CF3\u2CF9-\u2D25\u2D27\u2D2D\u2D30-\u2D67\u2D6F\u2D70\u2D7F-\u2D96\u2DA0-\u2DA6\u2DA8-\u2DAE\u2DB0-\u2DB6\u2DB8-\u2DBE\u2DC0-\u2DC6\u2DC8-\u2DCE\u2DD0-\u2DD6\u2DD8-\u2DDE\u2DE0-\u2E5D\u2E80-\u2E99\u2E9B-\u2EF3\u2F00-\u2FD5\u2FF0-\u2FFB\u3001-\u303F\u3041-\u3096\u3099-\u30FF\u3105-\u312F\u3131-\u318E\u3190-\u31E3\u31F0-\u321E\u3220-\uA48C\uA490-\uA4C6\uA4D0-\uA62B\uA640-\uA6F7\uA700-\uA7CA\uA7D0\uA7D1\uA7D3\uA7D5-\uA7D9\uA7F2-\uA82C\uA830-\uA839\uA840-\uA877\uA880-\uA8C5\uA8CE-\uA8D9\uA8E0-\uA953\uA95F-\uA97C\uA980-\uA9CD\uA9CF-\uA9D9\uA9DE-\uA9FE\uAA00-\uAA36\uAA40-\uAA4D\uAA50-\uAA59\uAA5C-\uAAC2\uAADB-\uAAF6\uAB01-\uAB06\uAB09-\uAB0E\uAB11-\uAB16\uAB20-\uAB26\uAB28-\uAB2E\uAB30-\uAB6B\uAB70-\uABED\uABF0-\uABF9\uAC00-\uD7A3\uD7B0-\uD7C6\uD7CB-\uD7FB\uD800-\uFA6D\uFA70-\uFAD9\uFB00-\uFB06\uFB13-\uFB17\uFB1E\uFB29\uFD3E-\uFD4F\uFDCF\uFDFD-\uFE19\uFE20-\uFE52\uFE54-\uFE66\uFE68-\uFE6B\uFEFF\uFF01-\uFFBE\uFFC2-\uFFC7\uFFCA-\uFFCF\uFFD2-\uFFD7\uFFDA-\uFFDC\uFFE0-\uFFE6\uFFE8-\uFFEE\uFFF9-\uFFFD\u{10000}-\u{1000B}\u{1000D}-\u{10026}\u{10028}-\u{1003A}\u{1003C}\u{1003D}\u{1003F}-\u{1004D}\u{10050}-\u{1005D}\u{10080}-\u{100FA}\u{10100}-\u{10102}\u{10107}-\u{10133}\u{10137}-\u{1018E}\u{10190}-\u{1019C}\u{101A0}\u{101D0}-\u{101FD}\u{10280}-\u{1029C}\u{102A0}-\u{102D0}\u{102E0}-\u{102FB}\u{10300}-\u{10323}\u{1032D}-\u{1034A}\u{10350}-\u{1037A}\u{10380}-\u{1039D}\u{1039F}-\u{103C3}\u{103C8}-\u{103D5}\u{10400}-\u{1049D}\u{104A0}-\u{104A9}\u{104B0}-\u{104D3}\u{104D8}-\u{104FB}\u{10500}-\u{10527}\u{10530}-\u{10563}\u{1056F}-\u{1057A}\u{1057C}-\u{1058A}\u{1058C}-\u{10592}\u{10594}\u{10595}\u{10597}-\u{105A1}\u{105A3}-\u{105B1}\u{105B3}-\u{105B9}\u{105BB}\u{105BC}\u{10600}-\u{10736}\u{10740}-\u{10755}\u{10760}-\u{10767}\u{10780}-\u{10785}\u{10787}-\u{107B0}\u{107B2}-\u{107BA}\u{1091F}\u{10A01}-\u{10A03}\u{10A05}\u{10A06}\u{10A0C}-\u{10A0F}\u{10A38}-\u{10A3A}\u{10A3F}\u{10AE5}\u{10AE6}\u{10B39}-\u{10B3F}\u{10D24}-\u{10D27}\u{10EAB}\u{10EAC}\u{10F46}-\u{10F50}\u{10F82}-\u{10F85}\u{11000}-\u{1104D}\u{11052}-\u{11075}\u{1107F}-\u{110C2}\u{110CD}\u{110D0}-\u{110E8}\u{110F0}-\u{110F9}\u{11100}-\u{11134}\u{11136}-\u{11147}\u{11150}-\u{11176}\u{11180}-\u{111DF}\u{111E1}-\u{111F4}\u{11200}-\u{11211}\u{11213}-\u{1123E}\u{11280}-\u{11286}\u{11288}\u{1128A}-\u{1128D}\u{1128F}-\u{1129D}\u{1129F}-\u{112A9}\u{112B0}-\u{112EA}\u{112F0}-\u{112F9}\u{11300}-\u{11303}\u{11305}-\u{1130C}\u{1130F}\u{11310}\u{11313}-\u{11328}\u{1132A}-\u{11330}\u{11332}\u{11333}\u{11335}-\u{11339}\u{1133B}-\u{11344}\u{11347}\u{11348}\u{1134B}-\u{1134D}\u{11350}\u{11357}\u{1135D}-\u{11363}\u{11366}-\u{1136C}\u{11370}-\u{11374}\u{11400}-\u{1145B}\u{1145D}-\u{11461}\u{11480}-\u{114C7}\u{114D0}-\u{114D9}\u{11580}-\u{115B5}\u{115B8}-\u{115DD}\u{11600}-\u{11644}\u{11650}-\u{11659}\u{11660}-\u{1166C}\u{11680}-\u{116B9}\u{116C0}-\u{116C9}\u{11700}-\u{1171A}\u{1171D}-\u{1172B}\u{11730}-\u{11746}\u{11800}-\u{1183B}\u{118A0}-\u{118F2}\u{118FF}-\u{11906}\u{11909}\u{1190C}-\u{11913}\u{11915}\u{11916}\u{11918}-\u{11935}\u{11937}\u{11938}\u{1193B}-\u{11946}\u{11950}-\u{11959}\u{119A0}-\u{119A7}\u{119AA}-\u{119D7}\u{119DA}-\u{119E4}\u{11A00}-\u{11A47}\u{11A50}-\u{11AA2}\u{11AB0}-\u{11AF8}\u{11C00}-\u{11C08}\u{11C0A}-\u{11C36}\u{11C38}-\u{11C45}\u{11C50}-\u{11C6C}\u{11C70}-\u{11C8F}\u{11C92}-\u{11CA7}\u{11CA9}-\u{11CB6}\u{11D00}-\u{11D06}\u{11D08}\u{11D09}\u{11D0B}-\u{11D36}\u{11D3A}\u{11D3C}\u{11D3D}\u{11D3F}-\u{11D47}\u{11D50}-\u{11D59}\u{11D60}-\u{11D65}\u{11D67}\u{11D68}\u{11D6A}-\u{11D8E}\u{11D90}\u{11D91}\u{11D93}-\u{11D98}\u{11DA0}-\u{11DA9}\u{11EE0}-\u{11EF8}\u{11FB0}\u{11FC0}-\u{11FF1}\u{11FFF}-\u{12399}\u{12400}-\u{1246E}\u{12470}-\u{12474}\u{12480}-\u{12543}\u{12F90}-\u{12FF2}\u{13000}-\u{1342E}\u{13430}-\u{13438}\u{14400}-\u{14646}\u{16800}-\u{16A38}\u{16A40}-\u{16A5E}\u{16A60}-\u{16A69}\u{16A6E}-\u{16ABE}\u{16AC0}-\u{16AC9}\u{16AD0}-\u{16AED}\u{16AF0}-\u{16AF5}\u{16B00}-\u{16B45}\u{16B50}-\u{16B59}\u{16B5B}-\u{16B61}\u{16B63}-\u{16B77}\u{16B7D}-\u{16B8F}\u{16E40}-\u{16E9A}\u{16F00}-\u{16F4A}\u{16F4F}-\u{16F87}\u{16F8F}-\u{16F9F}\u{16FE0}-\u{16FE4}\u{16FF0}\u{16FF1}\u{17000}-\u{187F7}\u{18800}-\u{18CD5}\u{18D00}-\u{18D08}\u{1AFF0}-\u{1AFF3}\u{1AFF5}-\u{1AFFB}\u{1AFFD}\u{1AFFE}\u{1B000}-\u{1B122}\u{1B150}-\u{1B152}\u{1B164}-\u{1B167}\u{1B170}-\u{1B2FB}\u{1BC00}-\u{1BC6A}\u{1BC70}-\u{1BC7C}\u{1BC80}-\u{1BC88}\u{1BC90}-\u{1BC99}\u{1BC9C}-\u{1BCA3}\u{1CF00}-\u{1CF2D}\u{1CF30}-\u{1CF46}\u{1CF50}-\u{1CFC3}\u{1D000}-\u{1D0F5}\u{1D100}-\u{1D126}\u{1D129}-\u{1D1EA}\u{1D200}-\u{1D245}\u{1D2E0}-\u{1D2F3}\u{1D300}-\u{1D356}\u{1D360}-\u{1D378}\u{1D400}-\u{1D454}\u{1D456}-\u{1D49C}\u{1D49E}\u{1D49F}\u{1D4A2}\u{1D4A5}\u{1D4A6}\u{1D4A9}-\u{1D4AC}\u{1D4AE}-\u{1D4B9}\u{1D4BB}\u{1D4BD}-\u{1D4C3}\u{1D4C5}-\u{1D505}\u{1D507}-\u{1D50A}\u{1D50D}-\u{1D514}\u{1D516}-\u{1D51C}\u{1D51E}-\u{1D539}\u{1D53B}-\u{1D53E}\u{1D540}-\u{1D544}\u{1D546}\u{1D54A}-\u{1D550}\u{1D552}-\u{1D6A5}\u{1D6A8}-\u{1D7CB}\u{1D7CE}-\u{1DA8B}\u{1DA9B}-\u{1DA9F}\u{1DAA1}-\u{1DAAF}\u{1DF00}-\u{1DF1E}\u{1E000}-\u{1E006}\u{1E008}-\u{1E018}\u{1E01B}-\u{1E021}\u{1E023}\u{1E024}\u{1E026}-\u{1E02A}\u{1E100}-\u{1E12C}\u{1E130}-\u{1E13D}\u{1E140}-\u{1E149}\u{1E14E}\u{1E14F}\u{1E290}-\u{1E2AE}\u{1E2C0}-\u{1E2F9}\u{1E2FF}\u{1E7E0}-\u{1E7E6}\u{1E7E8}-\u{1E7EB}\u{1E7ED}\u{1E7EE}\u{1E7F0}-\u{1E7FE}\u{1E8D0}-\u{1E8D6}\u{1E944}-\u{1E94A}\u{1EEF0}\u{1EEF1}\u{1F000}-\u{1F02B}\u{1F030}-\u{1F093}\u{1F0A0}-\u{1F0AE}\u{1F0B1}-\u{1F0BF}\u{1F0C1}-\u{1F0CF}\u{1F0D1}-\u{1F0F5}\u{1F100}-\u{1F1AD}\u{1F1E6}-\u{1F202}\u{1F210}-\u{1F23B}\u{1F240}-\u{1F248}\u{1F250}\u{1F251}\u{1F260}-\u{1F265}\u{1F300}-\u{1F6D7}\u{1F6DD}-\u{1F6EC}\u{1F6F0}-\u{1F6FC}\u{1F700}-\u{1F773}\u{1F780}-\u{1F7D8}\u{1F7E0}-\u{1F7EB}\u{1F7F0}\u{1F800}-\u{1F80B}\u{1F810}-\u{1F847}\u{1F850}-\u{1F859}\u{1F860}-\u{1F887}\u{1F890}-\u{1F8AD}\u{1F8B0}\u{1F8B1}\u{1F900}-\u{1FA53}\u{1FA60}-\u{1FA6D}\u{1FA70}-\u{1FA74}\u{1FA78}-\u{1FA7C}\u{1FA80}-\u{1FA86}\u{1FA90}-\u{1FAAC}\u{1FAB0}-\u{1FABA}\u{1FAC0}-\u{1FAC5}\u{1FAD0}-\u{1FAD9}\u{1FAE0}-\u{1FAE7}\u{1FAF0}-\u{1FAF6}\u{1FB00}-\u{1FB92}\u{1FB94}-\u{1FBCA}\u{1FBF0}-\u{1FBF9}\u{20000}-\u{2A6DF}\u{2A700}-\u{2B738}\u{2B740}-\u{2B81D}\u{2B820}-\u{2CEA1}\u{2CEB0}-\u{2EBE0}\u{2F800}-\u{2FA1D}\u{30000}-\u{3134A}\u{E0001}\u{E0020}-\u{E007F}\u{E0100}-\u{E01EF}\u{F0000}-\u{FFFFD}\u{100000}-\u{10FFFD}]*$/u;
  const bidiS6 =
    /[0-9A-Za-z\xAA\xB2\xB3\xB5\xB9\xBA\xC0-\xD6\xD8-\xF6\xF8-\u02B8\u02BB-\u02C1\u02D0\u02D1\u02E0-\u02E4\u02EE\u0370-\u0373\u0376\u0377\u037A-\u037D\u037F\u0386\u0388-\u038A\u038C\u038E-\u03A1\u03A3-\u03F5\u03F7-\u0482\u048A-\u052F\u0531-\u0556\u0559-\u0589\u06F0-\u06F9\u0903-\u0939\u093B\u093D-\u0940\u0949-\u094C\u094E-\u0950\u0958-\u0961\u0964-\u0980\u0982\u0983\u0985-\u098C\u098F\u0990\u0993-\u09A8\u09AA-\u09B0\u09B2\u09B6-\u09B9\u09BD-\u09C0\u09C7\u09C8\u09CB\u09CC\u09CE\u09D7\u09DC\u09DD\u09DF-\u09E1\u09E6-\u09F1\u09F4-\u09FA\u09FC\u09FD\u0A03\u0A05-\u0A0A\u0A0F\u0A10\u0A13-\u0A28\u0A2A-\u0A30\u0A32\u0A33\u0A35\u0A36\u0A38\u0A39\u0A3E-\u0A40\u0A59-\u0A5C\u0A5E\u0A66-\u0A6F\u0A72-\u0A74\u0A76\u0A83\u0A85-\u0A8D\u0A8F-\u0A91\u0A93-\u0AA8\u0AAA-\u0AB0\u0AB2\u0AB3\u0AB5-\u0AB9\u0ABD-\u0AC0\u0AC9\u0ACB\u0ACC\u0AD0\u0AE0\u0AE1\u0AE6-\u0AF0\u0AF9\u0B02\u0B03\u0B05-\u0B0C\u0B0F\u0B10\u0B13-\u0B28\u0B2A-\u0B30\u0B32\u0B33\u0B35-\u0B39\u0B3D\u0B3E\u0B40\u0B47\u0B48\u0B4B\u0B4C\u0B57\u0B5C\u0B5D\u0B5F-\u0B61\u0B66-\u0B77\u0B83\u0B85-\u0B8A\u0B8E-\u0B90\u0B92-\u0B95\u0B99\u0B9A\u0B9C\u0B9E\u0B9F\u0BA3\u0BA4\u0BA8-\u0BAA\u0BAE-\u0BB9\u0BBE\u0BBF\u0BC1\u0BC2\u0BC6-\u0BC8\u0BCA-\u0BCC\u0BD0\u0BD7\u0BE6-\u0BF2\u0C01-\u0C03\u0C05-\u0C0C\u0C0E-\u0C10\u0C12-\u0C28\u0C2A-\u0C39\u0C3D\u0C41-\u0C44\u0C58-\u0C5A\u0C5D\u0C60\u0C61\u0C66-\u0C6F\u0C77\u0C7F\u0C80\u0C82-\u0C8C\u0C8E-\u0C90\u0C92-\u0CA8\u0CAA-\u0CB3\u0CB5-\u0CB9\u0CBD-\u0CC4\u0CC6-\u0CC8\u0CCA\u0CCB\u0CD5\u0CD6\u0CDD\u0CDE\u0CE0\u0CE1\u0CE6-\u0CEF\u0CF1\u0CF2\u0D02-\u0D0C\u0D0E-\u0D10\u0D12-\u0D3A\u0D3D-\u0D40\u0D46-\u0D48\u0D4A-\u0D4C\u0D4E\u0D4F\u0D54-\u0D61\u0D66-\u0D7F\u0D82\u0D83\u0D85-\u0D96\u0D9A-\u0DB1\u0DB3-\u0DBB\u0DBD\u0DC0-\u0DC6\u0DCF-\u0DD1\u0DD8-\u0DDF\u0DE6-\u0DEF\u0DF2-\u0DF4\u0E01-\u0E30\u0E32\u0E33\u0E40-\u0E46\u0E4F-\u0E5B\u0E81\u0E82\u0E84\u0E86-\u0E8A\u0E8C-\u0EA3\u0EA5\u0EA7-\u0EB0\u0EB2\u0EB3\u0EBD\u0EC0-\u0EC4\u0EC6\u0ED0-\u0ED9\u0EDC-\u0EDF\u0F00-\u0F17\u0F1A-\u0F34\u0F36\u0F38\u0F3E-\u0F47\u0F49-\u0F6C\u0F7F\u0F85\u0F88-\u0F8C\u0FBE-\u0FC5\u0FC7-\u0FCC\u0FCE-\u0FDA\u1000-\u102C\u1031\u1038\u103B\u103C\u103F-\u1057\u105A-\u105D\u1061-\u1070\u1075-\u1081\u1083\u1084\u1087-\u108C\u108E-\u109C\u109E-\u10C5\u10C7\u10CD\u10D0-\u1248\u124A-\u124D\u1250-\u1256\u1258\u125A-\u125D\u1260-\u1288\u128A-\u128D\u1290-\u12B0\u12B2-\u12B5\u12B8-\u12BE\u12C0\u12C2-\u12C5\u12C8-\u12D6\u12D8-\u1310\u1312-\u1315\u1318-\u135A\u1360-\u137C\u1380-\u138F\u13A0-\u13F5\u13F8-\u13FD\u1401-\u167F\u1681-\u169A\u16A0-\u16F8\u1700-\u1711\u1715\u171F-\u1731\u1734-\u1736\u1740-\u1751\u1760-\u176C\u176E-\u1770\u1780-\u17B3\u17B6\u17BE-\u17C5\u17C7\u17C8\u17D4-\u17DA\u17DC\u17E0-\u17E9\u1810-\u1819\u1820-\u1878\u1880-\u1884\u1887-\u18A8\u18AA\u18B0-\u18F5\u1900-\u191E\u1923-\u1926\u1929-\u192B\u1930\u1931\u1933-\u1938\u1946-\u196D\u1970-\u1974\u1980-\u19AB\u19B0-\u19C9\u19D0-\u19DA\u1A00-\u1A16\u1A19\u1A1A\u1A1E-\u1A55\u1A57\u1A61\u1A63\u1A64\u1A6D-\u1A72\u1A80-\u1A89\u1A90-\u1A99\u1AA0-\u1AAD\u1B04-\u1B33\u1B35\u1B3B\u1B3D-\u1B41\u1B43-\u1B4C\u1B50-\u1B6A\u1B74-\u1B7E\u1B82-\u1BA1\u1BA6\u1BA7\u1BAA\u1BAE-\u1BE5\u1BE7\u1BEA-\u1BEC\u1BEE\u1BF2\u1BF3\u1BFC-\u1C2B\u1C34\u1C35\u1C3B-\u1C49\u1C4D-\u1C88\u1C90-\u1CBA\u1CBD-\u1CC7\u1CD3\u1CE1\u1CE9-\u1CEC\u1CEE-\u1CF3\u1CF5-\u1CF7\u1CFA\u1D00-\u1DBF\u1E00-\u1F15\u1F18-\u1F1D\u1F20-\u1F45\u1F48-\u1F4D\u1F50-\u1F57\u1F59\u1F5B\u1F5D\u1F5F-\u1F7D\u1F80-\u1FB4\u1FB6-\u1FBC\u1FBE\u1FC2-\u1FC4\u1FC6-\u1FCC\u1FD0-\u1FD3\u1FD6-\u1FDB\u1FE0-\u1FEC\u1FF2-\u1FF4\u1FF6-\u1FFC\u200E\u2070\u2071\u2074-\u2079\u207F-\u2089\u2090-\u209C\u2102\u2107\u210A-\u2113\u2115\u2119-\u211D\u2124\u2126\u2128\u212A-\u212D\u212F-\u2139\u213C-\u213F\u2145-\u2149\u214E\u214F\u2160-\u2188\u2336-\u237A\u2395\u2488-\u24E9\u26AC\u2800-\u28FF\u2C00-\u2CE4\u2CEB-\u2CEE\u2CF2\u2CF3\u2D00-\u2D25\u2D27\u2D2D\u2D30-\u2D67\u2D6F\u2D70\u2D80-\u2D96\u2DA0-\u2DA6\u2DA8-\u2DAE\u2DB0-\u2DB6\u2DB8-\u2DBE\u2DC0-\u2DC6\u2DC8-\u2DCE\u2DD0-\u2DD6\u2DD8-\u2DDE\u3005-\u3007\u3021-\u3029\u302E\u302F\u3031-\u3035\u3038-\u303C\u3041-\u3096\u309D-\u309F\u30A1-\u30FA\u30FC-\u30FF\u3105-\u312F\u3131-\u318E\u3190-\u31BF\u31F0-\u321C\u3220-\u324F\u3260-\u327B\u327F-\u32B0\u32C0-\u32CB\u32D0-\u3376\u337B-\u33DD\u33E0-\u33FE\u3400-\u4DBF\u4E00-\uA48C\uA4D0-\uA60C\uA610-\uA62B\uA640-\uA66E\uA680-\uA69D\uA6A0-\uA6EF\uA6F2-\uA6F7\uA722-\uA787\uA789-\uA7CA\uA7D0\uA7D1\uA7D3\uA7D5-\uA7D9\uA7F2-\uA801\uA803-\uA805\uA807-\uA80A\uA80C-\uA824\uA827\uA830-\uA837\uA840-\uA873\uA880-\uA8C3\uA8CE-\uA8D9\uA8F2-\uA8FE\uA900-\uA925\uA92E-\uA946\uA952\uA953\uA95F-\uA97C\uA983-\uA9B2\uA9B4\uA9B5\uA9BA\uA9BB\uA9BE-\uA9CD\uA9CF-\uA9D9\uA9DE-\uA9E4\uA9E6-\uA9FE\uAA00-\uAA28\uAA2F\uAA30\uAA33\uAA34\uAA40-\uAA42\uAA44-\uAA4B\uAA4D\uAA50-\uAA59\uAA5C-\uAA7B\uAA7D-\uAAAF\uAAB1\uAAB5\uAAB6\uAAB9-\uAABD\uAAC0\uAAC2\uAADB-\uAAEB\uAAEE-\uAAF5\uAB01-\uAB06\uAB09-\uAB0E\uAB11-\uAB16\uAB20-\uAB26\uAB28-\uAB2E\uAB30-\uAB69\uAB70-\uABE4\uABE6\uABE7\uABE9-\uABEC\uABF0-\uABF9\uAC00-\uD7A3\uD7B0-\uD7C6\uD7CB-\uD7FB\uD800-\uFA6D\uFA70-\uFAD9\uFB00-\uFB06\uFB13-\uFB17\uFF10-\uFF19\uFF21-\uFF3A\uFF41-\uFF5A\uFF66-\uFFBE\uFFC2-\uFFC7\uFFCA-\uFFCF\uFFD2-\uFFD7\uFFDA-\uFFDC\u{10000}-\u{1000B}\u{1000D}-\u{10026}\u{10028}-\u{1003A}\u{1003C}\u{1003D}\u{1003F}-\u{1004D}\u{10050}-\u{1005D}\u{10080}-\u{100FA}\u{10100}\u{10102}\u{10107}-\u{10133}\u{10137}-\u{1013F}\u{1018D}\u{1018E}\u{101D0}-\u{101FC}\u{10280}-\u{1029C}\u{102A0}-\u{102D0}\u{102E1}-\u{102FB}\u{10300}-\u{10323}\u{1032D}-\u{1034A}\u{10350}-\u{10375}\u{10380}-\u{1039D}\u{1039F}-\u{103C3}\u{103C8}-\u{103D5}\u{10400}-\u{1049D}\u{104A0}-\u{104A9}\u{104B0}-\u{104D3}\u{104D8}-\u{104FB}\u{10500}-\u{10527}\u{10530}-\u{10563}\u{1056F}-\u{1057A}\u{1057C}-\u{1058A}\u{1058C}-\u{10592}\u{10594}\u{10595}\u{10597}-\u{105A1}\u{105A3}-\u{105B1}\u{105B3}-\u{105B9}\u{105BB}\u{105BC}\u{10600}-\u{10736}\u{10740}-\u{10755}\u{10760}-\u{10767}\u{10780}-\u{10785}\u{10787}-\u{107B0}\u{107B2}-\u{107BA}\u{11000}\u{11002}-\u{11037}\u{11047}-\u{1104D}\u{11066}-\u{1106F}\u{11071}\u{11072}\u{11075}\u{11082}-\u{110B2}\u{110B7}\u{110B8}\u{110BB}-\u{110C1}\u{110CD}\u{110D0}-\u{110E8}\u{110F0}-\u{110F9}\u{11103}-\u{11126}\u{1112C}\u{11136}-\u{11147}\u{11150}-\u{11172}\u{11174}-\u{11176}\u{11182}-\u{111B5}\u{111BF}-\u{111C8}\u{111CD}\u{111CE}\u{111D0}-\u{111DF}\u{111E1}-\u{111F4}\u{11200}-\u{11211}\u{11213}-\u{1122E}\u{11232}\u{11233}\u{11235}\u{11238}-\u{1123D}\u{11280}-\u{11286}\u{11288}\u{1128A}-\u{1128D}\u{1128F}-\u{1129D}\u{1129F}-\u{112A9}\u{112B0}-\u{112DE}\u{112E0}-\u{112E2}\u{112F0}-\u{112F9}\u{11302}\u{11303}\u{11305}-\u{1130C}\u{1130F}\u{11310}\u{11313}-\u{11328}\u{1132A}-\u{11330}\u{11332}\u{11333}\u{11335}-\u{11339}\u{1133D}-\u{1133F}\u{11341}-\u{11344}\u{11347}\u{11348}\u{1134B}-\u{1134D}\u{11350}\u{11357}\u{1135D}-\u{11363}\u{11400}-\u{11437}\u{11440}\u{11441}\u{11445}\u{11447}-\u{1145B}\u{1145D}\u{1145F}-\u{11461}\u{11480}-\u{114B2}\u{114B9}\u{114BB}-\u{114BE}\u{114C1}\u{114C4}-\u{114C7}\u{114D0}-\u{114D9}\u{11580}-\u{115B1}\u{115B8}-\u{115BB}\u{115BE}\u{115C1}-\u{115DB}\u{11600}-\u{11632}\u{1163B}\u{1163C}\u{1163E}\u{11641}-\u{11644}\u{11650}-\u{11659}\u{11680}-\u{116AA}\u{116AC}\u{116AE}\u{116AF}\u{116B6}\u{116B8}\u{116B9}\u{116C0}-\u{116C9}\u{11700}-\u{1171A}\u{11720}\u{11721}\u{11726}\u{11730}-\u{11746}\u{11800}-\u{1182E}\u{11838}\u{1183B}\u{118A0}-\u{118F2}\u{118FF}-\u{11906}\u{11909}\u{1190C}-\u{11913}\u{11915}\u{11916}\u{11918}-\u{11935}\u{11937}\u{11938}\u{1193D}\u{1193F}-\u{11942}\u{11944}-\u{11946}\u{11950}-\u{11959}\u{119A0}-\u{119A7}\u{119AA}-\u{119D3}\u{119DC}-\u{119DF}\u{119E1}-\u{119E4}\u{11A00}\u{11A07}\u{11A08}\u{11A0B}-\u{11A32}\u{11A39}\u{11A3A}\u{11A3F}-\u{11A46}\u{11A50}\u{11A57}\u{11A58}\u{11A5C}-\u{11A89}\u{11A97}\u{11A9A}-\u{11AA2}\u{11AB0}-\u{11AF8}\u{11C00}-\u{11C08}\u{11C0A}-\u{11C2F}\u{11C3E}-\u{11C45}\u{11C50}-\u{11C6C}\u{11C70}-\u{11C8F}\u{11CA9}\u{11CB1}\u{11CB4}\u{11D00}-\u{11D06}\u{11D08}\u{11D09}\u{11D0B}-\u{11D30}\u{11D46}\u{11D50}-\u{11D59}\u{11D60}-\u{11D65}\u{11D67}\u{11D68}\u{11D6A}-\u{11D8E}\u{11D93}\u{11D94}\u{11D96}\u{11D98}\u{11DA0}-\u{11DA9}\u{11EE0}-\u{11EF2}\u{11EF5}-\u{11EF8}\u{11FB0}\u{11FC0}-\u{11FD4}\u{11FFF}-\u{12399}\u{12400}-\u{1246E}\u{12470}-\u{12474}\u{12480}-\u{12543}\u{12F90}-\u{12FF2}\u{13000}-\u{1342E}\u{13430}-\u{13438}\u{14400}-\u{14646}\u{16800}-\u{16A38}\u{16A40}-\u{16A5E}\u{16A60}-\u{16A69}\u{16A6E}-\u{16ABE}\u{16AC0}-\u{16AC9}\u{16AD0}-\u{16AED}\u{16AF5}\u{16B00}-\u{16B2F}\u{16B37}-\u{16B45}\u{16B50}-\u{16B59}\u{16B5B}-\u{16B61}\u{16B63}-\u{16B77}\u{16B7D}-\u{16B8F}\u{16E40}-\u{16E9A}\u{16F00}-\u{16F4A}\u{16F50}-\u{16F87}\u{16F93}-\u{16F9F}\u{16FE0}\u{16FE1}\u{16FE3}\u{16FF0}\u{16FF1}\u{17000}-\u{187F7}\u{18800}-\u{18CD5}\u{18D00}-\u{18D08}\u{1AFF0}-\u{1AFF3}\u{1AFF5}-\u{1AFFB}\u{1AFFD}\u{1AFFE}\u{1B000}-\u{1B122}\u{1B150}-\u{1B152}\u{1B164}-\u{1B167}\u{1B170}-\u{1B2FB}\u{1BC00}-\u{1BC6A}\u{1BC70}-\u{1BC7C}\u{1BC80}-\u{1BC88}\u{1BC90}-\u{1BC99}\u{1BC9C}\u{1BC9F}\u{1CF50}-\u{1CFC3}\u{1D000}-\u{1D0F5}\u{1D100}-\u{1D126}\u{1D129}-\u{1D166}\u{1D16A}-\u{1D172}\u{1D183}\u{1D184}\u{1D18C}-\u{1D1A9}\u{1D1AE}-\u{1D1E8}\u{1D2E0}-\u{1D2F3}\u{1D360}-\u{1D378}\u{1D400}-\u{1D454}\u{1D456}-\u{1D49C}\u{1D49E}\u{1D49F}\u{1D4A2}\u{1D4A5}\u{1D4A6}\u{1D4A9}-\u{1D4AC}\u{1D4AE}-\u{1D4B9}\u{1D4BB}\u{1D4BD}-\u{1D4C3}\u{1D4C5}-\u{1D505}\u{1D507}-\u{1D50A}\u{1D50D}-\u{1D514}\u{1D516}-\u{1D51C}\u{1D51E}-\u{1D539}\u{1D53B}-\u{1D53E}\u{1D540}-\u{1D544}\u{1D546}\u{1D54A}-\u{1D550}\u{1D552}-\u{1D6A5}\u{1D6A8}-\u{1D6DA}\u{1D6DC}-\u{1D714}\u{1D716}-\u{1D74E}\u{1D750}-\u{1D788}\u{1D78A}-\u{1D7C2}\u{1D7C4}-\u{1D7CB}\u{1D7CE}-\u{1D9FF}\u{1DA37}-\u{1DA3A}\u{1DA6D}-\u{1DA74}\u{1DA76}-\u{1DA83}\u{1DA85}-\u{1DA8B}\u{1DF00}-\u{1DF1E}\u{1E100}-\u{1E12C}\u{1E137}-\u{1E13D}\u{1E140}-\u{1E149}\u{1E14E}\u{1E14F}\u{1E290}-\u{1E2AD}\u{1E2C0}-\u{1E2EB}\u{1E2F0}-\u{1E2F9}\u{1E7E0}-\u{1E7E6}\u{1E7E8}-\u{1E7EB}\u{1E7ED}\u{1E7EE}\u{1E7F0}-\u{1E7FE}\u{1F100}-\u{1F10A}\u{1F110}-\u{1F12E}\u{1F130}-\u{1F169}\u{1F170}-\u{1F1AC}\u{1F1E6}-\u{1F202}\u{1F210}-\u{1F23B}\u{1F240}-\u{1F248}\u{1F250}\u{1F251}\u{1FBF0}-\u{1FBF9}\u{20000}-\u{2A6DF}\u{2A700}-\u{2B738}\u{2B740}-\u{2B81D}\u{2B820}-\u{2CEA1}\u{2CEB0}-\u{2EBE0}\u{2F800}-\u{2FA1D}\u{30000}-\u{3134A}\u{F0000}-\u{FFFFD}\u{100000}-\u{10FFFD}][\u0300-\u036F\u0483-\u0489\u0591-\u05BD\u05BF\u05C1\u05C2\u05C4\u05C5\u05C7\u0610-\u061A\u064B-\u065F\u0670\u06D6-\u06DC\u06DF-\u06E4\u06E7\u06E8\u06EA-\u06ED\u0711\u0730-\u074A\u07A6-\u07B0\u07EB-\u07F3\u07FD\u0816-\u0819\u081B-\u0823\u0825-\u0827\u0829-\u082D\u0859-\u085B\u0898-\u089F\u08CA-\u08E1\u08E3-\u0902\u093A\u093C\u0941-\u0948\u094D\u0951-\u0957\u0962\u0963\u0981\u09BC\u09C1-\u09C4\u09CD\u09E2\u09E3\u09FE\u0A01\u0A02\u0A3C\u0A41\u0A42\u0A47\u0A48\u0A4B-\u0A4D\u0A51\u0A70\u0A71\u0A75\u0A81\u0A82\u0ABC\u0AC1-\u0AC5\u0AC7\u0AC8\u0ACD\u0AE2\u0AE3\u0AFA-\u0AFF\u0B01\u0B3C\u0B3F\u0B41-\u0B44\u0B4D\u0B55\u0B56\u0B62\u0B63\u0B82\u0BC0\u0BCD\u0C00\u0C04\u0C3C\u0C3E-\u0C40\u0C46-\u0C48\u0C4A-\u0C4D\u0C55\u0C56\u0C62\u0C63\u0C81\u0CBC\u0CCC\u0CCD\u0CE2\u0CE3\u0D00\u0D01\u0D3B\u0D3C\u0D41-\u0D44\u0D4D\u0D62\u0D63\u0D81\u0DCA\u0DD2-\u0DD4\u0DD6\u0E31\u0E34-\u0E3A\u0E47-\u0E4E\u0EB1\u0EB4-\u0EBC\u0EC8-\u0ECD\u0F18\u0F19\u0F35\u0F37\u0F39\u0F71-\u0F7E\u0F80-\u0F84\u0F86\u0F87\u0F8D-\u0F97\u0F99-\u0FBC\u0FC6\u102D-\u1030\u1032-\u1037\u1039\u103A\u103D\u103E\u1058\u1059\u105E-\u1060\u1071-\u1074\u1082\u1085\u1086\u108D\u109D\u135D-\u135F\u1712-\u1714\u1732\u1733\u1752\u1753\u1772\u1773\u17B4\u17B5\u17B7-\u17BD\u17C6\u17C9-\u17D3\u17DD\u180B-\u180D\u180F\u1885\u1886\u18A9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193B\u1A17\u1A18\u1A1B\u1A56\u1A58-\u1A5E\u1A60\u1A62\u1A65-\u1A6C\u1A73-\u1A7C\u1A7F\u1AB0-\u1ACE\u1B00-\u1B03\u1B34\u1B36-\u1B3A\u1B3C\u1B42\u1B6B-\u1B73\u1B80\u1B81\u1BA2-\u1BA5\u1BA8\u1BA9\u1BAB-\u1BAD\u1BE6\u1BE8\u1BE9\u1BED\u1BEF-\u1BF1\u1C2C-\u1C33\u1C36\u1C37\u1CD0-\u1CD2\u1CD4-\u1CE0\u1CE2-\u1CE8\u1CED\u1CF4\u1CF8\u1CF9\u1DC0-\u1DFF\u20D0-\u20F0\u2CEF-\u2CF1\u2D7F\u2DE0-\u2DFF\u302A-\u302D\u3099\u309A\uA66F-\uA672\uA674-\uA67D\uA69E\uA69F\uA6F0\uA6F1\uA802\uA806\uA80B\uA825\uA826\uA82C\uA8C4\uA8C5\uA8E0-\uA8F1\uA8FF\uA926-\uA92D\uA947-\uA951\uA980-\uA982\uA9B3\uA9B6-\uA9B9\uA9BC\uA9BD\uA9E5\uAA29-\uAA2E\uAA31\uAA32\uAA35\uAA36\uAA43\uAA4C\uAA7C\uAAB0\uAAB2-\uAAB4\uAAB7\uAAB8\uAABE\uAABF\uAAC1\uAAEC\uAAED\uAAF6\uABE5\uABE8\uABED\uFB1E\uFE00-\uFE0F\uFE20-\uFE2F\u{101FD}\u{102E0}\u{10376}-\u{1037A}\u{10A01}-\u{10A03}\u{10A05}\u{10A06}\u{10A0C}-\u{10A0F}\u{10A38}-\u{10A3A}\u{10A3F}\u{10AE5}\u{10AE6}\u{10D24}-\u{10D27}\u{10EAB}\u{10EAC}\u{10F46}-\u{10F50}\u{10F82}-\u{10F85}\u{11001}\u{11038}-\u{11046}\u{11070}\u{11073}\u{11074}\u{1107F}-\u{11081}\u{110B3}-\u{110B6}\u{110B9}\u{110BA}\u{110C2}\u{11100}-\u{11102}\u{11127}-\u{1112B}\u{1112D}-\u{11134}\u{11173}\u{11180}\u{11181}\u{111B6}-\u{111BE}\u{111C9}-\u{111CC}\u{111CF}\u{1122F}-\u{11231}\u{11234}\u{11236}\u{11237}\u{1123E}\u{112DF}\u{112E3}-\u{112EA}\u{11300}\u{11301}\u{1133B}\u{1133C}\u{11340}\u{11366}-\u{1136C}\u{11370}-\u{11374}\u{11438}-\u{1143F}\u{11442}-\u{11444}\u{11446}\u{1145E}\u{114B3}-\u{114B8}\u{114BA}\u{114BF}\u{114C0}\u{114C2}\u{114C3}\u{115B2}-\u{115B5}\u{115BC}\u{115BD}\u{115BF}\u{115C0}\u{115DC}\u{115DD}\u{11633}-\u{1163A}\u{1163D}\u{1163F}\u{11640}\u{116AB}\u{116AD}\u{116B0}-\u{116B5}\u{116B7}\u{1171D}-\u{1171F}\u{11722}-\u{11725}\u{11727}-\u{1172B}\u{1182F}-\u{11837}\u{11839}\u{1183A}\u{1193B}\u{1193C}\u{1193E}\u{11943}\u{119D4}-\u{119D7}\u{119DA}\u{119DB}\u{119E0}\u{11A01}-\u{11A06}\u{11A09}\u{11A0A}\u{11A33}-\u{11A38}\u{11A3B}-\u{11A3E}\u{11A47}\u{11A51}-\u{11A56}\u{11A59}-\u{11A5B}\u{11A8A}-\u{11A96}\u{11A98}\u{11A99}\u{11C30}-\u{11C36}\u{11C38}-\u{11C3D}\u{11C92}-\u{11CA7}\u{11CAA}-\u{11CB0}\u{11CB2}\u{11CB3}\u{11CB5}\u{11CB6}\u{11D31}-\u{11D36}\u{11D3A}\u{11D3C}\u{11D3D}\u{11D3F}-\u{11D45}\u{11D47}\u{11D90}\u{11D91}\u{11D95}\u{11D97}\u{11EF3}\u{11EF4}\u{16AF0}-\u{16AF4}\u{16B30}-\u{16B36}\u{16F4F}\u{16F8F}-\u{16F92}\u{16FE4}\u{1BC9D}\u{1BC9E}\u{1CF00}-\u{1CF2D}\u{1CF30}-\u{1CF46}\u{1D167}-\u{1D169}\u{1D17B}-\u{1D182}\u{1D185}-\u{1D18B}\u{1D1AA}-\u{1D1AD}\u{1D242}-\u{1D244}\u{1DA00}-\u{1DA36}\u{1DA3B}-\u{1DA6C}\u{1DA75}\u{1DA84}\u{1DA9B}-\u{1DA9F}\u{1DAA1}-\u{1DAAF}\u{1E000}-\u{1E006}\u{1E008}-\u{1E018}\u{1E01B}-\u{1E021}\u{1E023}\u{1E024}\u{1E026}-\u{1E02A}\u{1E130}-\u{1E136}\u{1E2AE}\u{1E2EC}-\u{1E2EF}\u{1E8D0}-\u{1E8D6}\u{1E944}-\u{1E94A}\u{E0100}-\u{E01EF}]*$/u;

  regexes = {
    combiningMarks,
    combiningClassVirama,
    validZWNJ,
    bidiDomain,
    bidiS1LTR,
    bidiS1RTL,
    bidiS2,
    bidiS3,
    bidiS4EN,
    bidiS4AN,
    bidiS5,
    bidiS6,
  };
  return regexes;
}

const require$$2 = [
  [[0, 44], 4],
  [[45, 46], 2],
  [47, 4],
  [[48, 57], 2],
  [[58, 64], 4],
  [65, 1, "a"],
  [66, 1, "b"],
  [67, 1, "c"],
  [68, 1, "d"],
  [69, 1, "e"],
  [70, 1, "f"],
  [71, 1, "g"],
  [72, 1, "h"],
  [73, 1, "i"],
  [74, 1, "j"],
  [75, 1, "k"],
  [76, 1, "l"],
  [77, 1, "m"],
  [78, 1, "n"],
  [79, 1, "o"],
  [80, 1, "p"],
  [81, 1, "q"],
  [82, 1, "r"],
  [83, 1, "s"],
  [84, 1, "t"],
  [85, 1, "u"],
  [86, 1, "v"],
  [87, 1, "w"],
  [88, 1, "x"],
  [89, 1, "y"],
  [90, 1, "z"],
  [[91, 96], 4],
  [[97, 122], 2],
  [[123, 127], 4],
  [[128, 159], 3],
  [160, 5, " "],
  [[161, 167], 2],
  [168, 5, " "],
  [169, 2],
  [170, 1, "a"],
  [[171, 172], 2],
  [173, 7],
  [174, 2],
  [175, 5, " "],
  [[176, 177], 2],
  [178, 1, "2"],
  [179, 1, "3"],
  [180, 5, " "],
  [181, 1, ""],
  [182, 2],
  [183, 2],
  [184, 5, " "],
  [185, 1, "1"],
  [186, 1, "o"],
  [187, 2],
  [188, 1, "14"],
  [189, 1, "12"],
  [190, 1, "34"],
  [191, 2],
  [192, 1, ""],
  [193, 1, ""],
  [194, 1, ""],
  [195, 1, ""],
  [196, 1, ""],
  [197, 1, ""],
  [198, 1, ""],
  [199, 1, ""],
  [200, 1, ""],
  [201, 1, ""],
  [202, 1, ""],
  [203, 1, ""],
  [204, 1, ""],
  [205, 1, ""],
  [206, 1, ""],
  [207, 1, ""],
  [208, 1, ""],
  [209, 1, ""],
  [210, 1, ""],
  [211, 1, ""],
  [212, 1, ""],
  [213, 1, ""],
  [214, 1, ""],
  [215, 2],
  [216, 1, ""],
  [217, 1, ""],
  [218, 1, ""],
  [219, 1, ""],
  [220, 1, ""],
  [221, 1, ""],
  [222, 1, ""],
  [223, 6, "ss"],
  [[224, 246], 2],
  [247, 2],
  [[248, 255], 2],
  [256, 1, ""],
  [257, 2],
  [258, 1, ""],
  [259, 2],
  [260, 1, ""],
  [261, 2],
  [262, 1, ""],
  [263, 2],
  [264, 1, ""],
  [265, 2],
  [266, 1, ""],
  [267, 2],
  [268, 1, ""],
  [269, 2],
  [270, 1, ""],
  [271, 2],
  [272, 1, ""],
  [273, 2],
  [274, 1, ""],
  [275, 2],
  [276, 1, ""],
  [277, 2],
  [278, 1, ""],
  [279, 2],
  [280, 1, ""],
  [281, 2],
  [282, 1, ""],
  [283, 2],
  [284, 1, ""],
  [285, 2],
  [286, 1, ""],
  [287, 2],
  [288, 1, ""],
  [289, 2],
  [290, 1, ""],
  [291, 2],
  [292, 1, ""],
  [293, 2],
  [294, 1, ""],
  [295, 2],
  [296, 1, ""],
  [297, 2],
  [298, 1, ""],
  [299, 2],
  [300, 1, ""],
  [301, 2],
  [302, 1, ""],
  [303, 2],
  [304, 1, "i"],
  [305, 2],
  [[306, 307], 1, "ij"],
  [308, 1, ""],
  [309, 2],
  [310, 1, ""],
  [[311, 312], 2],
  [313, 1, ""],
  [314, 2],
  [315, 1, ""],
  [316, 2],
  [317, 1, ""],
  [318, 2],
  [[319, 320], 1, "l"],
  [321, 1, ""],
  [322, 2],
  [323, 1, ""],
  [324, 2],
  [325, 1, ""],
  [326, 2],
  [327, 1, ""],
  [328, 2],
  [329, 1, "n"],
  [330, 1, ""],
  [331, 2],
  [332, 1, ""],
  [333, 2],
  [334, 1, ""],
  [335, 2],
  [336, 1, ""],
  [337, 2],
  [338, 1, ""],
  [339, 2],
  [340, 1, ""],
  [341, 2],
  [342, 1, ""],
  [343, 2],
  [344, 1, ""],
  [345, 2],
  [346, 1, ""],
  [347, 2],
  [348, 1, ""],
  [349, 2],
  [350, 1, ""],
  [351, 2],
  [352, 1, ""],
  [353, 2],
  [354, 1, ""],
  [355, 2],
  [356, 1, ""],
  [357, 2],
  [358, 1, ""],
  [359, 2],
  [360, 1, ""],
  [361, 2],
  [362, 1, ""],
  [363, 2],
  [364, 1, ""],
  [365, 2],
  [366, 1, ""],
  [367, 2],
  [368, 1, ""],
  [369, 2],
  [370, 1, ""],
  [371, 2],
  [372, 1, ""],
  [373, 2],
  [374, 1, ""],
  [375, 2],
  [376, 1, ""],
  [377, 1, ""],
  [378, 2],
  [379, 1, ""],
  [380, 2],
  [381, 1, ""],
  [382, 2],
  [383, 1, "s"],
  [384, 2],
  [385, 1, ""],
  [386, 1, ""],
  [387, 2],
  [388, 1, ""],
  [389, 2],
  [390, 1, ""],
  [391, 1, ""],
  [392, 2],
  [393, 1, ""],
  [394, 1, ""],
  [395, 1, ""],
  [[396, 397], 2],
  [398, 1, ""],
  [399, 1, ""],
  [400, 1, ""],
  [401, 1, ""],
  [402, 2],
  [403, 1, ""],
  [404, 1, ""],
  [405, 2],
  [406, 1, ""],
  [407, 1, ""],
  [408, 1, ""],
  [[409, 411], 2],
  [412, 1, ""],
  [413, 1, ""],
  [414, 2],
  [415, 1, ""],
  [416, 1, ""],
  [417, 2],
  [418, 1, ""],
  [419, 2],
  [420, 1, ""],
  [421, 2],
  [422, 1, ""],
  [423, 1, ""],
  [424, 2],
  [425, 1, ""],
  [[426, 427], 2],
  [428, 1, ""],
  [429, 2],
  [430, 1, ""],
  [431, 1, ""],
  [432, 2],
  [433, 1, ""],
  [434, 1, ""],
  [435, 1, ""],
  [436, 2],
  [437, 1, ""],
  [438, 2],
  [439, 1, ""],
  [440, 1, ""],
  [[441, 443], 2],
  [444, 1, ""],
  [[445, 451], 2],
  [[452, 454], 1, "d"],
  [[455, 457], 1, "lj"],
  [[458, 460], 1, "nj"],
  [461, 1, ""],
  [462, 2],
  [463, 1, ""],
  [464, 2],
  [465, 1, ""],
  [466, 2],
  [467, 1, ""],
  [468, 2],
  [469, 1, ""],
  [470, 2],
  [471, 1, ""],
  [472, 2],
  [473, 1, ""],
  [474, 2],
  [475, 1, ""],
  [[476, 477], 2],
  [478, 1, ""],
  [479, 2],
  [480, 1, ""],
  [481, 2],
  [482, 1, ""],
  [483, 2],
  [484, 1, ""],
  [485, 2],
  [486, 1, ""],
  [487, 2],
  [488, 1, ""],
  [489, 2],
  [490, 1, ""],
  [491, 2],
  [492, 1, ""],
  [493, 2],
  [494, 1, ""],
  [[495, 496], 2],
  [[497, 499], 1, "dz"],
  [500, 1, ""],
  [501, 2],
  [502, 1, ""],
  [503, 1, ""],
  [504, 1, ""],
  [505, 2],
  [506, 1, ""],
  [507, 2],
  [508, 1, ""],
  [509, 2],
  [510, 1, ""],
  [511, 2],
  [512, 1, ""],
  [513, 2],
  [514, 1, ""],
  [515, 2],
  [516, 1, ""],
  [517, 2],
  [518, 1, ""],
  [519, 2],
  [520, 1, ""],
  [521, 2],
  [522, 1, ""],
  [523, 2],
  [524, 1, ""],
  [525, 2],
  [526, 1, ""],
  [527, 2],
  [528, 1, ""],
  [529, 2],
  [530, 1, ""],
  [531, 2],
  [532, 1, ""],
  [533, 2],
  [534, 1, ""],
  [535, 2],
  [536, 1, ""],
  [537, 2],
  [538, 1, ""],
  [539, 2],
  [540, 1, ""],
  [541, 2],
  [542, 1, ""],
  [543, 2],
  [544, 1, ""],
  [545, 2],
  [546, 1, ""],
  [547, 2],
  [548, 1, ""],
  [549, 2],
  [550, 1, ""],
  [551, 2],
  [552, 1, ""],
  [553, 2],
  [554, 1, ""],
  [555, 2],
  [556, 1, ""],
  [557, 2],
  [558, 1, ""],
  [559, 2],
  [560, 1, ""],
  [561, 2],
  [562, 1, ""],
  [563, 2],
  [[564, 566], 2],
  [[567, 569], 2],
  [570, 1, ""],
  [571, 1, ""],
  [572, 2],
  [573, 1, ""],
  [574, 1, ""],
  [[575, 576], 2],
  [577, 1, ""],
  [578, 2],
  [579, 1, ""],
  [580, 1, ""],
  [581, 1, ""],
  [582, 1, ""],
  [583, 2],
  [584, 1, ""],
  [585, 2],
  [586, 1, ""],
  [587, 2],
  [588, 1, ""],
  [589, 2],
  [590, 1, ""],
  [591, 2],
  [[592, 680], 2],
  [[681, 685], 2],
  [[686, 687], 2],
  [688, 1, "h"],
  [689, 1, ""],
  [690, 1, "j"],
  [691, 1, "r"],
  [692, 1, ""],
  [693, 1, ""],
  [694, 1, ""],
  [695, 1, "w"],
  [696, 1, "y"],
  [[697, 705], 2],
  [[706, 709], 2],
  [[710, 721], 2],
  [[722, 727], 2],
  [728, 5, " "],
  [729, 5, " "],
  [730, 5, " "],
  [731, 5, " "],
  [732, 5, " "],
  [733, 5, " "],
  [734, 2],
  [735, 2],
  [736, 1, ""],
  [737, 1, "l"],
  [738, 1, "s"],
  [739, 1, "x"],
  [740, 1, ""],
  [[741, 745], 2],
  [[746, 747], 2],
  [748, 2],
  [749, 2],
  [750, 2],
  [[751, 767], 2],
  [[768, 831], 2],
  [832, 1, ""],
  [833, 1, ""],
  [834, 2],
  [835, 1, ""],
  [836, 1, ""],
  [837, 1, ""],
  [[838, 846], 2],
  [847, 7],
  [[848, 855], 2],
  [[856, 860], 2],
  [[861, 863], 2],
  [[864, 865], 2],
  [866, 2],
  [[867, 879], 2],
  [880, 1, ""],
  [881, 2],
  [882, 1, ""],
  [883, 2],
  [884, 1, ""],
  [885, 2],
  [886, 1, ""],
  [887, 2],
  [[888, 889], 3],
  [890, 5, " "],
  [[891, 893], 2],
  [894, 5, ";"],
  [895, 1, ""],
  [[896, 899], 3],
  [900, 5, " "],
  [901, 5, " "],
  [902, 1, ""],
  [903, 1, ""],
  [904, 1, ""],
  [905, 1, ""],
  [906, 1, ""],
  [907, 3],
  [908, 1, ""],
  [909, 3],
  [910, 1, ""],
  [911, 1, ""],
  [912, 2],
  [913, 1, ""],
  [914, 1, ""],
  [915, 1, ""],
  [916, 1, ""],
  [917, 1, ""],
  [918, 1, ""],
  [919, 1, ""],
  [920, 1, ""],
  [921, 1, ""],
  [922, 1, ""],
  [923, 1, ""],
  [924, 1, ""],
  [925, 1, ""],
  [926, 1, ""],
  [927, 1, ""],
  [928, 1, ""],
  [929, 1, ""],
  [930, 3],
  [931, 1, ""],
  [932, 1, ""],
  [933, 1, ""],
  [934, 1, ""],
  [935, 1, ""],
  [936, 1, ""],
  [937, 1, ""],
  [938, 1, ""],
  [939, 1, ""],
  [[940, 961], 2],
  [962, 6, ""],
  [[963, 974], 2],
  [975, 1, ""],
  [976, 1, ""],
  [977, 1, ""],
  [978, 1, ""],
  [979, 1, ""],
  [980, 1, ""],
  [981, 1, ""],
  [982, 1, ""],
  [983, 2],
  [984, 1, ""],
  [985, 2],
  [986, 1, ""],
  [987, 2],
  [988, 1, ""],
  [989, 2],
  [990, 1, ""],
  [991, 2],
  [992, 1, ""],
  [993, 2],
  [994, 1, ""],
  [995, 2],
  [996, 1, ""],
  [997, 2],
  [998, 1, ""],
  [999, 2],
  [1000, 1, ""],
  [1001, 2],
  [1002, 1, ""],
  [1003, 2],
  [1004, 1, ""],
  [1005, 2],
  [1006, 1, ""],
  [1007, 2],
  [1008, 1, ""],
  [1009, 1, ""],
  [1010, 1, ""],
  [1011, 2],
  [1012, 1, ""],
  [1013, 1, ""],
  [1014, 2],
  [1015, 1, ""],
  [1016, 2],
  [1017, 1, ""],
  [1018, 1, ""],
  [1019, 2],
  [1020, 2],
  [1021, 1, ""],
  [1022, 1, ""],
  [1023, 1, ""],
  [1024, 1, ""],
  [1025, 1, ""],
  [1026, 1, ""],
  [1027, 1, ""],
  [1028, 1, ""],
  [1029, 1, ""],
  [1030, 1, ""],
  [1031, 1, ""],
  [1032, 1, ""],
  [1033, 1, ""],
  [1034, 1, ""],
  [1035, 1, ""],
  [1036, 1, ""],
  [1037, 1, ""],
  [1038, 1, ""],
  [1039, 1, ""],
  [1040, 1, ""],
  [1041, 1, ""],
  [1042, 1, ""],
  [1043, 1, ""],
  [1044, 1, ""],
  [1045, 1, ""],
  [1046, 1, ""],
  [1047, 1, ""],
  [1048, 1, ""],
  [1049, 1, ""],
  [1050, 1, ""],
  [1051, 1, ""],
  [1052, 1, ""],
  [1053, 1, ""],
  [1054, 1, ""],
  [1055, 1, ""],
  [1056, 1, ""],
  [1057, 1, ""],
  [1058, 1, ""],
  [1059, 1, ""],
  [1060, 1, ""],
  [1061, 1, ""],
  [1062, 1, ""],
  [1063, 1, ""],
  [1064, 1, ""],
  [1065, 1, ""],
  [1066, 1, ""],
  [1067, 1, ""],
  [1068, 1, ""],
  [1069, 1, ""],
  [1070, 1, ""],
  [1071, 1, ""],
  [[1072, 1103], 2],
  [1104, 2],
  [[1105, 1116], 2],
  [1117, 2],
  [[1118, 1119], 2],
  [1120, 1, ""],
  [1121, 2],
  [1122, 1, ""],
  [1123, 2],
  [1124, 1, ""],
  [1125, 2],
  [1126, 1, ""],
  [1127, 2],
  [1128, 1, ""],
  [1129, 2],
  [1130, 1, ""],
  [1131, 2],
  [1132, 1, ""],
  [1133, 2],
  [1134, 1, ""],
  [1135, 2],
  [1136, 1, ""],
  [1137, 2],
  [1138, 1, ""],
  [1139, 2],
  [1140, 1, ""],
  [1141, 2],
  [1142, 1, ""],
  [1143, 2],
  [1144, 1, ""],
  [1145, 2],
  [1146, 1, ""],
  [1147, 2],
  [1148, 1, ""],
  [1149, 2],
  [1150, 1, ""],
  [1151, 2],
  [1152, 1, ""],
  [1153, 2],
  [1154, 2],
  [[1155, 1158], 2],
  [1159, 2],
  [[1160, 1161], 2],
  [1162, 1, ""],
  [1163, 2],
  [1164, 1, ""],
  [1165, 2],
  [1166, 1, ""],
  [1167, 2],
  [1168, 1, ""],
  [1169, 2],
  [1170, 1, ""],
  [1171, 2],
  [1172, 1, ""],
  [1173, 2],
  [1174, 1, ""],
  [1175, 2],
  [1176, 1, ""],
  [1177, 2],
  [1178, 1, ""],
  [1179, 2],
  [1180, 1, ""],
  [1181, 2],
  [1182, 1, ""],
  [1183, 2],
  [1184, 1, ""],
  [1185, 2],
  [1186, 1, ""],
  [1187, 2],
  [1188, 1, ""],
  [1189, 2],
  [1190, 1, ""],
  [1191, 2],
  [1192, 1, ""],
  [1193, 2],
  [1194, 1, ""],
  [1195, 2],
  [1196, 1, ""],
  [1197, 2],
  [1198, 1, ""],
  [1199, 2],
  [1200, 1, ""],
  [1201, 2],
  [1202, 1, ""],
  [1203, 2],
  [1204, 1, ""],
  [1205, 2],
  [1206, 1, ""],
  [1207, 2],
  [1208, 1, ""],
  [1209, 2],
  [1210, 1, ""],
  [1211, 2],
  [1212, 1, ""],
  [1213, 2],
  [1214, 1, ""],
  [1215, 2],
  [1216, 3],
  [1217, 1, ""],
  [1218, 2],
  [1219, 1, ""],
  [1220, 2],
  [1221, 1, ""],
  [1222, 2],
  [1223, 1, ""],
  [1224, 2],
  [1225, 1, ""],
  [1226, 2],
  [1227, 1, ""],
  [1228, 2],
  [1229, 1, ""],
  [1230, 2],
  [1231, 2],
  [1232, 1, ""],
  [1233, 2],
  [1234, 1, ""],
  [1235, 2],
  [1236, 1, ""],
  [1237, 2],
  [1238, 1, ""],
  [1239, 2],
  [1240, 1, ""],
  [1241, 2],
  [1242, 1, ""],
  [1243, 2],
  [1244, 1, ""],
  [1245, 2],
  [1246, 1, ""],
  [1247, 2],
  [1248, 1, ""],
  [1249, 2],
  [1250, 1, ""],
  [1251, 2],
  [1252, 1, ""],
  [1253, 2],
  [1254, 1, ""],
  [1255, 2],
  [1256, 1, ""],
  [1257, 2],
  [1258, 1, ""],
  [1259, 2],
  [1260, 1, ""],
  [1261, 2],
  [1262, 1, ""],
  [1263, 2],
  [1264, 1, ""],
  [1265, 2],
  [1266, 1, ""],
  [1267, 2],
  [1268, 1, ""],
  [1269, 2],
  [1270, 1, ""],
  [1271, 2],
  [1272, 1, ""],
  [1273, 2],
  [1274, 1, ""],
  [1275, 2],
  [1276, 1, ""],
  [1277, 2],
  [1278, 1, ""],
  [1279, 2],
  [1280, 1, ""],
  [1281, 2],
  [1282, 1, ""],
  [1283, 2],
  [1284, 1, ""],
  [1285, 2],
  [1286, 1, ""],
  [1287, 2],
  [1288, 1, ""],
  [1289, 2],
  [1290, 1, ""],
  [1291, 2],
  [1292, 1, ""],
  [1293, 2],
  [1294, 1, ""],
  [1295, 2],
  [1296, 1, ""],
  [1297, 2],
  [1298, 1, ""],
  [1299, 2],
  [1300, 1, ""],
  [1301, 2],
  [1302, 1, ""],
  [1303, 2],
  [1304, 1, ""],
  [1305, 2],
  [1306, 1, ""],
  [1307, 2],
  [1308, 1, ""],
  [1309, 2],
  [1310, 1, ""],
  [1311, 2],
  [1312, 1, ""],
  [1313, 2],
  [1314, 1, ""],
  [1315, 2],
  [1316, 1, ""],
  [1317, 2],
  [1318, 1, ""],
  [1319, 2],
  [1320, 1, ""],
  [1321, 2],
  [1322, 1, ""],
  [1323, 2],
  [1324, 1, ""],
  [1325, 2],
  [1326, 1, ""],
  [1327, 2],
  [1328, 3],
  [1329, 1, ""],
  [1330, 1, ""],
  [1331, 1, ""],
  [1332, 1, ""],
  [1333, 1, ""],
  [1334, 1, ""],
  [1335, 1, ""],
  [1336, 1, ""],
  [1337, 1, ""],
  [1338, 1, ""],
  [1339, 1, ""],
  [1340, 1, ""],
  [1341, 1, ""],
  [1342, 1, ""],
  [1343, 1, ""],
  [1344, 1, ""],
  [1345, 1, ""],
  [1346, 1, ""],
  [1347, 1, ""],
  [1348, 1, ""],
  [1349, 1, ""],
  [1350, 1, ""],
  [1351, 1, ""],
  [1352, 1, ""],
  [1353, 1, ""],
  [1354, 1, ""],
  [1355, 1, ""],
  [1356, 1, ""],
  [1357, 1, ""],
  [1358, 1, ""],
  [1359, 1, ""],
  [1360, 1, ""],
  [1361, 1, ""],
  [1362, 1, ""],
  [1363, 1, ""],
  [1364, 1, ""],
  [1365, 1, ""],
  [1366, 1, ""],
  [[1367, 1368], 3],
  [1369, 2],
  [[1370, 1375], 2],
  [1376, 2],
  [[1377, 1414], 2],
  [1415, 1, ""],
  [1416, 2],
  [1417, 2],
  [1418, 2],
  [[1419, 1420], 3],
  [[1421, 1422], 2],
  [1423, 2],
  [1424, 3],
  [[1425, 1441], 2],
  [1442, 2],
  [[1443, 1455], 2],
  [[1456, 1465], 2],
  [1466, 2],
  [[1467, 1469], 2],
  [1470, 2],
  [1471, 2],
  [1472, 2],
  [[1473, 1474], 2],
  [1475, 2],
  [1476, 2],
  [1477, 2],
  [1478, 2],
  [1479, 2],
  [[1480, 1487], 3],
  [[1488, 1514], 2],
  [[1515, 1518], 3],
  [1519, 2],
  [[1520, 1524], 2],
  [[1525, 1535], 3],
  [[1536, 1539], 3],
  [1540, 3],
  [1541, 3],
  [[1542, 1546], 2],
  [1547, 2],
  [1548, 2],
  [[1549, 1551], 2],
  [[1552, 1557], 2],
  [[1558, 1562], 2],
  [1563, 2],
  [1564, 3],
  [1565, 2],
  [1566, 2],
  [1567, 2],
  [1568, 2],
  [[1569, 1594], 2],
  [[1595, 1599], 2],
  [1600, 2],
  [[1601, 1618], 2],
  [[1619, 1621], 2],
  [[1622, 1624], 2],
  [[1625, 1630], 2],
  [1631, 2],
  [[1632, 1641], 2],
  [[1642, 1645], 2],
  [[1646, 1647], 2],
  [[1648, 1652], 2],
  [1653, 1, ""],
  [1654, 1, ""],
  [1655, 1, ""],
  [1656, 1, ""],
  [[1657, 1719], 2],
  [[1720, 1721], 2],
  [[1722, 1726], 2],
  [1727, 2],
  [[1728, 1742], 2],
  [1743, 2],
  [[1744, 1747], 2],
  [1748, 2],
  [[1749, 1756], 2],
  [1757, 3],
  [1758, 2],
  [[1759, 1768], 2],
  [1769, 2],
  [[1770, 1773], 2],
  [[1774, 1775], 2],
  [[1776, 1785], 2],
  [[1786, 1790], 2],
  [1791, 2],
  [[1792, 1805], 2],
  [1806, 3],
  [1807, 3],
  [[1808, 1836], 2],
  [[1837, 1839], 2],
  [[1840, 1866], 2],
  [[1867, 1868], 3],
  [[1869, 1871], 2],
  [[1872, 1901], 2],
  [[1902, 1919], 2],
  [[1920, 1968], 2],
  [1969, 2],
  [[1970, 1983], 3],
  [[1984, 2037], 2],
  [[2038, 2042], 2],
  [[2043, 2044], 3],
  [2045, 2],
  [[2046, 2047], 2],
  [[2048, 2093], 2],
  [[2094, 2095], 3],
  [[2096, 2110], 2],
  [2111, 3],
  [[2112, 2139], 2],
  [[2140, 2141], 3],
  [2142, 2],
  [2143, 3],
  [[2144, 2154], 2],
  [[2155, 2159], 3],
  [[2160, 2183], 2],
  [2184, 2],
  [[2185, 2190], 2],
  [2191, 3],
  [[2192, 2193], 3],
  [[2194, 2199], 3],
  [[2200, 2207], 2],
  [2208, 2],
  [2209, 2],
  [[2210, 2220], 2],
  [[2221, 2226], 2],
  [[2227, 2228], 2],
  [2229, 2],
  [[2230, 2237], 2],
  [[2238, 2247], 2],
  [[2248, 2258], 2],
  [2259, 2],
  [[2260, 2273], 2],
  [2274, 3],
  [2275, 2],
  [[2276, 2302], 2],
  [2303, 2],
  [2304, 2],
  [[2305, 2307], 2],
  [2308, 2],
  [[2309, 2361], 2],
  [[2362, 2363], 2],
  [[2364, 2381], 2],
  [2382, 2],
  [2383, 2],
  [[2384, 2388], 2],
  [2389, 2],
  [[2390, 2391], 2],
  [2392, 1, ""],
  [2393, 1, ""],
  [2394, 1, ""],
  [2395, 1, ""],
  [2396, 1, ""],
  [2397, 1, ""],
  [2398, 1, ""],
  [2399, 1, ""],
  [[2400, 2403], 2],
  [[2404, 2405], 2],
  [[2406, 2415], 2],
  [2416, 2],
  [[2417, 2418], 2],
  [[2419, 2423], 2],
  [2424, 2],
  [[2425, 2426], 2],
  [[2427, 2428], 2],
  [2429, 2],
  [[2430, 2431], 2],
  [2432, 2],
  [[2433, 2435], 2],
  [2436, 3],
  [[2437, 2444], 2],
  [[2445, 2446], 3],
  [[2447, 2448], 2],
  [[2449, 2450], 3],
  [[2451, 2472], 2],
  [2473, 3],
  [[2474, 2480], 2],
  [2481, 3],
  [2482, 2],
  [[2483, 2485], 3],
  [[2486, 2489], 2],
  [[2490, 2491], 3],
  [2492, 2],
  [2493, 2],
  [[2494, 2500], 2],
  [[2501, 2502], 3],
  [[2503, 2504], 2],
  [[2505, 2506], 3],
  [[2507, 2509], 2],
  [2510, 2],
  [[2511, 2518], 3],
  [2519, 2],
  [[2520, 2523], 3],
  [2524, 1, ""],
  [2525, 1, ""],
  [2526, 3],
  [2527, 1, ""],
  [[2528, 2531], 2],
  [[2532, 2533], 3],
  [[2534, 2545], 2],
  [[2546, 2554], 2],
  [2555, 2],
  [2556, 2],
  [2557, 2],
  [2558, 2],
  [[2559, 2560], 3],
  [2561, 2],
  [2562, 2],
  [2563, 2],
  [2564, 3],
  [[2565, 2570], 2],
  [[2571, 2574], 3],
  [[2575, 2576], 2],
  [[2577, 2578], 3],
  [[2579, 2600], 2],
  [2601, 3],
  [[2602, 2608], 2],
  [2609, 3],
  [2610, 2],
  [2611, 1, ""],
  [2612, 3],
  [2613, 2],
  [2614, 1, ""],
  [2615, 3],
  [[2616, 2617], 2],
  [[2618, 2619], 3],
  [2620, 2],
  [2621, 3],
  [[2622, 2626], 2],
  [[2627, 2630], 3],
  [[2631, 2632], 2],
  [[2633, 2634], 3],
  [[2635, 2637], 2],
  [[2638, 2640], 3],
  [2641, 2],
  [[2642, 2648], 3],
  [2649, 1, ""],
  [2650, 1, ""],
  [2651, 1, ""],
  [2652, 2],
  [2653, 3],
  [2654, 1, ""],
  [[2655, 2661], 3],
  [[2662, 2676], 2],
  [2677, 2],
  [2678, 2],
  [[2679, 2688], 3],
  [[2689, 2691], 2],
  [2692, 3],
  [[2693, 2699], 2],
  [2700, 2],
  [2701, 2],
  [2702, 3],
  [[2703, 2705], 2],
  [2706, 3],
  [[2707, 2728], 2],
  [2729, 3],
  [[2730, 2736], 2],
  [2737, 3],
  [[2738, 2739], 2],
  [2740, 3],
  [[2741, 2745], 2],
  [[2746, 2747], 3],
  [[2748, 2757], 2],
  [2758, 3],
  [[2759, 2761], 2],
  [2762, 3],
  [[2763, 2765], 2],
  [[2766, 2767], 3],
  [2768, 2],
  [[2769, 2783], 3],
  [2784, 2],
  [[2785, 2787], 2],
  [[2788, 2789], 3],
  [[2790, 2799], 2],
  [2800, 2],
  [2801, 2],
  [[2802, 2808], 3],
  [2809, 2],
  [[2810, 2815], 2],
  [2816, 3],
  [[2817, 2819], 2],
  [2820, 3],
  [[2821, 2828], 2],
  [[2829, 2830], 3],
  [[2831, 2832], 2],
  [[2833, 2834], 3],
  [[2835, 2856], 2],
  [2857, 3],
  [[2858, 2864], 2],
  [2865, 3],
  [[2866, 2867], 2],
  [2868, 3],
  [2869, 2],
  [[2870, 2873], 2],
  [[2874, 2875], 3],
  [[2876, 2883], 2],
  [2884, 2],
  [[2885, 2886], 3],
  [[2887, 2888], 2],
  [[2889, 2890], 3],
  [[2891, 2893], 2],
  [[2894, 2900], 3],
  [2901, 2],
  [[2902, 2903], 2],
  [[2904, 2907], 3],
  [2908, 1, ""],
  [2909, 1, ""],
  [2910, 3],
  [[2911, 2913], 2],
  [[2914, 2915], 2],
  [[2916, 2917], 3],
  [[2918, 2927], 2],
  [2928, 2],
  [2929, 2],
  [[2930, 2935], 2],
  [[2936, 2945], 3],
  [[2946, 2947], 2],
  [2948, 3],
  [[2949, 2954], 2],
  [[2955, 2957], 3],
  [[2958, 2960], 2],
  [2961, 3],
  [[2962, 2965], 2],
  [[2966, 2968], 3],
  [[2969, 2970], 2],
  [2971, 3],
  [2972, 2],
  [2973, 3],
  [[2974, 2975], 2],
  [[2976, 2978], 3],
  [[2979, 2980], 2],
  [[2981, 2983], 3],
  [[2984, 2986], 2],
  [[2987, 2989], 3],
  [[2990, 2997], 2],
  [2998, 2],
  [[2999, 3001], 2],
  [[3002, 3005], 3],
  [[3006, 3010], 2],
  [[3011, 3013], 3],
  [[3014, 3016], 2],
  [3017, 3],
  [[3018, 3021], 2],
  [[3022, 3023], 3],
  [3024, 2],
  [[3025, 3030], 3],
  [3031, 2],
  [[3032, 3045], 3],
  [3046, 2],
  [[3047, 3055], 2],
  [[3056, 3058], 2],
  [[3059, 3066], 2],
  [[3067, 3071], 3],
  [3072, 2],
  [[3073, 3075], 2],
  [3076, 2],
  [[3077, 3084], 2],
  [3085, 3],
  [[3086, 3088], 2],
  [3089, 3],
  [[3090, 3112], 2],
  [3113, 3],
  [[3114, 3123], 2],
  [3124, 2],
  [[3125, 3129], 2],
  [[3130, 3131], 3],
  [3132, 2],
  [3133, 2],
  [[3134, 3140], 2],
  [3141, 3],
  [[3142, 3144], 2],
  [3145, 3],
  [[3146, 3149], 2],
  [[3150, 3156], 3],
  [[3157, 3158], 2],
  [3159, 3],
  [[3160, 3161], 2],
  [3162, 2],
  [[3163, 3164], 3],
  [3165, 2],
  [[3166, 3167], 3],
  [[3168, 3169], 2],
  [[3170, 3171], 2],
  [[3172, 3173], 3],
  [[3174, 3183], 2],
  [[3184, 3190], 3],
  [3191, 2],
  [[3192, 3199], 2],
  [3200, 2],
  [3201, 2],
  [[3202, 3203], 2],
  [3204, 2],
  [[3205, 3212], 2],
  [3213, 3],
  [[3214, 3216], 2],
  [3217, 3],
  [[3218, 3240], 2],
  [3241, 3],
  [[3242, 3251], 2],
  [3252, 3],
  [[3253, 3257], 2],
  [[3258, 3259], 3],
  [[3260, 3261], 2],
  [[3262, 3268], 2],
  [3269, 3],
  [[3270, 3272], 2],
  [3273, 3],
  [[3274, 3277], 2],
  [[3278, 3284], 3],
  [[3285, 3286], 2],
  [[3287, 3292], 3],
  [3293, 2],
  [3294, 2],
  [3295, 3],
  [[3296, 3297], 2],
  [[3298, 3299], 2],
  [[3300, 3301], 3],
  [[3302, 3311], 2],
  [3312, 3],
  [[3313, 3314], 2],
  [[3315, 3327], 3],
  [3328, 2],
  [3329, 2],
  [[3330, 3331], 2],
  [3332, 2],
  [[3333, 3340], 2],
  [3341, 3],
  [[3342, 3344], 2],
  [3345, 3],
  [[3346, 3368], 2],
  [3369, 2],
  [[3370, 3385], 2],
  [3386, 2],
  [[3387, 3388], 2],
  [3389, 2],
  [[3390, 3395], 2],
  [3396, 2],
  [3397, 3],
  [[3398, 3400], 2],
  [3401, 3],
  [[3402, 3405], 2],
  [3406, 2],
  [3407, 2],
  [[3408, 3411], 3],
  [[3412, 3414], 2],
  [3415, 2],
  [[3416, 3422], 2],
  [3423, 2],
  [[3424, 3425], 2],
  [[3426, 3427], 2],
  [[3428, 3429], 3],
  [[3430, 3439], 2],
  [[3440, 3445], 2],
  [[3446, 3448], 2],
  [3449, 2],
  [[3450, 3455], 2],
  [3456, 3],
  [3457, 2],
  [[3458, 3459], 2],
  [3460, 3],
  [[3461, 3478], 2],
  [[3479, 3481], 3],
  [[3482, 3505], 2],
  [3506, 3],
  [[3507, 3515], 2],
  [3516, 3],
  [3517, 2],
  [[3518, 3519], 3],
  [[3520, 3526], 2],
  [[3527, 3529], 3],
  [3530, 2],
  [[3531, 3534], 3],
  [[3535, 3540], 2],
  [3541, 3],
  [3542, 2],
  [3543, 3],
  [[3544, 3551], 2],
  [[3552, 3557], 3],
  [[3558, 3567], 2],
  [[3568, 3569], 3],
  [[3570, 3571], 2],
  [3572, 2],
  [[3573, 3584], 3],
  [[3585, 3634], 2],
  [3635, 1, ""],
  [[3636, 3642], 2],
  [[3643, 3646], 3],
  [3647, 2],
  [[3648, 3662], 2],
  [3663, 2],
  [[3664, 3673], 2],
  [[3674, 3675], 2],
  [[3676, 3712], 3],
  [[3713, 3714], 2],
  [3715, 3],
  [3716, 2],
  [3717, 3],
  [3718, 2],
  [[3719, 3720], 2],
  [3721, 2],
  [3722, 2],
  [3723, 3],
  [3724, 2],
  [3725, 2],
  [[3726, 3731], 2],
  [[3732, 3735], 2],
  [3736, 2],
  [[3737, 3743], 2],
  [3744, 2],
  [[3745, 3747], 2],
  [3748, 3],
  [3749, 2],
  [3750, 3],
  [3751, 2],
  [[3752, 3753], 2],
  [[3754, 3755], 2],
  [3756, 2],
  [[3757, 3762], 2],
  [3763, 1, ""],
  [[3764, 3769], 2],
  [3770, 2],
  [[3771, 3773], 2],
  [[3774, 3775], 3],
  [[3776, 3780], 2],
  [3781, 3],
  [3782, 2],
  [3783, 3],
  [[3784, 3789], 2],
  [[3790, 3791], 3],
  [[3792, 3801], 2],
  [[3802, 3803], 3],
  [3804, 1, ""],
  [3805, 1, ""],
  [[3806, 3807], 2],
  [[3808, 3839], 3],
  [3840, 2],
  [[3841, 3850], 2],
  [3851, 2],
  [3852, 1, ""],
  [[3853, 3863], 2],
  [[3864, 3865], 2],
  [[3866, 3871], 2],
  [[3872, 3881], 2],
  [[3882, 3892], 2],
  [3893, 2],
  [3894, 2],
  [3895, 2],
  [3896, 2],
  [3897, 2],
  [[3898, 3901], 2],
  [[3902, 3906], 2],
  [3907, 1, ""],
  [[3908, 3911], 2],
  [3912, 3],
  [[3913, 3916], 2],
  [3917, 1, ""],
  [[3918, 3921], 2],
  [3922, 1, ""],
  [[3923, 3926], 2],
  [3927, 1, ""],
  [[3928, 3931], 2],
  [3932, 1, ""],
  [[3933, 3944], 2],
  [3945, 1, ""],
  [3946, 2],
  [[3947, 3948], 2],
  [[3949, 3952], 3],
  [[3953, 3954], 2],
  [3955, 1, ""],
  [3956, 2],
  [3957, 1, ""],
  [3958, 1, ""],
  [3959, 1, ""],
  [3960, 1, ""],
  [3961, 1, ""],
  [[3962, 3968], 2],
  [3969, 1, ""],
  [[3970, 3972], 2],
  [3973, 2],
  [[3974, 3979], 2],
  [[3980, 3983], 2],
  [[3984, 3986], 2],
  [3987, 1, ""],
  [[3988, 3989], 2],
  [3990, 2],
  [3991, 2],
  [3992, 3],
  [[3993, 3996], 2],
  [3997, 1, ""],
  [[3998, 4001], 2],
  [4002, 1, ""],
  [[4003, 4006], 2],
  [4007, 1, ""],
  [[4008, 4011], 2],
  [4012, 1, ""],
  [4013, 2],
  [[4014, 4016], 2],
  [[4017, 4023], 2],
  [4024, 2],
  [4025, 1, ""],
  [[4026, 4028], 2],
  [4029, 3],
  [[4030, 4037], 2],
  [4038, 2],
  [[4039, 4044], 2],
  [4045, 3],
  [4046, 2],
  [4047, 2],
  [[4048, 4049], 2],
  [[4050, 4052], 2],
  [[4053, 4056], 2],
  [[4057, 4058], 2],
  [[4059, 4095], 3],
  [[4096, 4129], 2],
  [4130, 2],
  [[4131, 4135], 2],
  [4136, 2],
  [[4137, 4138], 2],
  [4139, 2],
  [[4140, 4146], 2],
  [[4147, 4149], 2],
  [[4150, 4153], 2],
  [[4154, 4159], 2],
  [[4160, 4169], 2],
  [[4170, 4175], 2],
  [[4176, 4185], 2],
  [[4186, 4249], 2],
  [[4250, 4253], 2],
  [[4254, 4255], 2],
  [[4256, 4293], 3],
  [4294, 3],
  [4295, 1, ""],
  [[4296, 4300], 3],
  [4301, 1, ""],
  [[4302, 4303], 3],
  [[4304, 4342], 2],
  [[4343, 4344], 2],
  [[4345, 4346], 2],
  [4347, 2],
  [4348, 1, ""],
  [[4349, 4351], 2],
  [[4352, 4441], 2],
  [[4442, 4446], 2],
  [[4447, 4448], 3],
  [[4449, 4514], 2],
  [[4515, 4519], 2],
  [[4520, 4601], 2],
  [[4602, 4607], 2],
  [[4608, 4614], 2],
  [4615, 2],
  [[4616, 4678], 2],
  [4679, 2],
  [4680, 2],
  [4681, 3],
  [[4682, 4685], 2],
  [[4686, 4687], 3],
  [[4688, 4694], 2],
  [4695, 3],
  [4696, 2],
  [4697, 3],
  [[4698, 4701], 2],
  [[4702, 4703], 3],
  [[4704, 4742], 2],
  [4743, 2],
  [4744, 2],
  [4745, 3],
  [[4746, 4749], 2],
  [[4750, 4751], 3],
  [[4752, 4782], 2],
  [4783, 2],
  [4784, 2],
  [4785, 3],
  [[4786, 4789], 2],
  [[4790, 4791], 3],
  [[4792, 4798], 2],
  [4799, 3],
  [4800, 2],
  [4801, 3],
  [[4802, 4805], 2],
  [[4806, 4807], 3],
  [[4808, 4814], 2],
  [4815, 2],
  [[4816, 4822], 2],
  [4823, 3],
  [[4824, 4846], 2],
  [4847, 2],
  [[4848, 4878], 2],
  [4879, 2],
  [4880, 2],
  [4881, 3],
  [[4882, 4885], 2],
  [[4886, 4887], 3],
  [[4888, 4894], 2],
  [4895, 2],
  [[4896, 4934], 2],
  [4935, 2],
  [[4936, 4954], 2],
  [[4955, 4956], 3],
  [[4957, 4958], 2],
  [4959, 2],
  [4960, 2],
  [[4961, 4988], 2],
  [[4989, 4991], 3],
  [[4992, 5007], 2],
  [[5008, 5017], 2],
  [[5018, 5023], 3],
  [[5024, 5108], 2],
  [5109, 2],
  [[5110, 5111], 3],
  [5112, 1, ""],
  [5113, 1, ""],
  [5114, 1, ""],
  [5115, 1, ""],
  [5116, 1, ""],
  [5117, 1, ""],
  [[5118, 5119], 3],
  [5120, 2],
  [[5121, 5740], 2],
  [[5741, 5742], 2],
  [[5743, 5750], 2],
  [[5751, 5759], 2],
  [5760, 3],
  [[5761, 5786], 2],
  [[5787, 5788], 2],
  [[5789, 5791], 3],
  [[5792, 5866], 2],
  [[5867, 5872], 2],
  [[5873, 5880], 2],
  [[5881, 5887], 3],
  [[5888, 5900], 2],
  [5901, 2],
  [[5902, 5908], 2],
  [5909, 2],
  [[5910, 5918], 3],
  [5919, 2],
  [[5920, 5940], 2],
  [[5941, 5942], 2],
  [[5943, 5951], 3],
  [[5952, 5971], 2],
  [[5972, 5983], 3],
  [[5984, 5996], 2],
  [5997, 3],
  [[5998, 6000], 2],
  [6001, 3],
  [[6002, 6003], 2],
  [[6004, 6015], 3],
  [[6016, 6067], 2],
  [[6068, 6069], 3],
  [[6070, 6099], 2],
  [[6100, 6102], 2],
  [6103, 2],
  [[6104, 6107], 2],
  [6108, 2],
  [6109, 2],
  [[6110, 6111], 3],
  [[6112, 6121], 2],
  [[6122, 6127], 3],
  [[6128, 6137], 2],
  [[6138, 6143], 3],
  [[6144, 6149], 2],
  [6150, 3],
  [[6151, 6154], 2],
  [[6155, 6157], 7],
  [6158, 3],
  [6159, 7],
  [[6160, 6169], 2],
  [[6170, 6175], 3],
  [[6176, 6263], 2],
  [6264, 2],
  [[6265, 6271], 3],
  [[6272, 6313], 2],
  [6314, 2],
  [[6315, 6319], 3],
  [[6320, 6389], 2],
  [[6390, 6399], 3],
  [[6400, 6428], 2],
  [[6429, 6430], 2],
  [6431, 3],
  [[6432, 6443], 2],
  [[6444, 6447], 3],
  [[6448, 6459], 2],
  [[6460, 6463], 3],
  [6464, 2],
  [[6465, 6467], 3],
  [[6468, 6469], 2],
  [[6470, 6509], 2],
  [[6510, 6511], 3],
  [[6512, 6516], 2],
  [[6517, 6527], 3],
  [[6528, 6569], 2],
  [[6570, 6571], 2],
  [[6572, 6575], 3],
  [[6576, 6601], 2],
  [[6602, 6607], 3],
  [[6608, 6617], 2],
  [6618, 2],
  [[6619, 6621], 3],
  [[6622, 6623], 2],
  [[6624, 6655], 2],
  [[6656, 6683], 2],
  [[6684, 6685], 3],
  [[6686, 6687], 2],
  [[6688, 6750], 2],
  [6751, 3],
  [[6752, 6780], 2],
  [[6781, 6782], 3],
  [[6783, 6793], 2],
  [[6794, 6799], 3],
  [[6800, 6809], 2],
  [[6810, 6815], 3],
  [[6816, 6822], 2],
  [6823, 2],
  [[6824, 6829], 2],
  [[6830, 6831], 3],
  [[6832, 6845], 2],
  [6846, 2],
  [[6847, 6848], 2],
  [[6849, 6862], 2],
  [[6863, 6911], 3],
  [[6912, 6987], 2],
  [6988, 2],
  [[6989, 6991], 3],
  [[6992, 7001], 2],
  [[7002, 7018], 2],
  [[7019, 7027], 2],
  [[7028, 7036], 2],
  [[7037, 7038], 2],
  [7039, 3],
  [[7040, 7082], 2],
  [[7083, 7085], 2],
  [[7086, 7097], 2],
  [[7098, 7103], 2],
  [[7104, 7155], 2],
  [[7156, 7163], 3],
  [[7164, 7167], 2],
  [[7168, 7223], 2],
  [[7224, 7226], 3],
  [[7227, 7231], 2],
  [[7232, 7241], 2],
  [[7242, 7244], 3],
  [[7245, 7293], 2],
  [[7294, 7295], 2],
  [7296, 1, ""],
  [7297, 1, ""],
  [7298, 1, ""],
  [7299, 1, ""],
  [[7300, 7301], 1, ""],
  [7302, 1, ""],
  [7303, 1, ""],
  [7304, 1, ""],
  [[7305, 7311], 3],
  [7312, 1, ""],
  [7313, 1, ""],
  [7314, 1, ""],
  [7315, 1, ""],
  [7316, 1, ""],
  [7317, 1, ""],
  [7318, 1, ""],
  [7319, 1, ""],
  [7320, 1, ""],
  [7321, 1, ""],
  [7322, 1, ""],
  [7323, 1, ""],
  [7324, 1, ""],
  [7325, 1, ""],
  [7326, 1, ""],
  [7327, 1, ""],
  [7328, 1, ""],
  [7329, 1, ""],
  [7330, 1, ""],
  [7331, 1, ""],
  [7332, 1, ""],
  [7333, 1, ""],
  [7334, 1, ""],
  [7335, 1, ""],
  [7336, 1, ""],
  [7337, 1, ""],
  [7338, 1, ""],
  [7339, 1, ""],
  [7340, 1, ""],
  [7341, 1, ""],
  [7342, 1, ""],
  [7343, 1, ""],
  [7344, 1, ""],
  [7345, 1, ""],
  [7346, 1, ""],
  [7347, 1, ""],
  [7348, 1, ""],
  [7349, 1, ""],
  [7350, 1, ""],
  [7351, 1, ""],
  [7352, 1, ""],
  [7353, 1, ""],
  [7354, 1, ""],
  [[7355, 7356], 3],
  [7357, 1, ""],
  [7358, 1, ""],
  [7359, 1, ""],
  [[7360, 7367], 2],
  [[7368, 7375], 3],
  [[7376, 7378], 2],
  [7379, 2],
  [[7380, 7410], 2],
  [[7411, 7414], 2],
  [7415, 2],
  [[7416, 7417], 2],
  [7418, 2],
  [[7419, 7423], 3],
  [[7424, 7467], 2],
  [7468, 1, "a"],
  [7469, 1, ""],
  [7470, 1, "b"],
  [7471, 2],
  [7472, 1, "d"],
  [7473, 1, "e"],
  [7474, 1, ""],
  [7475, 1, "g"],
  [7476, 1, "h"],
  [7477, 1, "i"],
  [7478, 1, "j"],
  [7479, 1, "k"],
  [7480, 1, "l"],
  [7481, 1, "m"],
  [7482, 1, "n"],
  [7483, 2],
  [7484, 1, "o"],
  [7485, 1, ""],
  [7486, 1, "p"],
  [7487, 1, "r"],
  [7488, 1, "t"],
  [7489, 1, "u"],
  [7490, 1, "w"],
  [7491, 1, "a"],
  [7492, 1, ""],
  [7493, 1, ""],
  [7494, 1, ""],
  [7495, 1, "b"],
  [7496, 1, "d"],
  [7497, 1, "e"],
  [7498, 1, ""],
  [7499, 1, ""],
  [7500, 1, ""],
  [7501, 1, "g"],
  [7502, 2],
  [7503, 1, "k"],
  [7504, 1, "m"],
  [7505, 1, ""],
  [7506, 1, "o"],
  [7507, 1, ""],
  [7508, 1, ""],
  [7509, 1, ""],
  [7510, 1, "p"],
  [7511, 1, "t"],
  [7512, 1, "u"],
  [7513, 1, ""],
  [7514, 1, ""],
  [7515, 1, "v"],
  [7516, 1, ""],
  [7517, 1, ""],
  [7518, 1, ""],
  [7519, 1, ""],
  [7520, 1, ""],
  [7521, 1, ""],
  [7522, 1, "i"],
  [7523, 1, "r"],
  [7524, 1, "u"],
  [7525, 1, "v"],
  [7526, 1, ""],
  [7527, 1, ""],
  [7528, 1, ""],
  [7529, 1, ""],
  [7530, 1, ""],
  [7531, 2],
  [[7532, 7543], 2],
  [7544, 1, ""],
  [[7545, 7578], 2],
  [7579, 1, ""],
  [7580, 1, "c"],
  [7581, 1, ""],
  [7582, 1, ""],
  [7583, 1, ""],
  [7584, 1, "f"],
  [7585, 1, ""],
  [7586, 1, ""],
  [7587, 1, ""],
  [7588, 1, ""],
  [7589, 1, ""],
  [7590, 1, ""],
  [7591, 1, ""],
  [7592, 1, ""],
  [7593, 1, ""],
  [7594, 1, ""],
  [7595, 1, ""],
  [7596, 1, ""],
  [7597, 1, ""],
  [7598, 1, ""],
  [7599, 1, ""],
  [7600, 1, ""],
  [7601, 1, ""],
  [7602, 1, ""],
  [7603, 1, ""],
  [7604, 1, ""],
  [7605, 1, ""],
  [7606, 1, ""],
  [7607, 1, ""],
  [7608, 1, ""],
  [7609, 1, ""],
  [7610, 1, ""],
  [7611, 1, "z"],
  [7612, 1, ""],
  [7613, 1, ""],
  [7614, 1, ""],
  [7615, 1, ""],
  [[7616, 7619], 2],
  [[7620, 7626], 2],
  [[7627, 7654], 2],
  [[7655, 7669], 2],
  [[7670, 7673], 2],
  [7674, 2],
  [7675, 2],
  [7676, 2],
  [7677, 2],
  [[7678, 7679], 2],
  [7680, 1, ""],
  [7681, 2],
  [7682, 1, ""],
  [7683, 2],
  [7684, 1, ""],
  [7685, 2],
  [7686, 1, ""],
  [7687, 2],
  [7688, 1, ""],
  [7689, 2],
  [7690, 1, ""],
  [7691, 2],
  [7692, 1, ""],
  [7693, 2],
  [7694, 1, ""],
  [7695, 2],
  [7696, 1, ""],
  [7697, 2],
  [7698, 1, ""],
  [7699, 2],
  [7700, 1, ""],
  [7701, 2],
  [7702, 1, ""],
  [7703, 2],
  [7704, 1, ""],
  [7705, 2],
  [7706, 1, ""],
  [7707, 2],
  [7708, 1, ""],
  [7709, 2],
  [7710, 1, ""],
  [7711, 2],
  [7712, 1, ""],
  [7713, 2],
  [7714, 1, ""],
  [7715, 2],
  [7716, 1, ""],
  [7717, 2],
  [7718, 1, ""],
  [7719, 2],
  [7720, 1, ""],
  [7721, 2],
  [7722, 1, ""],
  [7723, 2],
  [7724, 1, ""],
  [7725, 2],
  [7726, 1, ""],
  [7727, 2],
  [7728, 1, ""],
  [7729, 2],
  [7730, 1, ""],
  [7731, 2],
  [7732, 1, ""],
  [7733, 2],
  [7734, 1, ""],
  [7735, 2],
  [7736, 1, ""],
  [7737, 2],
  [7738, 1, ""],
  [7739, 2],
  [7740, 1, ""],
  [7741, 2],
  [7742, 1, ""],
  [7743, 2],
  [7744, 1, ""],
  [7745, 2],
  [7746, 1, ""],
  [7747, 2],
  [7748, 1, ""],
  [7749, 2],
  [7750, 1, ""],
  [7751, 2],
  [7752, 1, ""],
  [7753, 2],
  [7754, 1, ""],
  [7755, 2],
  [7756, 1, ""],
  [7757, 2],
  [7758, 1, ""],
  [7759, 2],
  [7760, 1, ""],
  [7761, 2],
  [7762, 1, ""],
  [7763, 2],
  [7764, 1, ""],
  [7765, 2],
  [7766, 1, ""],
  [7767, 2],
  [7768, 1, ""],
  [7769, 2],
  [7770, 1, ""],
  [7771, 2],
  [7772, 1, ""],
  [7773, 2],
  [7774, 1, ""],
  [7775, 2],
  [7776, 1, ""],
  [7777, 2],
  [7778, 1, ""],
  [7779, 2],
  [7780, 1, ""],
  [7781, 2],
  [7782, 1, ""],
  [7783, 2],
  [7784, 1, ""],
  [7785, 2],
  [7786, 1, ""],
  [7787, 2],
  [7788, 1, ""],
  [7789, 2],
  [7790, 1, ""],
  [7791, 2],
  [7792, 1, ""],
  [7793, 2],
  [7794, 1, ""],
  [7795, 2],
  [7796, 1, ""],
  [7797, 2],
  [7798, 1, ""],
  [7799, 2],
  [7800, 1, ""],
  [7801, 2],
  [7802, 1, ""],
  [7803, 2],
  [7804, 1, ""],
  [7805, 2],
  [7806, 1, ""],
  [7807, 2],
  [7808, 1, ""],
  [7809, 2],
  [7810, 1, ""],
  [7811, 2],
  [7812, 1, ""],
  [7813, 2],
  [7814, 1, ""],
  [7815, 2],
  [7816, 1, ""],
  [7817, 2],
  [7818, 1, ""],
  [7819, 2],
  [7820, 1, ""],
  [7821, 2],
  [7822, 1, ""],
  [7823, 2],
  [7824, 1, ""],
  [7825, 2],
  [7826, 1, ""],
  [7827, 2],
  [7828, 1, ""],
  [[7829, 7833], 2],
  [7834, 1, "a"],
  [7835, 1, ""],
  [[7836, 7837], 2],
  [7838, 1, "ss"],
  [7839, 2],
  [7840, 1, ""],
  [7841, 2],
  [7842, 1, ""],
  [7843, 2],
  [7844, 1, ""],
  [7845, 2],
  [7846, 1, ""],
  [7847, 2],
  [7848, 1, ""],
  [7849, 2],
  [7850, 1, ""],
  [7851, 2],
  [7852, 1, ""],
  [7853, 2],
  [7854, 1, ""],
  [7855, 2],
  [7856, 1, ""],
  [7857, 2],
  [7858, 1, ""],
  [7859, 2],
  [7860, 1, ""],
  [7861, 2],
  [7862, 1, ""],
  [7863, 2],
  [7864, 1, ""],
  [7865, 2],
  [7866, 1, ""],
  [7867, 2],
  [7868, 1, ""],
  [7869, 2],
  [7870, 1, ""],
  [7871, 2],
  [7872, 1, ""],
  [7873, 2],
  [7874, 1, ""],
  [7875, 2],
  [7876, 1, ""],
  [7877, 2],
  [7878, 1, ""],
  [7879, 2],
  [7880, 1, ""],
  [7881, 2],
  [7882, 1, ""],
  [7883, 2],
  [7884, 1, ""],
  [7885, 2],
  [7886, 1, ""],
  [7887, 2],
  [7888, 1, ""],
  [7889, 2],
  [7890, 1, ""],
  [7891, 2],
  [7892, 1, ""],
  [7893, 2],
  [7894, 1, ""],
  [7895, 2],
  [7896, 1, ""],
  [7897, 2],
  [7898, 1, ""],
  [7899, 2],
  [7900, 1, ""],
  [7901, 2],
  [7902, 1, ""],
  [7903, 2],
  [7904, 1, ""],
  [7905, 2],
  [7906, 1, ""],
  [7907, 2],
  [7908, 1, ""],
  [7909, 2],
  [7910, 1, ""],
  [7911, 2],
  [7912, 1, ""],
  [7913, 2],
  [7914, 1, ""],
  [7915, 2],
  [7916, 1, ""],
  [7917, 2],
  [7918, 1, ""],
  [7919, 2],
  [7920, 1, ""],
  [7921, 2],
  [7922, 1, ""],
  [7923, 2],
  [7924, 1, ""],
  [7925, 2],
  [7926, 1, ""],
  [7927, 2],
  [7928, 1, ""],
  [7929, 2],
  [7930, 1, ""],
  [7931, 2],
  [7932, 1, ""],
  [7933, 2],
  [7934, 1, ""],
  [7935, 2],
  [[7936, 7943], 2],
  [7944, 1, ""],
  [7945, 1, ""],
  [7946, 1, ""],
  [7947, 1, ""],
  [7948, 1, ""],
  [7949, 1, ""],
  [7950, 1, ""],
  [7951, 1, ""],
  [[7952, 7957], 2],
  [[7958, 7959], 3],
  [7960, 1, ""],
  [7961, 1, ""],
  [7962, 1, ""],
  [7963, 1, ""],
  [7964, 1, ""],
  [7965, 1, ""],
  [[7966, 7967], 3],
  [[7968, 7975], 2],
  [7976, 1, ""],
  [7977, 1, ""],
  [7978, 1, ""],
  [7979, 1, ""],
  [7980, 1, ""],
  [7981, 1, ""],
  [7982, 1, ""],
  [7983, 1, ""],
  [[7984, 7991], 2],
  [7992, 1, ""],
  [7993, 1, ""],
  [7994, 1, ""],
  [7995, 1, ""],
  [7996, 1, ""],
  [7997, 1, ""],
  [7998, 1, ""],
  [7999, 1, ""],
  [[8000, 8005], 2],
  [[8006, 8007], 3],
  [8008, 1, ""],
  [8009, 1, ""],
  [8010, 1, ""],
  [8011, 1, ""],
  [8012, 1, ""],
  [8013, 1, ""],
  [[8014, 8015], 3],
  [[8016, 8023], 2],
  [8024, 3],
  [8025, 1, ""],
  [8026, 3],
  [8027, 1, ""],
  [8028, 3],
  [8029, 1, ""],
  [8030, 3],
  [8031, 1, ""],
  [[8032, 8039], 2],
  [8040, 1, ""],
  [8041, 1, ""],
  [8042, 1, ""],
  [8043, 1, ""],
  [8044, 1, ""],
  [8045, 1, ""],
  [8046, 1, ""],
  [8047, 1, ""],
  [8048, 2],
  [8049, 1, ""],
  [8050, 2],
  [8051, 1, ""],
  [8052, 2],
  [8053, 1, ""],
  [8054, 2],
  [8055, 1, ""],
  [8056, 2],
  [8057, 1, ""],
  [8058, 2],
  [8059, 1, ""],
  [8060, 2],
  [8061, 1, ""],
  [[8062, 8063], 3],
  [8064, 1, ""],
  [8065, 1, ""],
  [8066, 1, ""],
  [8067, 1, ""],
  [8068, 1, ""],
  [8069, 1, ""],
  [8070, 1, ""],
  [8071, 1, ""],
  [8072, 1, ""],
  [8073, 1, ""],
  [8074, 1, ""],
  [8075, 1, ""],
  [8076, 1, ""],
  [8077, 1, ""],
  [8078, 1, ""],
  [8079, 1, ""],
  [8080, 1, ""],
  [8081, 1, ""],
  [8082, 1, ""],
  [8083, 1, ""],
  [8084, 1, ""],
  [8085, 1, ""],
  [8086, 1, ""],
  [8087, 1, ""],
  [8088, 1, ""],
  [8089, 1, ""],
  [8090, 1, ""],
  [8091, 1, ""],
  [8092, 1, ""],
  [8093, 1, ""],
  [8094, 1, ""],
  [8095, 1, ""],
  [8096, 1, ""],
  [8097, 1, ""],
  [8098, 1, ""],
  [8099, 1, ""],
  [8100, 1, ""],
  [8101, 1, ""],
  [8102, 1, ""],
  [8103, 1, ""],
  [8104, 1, ""],
  [8105, 1, ""],
  [8106, 1, ""],
  [8107, 1, ""],
  [8108, 1, ""],
  [8109, 1, ""],
  [8110, 1, ""],
  [8111, 1, ""],
  [[8112, 8113], 2],
  [8114, 1, ""],
  [8115, 1, ""],
  [8116, 1, ""],
  [8117, 3],
  [8118, 2],
  [8119, 1, ""],
  [8120, 1, ""],
  [8121, 1, ""],
  [8122, 1, ""],
  [8123, 1, ""],
  [8124, 1, ""],
  [8125, 5, " "],
  [8126, 1, ""],
  [8127, 5, " "],
  [8128, 5, " "],
  [8129, 5, " "],
  [8130, 1, ""],
  [8131, 1, ""],
  [8132, 1, ""],
  [8133, 3],
  [8134, 2],
  [8135, 1, ""],
  [8136, 1, ""],
  [8137, 1, ""],
  [8138, 1, ""],
  [8139, 1, ""],
  [8140, 1, ""],
  [8141, 5, " "],
  [8142, 5, " "],
  [8143, 5, " "],
  [[8144, 8146], 2],
  [8147, 1, ""],
  [[8148, 8149], 3],
  [[8150, 8151], 2],
  [8152, 1, ""],
  [8153, 1, ""],
  [8154, 1, ""],
  [8155, 1, ""],
  [8156, 3],
  [8157, 5, " "],
  [8158, 5, " "],
  [8159, 5, " "],
  [[8160, 8162], 2],
  [8163, 1, ""],
  [[8164, 8167], 2],
  [8168, 1, ""],
  [8169, 1, ""],
  [8170, 1, ""],
  [8171, 1, ""],
  [8172, 1, ""],
  [8173, 5, " "],
  [8174, 5, " "],
  [8175, 5, "`"],
  [[8176, 8177], 3],
  [8178, 1, ""],
  [8179, 1, ""],
  [8180, 1, ""],
  [8181, 3],
  [8182, 2],
  [8183, 1, ""],
  [8184, 1, ""],
  [8185, 1, ""],
  [8186, 1, ""],
  [8187, 1, ""],
  [8188, 1, ""],
  [8189, 5, " "],
  [8190, 5, " "],
  [8191, 3],
  [[8192, 8202], 5, " "],
  [8203, 7],
  [[8204, 8205], 6, ""],
  [[8206, 8207], 3],
  [8208, 2],
  [8209, 1, ""],
  [[8210, 8214], 2],
  [8215, 5, " "],
  [[8216, 8227], 2],
  [[8228, 8230], 3],
  [8231, 2],
  [[8232, 8238], 3],
  [8239, 5, " "],
  [[8240, 8242], 2],
  [8243, 1, ""],
  [8244, 1, ""],
  [8245, 2],
  [8246, 1, ""],
  [8247, 1, ""],
  [[8248, 8251], 2],
  [8252, 5, "!!"],
  [8253, 2],
  [8254, 5, " "],
  [[8255, 8262], 2],
  [8263, 5, "??"],
  [8264, 5, "?!"],
  [8265, 5, "!?"],
  [[8266, 8269], 2],
  [[8270, 8274], 2],
  [[8275, 8276], 2],
  [[8277, 8278], 2],
  [8279, 1, ""],
  [[8280, 8286], 2],
  [8287, 5, " "],
  [8288, 7],
  [[8289, 8291], 3],
  [8292, 7],
  [8293, 3],
  [[8294, 8297], 3],
  [[8298, 8303], 3],
  [8304, 1, "0"],
  [8305, 1, "i"],
  [[8306, 8307], 3],
  [8308, 1, "4"],
  [8309, 1, "5"],
  [8310, 1, "6"],
  [8311, 1, "7"],
  [8312, 1, "8"],
  [8313, 1, "9"],
  [8314, 5, "+"],
  [8315, 1, ""],
  [8316, 5, "="],
  [8317, 5, "("],
  [8318, 5, ")"],
  [8319, 1, "n"],
  [8320, 1, "0"],
  [8321, 1, "1"],
  [8322, 1, "2"],
  [8323, 1, "3"],
  [8324, 1, "4"],
  [8325, 1, "5"],
  [8326, 1, "6"],
  [8327, 1, "7"],
  [8328, 1, "8"],
  [8329, 1, "9"],
  [8330, 5, "+"],
  [8331, 1, ""],
  [8332, 5, "="],
  [8333, 5, "("],
  [8334, 5, ")"],
  [8335, 3],
  [8336, 1, "a"],
  [8337, 1, "e"],
  [8338, 1, "o"],
  [8339, 1, "x"],
  [8340, 1, ""],
  [8341, 1, "h"],
  [8342, 1, "k"],
  [8343, 1, "l"],
  [8344, 1, "m"],
  [8345, 1, "n"],
  [8346, 1, "p"],
  [8347, 1, "s"],
  [8348, 1, "t"],
  [[8349, 8351], 3],
  [[8352, 8359], 2],
  [8360, 1, "rs"],
  [[8361, 8362], 2],
  [8363, 2],
  [8364, 2],
  [[8365, 8367], 2],
  [[8368, 8369], 2],
  [[8370, 8373], 2],
  [[8374, 8376], 2],
  [8377, 2],
  [8378, 2],
  [[8379, 8381], 2],
  [8382, 2],
  [8383, 2],
  [8384, 2],
  [[8385, 8399], 3],
  [[8400, 8417], 2],
  [[8418, 8419], 2],
  [[8420, 8426], 2],
  [8427, 2],
  [[8428, 8431], 2],
  [8432, 2],
  [[8433, 8447], 3],
  [8448, 5, "a/c"],
  [8449, 5, "a/s"],
  [8450, 1, "c"],
  [8451, 1, "c"],
  [8452, 2],
  [8453, 5, "c/o"],
  [8454, 5, "c/u"],
  [8455, 1, ""],
  [8456, 2],
  [8457, 1, "f"],
  [8458, 1, "g"],
  [[8459, 8462], 1, "h"],
  [8463, 1, ""],
  [[8464, 8465], 1, "i"],
  [[8466, 8467], 1, "l"],
  [8468, 2],
  [8469, 1, "n"],
  [8470, 1, "no"],
  [[8471, 8472], 2],
  [8473, 1, "p"],
  [8474, 1, "q"],
  [[8475, 8477], 1, "r"],
  [[8478, 8479], 2],
  [8480, 1, "sm"],
  [8481, 1, "tel"],
  [8482, 1, "tm"],
  [8483, 2],
  [8484, 1, "z"],
  [8485, 2],
  [8486, 1, ""],
  [8487, 2],
  [8488, 1, "z"],
  [8489, 2],
  [8490, 1, "k"],
  [8491, 1, ""],
  [8492, 1, "b"],
  [8493, 1, "c"],
  [8494, 2],
  [[8495, 8496], 1, "e"],
  [8497, 1, "f"],
  [8498, 3],
  [8499, 1, "m"],
  [8500, 1, "o"],
  [8501, 1, ""],
  [8502, 1, ""],
  [8503, 1, ""],
  [8504, 1, ""],
  [8505, 1, "i"],
  [8506, 2],
  [8507, 1, "fax"],
  [8508, 1, ""],
  [[8509, 8510], 1, ""],
  [8511, 1, ""],
  [8512, 1, ""],
  [[8513, 8516], 2],
  [[8517, 8518], 1, "d"],
  [8519, 1, "e"],
  [8520, 1, "i"],
  [8521, 1, "j"],
  [[8522, 8523], 2],
  [8524, 2],
  [8525, 2],
  [8526, 2],
  [8527, 2],
  [8528, 1, "17"],
  [8529, 1, "19"],
  [8530, 1, "110"],
  [8531, 1, "13"],
  [8532, 1, "23"],
  [8533, 1, "15"],
  [8534, 1, "25"],
  [8535, 1, "35"],
  [8536, 1, "45"],
  [8537, 1, "16"],
  [8538, 1, "56"],
  [8539, 1, "18"],
  [8540, 1, "38"],
  [8541, 1, "58"],
  [8542, 1, "78"],
  [8543, 1, "1"],
  [8544, 1, "i"],
  [8545, 1, "ii"],
  [8546, 1, "iii"],
  [8547, 1, "iv"],
  [8548, 1, "v"],
  [8549, 1, "vi"],
  [8550, 1, "vii"],
  [8551, 1, "viii"],
  [8552, 1, "ix"],
  [8553, 1, "x"],
  [8554, 1, "xi"],
  [8555, 1, "xii"],
  [8556, 1, "l"],
  [8557, 1, "c"],
  [8558, 1, "d"],
  [8559, 1, "m"],
  [8560, 1, "i"],
  [8561, 1, "ii"],
  [8562, 1, "iii"],
  [8563, 1, "iv"],
  [8564, 1, "v"],
  [8565, 1, "vi"],
  [8566, 1, "vii"],
  [8567, 1, "viii"],
  [8568, 1, "ix"],
  [8569, 1, "x"],
  [8570, 1, "xi"],
  [8571, 1, "xii"],
  [8572, 1, "l"],
  [8573, 1, "c"],
  [8574, 1, "d"],
  [8575, 1, "m"],
  [[8576, 8578], 2],
  [8579, 3],
  [8580, 2],
  [[8581, 8584], 2],
  [8585, 1, "03"],
  [[8586, 8587], 2],
  [[8588, 8591], 3],
  [[8592, 8682], 2],
  [[8683, 8691], 2],
  [[8692, 8703], 2],
  [[8704, 8747], 2],
  [8748, 1, ""],
  [8749, 1, ""],
  [8750, 2],
  [8751, 1, ""],
  [8752, 1, ""],
  [[8753, 8799], 2],
  [8800, 4],
  [[8801, 8813], 2],
  [[8814, 8815], 4],
  [[8816, 8945], 2],
  [[8946, 8959], 2],
  [8960, 2],
  [8961, 2],
  [[8962, 9000], 2],
  [9001, 1, ""],
  [9002, 1, ""],
  [[9003, 9082], 2],
  [9083, 2],
  [9084, 2],
  [[9085, 9114], 2],
  [[9115, 9166], 2],
  [[9167, 9168], 2],
  [[9169, 9179], 2],
  [[9180, 9191], 2],
  [9192, 2],
  [[9193, 9203], 2],
  [[9204, 9210], 2],
  [[9211, 9214], 2],
  [9215, 2],
  [[9216, 9252], 2],
  [[9253, 9254], 2],
  [[9255, 9279], 3],
  [[9280, 9290], 2],
  [[9291, 9311], 3],
  [9312, 1, "1"],
  [9313, 1, "2"],
  [9314, 1, "3"],
  [9315, 1, "4"],
  [9316, 1, "5"],
  [9317, 1, "6"],
  [9318, 1, "7"],
  [9319, 1, "8"],
  [9320, 1, "9"],
  [9321, 1, "10"],
  [9322, 1, "11"],
  [9323, 1, "12"],
  [9324, 1, "13"],
  [9325, 1, "14"],
  [9326, 1, "15"],
  [9327, 1, "16"],
  [9328, 1, "17"],
  [9329, 1, "18"],
  [9330, 1, "19"],
  [9331, 1, "20"],
  [9332, 5, "(1)"],
  [9333, 5, "(2)"],
  [9334, 5, "(3)"],
  [9335, 5, "(4)"],
  [9336, 5, "(5)"],
  [9337, 5, "(6)"],
  [9338, 5, "(7)"],
  [9339, 5, "(8)"],
  [9340, 5, "(9)"],
  [9341, 5, "(10)"],
  [9342, 5, "(11)"],
  [9343, 5, "(12)"],
  [9344, 5, "(13)"],
  [9345, 5, "(14)"],
  [9346, 5, "(15)"],
  [9347, 5, "(16)"],
  [9348, 5, "(17)"],
  [9349, 5, "(18)"],
  [9350, 5, "(19)"],
  [9351, 5, "(20)"],
  [[9352, 9371], 3],
  [9372, 5, "(a)"],
  [9373, 5, "(b)"],
  [9374, 5, "(c)"],
  [9375, 5, "(d)"],
  [9376, 5, "(e)"],
  [9377, 5, "(f)"],
  [9378, 5, "(g)"],
  [9379, 5, "(h)"],
  [9380, 5, "(i)"],
  [9381, 5, "(j)"],
  [9382, 5, "(k)"],
  [9383, 5, "(l)"],
  [9384, 5, "(m)"],
  [9385, 5, "(n)"],
  [9386, 5, "(o)"],
  [9387, 5, "(p)"],
  [9388, 5, "(q)"],
  [9389, 5, "(r)"],
  [9390, 5, "(s)"],
  [9391, 5, "(t)"],
  [9392, 5, "(u)"],
  [9393, 5, "(v)"],
  [9394, 5, "(w)"],
  [9395, 5, "(x)"],
  [9396, 5, "(y)"],
  [9397, 5, "(z)"],
  [9398, 1, "a"],
  [9399, 1, "b"],
  [9400, 1, "c"],
  [9401, 1, "d"],
  [9402, 1, "e"],
  [9403, 1, "f"],
  [9404, 1, "g"],
  [9405, 1, "h"],
  [9406, 1, "i"],
  [9407, 1, "j"],
  [9408, 1, "k"],
  [9409, 1, "l"],
  [9410, 1, "m"],
  [9411, 1, "n"],
  [9412, 1, "o"],
  [9413, 1, "p"],
  [9414, 1, "q"],
  [9415, 1, "r"],
  [9416, 1, "s"],
  [9417, 1, "t"],
  [9418, 1, "u"],
  [9419, 1, "v"],
  [9420, 1, "w"],
  [9421, 1, "x"],
  [9422, 1, "y"],
  [9423, 1, "z"],
  [9424, 1, "a"],
  [9425, 1, "b"],
  [9426, 1, "c"],
  [9427, 1, "d"],
  [9428, 1, "e"],
  [9429, 1, "f"],
  [9430, 1, "g"],
  [9431, 1, "h"],
  [9432, 1, "i"],
  [9433, 1, "j"],
  [9434, 1, "k"],
  [9435, 1, "l"],
  [9436, 1, "m"],
  [9437, 1, "n"],
  [9438, 1, "o"],
  [9439, 1, "p"],
  [9440, 1, "q"],
  [9441, 1, "r"],
  [9442, 1, "s"],
  [9443, 1, "t"],
  [9444, 1, "u"],
  [9445, 1, "v"],
  [9446, 1, "w"],
  [9447, 1, "x"],
  [9448, 1, "y"],
  [9449, 1, "z"],
  [9450, 1, "0"],
  [[9451, 9470], 2],
  [9471, 2],
  [[9472, 9621], 2],
  [[9622, 9631], 2],
  [[9632, 9711], 2],
  [[9712, 9719], 2],
  [[9720, 9727], 2],
  [[9728, 9747], 2],
  [[9748, 9749], 2],
  [[9750, 9751], 2],
  [9752, 2],
  [9753, 2],
  [[9754, 9839], 2],
  [[9840, 9841], 2],
  [[9842, 9853], 2],
  [[9854, 9855], 2],
  [[9856, 9865], 2],
  [[9866, 9873], 2],
  [[9874, 9884], 2],
  [9885, 2],
  [[9886, 9887], 2],
  [[9888, 9889], 2],
  [[9890, 9905], 2],
  [9906, 2],
  [[9907, 9916], 2],
  [[9917, 9919], 2],
  [[9920, 9923], 2],
  [[9924, 9933], 2],
  [9934, 2],
  [[9935, 9953], 2],
  [9954, 2],
  [9955, 2],
  [[9956, 9959], 2],
  [[9960, 9983], 2],
  [9984, 2],
  [[9985, 9988], 2],
  [9989, 2],
  [[9990, 9993], 2],
  [[9994, 9995], 2],
  [[9996, 10023], 2],
  [10024, 2],
  [[10025, 10059], 2],
  [10060, 2],
  [10061, 2],
  [10062, 2],
  [[10063, 10066], 2],
  [[10067, 10069], 2],
  [10070, 2],
  [10071, 2],
  [[10072, 10078], 2],
  [[10079, 10080], 2],
  [[10081, 10087], 2],
  [[10088, 10101], 2],
  [[10102, 10132], 2],
  [[10133, 10135], 2],
  [[10136, 10159], 2],
  [10160, 2],
  [[10161, 10174], 2],
  [10175, 2],
  [[10176, 10182], 2],
  [[10183, 10186], 2],
  [10187, 2],
  [10188, 2],
  [10189, 2],
  [[10190, 10191], 2],
  [[10192, 10219], 2],
  [[10220, 10223], 2],
  [[10224, 10239], 2],
  [[10240, 10495], 2],
  [[10496, 10763], 2],
  [10764, 1, ""],
  [[10765, 10867], 2],
  [10868, 5, "::="],
  [10869, 5, "=="],
  [10870, 5, "==="],
  [[10871, 10971], 2],
  [10972, 1, ""],
  [[10973, 11007], 2],
  [[11008, 11021], 2],
  [[11022, 11027], 2],
  [[11028, 11034], 2],
  [[11035, 11039], 2],
  [[11040, 11043], 2],
  [[11044, 11084], 2],
  [[11085, 11087], 2],
  [[11088, 11092], 2],
  [[11093, 11097], 2],
  [[11098, 11123], 2],
  [[11124, 11125], 3],
  [[11126, 11157], 2],
  [11158, 3],
  [11159, 2],
  [[11160, 11193], 2],
  [[11194, 11196], 2],
  [[11197, 11208], 2],
  [11209, 2],
  [[11210, 11217], 2],
  [11218, 2],
  [[11219, 11243], 2],
  [[11244, 11247], 2],
  [[11248, 11262], 2],
  [11263, 2],
  [11264, 1, ""],
  [11265, 1, ""],
  [11266, 1, ""],
  [11267, 1, ""],
  [11268, 1, ""],
  [11269, 1, ""],
  [11270, 1, ""],
  [11271, 1, ""],
  [11272, 1, ""],
  [11273, 1, ""],
  [11274, 1, ""],
  [11275, 1, ""],
  [11276, 1, ""],
  [11277, 1, ""],
  [11278, 1, ""],
  [11279, 1, ""],
  [11280, 1, ""],
  [11281, 1, ""],
  [11282, 1, ""],
  [11283, 1, ""],
  [11284, 1, ""],
  [11285, 1, ""],
  [11286, 1, ""],
  [11287, 1, ""],
  [11288, 1, ""],
  [11289, 1, ""],
  [11290, 1, ""],
  [11291, 1, ""],
  [11292, 1, ""],
  [11293, 1, ""],
  [11294, 1, ""],
  [11295, 1, ""],
  [11296, 1, ""],
  [11297, 1, ""],
  [11298, 1, ""],
  [11299, 1, ""],
  [11300, 1, ""],
  [11301, 1, ""],
  [11302, 1, ""],
  [11303, 1, ""],
  [11304, 1, ""],
  [11305, 1, ""],
  [11306, 1, ""],
  [11307, 1, ""],
  [11308, 1, ""],
  [11309, 1, ""],
  [11310, 1, ""],
  [11311, 1, ""],
  [[11312, 11358], 2],
  [11359, 2],
  [11360, 1, ""],
  [11361, 2],
  [11362, 1, ""],
  [11363, 1, ""],
  [11364, 1, ""],
  [[11365, 11366], 2],
  [11367, 1, ""],
  [11368, 2],
  [11369, 1, ""],
  [11370, 2],
  [11371, 1, ""],
  [11372, 2],
  [11373, 1, ""],
  [11374, 1, ""],
  [11375, 1, ""],
  [11376, 1, ""],
  [11377, 2],
  [11378, 1, ""],
  [11379, 2],
  [11380, 2],
  [11381, 1, ""],
  [[11382, 11383], 2],
  [[11384, 11387], 2],
  [11388, 1, "j"],
  [11389, 1, "v"],
  [11390, 1, ""],
  [11391, 1, ""],
  [11392, 1, ""],
  [11393, 2],
  [11394, 1, ""],
  [11395, 2],
  [11396, 1, ""],
  [11397, 2],
  [11398, 1, ""],
  [11399, 2],
  [11400, 1, ""],
  [11401, 2],
  [11402, 1, ""],
  [11403, 2],
  [11404, 1, ""],
  [11405, 2],
  [11406, 1, ""],
  [11407, 2],
  [11408, 1, ""],
  [11409, 2],
  [11410, 1, ""],
  [11411, 2],
  [11412, 1, ""],
  [11413, 2],
  [11414, 1, ""],
  [11415, 2],
  [11416, 1, ""],
  [11417, 2],
  [11418, 1, ""],
  [11419, 2],
  [11420, 1, ""],
  [11421, 2],
  [11422, 1, ""],
  [11423, 2],
  [11424, 1, ""],
  [11425, 2],
  [11426, 1, ""],
  [11427, 2],
  [11428, 1, ""],
  [11429, 2],
  [11430, 1, ""],
  [11431, 2],
  [11432, 1, ""],
  [11433, 2],
  [11434, 1, ""],
  [11435, 2],
  [11436, 1, ""],
  [11437, 2],
  [11438, 1, ""],
  [11439, 2],
  [11440, 1, ""],
  [11441, 2],
  [11442, 1, ""],
  [11443, 2],
  [11444, 1, ""],
  [11445, 2],
  [11446, 1, ""],
  [11447, 2],
  [11448, 1, ""],
  [11449, 2],
  [11450, 1, ""],
  [11451, 2],
  [11452, 1, ""],
  [11453, 2],
  [11454, 1, ""],
  [11455, 2],
  [11456, 1, ""],
  [11457, 2],
  [11458, 1, ""],
  [11459, 2],
  [11460, 1, ""],
  [11461, 2],
  [11462, 1, ""],
  [11463, 2],
  [11464, 1, ""],
  [11465, 2],
  [11466, 1, ""],
  [11467, 2],
  [11468, 1, ""],
  [11469, 2],
  [11470, 1, ""],
  [11471, 2],
  [11472, 1, ""],
  [11473, 2],
  [11474, 1, ""],
  [11475, 2],
  [11476, 1, ""],
  [11477, 2],
  [11478, 1, ""],
  [11479, 2],
  [11480, 1, ""],
  [11481, 2],
  [11482, 1, ""],
  [11483, 2],
  [11484, 1, ""],
  [11485, 2],
  [11486, 1, ""],
  [11487, 2],
  [11488, 1, ""],
  [11489, 2],
  [11490, 1, ""],
  [[11491, 11492], 2],
  [[11493, 11498], 2],
  [11499, 1, ""],
  [11500, 2],
  [11501, 1, ""],
  [[11502, 11505], 2],
  [11506, 1, ""],
  [11507, 2],
  [[11508, 11512], 3],
  [[11513, 11519], 2],
  [[11520, 11557], 2],
  [11558, 3],
  [11559, 2],
  [[11560, 11564], 3],
  [11565, 2],
  [[11566, 11567], 3],
  [[11568, 11621], 2],
  [[11622, 11623], 2],
  [[11624, 11630], 3],
  [11631, 1, ""],
  [11632, 2],
  [[11633, 11646], 3],
  [11647, 2],
  [[11648, 11670], 2],
  [[11671, 11679], 3],
  [[11680, 11686], 2],
  [11687, 3],
  [[11688, 11694], 2],
  [11695, 3],
  [[11696, 11702], 2],
  [11703, 3],
  [[11704, 11710], 2],
  [11711, 3],
  [[11712, 11718], 2],
  [11719, 3],
  [[11720, 11726], 2],
  [11727, 3],
  [[11728, 11734], 2],
  [11735, 3],
  [[11736, 11742], 2],
  [11743, 3],
  [[11744, 11775], 2],
  [[11776, 11799], 2],
  [[11800, 11803], 2],
  [[11804, 11805], 2],
  [[11806, 11822], 2],
  [11823, 2],
  [11824, 2],
  [11825, 2],
  [[11826, 11835], 2],
  [[11836, 11842], 2],
  [[11843, 11844], 2],
  [[11845, 11849], 2],
  [[11850, 11854], 2],
  [11855, 2],
  [[11856, 11858], 2],
  [[11859, 11869], 2],
  [[11870, 11903], 3],
  [[11904, 11929], 2],
  [11930, 3],
  [[11931, 11934], 2],
  [11935, 1, ""],
  [[11936, 12018], 2],
  [12019, 1, ""],
  [[12020, 12031], 3],
  [12032, 1, ""],
  [12033, 1, ""],
  [12034, 1, ""],
  [12035, 1, ""],
  [12036, 1, ""],
  [12037, 1, ""],
  [12038, 1, ""],
  [12039, 1, ""],
  [12040, 1, ""],
  [12041, 1, ""],
  [12042, 1, ""],
  [12043, 1, ""],
  [12044, 1, ""],
  [12045, 1, ""],
  [12046, 1, ""],
  [12047, 1, ""],
  [12048, 1, ""],
  [12049, 1, ""],
  [12050, 1, ""],
  [12051, 1, ""],
  [12052, 1, ""],
  [12053, 1, ""],
  [12054, 1, ""],
  [12055, 1, ""],
  [12056, 1, ""],
  [12057, 1, ""],
  [12058, 1, ""],
  [12059, 1, ""],
  [12060, 1, ""],
  [12061, 1, ""],
  [12062, 1, ""],
  [12063, 1, ""],
  [12064, 1, ""],
  [12065, 1, ""],
  [12066, 1, ""],
  [12067, 1, ""],
  [12068, 1, ""],
  [12069, 1, ""],
  [12070, 1, ""],
  [12071, 1, ""],
  [12072, 1, ""],
  [12073, 1, ""],
  [12074, 1, ""],
  [12075, 1, ""],
  [12076, 1, ""],
  [12077, 1, ""],
  [12078, 1, ""],
  [12079, 1, ""],
  [12080, 1, ""],
  [12081, 1, ""],
  [12082, 1, ""],
  [12083, 1, ""],
  [12084, 1, ""],
  [12085, 1, ""],
  [12086, 1, ""],
  [12087, 1, ""],
  [12088, 1, ""],
  [12089, 1, ""],
  [12090, 1, ""],
  [12091, 1, ""],
  [12092, 1, ""],
  [12093, 1, ""],
  [12094, 1, ""],
  [12095, 1, ""],
  [12096, 1, ""],
  [12097, 1, ""],
  [12098, 1, ""],
  [12099, 1, ""],
  [12100, 1, ""],
  [12101, 1, ""],
  [12102, 1, ""],
  [12103, 1, ""],
  [12104, 1, ""],
  [12105, 1, ""],
  [12106, 1, ""],
  [12107, 1, ""],
  [12108, 1, ""],
  [12109, 1, ""],
  [12110, 1, ""],
  [12111, 1, ""],
  [12112, 1, ""],
  [12113, 1, ""],
  [12114, 1, ""],
  [12115, 1, ""],
  [12116, 1, ""],
  [12117, 1, ""],
  [12118, 1, ""],
  [12119, 1, ""],
  [12120, 1, ""],
  [12121, 1, ""],
  [12122, 1, ""],
  [12123, 1, ""],
  [12124, 1, ""],
  [12125, 1, ""],
  [12126, 1, ""],
  [12127, 1, ""],
  [12128, 1, ""],
  [12129, 1, ""],
  [12130, 1, ""],
  [12131, 1, ""],
  [12132, 1, ""],
  [12133, 1, ""],
  [12134, 1, ""],
  [12135, 1, ""],
  [12136, 1, ""],
  [12137, 1, ""],
  [12138, 1, ""],
  [12139, 1, ""],
  [12140, 1, ""],
  [12141, 1, ""],
  [12142, 1, ""],
  [12143, 1, ""],
  [12144, 1, ""],
  [12145, 1, ""],
  [12146, 1, ""],
  [12147, 1, ""],
  [12148, 1, ""],
  [12149, 1, ""],
  [12150, 1, ""],
  [12151, 1, ""],
  [12152, 1, ""],
  [12153, 1, ""],
  [12154, 1, ""],
  [12155, 1, ""],
  [12156, 1, ""],
  [12157, 1, ""],
  [12158, 1, ""],
  [12159, 1, ""],
  [12160, 1, ""],
  [12161, 1, ""],
  [12162, 1, ""],
  [12163, 1, ""],
  [12164, 1, ""],
  [12165, 1, ""],
  [12166, 1, ""],
  [12167, 1, ""],
  [12168, 1, ""],
  [12169, 1, ""],
  [12170, 1, ""],
  [12171, 1, ""],
  [12172, 1, ""],
  [12173, 1, ""],
  [12174, 1, ""],
  [12175, 1, ""],
  [12176, 1, ""],
  [12177, 1, ""],
  [12178, 1, ""],
  [12179, 1, ""],
  [12180, 1, ""],
  [12181, 1, ""],
  [12182, 1, ""],
  [12183, 1, ""],
  [12184, 1, ""],
  [12185, 1, ""],
  [12186, 1, ""],
  [12187, 1, ""],
  [12188, 1, ""],
  [12189, 1, ""],
  [12190, 1, ""],
  [12191, 1, ""],
  [12192, 1, ""],
  [12193, 1, ""],
  [12194, 1, ""],
  [12195, 1, ""],
  [12196, 1, ""],
  [12197, 1, ""],
  [12198, 1, ""],
  [12199, 1, ""],
  [12200, 1, ""],
  [12201, 1, ""],
  [12202, 1, ""],
  [12203, 1, ""],
  [12204, 1, ""],
  [12205, 1, ""],
  [12206, 1, ""],
  [12207, 1, ""],
  [12208, 1, ""],
  [12209, 1, ""],
  [12210, 1, ""],
  [12211, 1, ""],
  [12212, 1, ""],
  [12213, 1, ""],
  [12214, 1, ""],
  [12215, 1, ""],
  [12216, 1, ""],
  [12217, 1, ""],
  [12218, 1, ""],
  [12219, 1, ""],
  [12220, 1, ""],
  [12221, 1, ""],
  [12222, 1, ""],
  [12223, 1, ""],
  [12224, 1, ""],
  [12225, 1, ""],
  [12226, 1, ""],
  [12227, 1, ""],
  [12228, 1, ""],
  [12229, 1, ""],
  [12230, 1, ""],
  [12231, 1, ""],
  [12232, 1, ""],
  [12233, 1, ""],
  [12234, 1, ""],
  [12235, 1, ""],
  [12236, 1, ""],
  [12237, 1, ""],
  [12238, 1, ""],
  [12239, 1, ""],
  [12240, 1, ""],
  [12241, 1, ""],
  [12242, 1, ""],
  [12243, 1, ""],
  [12244, 1, ""],
  [12245, 1, ""],
  [[12246, 12271], 3],
  [[12272, 12283], 3],
  [[12284, 12287], 3],
  [12288, 5, " "],
  [12289, 2],
  [12290, 1, "."],
  [[12291, 12292], 2],
  [[12293, 12295], 2],
  [[12296, 12329], 2],
  [[12330, 12333], 2],
  [[12334, 12341], 2],
  [12342, 1, ""],
  [12343, 2],
  [12344, 1, ""],
  [12345, 1, ""],
  [12346, 1, ""],
  [12347, 2],
  [12348, 2],
  [12349, 2],
  [12350, 2],
  [12351, 2],
  [12352, 3],
  [[12353, 12436], 2],
  [[12437, 12438], 2],
  [[12439, 12440], 3],
  [[12441, 12442], 2],
  [12443, 5, " "],
  [12444, 5, " "],
  [[12445, 12446], 2],
  [12447, 1, ""],
  [12448, 2],
  [[12449, 12542], 2],
  [12543, 1, ""],
  [[12544, 12548], 3],
  [[12549, 12588], 2],
  [12589, 2],
  [12590, 2],
  [12591, 2],
  [12592, 3],
  [12593, 1, ""],
  [12594, 1, ""],
  [12595, 1, ""],
  [12596, 1, ""],
  [12597, 1, ""],
  [12598, 1, ""],
  [12599, 1, ""],
  [12600, 1, ""],
  [12601, 1, ""],
  [12602, 1, ""],
  [12603, 1, ""],
  [12604, 1, ""],
  [12605, 1, ""],
  [12606, 1, ""],
  [12607, 1, ""],
  [12608, 1, ""],
  [12609, 1, ""],
  [12610, 1, ""],
  [12611, 1, ""],
  [12612, 1, ""],
  [12613, 1, ""],
  [12614, 1, ""],
  [12615, 1, ""],
  [12616, 1, ""],
  [12617, 1, ""],
  [12618, 1, ""],
  [12619, 1, ""],
  [12620, 1, ""],
  [12621, 1, ""],
  [12622, 1, ""],
  [12623, 1, ""],
  [12624, 1, ""],
  [12625, 1, ""],
  [12626, 1, ""],
  [12627, 1, ""],
  [12628, 1, ""],
  [12629, 1, ""],
  [12630, 1, ""],
  [12631, 1, ""],
  [12632, 1, ""],
  [12633, 1, ""],
  [12634, 1, ""],
  [12635, 1, ""],
  [12636, 1, ""],
  [12637, 1, ""],
  [12638, 1, ""],
  [12639, 1, ""],
  [12640, 1, ""],
  [12641, 1, ""],
  [12642, 1, ""],
  [12643, 1, ""],
  [12644, 3],
  [12645, 1, ""],
  [12646, 1, ""],
  [12647, 1, ""],
  [12648, 1, ""],
  [12649, 1, ""],
  [12650, 1, ""],
  [12651, 1, ""],
  [12652, 1, ""],
  [12653, 1, ""],
  [12654, 1, ""],
  [12655, 1, ""],
  [12656, 1, ""],
  [12657, 1, ""],
  [12658, 1, ""],
  [12659, 1, ""],
  [12660, 1, ""],
  [12661, 1, ""],
  [12662, 1, ""],
  [12663, 1, ""],
  [12664, 1, ""],
  [12665, 1, ""],
  [12666, 1, ""],
  [12667, 1, ""],
  [12668, 1, ""],
  [12669, 1, ""],
  [12670, 1, ""],
  [12671, 1, ""],
  [12672, 1, ""],
  [12673, 1, ""],
  [12674, 1, ""],
  [12675, 1, ""],
  [12676, 1, ""],
  [12677, 1, ""],
  [12678, 1, ""],
  [12679, 1, ""],
  [12680, 1, ""],
  [12681, 1, ""],
  [12682, 1, ""],
  [12683, 1, ""],
  [12684, 1, ""],
  [12685, 1, ""],
  [12686, 1, ""],
  [12687, 3],
  [[12688, 12689], 2],
  [12690, 1, ""],
  [12691, 1, ""],
  [12692, 1, ""],
  [12693, 1, ""],
  [12694, 1, ""],
  [12695, 1, ""],
  [12696, 1, ""],
  [12697, 1, ""],
  [12698, 1, ""],
  [12699, 1, ""],
  [12700, 1, ""],
  [12701, 1, ""],
  [12702, 1, ""],
  [12703, 1, ""],
  [[12704, 12727], 2],
  [[12728, 12730], 2],
  [[12731, 12735], 2],
  [[12736, 12751], 2],
  [[12752, 12771], 2],
  [[12772, 12783], 3],
  [[12784, 12799], 2],
  [12800, 5, "()"],
  [12801, 5, "()"],
  [12802, 5, "()"],
  [12803, 5, "()"],
  [12804, 5, "()"],
  [12805, 5, "()"],
  [12806, 5, "()"],
  [12807, 5, "()"],
  [12808, 5, "()"],
  [12809, 5, "()"],
  [12810, 5, "()"],
  [12811, 5, "()"],
  [12812, 5, "()"],
  [12813, 5, "()"],
  [12814, 5, "()"],
  [12815, 5, "()"],
  [12816, 5, "()"],
  [12817, 5, "()"],
  [12818, 5, "()"],
  [12819, 5, "()"],
  [12820, 5, "()"],
  [12821, 5, "()"],
  [12822, 5, "()"],
  [12823, 5, "()"],
  [12824, 5, "()"],
  [12825, 5, "()"],
  [12826, 5, "()"],
  [12827, 5, "()"],
  [12828, 5, "()"],
  [12829, 5, "()"],
  [12830, 5, "()"],
  [12831, 3],
  [12832, 5, "()"],
  [12833, 5, "()"],
  [12834, 5, "()"],
  [12835, 5, "()"],
  [12836, 5, "()"],
  [12837, 5, "()"],
  [12838, 5, "()"],
  [12839, 5, "()"],
  [12840, 5, "()"],
  [12841, 5, "()"],
  [12842, 5, "()"],
  [12843, 5, "()"],
  [12844, 5, "()"],
  [12845, 5, "()"],
  [12846, 5, "()"],
  [12847, 5, "()"],
  [12848, 5, "()"],
  [12849, 5, "()"],
  [12850, 5, "()"],
  [12851, 5, "()"],
  [12852, 5, "()"],
  [12853, 5, "()"],
  [12854, 5, "()"],
  [12855, 5, "()"],
  [12856, 5, "()"],
  [12857, 5, "()"],
  [12858, 5, "()"],
  [12859, 5, "()"],
  [12860, 5, "()"],
  [12861, 5, "()"],
  [12862, 5, "()"],
  [12863, 5, "()"],
  [12864, 5, "()"],
  [12865, 5, "()"],
  [12866, 5, "()"],
  [12867, 5, "()"],
  [12868, 1, ""],
  [12869, 1, ""],
  [12870, 1, ""],
  [12871, 1, ""],
  [[12872, 12879], 2],
  [12880, 1, "pte"],
  [12881, 1, "21"],
  [12882, 1, "22"],
  [12883, 1, "23"],
  [12884, 1, "24"],
  [12885, 1, "25"],
  [12886, 1, "26"],
  [12887, 1, "27"],
  [12888, 1, "28"],
  [12889, 1, "29"],
  [12890, 1, "30"],
  [12891, 1, "31"],
  [12892, 1, "32"],
  [12893, 1, "33"],
  [12894, 1, "34"],
  [12895, 1, "35"],
  [12896, 1, ""],
  [12897, 1, ""],
  [12898, 1, ""],
  [12899, 1, ""],
  [12900, 1, ""],
  [12901, 1, ""],
  [12902, 1, ""],
  [12903, 1, ""],
  [12904, 1, ""],
  [12905, 1, ""],
  [12906, 1, ""],
  [12907, 1, ""],
  [12908, 1, ""],
  [12909, 1, ""],
  [12910, 1, ""],
  [12911, 1, ""],
  [12912, 1, ""],
  [12913, 1, ""],
  [12914, 1, ""],
  [12915, 1, ""],
  [12916, 1, ""],
  [12917, 1, ""],
  [12918, 1, ""],
  [12919, 1, ""],
  [12920, 1, ""],
  [12921, 1, ""],
  [12922, 1, ""],
  [12923, 1, ""],
  [12924, 1, ""],
  [12925, 1, ""],
  [12926, 1, ""],
  [12927, 2],
  [12928, 1, ""],
  [12929, 1, ""],
  [12930, 1, ""],
  [12931, 1, ""],
  [12932, 1, ""],
  [12933, 1, ""],
  [12934, 1, ""],
  [12935, 1, ""],
  [12936, 1, ""],
  [12937, 1, ""],
  [12938, 1, ""],
  [12939, 1, ""],
  [12940, 1, ""],
  [12941, 1, ""],
  [12942, 1, ""],
  [12943, 1, ""],
  [12944, 1, ""],
  [12945, 1, ""],
  [12946, 1, ""],
  [12947, 1, ""],
  [12948, 1, ""],
  [12949, 1, ""],
  [12950, 1, ""],
  [12951, 1, ""],
  [12952, 1, ""],
  [12953, 1, ""],
  [12954, 1, ""],
  [12955, 1, ""],
  [12956, 1, ""],
  [12957, 1, ""],
  [12958, 1, ""],
  [12959, 1, ""],
  [12960, 1, ""],
  [12961, 1, ""],
  [12962, 1, ""],
  [12963, 1, ""],
  [12964, 1, ""],
  [12965, 1, ""],
  [12966, 1, ""],
  [12967, 1, ""],
  [12968, 1, ""],
  [12969, 1, ""],
  [12970, 1, ""],
  [12971, 1, ""],
  [12972, 1, ""],
  [12973, 1, ""],
  [12974, 1, ""],
  [12975, 1, ""],
  [12976, 1, ""],
  [12977, 1, "36"],
  [12978, 1, "37"],
  [12979, 1, "38"],
  [12980, 1, "39"],
  [12981, 1, "40"],
  [12982, 1, "41"],
  [12983, 1, "42"],
  [12984, 1, "43"],
  [12985, 1, "44"],
  [12986, 1, "45"],
  [12987, 1, "46"],
  [12988, 1, "47"],
  [12989, 1, "48"],
  [12990, 1, "49"],
  [12991, 1, "50"],
  [12992, 1, "1"],
  [12993, 1, "2"],
  [12994, 1, "3"],
  [12995, 1, "4"],
  [12996, 1, "5"],
  [12997, 1, "6"],
  [12998, 1, "7"],
  [12999, 1, "8"],
  [13000, 1, "9"],
  [13001, 1, "10"],
  [13002, 1, "11"],
  [13003, 1, "12"],
  [13004, 1, "hg"],
  [13005, 1, "erg"],
  [13006, 1, "ev"],
  [13007, 1, "ltd"],
  [13008, 1, ""],
  [13009, 1, ""],
  [13010, 1, ""],
  [13011, 1, ""],
  [13012, 1, ""],
  [13013, 1, ""],
  [13014, 1, ""],
  [13015, 1, ""],
  [13016, 1, ""],
  [13017, 1, ""],
  [13018, 1, ""],
  [13019, 1, ""],
  [13020, 1, ""],
  [13021, 1, ""],
  [13022, 1, ""],
  [13023, 1, ""],
  [13024, 1, ""],
  [13025, 1, ""],
  [13026, 1, ""],
  [13027, 1, ""],
  [13028, 1, ""],
  [13029, 1, ""],
  [13030, 1, ""],
  [13031, 1, ""],
  [13032, 1, ""],
  [13033, 1, ""],
  [13034, 1, ""],
  [13035, 1, ""],
  [13036, 1, ""],
  [13037, 1, ""],
  [13038, 1, ""],
  [13039, 1, ""],
  [13040, 1, ""],
  [13041, 1, ""],
  [13042, 1, ""],
  [13043, 1, ""],
  [13044, 1, ""],
  [13045, 1, ""],
  [13046, 1, ""],
  [13047, 1, ""],
  [13048, 1, ""],
  [13049, 1, ""],
  [13050, 1, ""],
  [13051, 1, ""],
  [13052, 1, ""],
  [13053, 1, ""],
  [13054, 1, ""],
  [13055, 1, ""],
  [13056, 1, ""],
  [13057, 1, ""],
  [13058, 1, ""],
  [13059, 1, ""],
  [13060, 1, ""],
  [13061, 1, ""],
  [13062, 1, ""],
  [13063, 1, ""],
  [13064, 1, ""],
  [13065, 1, ""],
  [13066, 1, ""],
  [13067, 1, ""],
  [13068, 1, ""],
  [13069, 1, ""],
  [13070, 1, ""],
  [13071, 1, ""],
  [13072, 1, ""],
  [13073, 1, ""],
  [13074, 1, ""],
  [13075, 1, ""],
  [13076, 1, ""],
  [13077, 1, ""],
  [13078, 1, ""],
  [13079, 1, ""],
  [13080, 1, ""],
  [13081, 1, ""],
  [13082, 1, ""],
  [13083, 1, ""],
  [13084, 1, ""],
  [13085, 1, ""],
  [13086, 1, ""],
  [13087, 1, ""],
  [13088, 1, ""],
  [13089, 1, ""],
  [13090, 1, ""],
  [13091, 1, ""],
  [13092, 1, ""],
  [13093, 1, ""],
  [13094, 1, ""],
  [13095, 1, ""],
  [13096, 1, ""],
  [13097, 1, ""],
  [13098, 1, ""],
  [13099, 1, ""],
  [13100, 1, ""],
  [13101, 1, ""],
  [13102, 1, ""],
  [13103, 1, ""],
  [13104, 1, ""],
  [13105, 1, ""],
  [13106, 1, ""],
  [13107, 1, ""],
  [13108, 1, ""],
  [13109, 1, ""],
  [13110, 1, ""],
  [13111, 1, ""],
  [13112, 1, ""],
  [13113, 1, ""],
  [13114, 1, ""],
  [13115, 1, ""],
  [13116, 1, ""],
  [13117, 1, ""],
  [13118, 1, ""],
  [13119, 1, ""],
  [13120, 1, ""],
  [13121, 1, ""],
  [13122, 1, ""],
  [13123, 1, ""],
  [13124, 1, ""],
  [13125, 1, ""],
  [13126, 1, ""],
  [13127, 1, ""],
  [13128, 1, ""],
  [13129, 1, ""],
  [13130, 1, ""],
  [13131, 1, ""],
  [13132, 1, ""],
  [13133, 1, ""],
  [13134, 1, ""],
  [13135, 1, ""],
  [13136, 1, ""],
  [13137, 1, ""],
  [13138, 1, ""],
  [13139, 1, ""],
  [13140, 1, ""],
  [13141, 1, ""],
  [13142, 1, ""],
  [13143, 1, ""],
  [13144, 1, "0"],
  [13145, 1, "1"],
  [13146, 1, "2"],
  [13147, 1, "3"],
  [13148, 1, "4"],
  [13149, 1, "5"],
  [13150, 1, "6"],
  [13151, 1, "7"],
  [13152, 1, "8"],
  [13153, 1, "9"],
  [13154, 1, "10"],
  [13155, 1, "11"],
  [13156, 1, "12"],
  [13157, 1, "13"],
  [13158, 1, "14"],
  [13159, 1, "15"],
  [13160, 1, "16"],
  [13161, 1, "17"],
  [13162, 1, "18"],
  [13163, 1, "19"],
  [13164, 1, "20"],
  [13165, 1, "21"],
  [13166, 1, "22"],
  [13167, 1, "23"],
  [13168, 1, "24"],
  [13169, 1, "hpa"],
  [13170, 1, "da"],
  [13171, 1, "au"],
  [13172, 1, "bar"],
  [13173, 1, "ov"],
  [13174, 1, "pc"],
  [13175, 1, "dm"],
  [13176, 1, "dm2"],
  [13177, 1, "dm3"],
  [13178, 1, "iu"],
  [13179, 1, ""],
  [13180, 1, ""],
  [13181, 1, ""],
  [13182, 1, ""],
  [13183, 1, ""],
  [13184, 1, "pa"],
  [13185, 1, "na"],
  [13186, 1, "a"],
  [13187, 1, "ma"],
  [13188, 1, "ka"],
  [13189, 1, "kb"],
  [13190, 1, "mb"],
  [13191, 1, "gb"],
  [13192, 1, "cal"],
  [13193, 1, "kcal"],
  [13194, 1, "pf"],
  [13195, 1, "nf"],
  [13196, 1, "f"],
  [13197, 1, "g"],
  [13198, 1, "mg"],
  [13199, 1, "kg"],
  [13200, 1, "hz"],
  [13201, 1, "khz"],
  [13202, 1, "mhz"],
  [13203, 1, "ghz"],
  [13204, 1, "thz"],
  [13205, 1, "l"],
  [13206, 1, "ml"],
  [13207, 1, "dl"],
  [13208, 1, "kl"],
  [13209, 1, "fm"],
  [13210, 1, "nm"],
  [13211, 1, "m"],
  [13212, 1, "mm"],
  [13213, 1, "cm"],
  [13214, 1, "km"],
  [13215, 1, "mm2"],
  [13216, 1, "cm2"],
  [13217, 1, "m2"],
  [13218, 1, "km2"],
  [13219, 1, "mm3"],
  [13220, 1, "cm3"],
  [13221, 1, "m3"],
  [13222, 1, "km3"],
  [13223, 1, "ms"],
  [13224, 1, "ms2"],
  [13225, 1, "pa"],
  [13226, 1, "kpa"],
  [13227, 1, "mpa"],
  [13228, 1, "gpa"],
  [13229, 1, "rad"],
  [13230, 1, "rads"],
  [13231, 1, "rads2"],
  [13232, 1, "ps"],
  [13233, 1, "ns"],
  [13234, 1, "s"],
  [13235, 1, "ms"],
  [13236, 1, "pv"],
  [13237, 1, "nv"],
  [13238, 1, "v"],
  [13239, 1, "mv"],
  [13240, 1, "kv"],
  [13241, 1, "mv"],
  [13242, 1, "pw"],
  [13243, 1, "nw"],
  [13244, 1, "w"],
  [13245, 1, "mw"],
  [13246, 1, "kw"],
  [13247, 1, "mw"],
  [13248, 1, "k"],
  [13249, 1, "m"],
  [13250, 3],
  [13251, 1, "bq"],
  [13252, 1, "cc"],
  [13253, 1, "cd"],
  [13254, 1, "ckg"],
  [13255, 3],
  [13256, 1, "db"],
  [13257, 1, "gy"],
  [13258, 1, "ha"],
  [13259, 1, "hp"],
  [13260, 1, "in"],
  [13261, 1, "kk"],
  [13262, 1, "km"],
  [13263, 1, "kt"],
  [13264, 1, "lm"],
  [13265, 1, "ln"],
  [13266, 1, "log"],
  [13267, 1, "lx"],
  [13268, 1, "mb"],
  [13269, 1, "mil"],
  [13270, 1, "mol"],
  [13271, 1, "ph"],
  [13272, 3],
  [13273, 1, "ppm"],
  [13274, 1, "pr"],
  [13275, 1, "sr"],
  [13276, 1, "sv"],
  [13277, 1, "wb"],
  [13278, 1, "vm"],
  [13279, 1, "am"],
  [13280, 1, "1"],
  [13281, 1, "2"],
  [13282, 1, "3"],
  [13283, 1, "4"],
  [13284, 1, "5"],
  [13285, 1, "6"],
  [13286, 1, "7"],
  [13287, 1, "8"],
  [13288, 1, "9"],
  [13289, 1, "10"],
  [13290, 1, "11"],
  [13291, 1, "12"],
  [13292, 1, "13"],
  [13293, 1, "14"],
  [13294, 1, "15"],
  [13295, 1, "16"],
  [13296, 1, "17"],
  [13297, 1, "18"],
  [13298, 1, "19"],
  [13299, 1, "20"],
  [13300, 1, "21"],
  [13301, 1, "22"],
  [13302, 1, "23"],
  [13303, 1, "24"],
  [13304, 1, "25"],
  [13305, 1, "26"],
  [13306, 1, "27"],
  [13307, 1, "28"],
  [13308, 1, "29"],
  [13309, 1, "30"],
  [13310, 1, "31"],
  [13311, 1, "gal"],
  [[13312, 19893], 2],
  [[19894, 19903], 2],
  [[19904, 19967], 2],
  [[19968, 40869], 2],
  [[40870, 40891], 2],
  [[40892, 40899], 2],
  [[40900, 40907], 2],
  [40908, 2],
  [[40909, 40917], 2],
  [[40918, 40938], 2],
  [[40939, 40943], 2],
  [[40944, 40956], 2],
  [[40957, 40959], 2],
  [[40960, 42124], 2],
  [[42125, 42127], 3],
  [[42128, 42145], 2],
  [[42146, 42147], 2],
  [[42148, 42163], 2],
  [42164, 2],
  [[42165, 42176], 2],
  [42177, 2],
  [[42178, 42180], 2],
  [42181, 2],
  [42182, 2],
  [[42183, 42191], 3],
  [[42192, 42237], 2],
  [[42238, 42239], 2],
  [[42240, 42508], 2],
  [[42509, 42511], 2],
  [[42512, 42539], 2],
  [[42540, 42559], 3],
  [42560, 1, ""],
  [42561, 2],
  [42562, 1, ""],
  [42563, 2],
  [42564, 1, ""],
  [42565, 2],
  [42566, 1, ""],
  [42567, 2],
  [42568, 1, ""],
  [42569, 2],
  [42570, 1, ""],
  [42571, 2],
  [42572, 1, ""],
  [42573, 2],
  [42574, 1, ""],
  [42575, 2],
  [42576, 1, ""],
  [42577, 2],
  [42578, 1, ""],
  [42579, 2],
  [42580, 1, ""],
  [42581, 2],
  [42582, 1, ""],
  [42583, 2],
  [42584, 1, ""],
  [42585, 2],
  [42586, 1, ""],
  [42587, 2],
  [42588, 1, ""],
  [42589, 2],
  [42590, 1, ""],
  [42591, 2],
  [42592, 1, ""],
  [42593, 2],
  [42594, 1, ""],
  [42595, 2],
  [42596, 1, ""],
  [42597, 2],
  [42598, 1, ""],
  [42599, 2],
  [42600, 1, ""],
  [42601, 2],
  [42602, 1, ""],
  [42603, 2],
  [42604, 1, ""],
  [[42605, 42607], 2],
  [[42608, 42611], 2],
  [[42612, 42619], 2],
  [[42620, 42621], 2],
  [42622, 2],
  [42623, 2],
  [42624, 1, ""],
  [42625, 2],
  [42626, 1, ""],
  [42627, 2],
  [42628, 1, ""],
  [42629, 2],
  [42630, 1, ""],
  [42631, 2],
  [42632, 1, ""],
  [42633, 2],
  [42634, 1, ""],
  [42635, 2],
  [42636, 1, ""],
  [42637, 2],
  [42638, 1, ""],
  [42639, 2],
  [42640, 1, ""],
  [42641, 2],
  [42642, 1, ""],
  [42643, 2],
  [42644, 1, ""],
  [42645, 2],
  [42646, 1, ""],
  [42647, 2],
  [42648, 1, ""],
  [42649, 2],
  [42650, 1, ""],
  [42651, 2],
  [42652, 1, ""],
  [42653, 1, ""],
  [42654, 2],
  [42655, 2],
  [[42656, 42725], 2],
  [[42726, 42735], 2],
  [[42736, 42737], 2],
  [[42738, 42743], 2],
  [[42744, 42751], 3],
  [[42752, 42774], 2],
  [[42775, 42778], 2],
  [[42779, 42783], 2],
  [[42784, 42785], 2],
  [42786, 1, ""],
  [42787, 2],
  [42788, 1, ""],
  [42789, 2],
  [42790, 1, ""],
  [42791, 2],
  [42792, 1, ""],
  [42793, 2],
  [42794, 1, ""],
  [42795, 2],
  [42796, 1, ""],
  [42797, 2],
  [42798, 1, ""],
  [[42799, 42801], 2],
  [42802, 1, ""],
  [42803, 2],
  [42804, 1, ""],
  [42805, 2],
  [42806, 1, ""],
  [42807, 2],
  [42808, 1, ""],
  [42809, 2],
  [42810, 1, ""],
  [42811, 2],
  [42812, 1, ""],
  [42813, 2],
  [42814, 1, ""],
  [42815, 2],
  [42816, 1, ""],
  [42817, 2],
  [42818, 1, ""],
  [42819, 2],
  [42820, 1, ""],
  [42821, 2],
  [42822, 1, ""],
  [42823, 2],
  [42824, 1, ""],
  [42825, 2],
  [42826, 1, ""],
  [42827, 2],
  [42828, 1, ""],
  [42829, 2],
  [42830, 1, ""],
  [42831, 2],
  [42832, 1, ""],
  [42833, 2],
  [42834, 1, ""],
  [42835, 2],
  [42836, 1, ""],
  [42837, 2],
  [42838, 1, ""],
  [42839, 2],
  [42840, 1, ""],
  [42841, 2],
  [42842, 1, ""],
  [42843, 2],
  [42844, 1, ""],
  [42845, 2],
  [42846, 1, ""],
  [42847, 2],
  [42848, 1, ""],
  [42849, 2],
  [42850, 1, ""],
  [42851, 2],
  [42852, 1, ""],
  [42853, 2],
  [42854, 1, ""],
  [42855, 2],
  [42856, 1, ""],
  [42857, 2],
  [42858, 1, ""],
  [42859, 2],
  [42860, 1, ""],
  [42861, 2],
  [42862, 1, ""],
  [42863, 2],
  [42864, 1, ""],
  [[42865, 42872], 2],
  [42873, 1, ""],
  [42874, 2],
  [42875, 1, ""],
  [42876, 2],
  [42877, 1, ""],
  [42878, 1, ""],
  [42879, 2],
  [42880, 1, ""],
  [42881, 2],
  [42882, 1, ""],
  [42883, 2],
  [42884, 1, ""],
  [42885, 2],
  [42886, 1, ""],
  [[42887, 42888], 2],
  [[42889, 42890], 2],
  [42891, 1, ""],
  [42892, 2],
  [42893, 1, ""],
  [42894, 2],
  [42895, 2],
  [42896, 1, ""],
  [42897, 2],
  [42898, 1, ""],
  [42899, 2],
  [[42900, 42901], 2],
  [42902, 1, ""],
  [42903, 2],
  [42904, 1, ""],
  [42905, 2],
  [42906, 1, ""],
  [42907, 2],
  [42908, 1, ""],
  [42909, 2],
  [42910, 1, ""],
  [42911, 2],
  [42912, 1, ""],
  [42913, 2],
  [42914, 1, ""],
  [42915, 2],
  [42916, 1, ""],
  [42917, 2],
  [42918, 1, ""],
  [42919, 2],
  [42920, 1, ""],
  [42921, 2],
  [42922, 1, ""],
  [42923, 1, ""],
  [42924, 1, ""],
  [42925, 1, ""],
  [42926, 1, ""],
  [42927, 2],
  [42928, 1, ""],
  [42929, 1, ""],
  [42930, 1, ""],
  [42931, 1, ""],
  [42932, 1, ""],
  [42933, 2],
  [42934, 1, ""],
  [42935, 2],
  [42936, 1, ""],
  [42937, 2],
  [42938, 1, ""],
  [42939, 2],
  [42940, 1, ""],
  [42941, 2],
  [42942, 1, ""],
  [42943, 2],
  [42944, 1, ""],
  [42945, 2],
  [42946, 1, ""],
  [42947, 2],
  [42948, 1, ""],
  [42949, 1, ""],
  [42950, 1, ""],
  [42951, 1, ""],
  [42952, 2],
  [42953, 1, ""],
  [42954, 2],
  [[42955, 42959], 3],
  [42960, 1, ""],
  [42961, 2],
  [42962, 3],
  [42963, 2],
  [42964, 3],
  [42965, 2],
  [42966, 1, ""],
  [42967, 2],
  [42968, 1, ""],
  [42969, 2],
  [[42970, 42993], 3],
  [42994, 1, "c"],
  [42995, 1, "f"],
  [42996, 1, "q"],
  [42997, 1, ""],
  [42998, 2],
  [42999, 2],
  [43000, 1, ""],
  [43001, 1, ""],
  [43002, 2],
  [[43003, 43007], 2],
  [[43008, 43047], 2],
  [[43048, 43051], 2],
  [43052, 2],
  [[43053, 43055], 3],
  [[43056, 43065], 2],
  [[43066, 43071], 3],
  [[43072, 43123], 2],
  [[43124, 43127], 2],
  [[43128, 43135], 3],
  [[43136, 43204], 2],
  [43205, 2],
  [[43206, 43213], 3],
  [[43214, 43215], 2],
  [[43216, 43225], 2],
  [[43226, 43231], 3],
  [[43232, 43255], 2],
  [[43256, 43258], 2],
  [43259, 2],
  [43260, 2],
  [43261, 2],
  [[43262, 43263], 2],
  [[43264, 43309], 2],
  [[43310, 43311], 2],
  [[43312, 43347], 2],
  [[43348, 43358], 3],
  [43359, 2],
  [[43360, 43388], 2],
  [[43389, 43391], 3],
  [[43392, 43456], 2],
  [[43457, 43469], 2],
  [43470, 3],
  [[43471, 43481], 2],
  [[43482, 43485], 3],
  [[43486, 43487], 2],
  [[43488, 43518], 2],
  [43519, 3],
  [[43520, 43574], 2],
  [[43575, 43583], 3],
  [[43584, 43597], 2],
  [[43598, 43599], 3],
  [[43600, 43609], 2],
  [[43610, 43611], 3],
  [[43612, 43615], 2],
  [[43616, 43638], 2],
  [[43639, 43641], 2],
  [[43642, 43643], 2],
  [[43644, 43647], 2],
  [[43648, 43714], 2],
  [[43715, 43738], 3],
  [[43739, 43741], 2],
  [[43742, 43743], 2],
  [[43744, 43759], 2],
  [[43760, 43761], 2],
  [[43762, 43766], 2],
  [[43767, 43776], 3],
  [[43777, 43782], 2],
  [[43783, 43784], 3],
  [[43785, 43790], 2],
  [[43791, 43792], 3],
  [[43793, 43798], 2],
  [[43799, 43807], 3],
  [[43808, 43814], 2],
  [43815, 3],
  [[43816, 43822], 2],
  [43823, 3],
  [[43824, 43866], 2],
  [43867, 2],
  [43868, 1, ""],
  [43869, 1, ""],
  [43870, 1, ""],
  [43871, 1, ""],
  [[43872, 43875], 2],
  [[43876, 43877], 2],
  [[43878, 43879], 2],
  [43880, 2],
  [43881, 1, ""],
  [[43882, 43883], 2],
  [[43884, 43887], 3],
  [43888, 1, ""],
  [43889, 1, ""],
  [43890, 1, ""],
  [43891, 1, ""],
  [43892, 1, ""],
  [43893, 1, ""],
  [43894, 1, ""],
  [43895, 1, ""],
  [43896, 1, ""],
  [43897, 1, ""],
  [43898, 1, ""],
  [43899, 1, ""],
  [43900, 1, ""],
  [43901, 1, ""],
  [43902, 1, ""],
  [43903, 1, ""],
  [43904, 1, ""],
  [43905, 1, ""],
  [43906, 1, ""],
  [43907, 1, ""],
  [43908, 1, ""],
  [43909, 1, ""],
  [43910, 1, ""],
  [43911, 1, ""],
  [43912, 1, ""],
  [43913, 1, ""],
  [43914, 1, ""],
  [43915, 1, ""],
  [43916, 1, ""],
  [43917, 1, ""],
  [43918, 1, ""],
  [43919, 1, ""],
  [43920, 1, ""],
  [43921, 1, ""],
  [43922, 1, ""],
  [43923, 1, ""],
  [43924, 1, ""],
  [43925, 1, ""],
  [43926, 1, ""],
  [43927, 1, ""],
  [43928, 1, ""],
  [43929, 1, ""],
  [43930, 1, ""],
  [43931, 1, ""],
  [43932, 1, ""],
  [43933, 1, ""],
  [43934, 1, ""],
  [43935, 1, ""],
  [43936, 1, ""],
  [43937, 1, ""],
  [43938, 1, ""],
  [43939, 1, ""],
  [43940, 1, ""],
  [43941, 1, ""],
  [43942, 1, ""],
  [43943, 1, ""],
  [43944, 1, ""],
  [43945, 1, ""],
  [43946, 1, ""],
  [43947, 1, ""],
  [43948, 1, ""],
  [43949, 1, ""],
  [43950, 1, ""],
  [43951, 1, ""],
  [43952, 1, ""],
  [43953, 1, ""],
  [43954, 1, ""],
  [43955, 1, ""],
  [43956, 1, ""],
  [43957, 1, ""],
  [43958, 1, ""],
  [43959, 1, ""],
  [43960, 1, ""],
  [43961, 1, ""],
  [43962, 1, ""],
  [43963, 1, ""],
  [43964, 1, ""],
  [43965, 1, ""],
  [43966, 1, ""],
  [43967, 1, ""],
  [[43968, 44010], 2],
  [44011, 2],
  [[44012, 44013], 2],
  [[44014, 44015], 3],
  [[44016, 44025], 2],
  [[44026, 44031], 3],
  [[44032, 55203], 2],
  [[55204, 55215], 3],
  [[55216, 55238], 2],
  [[55239, 55242], 3],
  [[55243, 55291], 2],
  [[55292, 55295], 3],
  [[55296, 57343], 3],
  [[57344, 63743], 3],
  [63744, 1, ""],
  [63745, 1, ""],
  [63746, 1, ""],
  [63747, 1, ""],
  [63748, 1, ""],
  [63749, 1, ""],
  [63750, 1, ""],
  [[63751, 63752], 1, ""],
  [63753, 1, ""],
  [63754, 1, ""],
  [63755, 1, ""],
  [63756, 1, ""],
  [63757, 1, ""],
  [63758, 1, ""],
  [63759, 1, ""],
  [63760, 1, ""],
  [63761, 1, ""],
  [63762, 1, ""],
  [63763, 1, ""],
  [63764, 1, ""],
  [63765, 1, ""],
  [63766, 1, ""],
  [63767, 1, ""],
  [63768, 1, ""],
  [63769, 1, ""],
  [63770, 1, ""],
  [63771, 1, ""],
  [63772, 1, ""],
  [63773, 1, ""],
  [63774, 1, ""],
  [63775, 1, ""],
  [63776, 1, ""],
  [63777, 1, ""],
  [63778, 1, ""],
  [63779, 1, ""],
  [63780, 1, ""],
  [63781, 1, ""],
  [63782, 1, ""],
  [63783, 1, ""],
  [63784, 1, ""],
  [63785, 1, ""],
  [63786, 1, ""],
  [63787, 1, ""],
  [63788, 1, ""],
  [63789, 1, ""],
  [63790, 1, ""],
  [63791, 1, ""],
  [63792, 1, ""],
  [63793, 1, ""],
  [63794, 1, ""],
  [63795, 1, ""],
  [63796, 1, ""],
  [63797, 1, ""],
  [63798, 1, ""],
  [63799, 1, ""],
  [63800, 1, ""],
  [63801, 1, ""],
  [63802, 1, ""],
  [63803, 1, ""],
  [63804, 1, ""],
  [63805, 1, ""],
  [63806, 1, ""],
  [63807, 1, ""],
  [63808, 1, ""],
  [63809, 1, ""],
  [63810, 1, ""],
  [63811, 1, ""],
  [63812, 1, ""],
  [63813, 1, ""],
  [63814, 1, ""],
  [63815, 1, ""],
  [63816, 1, ""],
  [63817, 1, ""],
  [63818, 1, ""],
  [63819, 1, ""],
  [63820, 1, ""],
  [63821, 1, ""],
  [63822, 1, ""],
  [63823, 1, ""],
  [63824, 1, ""],
  [63825, 1, ""],
  [63826, 1, ""],
  [63827, 1, ""],
  [63828, 1, ""],
  [63829, 1, ""],
  [63830, 1, ""],
  [63831, 1, ""],
  [63832, 1, ""],
  [63833, 1, ""],
  [63834, 1, ""],
  [63835, 1, ""],
  [63836, 1, ""],
  [63837, 1, ""],
  [63838, 1, ""],
  [63839, 1, ""],
  [63840, 1, ""],
  [63841, 1, ""],
  [63842, 1, ""],
  [63843, 1, ""],
  [63844, 1, ""],
  [63845, 1, ""],
  [63846, 1, ""],
  [63847, 1, ""],
  [63848, 1, ""],
  [63849, 1, ""],
  [63850, 1, ""],
  [63851, 1, ""],
  [63852, 1, ""],
  [63853, 1, ""],
  [63854, 1, ""],
  [63855, 1, ""],
  [63856, 1, ""],
  [63857, 1, ""],
  [63858, 1, ""],
  [63859, 1, ""],
  [63860, 1, ""],
  [63861, 1, ""],
  [63862, 1, ""],
  [63863, 1, ""],
  [63864, 1, ""],
  [63865, 1, ""],
  [63866, 1, ""],
  [63867, 1, ""],
  [63868, 1, ""],
  [63869, 1, ""],
  [63870, 1, ""],
  [63871, 1, ""],
  [63872, 1, ""],
  [63873, 1, ""],
  [63874, 1, ""],
  [63875, 1, ""],
  [63876, 1, ""],
  [63877, 1, ""],
  [63878, 1, ""],
  [63879, 1, ""],
  [63880, 1, ""],
  [63881, 1, ""],
  [63882, 1, ""],
  [63883, 1, ""],
  [63884, 1, ""],
  [63885, 1, ""],
  [63886, 1, ""],
  [63887, 1, ""],
  [63888, 1, ""],
  [63889, 1, ""],
  [63890, 1, ""],
  [63891, 1, ""],
  [63892, 1, ""],
  [63893, 1, ""],
  [63894, 1, ""],
  [63895, 1, ""],
  [63896, 1, ""],
  [63897, 1, ""],
  [63898, 1, ""],
  [63899, 1, ""],
  [63900, 1, ""],
  [63901, 1, ""],
  [63902, 1, ""],
  [63903, 1, ""],
  [63904, 1, ""],
  [63905, 1, ""],
  [63906, 1, ""],
  [63907, 1, ""],
  [63908, 1, ""],
  [63909, 1, ""],
  [63910, 1, ""],
  [63911, 1, ""],
  [63912, 1, ""],
  [63913, 1, ""],
  [63914, 1, ""],
  [63915, 1, ""],
  [63916, 1, ""],
  [63917, 1, ""],
  [63918, 1, ""],
  [63919, 1, ""],
  [63920, 1, ""],
  [63921, 1, ""],
  [63922, 1, ""],
  [63923, 1, ""],
  [63924, 1, ""],
  [63925, 1, ""],
  [63926, 1, ""],
  [63927, 1, ""],
  [63928, 1, ""],
  [63929, 1, ""],
  [63930, 1, ""],
  [63931, 1, ""],
  [63932, 1, ""],
  [63933, 1, ""],
  [63934, 1, ""],
  [63935, 1, ""],
  [63936, 1, ""],
  [63937, 1, ""],
  [63938, 1, ""],
  [63939, 1, ""],
  [63940, 1, ""],
  [63941, 1, ""],
  [63942, 1, ""],
  [63943, 1, ""],
  [63944, 1, ""],
  [63945, 1, ""],
  [63946, 1, ""],
  [63947, 1, ""],
  [63948, 1, ""],
  [63949, 1, ""],
  [63950, 1, ""],
  [63951, 1, ""],
  [63952, 1, ""],
  [63953, 1, ""],
  [63954, 1, ""],
  [63955, 1, ""],
  [63956, 1, ""],
  [63957, 1, ""],
  [63958, 1, ""],
  [63959, 1, ""],
  [63960, 1, ""],
  [63961, 1, ""],
  [63962, 1, ""],
  [63963, 1, ""],
  [63964, 1, ""],
  [63965, 1, ""],
  [63966, 1, ""],
  [63967, 1, ""],
  [63968, 1, ""],
  [63969, 1, ""],
  [63970, 1, ""],
  [63971, 1, ""],
  [63972, 1, ""],
  [63973, 1, ""],
  [63974, 1, ""],
  [63975, 1, ""],
  [63976, 1, ""],
  [63977, 1, ""],
  [63978, 1, ""],
  [63979, 1, ""],
  [63980, 1, ""],
  [63981, 1, ""],
  [63982, 1, ""],
  [63983, 1, ""],
  [63984, 1, ""],
  [63985, 1, ""],
  [63986, 1, ""],
  [63987, 1, ""],
  [63988, 1, ""],
  [63989, 1, ""],
  [63990, 1, ""],
  [63991, 1, ""],
  [63992, 1, ""],
  [63993, 1, ""],
  [63994, 1, ""],
  [63995, 1, ""],
  [63996, 1, ""],
  [63997, 1, ""],
  [63998, 1, ""],
  [63999, 1, ""],
  [64000, 1, ""],
  [64001, 1, ""],
  [64002, 1, ""],
  [64003, 1, ""],
  [64004, 1, ""],
  [64005, 1, ""],
  [64006, 1, ""],
  [64007, 1, ""],
  [64008, 1, ""],
  [64009, 1, ""],
  [64010, 1, ""],
  [64011, 1, ""],
  [64012, 1, ""],
  [64013, 1, ""],
  [[64014, 64015], 2],
  [64016, 1, ""],
  [64017, 2],
  [64018, 1, ""],
  [[64019, 64020], 2],
  [64021, 1, ""],
  [64022, 1, ""],
  [64023, 1, ""],
  [64024, 1, ""],
  [64025, 1, ""],
  [64026, 1, ""],
  [64027, 1, ""],
  [64028, 1, ""],
  [64029, 1, ""],
  [64030, 1, ""],
  [64031, 2],
  [64032, 1, ""],
  [64033, 2],
  [64034, 1, ""],
  [[64035, 64036], 2],
  [64037, 1, ""],
  [64038, 1, ""],
  [[64039, 64041], 2],
  [64042, 1, ""],
  [64043, 1, ""],
  [64044, 1, ""],
  [64045, 1, ""],
  [64046, 1, ""],
  [64047, 1, ""],
  [64048, 1, ""],
  [64049, 1, ""],
  [64050, 1, ""],
  [64051, 1, ""],
  [64052, 1, ""],
  [64053, 1, ""],
  [64054, 1, ""],
  [64055, 1, ""],
  [64056, 1, ""],
  [64057, 1, ""],
  [64058, 1, ""],
  [64059, 1, ""],
  [64060, 1, ""],
  [64061, 1, ""],
  [64062, 1, ""],
  [64063, 1, ""],
  [64064, 1, ""],
  [64065, 1, ""],
  [64066, 1, ""],
  [64067, 1, ""],
  [64068, 1, ""],
  [64069, 1, ""],
  [64070, 1, ""],
  [64071, 1, ""],
  [64072, 1, ""],
  [64073, 1, ""],
  [64074, 1, ""],
  [64075, 1, ""],
  [64076, 1, ""],
  [64077, 1, ""],
  [64078, 1, ""],
  [64079, 1, ""],
  [64080, 1, ""],
  [64081, 1, ""],
  [64082, 1, ""],
  [64083, 1, ""],
  [64084, 1, ""],
  [64085, 1, ""],
  [64086, 1, ""],
  [64087, 1, ""],
  [64088, 1, ""],
  [64089, 1, ""],
  [64090, 1, ""],
  [64091, 1, ""],
  [64092, 1, ""],
  [[64093, 64094], 1, ""],
  [64095, 1, ""],
  [64096, 1, ""],
  [64097, 1, ""],
  [64098, 1, ""],
  [64099, 1, ""],
  [64100, 1, ""],
  [64101, 1, ""],
  [64102, 1, ""],
  [64103, 1, ""],
  [64104, 1, ""],
  [64105, 1, ""],
  [64106, 1, ""],
  [64107, 1, ""],
  [64108, 1, ""],
  [64109, 1, ""],
  [[64110, 64111], 3],
  [64112, 1, ""],
  [64113, 1, ""],
  [64114, 1, ""],
  [64115, 1, ""],
  [64116, 1, ""],
  [64117, 1, ""],
  [64118, 1, ""],
  [64119, 1, ""],
  [64120, 1, ""],
  [64121, 1, ""],
  [64122, 1, ""],
  [64123, 1, ""],
  [64124, 1, ""],
  [64125, 1, ""],
  [64126, 1, ""],
  [64127, 1, ""],
  [64128, 1, ""],
  [64129, 1, ""],
  [64130, 1, ""],
  [64131, 1, ""],
  [64132, 1, ""],
  [64133, 1, ""],
  [64134, 1, ""],
  [64135, 1, ""],
  [64136, 1, ""],
  [64137, 1, ""],
  [64138, 1, ""],
  [64139, 1, ""],
  [64140, 1, ""],
  [64141, 1, ""],
  [64142, 1, ""],
  [64143, 1, ""],
  [64144, 1, ""],
  [64145, 1, ""],
  [64146, 1, ""],
  [64147, 1, ""],
  [64148, 1, ""],
  [64149, 1, ""],
  [64150, 1, ""],
  [64151, 1, ""],
  [64152, 1, ""],
  [64153, 1, ""],
  [64154, 1, ""],
  [64155, 1, ""],
  [64156, 1, ""],
  [64157, 1, ""],
  [64158, 1, ""],
  [64159, 1, ""],
  [64160, 1, ""],
  [64161, 1, ""],
  [64162, 1, ""],
  [64163, 1, ""],
  [64164, 1, ""],
  [64165, 1, ""],
  [64166, 1, ""],
  [64167, 1, ""],
  [64168, 1, ""],
  [64169, 1, ""],
  [64170, 1, ""],
  [64171, 1, ""],
  [64172, 1, ""],
  [64173, 1, ""],
  [64174, 1, ""],
  [64175, 1, ""],
  [64176, 1, ""],
  [64177, 1, ""],
  [64178, 1, ""],
  [64179, 1, ""],
  [64180, 1, ""],
  [64181, 1, ""],
  [64182, 1, ""],
  [64183, 1, ""],
  [64184, 1, ""],
  [64185, 1, ""],
  [64186, 1, ""],
  [64187, 1, ""],
  [64188, 1, ""],
  [64189, 1, ""],
  [64190, 1, ""],
  [64191, 1, ""],
  [64192, 1, ""],
  [64193, 1, ""],
  [64194, 1, ""],
  [64195, 1, ""],
  [64196, 1, ""],
  [64197, 1, ""],
  [64198, 1, ""],
  [64199, 1, ""],
  [64200, 1, ""],
  [64201, 1, ""],
  [64202, 1, ""],
  [64203, 1, ""],
  [64204, 1, ""],
  [64205, 1, ""],
  [64206, 1, ""],
  [64207, 1, ""],
  [64208, 1, ""],
  [64209, 1, ""],
  [64210, 1, ""],
  [64211, 1, ""],
  [64212, 1, ""],
  [64213, 1, ""],
  [64214, 1, ""],
  [64215, 1, ""],
  [64216, 1, ""],
  [64217, 1, ""],
  [[64218, 64255], 3],
  [64256, 1, "ff"],
  [64257, 1, "fi"],
  [64258, 1, "fl"],
  [64259, 1, "ffi"],
  [64260, 1, "ffl"],
  [[64261, 64262], 1, "st"],
  [[64263, 64274], 3],
  [64275, 1, ""],
  [64276, 1, ""],
  [64277, 1, ""],
  [64278, 1, ""],
  [64279, 1, ""],
  [[64280, 64284], 3],
  [64285, 1, ""],
  [64286, 2],
  [64287, 1, ""],
  [64288, 1, ""],
  [64289, 1, ""],
  [64290, 1, ""],
  [64291, 1, ""],
  [64292, 1, ""],
  [64293, 1, ""],
  [64294, 1, ""],
  [64295, 1, ""],
  [64296, 1, ""],
  [64297, 5, "+"],
  [64298, 1, ""],
  [64299, 1, ""],
  [64300, 1, ""],
  [64301, 1, ""],
  [64302, 1, ""],
  [64303, 1, ""],
  [64304, 1, ""],
  [64305, 1, ""],
  [64306, 1, ""],
  [64307, 1, ""],
  [64308, 1, ""],
  [64309, 1, ""],
  [64310, 1, ""],
  [64311, 3],
  [64312, 1, ""],
  [64313, 1, ""],
  [64314, 1, ""],
  [64315, 1, ""],
  [64316, 1, ""],
  [64317, 3],
  [64318, 1, ""],
  [64319, 3],
  [64320, 1, ""],
  [64321, 1, ""],
  [64322, 3],
  [64323, 1, ""],
  [64324, 1, ""],
  [64325, 3],
  [64326, 1, ""],
  [64327, 1, ""],
  [64328, 1, ""],
  [64329, 1, ""],
  [64330, 1, ""],
  [64331, 1, ""],
  [64332, 1, ""],
  [64333, 1, ""],
  [64334, 1, ""],
  [64335, 1, ""],
  [[64336, 64337], 1, ""],
  [[64338, 64341], 1, ""],
  [[64342, 64345], 1, ""],
  [[64346, 64349], 1, ""],
  [[64350, 64353], 1, ""],
  [[64354, 64357], 1, ""],
  [[64358, 64361], 1, ""],
  [[64362, 64365], 1, ""],
  [[64366, 64369], 1, ""],
  [[64370, 64373], 1, ""],
  [[64374, 64377], 1, ""],
  [[64378, 64381], 1, ""],
  [[64382, 64385], 1, ""],
  [[64386, 64387], 1, ""],
  [[64388, 64389], 1, ""],
  [[64390, 64391], 1, ""],
  [[64392, 64393], 1, ""],
  [[64394, 64395], 1, ""],
  [[64396, 64397], 1, ""],
  [[64398, 64401], 1, ""],
  [[64402, 64405], 1, ""],
  [[64406, 64409], 1, ""],
  [[64410, 64413], 1, ""],
  [[64414, 64415], 1, ""],
  [[64416, 64419], 1, ""],
  [[64420, 64421], 1, ""],
  [[64422, 64425], 1, ""],
  [[64426, 64429], 1, ""],
  [[64430, 64431], 1, ""],
  [[64432, 64433], 1, ""],
  [[64434, 64449], 2],
  [64450, 2],
  [[64451, 64466], 3],
  [[64467, 64470], 1, ""],
  [[64471, 64472], 1, ""],
  [[64473, 64474], 1, ""],
  [[64475, 64476], 1, ""],
  [64477, 1, ""],
  [[64478, 64479], 1, ""],
  [[64480, 64481], 1, ""],
  [[64482, 64483], 1, ""],
  [[64484, 64487], 1, ""],
  [[64488, 64489], 1, ""],
  [[64490, 64491], 1, ""],
  [[64492, 64493], 1, ""],
  [[64494, 64495], 1, ""],
  [[64496, 64497], 1, ""],
  [[64498, 64499], 1, ""],
  [[64500, 64501], 1, ""],
  [[64502, 64504], 1, ""],
  [[64505, 64507], 1, ""],
  [[64508, 64511], 1, ""],
  [64512, 1, ""],
  [64513, 1, ""],
  [64514, 1, ""],
  [64515, 1, ""],
  [64516, 1, ""],
  [64517, 1, ""],
  [64518, 1, ""],
  [64519, 1, ""],
  [64520, 1, ""],
  [64521, 1, ""],
  [64522, 1, ""],
  [64523, 1, ""],
  [64524, 1, ""],
  [64525, 1, ""],
  [64526, 1, ""],
  [64527, 1, ""],
  [64528, 1, ""],
  [64529, 1, ""],
  [64530, 1, ""],
  [64531, 1, ""],
  [64532, 1, ""],
  [64533, 1, ""],
  [64534, 1, ""],
  [64535, 1, ""],
  [64536, 1, ""],
  [64537, 1, ""],
  [64538, 1, ""],
  [64539, 1, ""],
  [64540, 1, ""],
  [64541, 1, ""],
  [64542, 1, ""],
  [64543, 1, ""],
  [64544, 1, ""],
  [64545, 1, ""],
  [64546, 1, ""],
  [64547, 1, ""],
  [64548, 1, ""],
  [64549, 1, ""],
  [64550, 1, ""],
  [64551, 1, ""],
  [64552, 1, ""],
  [64553, 1, ""],
  [64554, 1, ""],
  [64555, 1, ""],
  [64556, 1, ""],
  [64557, 1, ""],
  [64558, 1, ""],
  [64559, 1, ""],
  [64560, 1, ""],
  [64561, 1, ""],
  [64562, 1, ""],
  [64563, 1, ""],
  [64564, 1, ""],
  [64565, 1, ""],
  [64566, 1, ""],
  [64567, 1, ""],
  [64568, 1, ""],
  [64569, 1, ""],
  [64570, 1, ""],
  [64571, 1, ""],
  [64572, 1, ""],
  [64573, 1, ""],
  [64574, 1, ""],
  [64575, 1, ""],
  [64576, 1, ""],
  [64577, 1, ""],
  [64578, 1, ""],
  [64579, 1, ""],
  [64580, 1, ""],
  [64581, 1, ""],
  [64582, 1, ""],
  [64583, 1, ""],
  [64584, 1, ""],
  [64585, 1, ""],
  [64586, 1, ""],
  [64587, 1, ""],
  [64588, 1, ""],
  [64589, 1, ""],
  [64590, 1, ""],
  [64591, 1, ""],
  [64592, 1, ""],
  [64593, 1, ""],
  [64594, 1, ""],
  [64595, 1, ""],
  [64596, 1, ""],
  [64597, 1, ""],
  [64598, 1, ""],
  [64599, 1, ""],
  [64600, 1, ""],
  [64601, 1, ""],
  [64602, 1, ""],
  [64603, 1, ""],
  [64604, 1, ""],
  [64605, 1, ""],
  [64606, 5, " "],
  [64607, 5, " "],
  [64608, 5, " "],
  [64609, 5, " "],
  [64610, 5, " "],
  [64611, 5, " "],
  [64612, 1, ""],
  [64613, 1, ""],
  [64614, 1, ""],
  [64615, 1, ""],
  [64616, 1, ""],
  [64617, 1, ""],
  [64618, 1, ""],
  [64619, 1, ""],
  [64620, 1, ""],
  [64621, 1, ""],
  [64622, 1, ""],
  [64623, 1, ""],
  [64624, 1, ""],
  [64625, 1, ""],
  [64626, 1, ""],
  [64627, 1, ""],
  [64628, 1, ""],
  [64629, 1, ""],
  [64630, 1, ""],
  [64631, 1, ""],
  [64632, 1, ""],
  [64633, 1, ""],
  [64634, 1, ""],
  [64635, 1, ""],
  [64636, 1, ""],
  [64637, 1, ""],
  [64638, 1, ""],
  [64639, 1, ""],
  [64640, 1, ""],
  [64641, 1, ""],
  [64642, 1, ""],
  [64643, 1, ""],
  [64644, 1, ""],
  [64645, 1, ""],
  [64646, 1, ""],
  [64647, 1, ""],
  [64648, 1, ""],
  [64649, 1, ""],
  [64650, 1, ""],
  [64651, 1, ""],
  [64652, 1, ""],
  [64653, 1, ""],
  [64654, 1, ""],
  [64655, 1, ""],
  [64656, 1, ""],
  [64657, 1, ""],
  [64658, 1, ""],
  [64659, 1, ""],
  [64660, 1, ""],
  [64661, 1, ""],
  [64662, 1, ""],
  [64663, 1, ""],
  [64664, 1, ""],
  [64665, 1, ""],
  [64666, 1, ""],
  [64667, 1, ""],
  [64668, 1, ""],
  [64669, 1, ""],
  [64670, 1, ""],
  [64671, 1, ""],
  [64672, 1, ""],
  [64673, 1, ""],
  [64674, 1, ""],
  [64675, 1, ""],
  [64676, 1, ""],
  [64677, 1, ""],
  [64678, 1, ""],
  [64679, 1, ""],
  [64680, 1, ""],
  [64681, 1, ""],
  [64682, 1, ""],
  [64683, 1, ""],
  [64684, 1, ""],
  [64685, 1, ""],
  [64686, 1, ""],
  [64687, 1, ""],
  [64688, 1, ""],
  [64689, 1, ""],
  [64690, 1, ""],
  [64691, 1, ""],
  [64692, 1, ""],
  [64693, 1, ""],
  [64694, 1, ""],
  [64695, 1, ""],
  [64696, 1, ""],
  [64697, 1, ""],
  [64698, 1, ""],
  [64699, 1, ""],
  [64700, 1, ""],
  [64701, 1, ""],
  [64702, 1, ""],
  [64703, 1, ""],
  [64704, 1, ""],
  [64705, 1, ""],
  [64706, 1, ""],
  [64707, 1, ""],
  [64708, 1, ""],
  [64709, 1, ""],
  [64710, 1, ""],
  [64711, 1, ""],
  [64712, 1, ""],
  [64713, 1, ""],
  [64714, 1, ""],
  [64715, 1, ""],
  [64716, 1, ""],
  [64717, 1, ""],
  [64718, 1, ""],
  [64719, 1, ""],
  [64720, 1, ""],
  [64721, 1, ""],
  [64722, 1, ""],
  [64723, 1, ""],
  [64724, 1, ""],
  [64725, 1, ""],
  [64726, 1, ""],
  [64727, 1, ""],
  [64728, 1, ""],
  [64729, 1, ""],
  [64730, 1, ""],
  [64731, 1, ""],
  [64732, 1, ""],
  [64733, 1, ""],
  [64734, 1, ""],
  [64735, 1, ""],
  [64736, 1, ""],
  [64737, 1, ""],
  [64738, 1, ""],
  [64739, 1, ""],
  [64740, 1, ""],
  [64741, 1, ""],
  [64742, 1, ""],
  [64743, 1, ""],
  [64744, 1, ""],
  [64745, 1, ""],
  [64746, 1, ""],
  [64747, 1, ""],
  [64748, 1, ""],
  [64749, 1, ""],
  [64750, 1, ""],
  [64751, 1, ""],
  [64752, 1, ""],
  [64753, 1, ""],
  [64754, 1, ""],
  [64755, 1, ""],
  [64756, 1, ""],
  [64757, 1, ""],
  [64758, 1, ""],
  [64759, 1, ""],
  [64760, 1, ""],
  [64761, 1, ""],
  [64762, 1, ""],
  [64763, 1, ""],
  [64764, 1, ""],
  [64765, 1, ""],
  [64766, 1, ""],
  [64767, 1, ""],
  [64768, 1, ""],
  [64769, 1, ""],
  [64770, 1, ""],
  [64771, 1, ""],
  [64772, 1, ""],
  [64773, 1, ""],
  [64774, 1, ""],
  [64775, 1, ""],
  [64776, 1, ""],
  [64777, 1, ""],
  [64778, 1, ""],
  [64779, 1, ""],
  [64780, 1, ""],
  [64781, 1, ""],
  [64782, 1, ""],
  [64783, 1, ""],
  [64784, 1, ""],
  [64785, 1, ""],
  [64786, 1, ""],
  [64787, 1, ""],
  [64788, 1, ""],
  [64789, 1, ""],
  [64790, 1, ""],
  [64791, 1, ""],
  [64792, 1, ""],
  [64793, 1, ""],
  [64794, 1, ""],
  [64795, 1, ""],
  [64796, 1, ""],
  [64797, 1, ""],
  [64798, 1, ""],
  [64799, 1, ""],
  [64800, 1, ""],
  [64801, 1, ""],
  [64802, 1, ""],
  [64803, 1, ""],
  [64804, 1, ""],
  [64805, 1, ""],
  [64806, 1, ""],
  [64807, 1, ""],
  [64808, 1, ""],
  [64809, 1, ""],
  [64810, 1, ""],
  [64811, 1, ""],
  [64812, 1, ""],
  [64813, 1, ""],
  [64814, 1, ""],
  [64815, 1, ""],
  [64816, 1, ""],
  [64817, 1, ""],
  [64818, 1, ""],
  [64819, 1, ""],
  [64820, 1, ""],
  [64821, 1, ""],
  [64822, 1, ""],
  [64823, 1, ""],
  [64824, 1, ""],
  [64825, 1, ""],
  [64826, 1, ""],
  [64827, 1, ""],
  [[64828, 64829], 1, ""],
  [[64830, 64831], 2],
  [[64832, 64847], 2],
  [64848, 1, ""],
  [[64849, 64850], 1, ""],
  [64851, 1, ""],
  [64852, 1, ""],
  [64853, 1, ""],
  [64854, 1, ""],
  [64855, 1, ""],
  [[64856, 64857], 1, ""],
  [64858, 1, ""],
  [64859, 1, ""],
  [64860, 1, ""],
  [64861, 1, ""],
  [64862, 1, ""],
  [[64863, 64864], 1, ""],
  [64865, 1, ""],
  [[64866, 64867], 1, ""],
  [[64868, 64869], 1, ""],
  [64870, 1, ""],
  [[64871, 64872], 1, ""],
  [64873, 1, ""],
  [[64874, 64875], 1, ""],
  [[64876, 64877], 1, ""],
  [64878, 1, ""],
  [[64879, 64880], 1, ""],
  [[64881, 64882], 1, ""],
  [64883, 1, ""],
  [64884, 1, ""],
  [64885, 1, ""],
  [[64886, 64887], 1, ""],
  [64888, 1, ""],
  [64889, 1, ""],
  [64890, 1, ""],
  [64891, 1, ""],
  [[64892, 64893], 1, ""],
  [64894, 1, ""],
  [64895, 1, ""],
  [64896, 1, ""],
  [64897, 1, ""],
  [64898, 1, ""],
  [[64899, 64900], 1, ""],
  [[64901, 64902], 1, ""],
  [[64903, 64904], 1, ""],
  [64905, 1, ""],
  [64906, 1, ""],
  [64907, 1, ""],
  [64908, 1, ""],
  [64909, 1, ""],
  [64910, 1, ""],
  [64911, 1, ""],
  [[64912, 64913], 3],
  [64914, 1, ""],
  [64915, 1, ""],
  [64916, 1, ""],
  [64917, 1, ""],
  [64918, 1, ""],
  [[64919, 64920], 1, ""],
  [64921, 1, ""],
  [64922, 1, ""],
  [64923, 1, ""],
  [[64924, 64925], 1, ""],
  [64926, 1, ""],
  [64927, 1, ""],
  [64928, 1, ""],
  [64929, 1, ""],
  [64930, 1, ""],
  [64931, 1, ""],
  [64932, 1, ""],
  [64933, 1, ""],
  [64934, 1, ""],
  [64935, 1, ""],
  [64936, 1, ""],
  [64937, 1, ""],
  [64938, 1, ""],
  [64939, 1, ""],
  [64940, 1, ""],
  [64941, 1, ""],
  [64942, 1, ""],
  [64943, 1, ""],
  [64944, 1, ""],
  [64945, 1, ""],
  [64946, 1, ""],
  [64947, 1, ""],
  [64948, 1, ""],
  [64949, 1, ""],
  [64950, 1, ""],
  [64951, 1, ""],
  [64952, 1, ""],
  [64953, 1, ""],
  [64954, 1, ""],
  [64955, 1, ""],
  [64956, 1, ""],
  [64957, 1, ""],
  [64958, 1, ""],
  [64959, 1, ""],
  [64960, 1, ""],
  [64961, 1, ""],
  [64962, 1, ""],
  [64963, 1, ""],
  [64964, 1, ""],
  [64965, 1, ""],
  [64966, 1, ""],
  [64967, 1, ""],
  [[64968, 64974], 3],
  [64975, 2],
  [[64976, 65007], 3],
  [65008, 1, ""],
  [65009, 1, ""],
  [65010, 1, ""],
  [65011, 1, ""],
  [65012, 1, ""],
  [65013, 1, ""],
  [65014, 1, ""],
  [65015, 1, ""],
  [65016, 1, ""],
  [65017, 1, ""],
  [65018, 5, "   "],
  [65019, 5, " "],
  [65020, 1, ""],
  [65021, 2],
  [[65022, 65023], 2],
  [[65024, 65039], 7],
  [65040, 5, ","],
  [65041, 1, ""],
  [65042, 3],
  [65043, 5, ":"],
  [65044, 5, ";"],
  [65045, 5, "!"],
  [65046, 5, "?"],
  [65047, 1, ""],
  [65048, 1, ""],
  [65049, 3],
  [[65050, 65055], 3],
  [[65056, 65059], 2],
  [[65060, 65062], 2],
  [[65063, 65069], 2],
  [[65070, 65071], 2],
  [65072, 3],
  [65073, 1, ""],
  [65074, 1, ""],
  [[65075, 65076], 5, "_"],
  [65077, 5, "("],
  [65078, 5, ")"],
  [65079, 5, "{"],
  [65080, 5, "}"],
  [65081, 1, ""],
  [65082, 1, ""],
  [65083, 1, ""],
  [65084, 1, ""],
  [65085, 1, ""],
  [65086, 1, ""],
  [65087, 1, ""],
  [65088, 1, ""],
  [65089, 1, ""],
  [65090, 1, ""],
  [65091, 1, ""],
  [65092, 1, ""],
  [[65093, 65094], 2],
  [65095, 5, "["],
  [65096, 5, "]"],
  [[65097, 65100], 5, " "],
  [[65101, 65103], 5, "_"],
  [65104, 5, ","],
  [65105, 1, ""],
  [65106, 3],
  [65107, 3],
  [65108, 5, ";"],
  [65109, 5, ":"],
  [65110, 5, "?"],
  [65111, 5, "!"],
  [65112, 1, ""],
  [65113, 5, "("],
  [65114, 5, ")"],
  [65115, 5, "{"],
  [65116, 5, "}"],
  [65117, 1, ""],
  [65118, 1, ""],
  [65119, 5, "#"],
  [65120, 5, "&"],
  [65121, 5, "*"],
  [65122, 5, "+"],
  [65123, 1, "-"],
  [65124, 5, "<"],
  [65125, 5, ">"],
  [65126, 5, "="],
  [65127, 3],
  [65128, 5, "\\"],
  [65129, 5, "$"],
  [65130, 5, "%"],
  [65131, 5, "@"],
  [[65132, 65135], 3],
  [65136, 5, " "],
  [65137, 1, ""],
  [65138, 5, " "],
  [65139, 2],
  [65140, 5, " "],
  [65141, 3],
  [65142, 5, " "],
  [65143, 1, ""],
  [65144, 5, " "],
  [65145, 1, ""],
  [65146, 5, " "],
  [65147, 1, ""],
  [65148, 5, " "],
  [65149, 1, ""],
  [65150, 5, " "],
  [65151, 1, ""],
  [65152, 1, ""],
  [[65153, 65154], 1, ""],
  [[65155, 65156], 1, ""],
  [[65157, 65158], 1, ""],
  [[65159, 65160], 1, ""],
  [[65161, 65164], 1, ""],
  [[65165, 65166], 1, ""],
  [[65167, 65170], 1, ""],
  [[65171, 65172], 1, ""],
  [[65173, 65176], 1, ""],
  [[65177, 65180], 1, ""],
  [[65181, 65184], 1, ""],
  [[65185, 65188], 1, ""],
  [[65189, 65192], 1, ""],
  [[65193, 65194], 1, ""],
  [[65195, 65196], 1, ""],
  [[65197, 65198], 1, ""],
  [[65199, 65200], 1, ""],
  [[65201, 65204], 1, ""],
  [[65205, 65208], 1, ""],
  [[65209, 65212], 1, ""],
  [[65213, 65216], 1, ""],
  [[65217, 65220], 1, ""],
  [[65221, 65224], 1, ""],
  [[65225, 65228], 1, ""],
  [[65229, 65232], 1, ""],
  [[65233, 65236], 1, ""],
  [[65237, 65240], 1, ""],
  [[65241, 65244], 1, ""],
  [[65245, 65248], 1, ""],
  [[65249, 65252], 1, ""],
  [[65253, 65256], 1, ""],
  [[65257, 65260], 1, ""],
  [[65261, 65262], 1, ""],
  [[65263, 65264], 1, ""],
  [[65265, 65268], 1, ""],
  [[65269, 65270], 1, ""],
  [[65271, 65272], 1, ""],
  [[65273, 65274], 1, ""],
  [[65275, 65276], 1, ""],
  [[65277, 65278], 3],
  [65279, 7],
  [65280, 3],
  [65281, 5, "!"],
  [65282, 5, '"'],
  [65283, 5, "#"],
  [65284, 5, "$"],
  [65285, 5, "%"],
  [65286, 5, "&"],
  [65287, 5, "'"],
  [65288, 5, "("],
  [65289, 5, ")"],
  [65290, 5, "*"],
  [65291, 5, "+"],
  [65292, 5, ","],
  [65293, 1, "-"],
  [65294, 1, "."],
  [65295, 5, "/"],
  [65296, 1, "0"],
  [65297, 1, "1"],
  [65298, 1, "2"],
  [65299, 1, "3"],
  [65300, 1, "4"],
  [65301, 1, "5"],
  [65302, 1, "6"],
  [65303, 1, "7"],
  [65304, 1, "8"],
  [65305, 1, "9"],
  [65306, 5, ":"],
  [65307, 5, ";"],
  [65308, 5, "<"],
  [65309, 5, "="],
  [65310, 5, ">"],
  [65311, 5, "?"],
  [65312, 5, "@"],
  [65313, 1, "a"],
  [65314, 1, "b"],
  [65315, 1, "c"],
  [65316, 1, "d"],
  [65317, 1, "e"],
  [65318, 1, "f"],
  [65319, 1, "g"],
  [65320, 1, "h"],
  [65321, 1, "i"],
  [65322, 1, "j"],
  [65323, 1, "k"],
  [65324, 1, "l"],
  [65325, 1, "m"],
  [65326, 1, "n"],
  [65327, 1, "o"],
  [65328, 1, "p"],
  [65329, 1, "q"],
  [65330, 1, "r"],
  [65331, 1, "s"],
  [65332, 1, "t"],
  [65333, 1, "u"],
  [65334, 1, "v"],
  [65335, 1, "w"],
  [65336, 1, "x"],
  [65337, 1, "y"],
  [65338, 1, "z"],
  [65339, 5, "["],
  [65340, 5, "\\"],
  [65341, 5, "]"],
  [65342, 5, "^"],
  [65343, 5, "_"],
  [65344, 5, "`"],
  [65345, 1, "a"],
  [65346, 1, "b"],
  [65347, 1, "c"],
  [65348, 1, "d"],
  [65349, 1, "e"],
  [65350, 1, "f"],
  [65351, 1, "g"],
  [65352, 1, "h"],
  [65353, 1, "i"],
  [65354, 1, "j"],
  [65355, 1, "k"],
  [65356, 1, "l"],
  [65357, 1, "m"],
  [65358, 1, "n"],
  [65359, 1, "o"],
  [65360, 1, "p"],
  [65361, 1, "q"],
  [65362, 1, "r"],
  [65363, 1, "s"],
  [65364, 1, "t"],
  [65365, 1, "u"],
  [65366, 1, "v"],
  [65367, 1, "w"],
  [65368, 1, "x"],
  [65369, 1, "y"],
  [65370, 1, "z"],
  [65371, 5, "{"],
  [65372, 5, "|"],
  [65373, 5, "}"],
  [65374, 5, "~"],
  [65375, 1, ""],
  [65376, 1, ""],
  [65377, 1, "."],
  [65378, 1, ""],
  [65379, 1, ""],
  [65380, 1, ""],
  [65381, 1, ""],
  [65382, 1, ""],
  [65383, 1, ""],
  [65384, 1, ""],
  [65385, 1, ""],
  [65386, 1, ""],
  [65387, 1, ""],
  [65388, 1, ""],
  [65389, 1, ""],
  [65390, 1, ""],
  [65391, 1, ""],
  [65392, 1, ""],
  [65393, 1, ""],
  [65394, 1, ""],
  [65395, 1, ""],
  [65396, 1, ""],
  [65397, 1, ""],
  [65398, 1, ""],
  [65399, 1, ""],
  [65400, 1, ""],
  [65401, 1, ""],
  [65402, 1, ""],
  [65403, 1, ""],
  [65404, 1, ""],
  [65405, 1, ""],
  [65406, 1, ""],
  [65407, 1, ""],
  [65408, 1, ""],
  [65409, 1, ""],
  [65410, 1, ""],
  [65411, 1, ""],
  [65412, 1, ""],
  [65413, 1, ""],
  [65414, 1, ""],
  [65415, 1, ""],
  [65416, 1, ""],
  [65417, 1, ""],
  [65418, 1, ""],
  [65419, 1, ""],
  [65420, 1, ""],
  [65421, 1, ""],
  [65422, 1, ""],
  [65423, 1, ""],
  [65424, 1, ""],
  [65425, 1, ""],
  [65426, 1, ""],
  [65427, 1, ""],
  [65428, 1, ""],
  [65429, 1, ""],
  [65430, 1, ""],
  [65431, 1, ""],
  [65432, 1, ""],
  [65433, 1, ""],
  [65434, 1, ""],
  [65435, 1, ""],
  [65436, 1, ""],
  [65437, 1, ""],
  [65438, 1, ""],
  [65439, 1, ""],
  [65440, 3],
  [65441, 1, ""],
  [65442, 1, ""],
  [65443, 1, ""],
  [65444, 1, ""],
  [65445, 1, ""],
  [65446, 1, ""],
  [65447, 1, ""],
  [65448, 1, ""],
  [65449, 1, ""],
  [65450, 1, ""],
  [65451, 1, ""],
  [65452, 1, ""],
  [65453, 1, ""],
  [65454, 1, ""],
  [65455, 1, ""],
  [65456, 1, ""],
  [65457, 1, ""],
  [65458, 1, ""],
  [65459, 1, ""],
  [65460, 1, ""],
  [65461, 1, ""],
  [65462, 1, ""],
  [65463, 1, ""],
  [65464, 1, ""],
  [65465, 1, ""],
  [65466, 1, ""],
  [65467, 1, ""],
  [65468, 1, ""],
  [65469, 1, ""],
  [65470, 1, ""],
  [[65471, 65473], 3],
  [65474, 1, ""],
  [65475, 1, ""],
  [65476, 1, ""],
  [65477, 1, ""],
  [65478, 1, ""],
  [65479, 1, ""],
  [[65480, 65481], 3],
  [65482, 1, ""],
  [65483, 1, ""],
  [65484, 1, ""],
  [65485, 1, ""],
  [65486, 1, ""],
  [65487, 1, ""],
  [[65488, 65489], 3],
  [65490, 1, ""],
  [65491, 1, ""],
  [65492, 1, ""],
  [65493, 1, ""],
  [65494, 1, ""],
  [65495, 1, ""],
  [[65496, 65497], 3],
  [65498, 1, ""],
  [65499, 1, ""],
  [65500, 1, ""],
  [[65501, 65503], 3],
  [65504, 1, ""],
  [65505, 1, ""],
  [65506, 1, ""],
  [65507, 5, " "],
  [65508, 1, ""],
  [65509, 1, ""],
  [65510, 1, ""],
  [65511, 3],
  [65512, 1, ""],
  [65513, 1, ""],
  [65514, 1, ""],
  [65515, 1, ""],
  [65516, 1, ""],
  [65517, 1, ""],
  [65518, 1, ""],
  [[65519, 65528], 3],
  [[65529, 65531], 3],
  [65532, 3],
  [65533, 3],
  [[65534, 65535], 3],
  [[65536, 65547], 2],
  [65548, 3],
  [[65549, 65574], 2],
  [65575, 3],
  [[65576, 65594], 2],
  [65595, 3],
  [[65596, 65597], 2],
  [65598, 3],
  [[65599, 65613], 2],
  [[65614, 65615], 3],
  [[65616, 65629], 2],
  [[65630, 65663], 3],
  [[65664, 65786], 2],
  [[65787, 65791], 3],
  [[65792, 65794], 2],
  [[65795, 65798], 3],
  [[65799, 65843], 2],
  [[65844, 65846], 3],
  [[65847, 65855], 2],
  [[65856, 65930], 2],
  [[65931, 65932], 2],
  [[65933, 65934], 2],
  [65935, 3],
  [[65936, 65947], 2],
  [65948, 2],
  [[65949, 65951], 3],
  [65952, 2],
  [[65953, 65999], 3],
  [[66000, 66044], 2],
  [66045, 2],
  [[66046, 66175], 3],
  [[66176, 66204], 2],
  [[66205, 66207], 3],
  [[66208, 66256], 2],
  [[66257, 66271], 3],
  [66272, 2],
  [[66273, 66299], 2],
  [[66300, 66303], 3],
  [[66304, 66334], 2],
  [66335, 2],
  [[66336, 66339], 2],
  [[66340, 66348], 3],
  [[66349, 66351], 2],
  [[66352, 66368], 2],
  [66369, 2],
  [[66370, 66377], 2],
  [66378, 2],
  [[66379, 66383], 3],
  [[66384, 66426], 2],
  [[66427, 66431], 3],
  [[66432, 66461], 2],
  [66462, 3],
  [66463, 2],
  [[66464, 66499], 2],
  [[66500, 66503], 3],
  [[66504, 66511], 2],
  [[66512, 66517], 2],
  [[66518, 66559], 3],
  [66560, 1, ""],
  [66561, 1, ""],
  [66562, 1, ""],
  [66563, 1, ""],
  [66564, 1, ""],
  [66565, 1, ""],
  [66566, 1, ""],
  [66567, 1, ""],
  [66568, 1, ""],
  [66569, 1, ""],
  [66570, 1, ""],
  [66571, 1, ""],
  [66572, 1, ""],
  [66573, 1, ""],
  [66574, 1, ""],
  [66575, 1, ""],
  [66576, 1, ""],
  [66577, 1, ""],
  [66578, 1, ""],
  [66579, 1, ""],
  [66580, 1, ""],
  [66581, 1, ""],
  [66582, 1, ""],
  [66583, 1, ""],
  [66584, 1, ""],
  [66585, 1, ""],
  [66586, 1, ""],
  [66587, 1, ""],
  [66588, 1, ""],
  [66589, 1, ""],
  [66590, 1, ""],
  [66591, 1, ""],
  [66592, 1, ""],
  [66593, 1, ""],
  [66594, 1, ""],
  [66595, 1, ""],
  [66596, 1, ""],
  [66597, 1, ""],
  [66598, 1, ""],
  [66599, 1, ""],
  [[66600, 66637], 2],
  [[66638, 66717], 2],
  [[66718, 66719], 3],
  [[66720, 66729], 2],
  [[66730, 66735], 3],
  [66736, 1, ""],
  [66737, 1, ""],
  [66738, 1, ""],
  [66739, 1, ""],
  [66740, 1, ""],
  [66741, 1, ""],
  [66742, 1, ""],
  [66743, 1, ""],
  [66744, 1, ""],
  [66745, 1, ""],
  [66746, 1, ""],
  [66747, 1, ""],
  [66748, 1, ""],
  [66749, 1, ""],
  [66750, 1, ""],
  [66751, 1, ""],
  [66752, 1, ""],
  [66753, 1, ""],
  [66754, 1, ""],
  [66755, 1, ""],
  [66756, 1, ""],
  [66757, 1, ""],
  [66758, 1, ""],
  [66759, 1, ""],
  [66760, 1, ""],
  [66761, 1, ""],
  [66762, 1, ""],
  [66763, 1, ""],
  [66764, 1, ""],
  [66765, 1, ""],
  [66766, 1, ""],
  [66767, 1, ""],
  [66768, 1, ""],
  [66769, 1, ""],
  [66770, 1, ""],
  [66771, 1, ""],
  [[66772, 66775], 3],
  [[66776, 66811], 2],
  [[66812, 66815], 3],
  [[66816, 66855], 2],
  [[66856, 66863], 3],
  [[66864, 66915], 2],
  [[66916, 66926], 3],
  [66927, 2],
  [66928, 1, ""],
  [66929, 1, ""],
  [66930, 1, ""],
  [66931, 1, ""],
  [66932, 1, ""],
  [66933, 1, ""],
  [66934, 1, ""],
  [66935, 1, ""],
  [66936, 1, ""],
  [66937, 1, ""],
  [66938, 1, ""],
  [66939, 3],
  [66940, 1, ""],
  [66941, 1, ""],
  [66942, 1, ""],
  [66943, 1, ""],
  [66944, 1, ""],
  [66945, 1, ""],
  [66946, 1, ""],
  [66947, 1, ""],
  [66948, 1, ""],
  [66949, 1, ""],
  [66950, 1, ""],
  [66951, 1, ""],
  [66952, 1, ""],
  [66953, 1, ""],
  [66954, 1, ""],
  [66955, 3],
  [66956, 1, ""],
  [66957, 1, ""],
  [66958, 1, ""],
  [66959, 1, ""],
  [66960, 1, ""],
  [66961, 1, ""],
  [66962, 1, ""],
  [66963, 3],
  [66964, 1, ""],
  [66965, 1, ""],
  [66966, 3],
  [[66967, 66977], 2],
  [66978, 3],
  [[66979, 66993], 2],
  [66994, 3],
  [[66995, 67001], 2],
  [67002, 3],
  [[67003, 67004], 2],
  [[67005, 67071], 3],
  [[67072, 67382], 2],
  [[67383, 67391], 3],
  [[67392, 67413], 2],
  [[67414, 67423], 3],
  [[67424, 67431], 2],
  [[67432, 67455], 3],
  [67456, 2],
  [67457, 1, ""],
  [67458, 1, ""],
  [67459, 1, ""],
  [67460, 1, ""],
  [67461, 1, ""],
  [67462, 3],
  [67463, 1, ""],
  [67464, 1, ""],
  [67465, 1, ""],
  [67466, 1, ""],
  [67467, 1, ""],
  [67468, 1, ""],
  [67469, 1, ""],
  [67470, 1, ""],
  [67471, 1, ""],
  [67472, 1, ""],
  [67473, 1, ""],
  [67474, 1, ""],
  [67475, 1, ""],
  [67476, 1, ""],
  [67477, 1, ""],
  [67478, 1, ""],
  [67479, 1, ""],
  [67480, 1, ""],
  [67481, 1, ""],
  [67482, 1, ""],
  [67483, 1, ""],
  [67484, 1, ""],
  [67485, 1, ""],
  [67486, 1, ""],
  [67487, 1, ""],
  [67488, 1, ""],
  [67489, 1, ""],
  [67490, 1, ""],
  [67491, 1, ""],
  [67492, 1, ""],
  [67493, 1, "q"],
  [67494, 1, ""],
  [67495, 1, ""],
  [67496, 1, ""],
  [67497, 1, ""],
  [67498, 1, ""],
  [67499, 1, ""],
  [67500, 1, ""],
  [67501, 1, ""],
  [67502, 1, ""],
  [67503, 1, ""],
  [67504, 1, ""],
  [67505, 3],
  [67506, 1, ""],
  [67507, 1, ""],
  [67508, 1, ""],
  [67509, 1, ""],
  [67510, 1, ""],
  [67511, 1, ""],
  [67512, 1, ""],
  [67513, 1, ""],
  [67514, 1, ""],
  [[67515, 67583], 3],
  [[67584, 67589], 2],
  [[67590, 67591], 3],
  [67592, 2],
  [67593, 3],
  [[67594, 67637], 2],
  [67638, 3],
  [[67639, 67640], 2],
  [[67641, 67643], 3],
  [67644, 2],
  [[67645, 67646], 3],
  [67647, 2],
  [[67648, 67669], 2],
  [67670, 3],
  [[67671, 67679], 2],
  [[67680, 67702], 2],
  [[67703, 67711], 2],
  [[67712, 67742], 2],
  [[67743, 67750], 3],
  [[67751, 67759], 2],
  [[67760, 67807], 3],
  [[67808, 67826], 2],
  [67827, 3],
  [[67828, 67829], 2],
  [[67830, 67834], 3],
  [[67835, 67839], 2],
  [[67840, 67861], 2],
  [[67862, 67865], 2],
  [[67866, 67867], 2],
  [[67868, 67870], 3],
  [67871, 2],
  [[67872, 67897], 2],
  [[67898, 67902], 3],
  [67903, 2],
  [[67904, 67967], 3],
  [[67968, 68023], 2],
  [[68024, 68027], 3],
  [[68028, 68029], 2],
  [[68030, 68031], 2],
  [[68032, 68047], 2],
  [[68048, 68049], 3],
  [[68050, 68095], 2],
  [[68096, 68099], 2],
  [68100, 3],
  [[68101, 68102], 2],
  [[68103, 68107], 3],
  [[68108, 68115], 2],
  [68116, 3],
  [[68117, 68119], 2],
  [68120, 3],
  [[68121, 68147], 2],
  [[68148, 68149], 2],
  [[68150, 68151], 3],
  [[68152, 68154], 2],
  [[68155, 68158], 3],
  [68159, 2],
  [[68160, 68167], 2],
  [68168, 2],
  [[68169, 68175], 3],
  [[68176, 68184], 2],
  [[68185, 68191], 3],
  [[68192, 68220], 2],
  [[68221, 68223], 2],
  [[68224, 68252], 2],
  [[68253, 68255], 2],
  [[68256, 68287], 3],
  [[68288, 68295], 2],
  [68296, 2],
  [[68297, 68326], 2],
  [[68327, 68330], 3],
  [[68331, 68342], 2],
  [[68343, 68351], 3],
  [[68352, 68405], 2],
  [[68406, 68408], 3],
  [[68409, 68415], 2],
  [[68416, 68437], 2],
  [[68438, 68439], 3],
  [[68440, 68447], 2],
  [[68448, 68466], 2],
  [[68467, 68471], 3],
  [[68472, 68479], 2],
  [[68480, 68497], 2],
  [[68498, 68504], 3],
  [[68505, 68508], 2],
  [[68509, 68520], 3],
  [[68521, 68527], 2],
  [[68528, 68607], 3],
  [[68608, 68680], 2],
  [[68681, 68735], 3],
  [68736, 1, ""],
  [68737, 1, ""],
  [68738, 1, ""],
  [68739, 1, ""],
  [68740, 1, ""],
  [68741, 1, ""],
  [68742, 1, ""],
  [68743, 1, ""],
  [68744, 1, ""],
  [68745, 1, ""],
  [68746, 1, ""],
  [68747, 1, ""],
  [68748, 1, ""],
  [68749, 1, ""],
  [68750, 1, ""],
  [68751, 1, ""],
  [68752, 1, ""],
  [68753, 1, ""],
  [68754, 1, ""],
  [68755, 1, ""],
  [68756, 1, ""],
  [68757, 1, ""],
  [68758, 1, ""],
  [68759, 1, ""],
  [68760, 1, ""],
  [68761, 1, ""],
  [68762, 1, ""],
  [68763, 1, ""],
  [68764, 1, ""],
  [68765, 1, ""],
  [68766, 1, ""],
  [68767, 1, ""],
  [68768, 1, ""],
  [68769, 1, ""],
  [68770, 1, ""],
  [68771, 1, ""],
  [68772, 1, ""],
  [68773, 1, ""],
  [68774, 1, ""],
  [68775, 1, ""],
  [68776, 1, ""],
  [68777, 1, ""],
  [68778, 1, ""],
  [68779, 1, ""],
  [68780, 1, ""],
  [68781, 1, ""],
  [68782, 1, ""],
  [68783, 1, ""],
  [68784, 1, ""],
  [68785, 1, ""],
  [68786, 1, ""],
  [[68787, 68799], 3],
  [[68800, 68850], 2],
  [[68851, 68857], 3],
  [[68858, 68863], 2],
  [[68864, 68903], 2],
  [[68904, 68911], 3],
  [[68912, 68921], 2],
  [[68922, 69215], 3],
  [[69216, 69246], 2],
  [69247, 3],
  [[69248, 69289], 2],
  [69290, 3],
  [[69291, 69292], 2],
  [69293, 2],
  [[69294, 69295], 3],
  [[69296, 69297], 2],
  [[69298, 69375], 3],
  [[69376, 69404], 2],
  [[69405, 69414], 2],
  [69415, 2],
  [[69416, 69423], 3],
  [[69424, 69456], 2],
  [[69457, 69465], 2],
  [[69466, 69487], 3],
  [[69488, 69509], 2],
  [[69510, 69513], 2],
  [[69514, 69551], 3],
  [[69552, 69572], 2],
  [[69573, 69579], 2],
  [[69580, 69599], 3],
  [[69600, 69622], 2],
  [[69623, 69631], 3],
  [[69632, 69702], 2],
  [[69703, 69709], 2],
  [[69710, 69713], 3],
  [[69714, 69733], 2],
  [[69734, 69743], 2],
  [[69744, 69749], 2],
  [[69750, 69758], 3],
  [69759, 2],
  [[69760, 69818], 2],
  [[69819, 69820], 2],
  [69821, 3],
  [[69822, 69825], 2],
  [69826, 2],
  [[69827, 69836], 3],
  [69837, 3],
  [[69838, 69839], 3],
  [[69840, 69864], 2],
  [[69865, 69871], 3],
  [[69872, 69881], 2],
  [[69882, 69887], 3],
  [[69888, 69940], 2],
  [69941, 3],
  [[69942, 69951], 2],
  [[69952, 69955], 2],
  [[69956, 69958], 2],
  [69959, 2],
  [[69960, 69967], 3],
  [[69968, 70003], 2],
  [[70004, 70005], 2],
  [70006, 2],
  [[70007, 70015], 3],
  [[70016, 70084], 2],
  [[70085, 70088], 2],
  [[70089, 70092], 2],
  [70093, 2],
  [[70094, 70095], 2],
  [[70096, 70105], 2],
  [70106, 2],
  [70107, 2],
  [70108, 2],
  [[70109, 70111], 2],
  [70112, 3],
  [[70113, 70132], 2],
  [[70133, 70143], 3],
  [[70144, 70161], 2],
  [70162, 3],
  [[70163, 70199], 2],
  [[70200, 70205], 2],
  [70206, 2],
  [[70207, 70271], 3],
  [[70272, 70278], 2],
  [70279, 3],
  [70280, 2],
  [70281, 3],
  [[70282, 70285], 2],
  [70286, 3],
  [[70287, 70301], 2],
  [70302, 3],
  [[70303, 70312], 2],
  [70313, 2],
  [[70314, 70319], 3],
  [[70320, 70378], 2],
  [[70379, 70383], 3],
  [[70384, 70393], 2],
  [[70394, 70399], 3],
  [70400, 2],
  [[70401, 70403], 2],
  [70404, 3],
  [[70405, 70412], 2],
  [[70413, 70414], 3],
  [[70415, 70416], 2],
  [[70417, 70418], 3],
  [[70419, 70440], 2],
  [70441, 3],
  [[70442, 70448], 2],
  [70449, 3],
  [[70450, 70451], 2],
  [70452, 3],
  [[70453, 70457], 2],
  [70458, 3],
  [70459, 2],
  [[70460, 70468], 2],
  [[70469, 70470], 3],
  [[70471, 70472], 2],
  [[70473, 70474], 3],
  [[70475, 70477], 2],
  [[70478, 70479], 3],
  [70480, 2],
  [[70481, 70486], 3],
  [70487, 2],
  [[70488, 70492], 3],
  [[70493, 70499], 2],
  [[70500, 70501], 3],
  [[70502, 70508], 2],
  [[70509, 70511], 3],
  [[70512, 70516], 2],
  [[70517, 70655], 3],
  [[70656, 70730], 2],
  [[70731, 70735], 2],
  [[70736, 70745], 2],
  [70746, 2],
  [70747, 2],
  [70748, 3],
  [70749, 2],
  [70750, 2],
  [70751, 2],
  [[70752, 70753], 2],
  [[70754, 70783], 3],
  [[70784, 70853], 2],
  [70854, 2],
  [70855, 2],
  [[70856, 70863], 3],
  [[70864, 70873], 2],
  [[70874, 71039], 3],
  [[71040, 71093], 2],
  [[71094, 71095], 3],
  [[71096, 71104], 2],
  [[71105, 71113], 2],
  [[71114, 71127], 2],
  [[71128, 71133], 2],
  [[71134, 71167], 3],
  [[71168, 71232], 2],
  [[71233, 71235], 2],
  [71236, 2],
  [[71237, 71247], 3],
  [[71248, 71257], 2],
  [[71258, 71263], 3],
  [[71264, 71276], 2],
  [[71277, 71295], 3],
  [[71296, 71351], 2],
  [71352, 2],
  [71353, 2],
  [[71354, 71359], 3],
  [[71360, 71369], 2],
  [[71370, 71423], 3],
  [[71424, 71449], 2],
  [71450, 2],
  [[71451, 71452], 3],
  [[71453, 71467], 2],
  [[71468, 71471], 3],
  [[71472, 71481], 2],
  [[71482, 71487], 2],
  [[71488, 71494], 2],
  [[71495, 71679], 3],
  [[71680, 71738], 2],
  [71739, 2],
  [[71740, 71839], 3],
  [71840, 1, ""],
  [71841, 1, ""],
  [71842, 1, ""],
  [71843, 1, ""],
  [71844, 1, ""],
  [71845, 1, ""],
  [71846, 1, ""],
  [71847, 1, ""],
  [71848, 1, ""],
  [71849, 1, ""],
  [71850, 1, ""],
  [71851, 1, ""],
  [71852, 1, ""],
  [71853, 1, ""],
  [71854, 1, ""],
  [71855, 1, ""],
  [71856, 1, ""],
  [71857, 1, ""],
  [71858, 1, ""],
  [71859, 1, ""],
  [71860, 1, ""],
  [71861, 1, ""],
  [71862, 1, ""],
  [71863, 1, ""],
  [71864, 1, ""],
  [71865, 1, ""],
  [71866, 1, ""],
  [71867, 1, ""],
  [71868, 1, ""],
  [71869, 1, ""],
  [71870, 1, ""],
  [71871, 1, ""],
  [[71872, 71913], 2],
  [[71914, 71922], 2],
  [[71923, 71934], 3],
  [71935, 2],
  [[71936, 71942], 2],
  [[71943, 71944], 3],
  [71945, 2],
  [[71946, 71947], 3],
  [[71948, 71955], 2],
  [71956, 3],
  [[71957, 71958], 2],
  [71959, 3],
  [[71960, 71989], 2],
  [71990, 3],
  [[71991, 71992], 2],
  [[71993, 71994], 3],
  [[71995, 72003], 2],
  [[72004, 72006], 2],
  [[72007, 72015], 3],
  [[72016, 72025], 2],
  [[72026, 72095], 3],
  [[72096, 72103], 2],
  [[72104, 72105], 3],
  [[72106, 72151], 2],
  [[72152, 72153], 3],
  [[72154, 72161], 2],
  [72162, 2],
  [[72163, 72164], 2],
  [[72165, 72191], 3],
  [[72192, 72254], 2],
  [[72255, 72262], 2],
  [72263, 2],
  [[72264, 72271], 3],
  [[72272, 72323], 2],
  [[72324, 72325], 2],
  [[72326, 72345], 2],
  [[72346, 72348], 2],
  [72349, 2],
  [[72350, 72354], 2],
  [[72355, 72367], 3],
  [[72368, 72383], 2],
  [[72384, 72440], 2],
  [[72441, 72703], 3],
  [[72704, 72712], 2],
  [72713, 3],
  [[72714, 72758], 2],
  [72759, 3],
  [[72760, 72768], 2],
  [[72769, 72773], 2],
  [[72774, 72783], 3],
  [[72784, 72793], 2],
  [[72794, 72812], 2],
  [[72813, 72815], 3],
  [[72816, 72817], 2],
  [[72818, 72847], 2],
  [[72848, 72849], 3],
  [[72850, 72871], 2],
  [72872, 3],
  [[72873, 72886], 2],
  [[72887, 72959], 3],
  [[72960, 72966], 2],
  [72967, 3],
  [[72968, 72969], 2],
  [72970, 3],
  [[72971, 73014], 2],
  [[73015, 73017], 3],
  [73018, 2],
  [73019, 3],
  [[73020, 73021], 2],
  [73022, 3],
  [[73023, 73031], 2],
  [[73032, 73039], 3],
  [[73040, 73049], 2],
  [[73050, 73055], 3],
  [[73056, 73061], 2],
  [73062, 3],
  [[73063, 73064], 2],
  [73065, 3],
  [[73066, 73102], 2],
  [73103, 3],
  [[73104, 73105], 2],
  [73106, 3],
  [[73107, 73112], 2],
  [[73113, 73119], 3],
  [[73120, 73129], 2],
  [[73130, 73439], 3],
  [[73440, 73462], 2],
  [[73463, 73464], 2],
  [[73465, 73647], 3],
  [73648, 2],
  [[73649, 73663], 3],
  [[73664, 73713], 2],
  [[73714, 73726], 3],
  [73727, 2],
  [[73728, 74606], 2],
  [[74607, 74648], 2],
  [74649, 2],
  [[74650, 74751], 3],
  [[74752, 74850], 2],
  [[74851, 74862], 2],
  [74863, 3],
  [[74864, 74867], 2],
  [74868, 2],
  [[74869, 74879], 3],
  [[74880, 75075], 2],
  [[75076, 77711], 3],
  [[77712, 77808], 2],
  [[77809, 77810], 2],
  [[77811, 77823], 3],
  [[77824, 78894], 2],
  [78895, 3],
  [[78896, 78904], 3],
  [[78905, 82943], 3],
  [[82944, 83526], 2],
  [[83527, 92159], 3],
  [[92160, 92728], 2],
  [[92729, 92735], 3],
  [[92736, 92766], 2],
  [92767, 3],
  [[92768, 92777], 2],
  [[92778, 92781], 3],
  [[92782, 92783], 2],
  [[92784, 92862], 2],
  [92863, 3],
  [[92864, 92873], 2],
  [[92874, 92879], 3],
  [[92880, 92909], 2],
  [[92910, 92911], 3],
  [[92912, 92916], 2],
  [92917, 2],
  [[92918, 92927], 3],
  [[92928, 92982], 2],
  [[92983, 92991], 2],
  [[92992, 92995], 2],
  [[92996, 92997], 2],
  [[92998, 93007], 3],
  [[93008, 93017], 2],
  [93018, 3],
  [[93019, 93025], 2],
  [93026, 3],
  [[93027, 93047], 2],
  [[93048, 93052], 3],
  [[93053, 93071], 2],
  [[93072, 93759], 3],
  [93760, 1, ""],
  [93761, 1, ""],
  [93762, 1, ""],
  [93763, 1, ""],
  [93764, 1, ""],
  [93765, 1, ""],
  [93766, 1, ""],
  [93767, 1, ""],
  [93768, 1, ""],
  [93769, 1, ""],
  [93770, 1, ""],
  [93771, 1, ""],
  [93772, 1, ""],
  [93773, 1, ""],
  [93774, 1, ""],
  [93775, 1, ""],
  [93776, 1, ""],
  [93777, 1, ""],
  [93778, 1, ""],
  [93779, 1, ""],
  [93780, 1, ""],
  [93781, 1, ""],
  [93782, 1, ""],
  [93783, 1, ""],
  [93784, 1, ""],
  [93785, 1, ""],
  [93786, 1, ""],
  [93787, 1, ""],
  [93788, 1, ""],
  [93789, 1, ""],
  [93790, 1, ""],
  [93791, 1, ""],
  [[93792, 93823], 2],
  [[93824, 93850], 2],
  [[93851, 93951], 3],
  [[93952, 94020], 2],
  [[94021, 94026], 2],
  [[94027, 94030], 3],
  [94031, 2],
  [[94032, 94078], 2],
  [[94079, 94087], 2],
  [[94088, 94094], 3],
  [[94095, 94111], 2],
  [[94112, 94175], 3],
  [94176, 2],
  [94177, 2],
  [94178, 2],
  [94179, 2],
  [94180, 2],
  [[94181, 94191], 3],
  [[94192, 94193], 2],
  [[94194, 94207], 3],
  [[94208, 100332], 2],
  [[100333, 100337], 2],
  [[100338, 100343], 2],
  [[100344, 100351], 3],
  [[100352, 101106], 2],
  [[101107, 101589], 2],
  [[101590, 101631], 3],
  [[101632, 101640], 2],
  [[101641, 110575], 3],
  [[110576, 110579], 2],
  [110580, 3],
  [[110581, 110587], 2],
  [110588, 3],
  [[110589, 110590], 2],
  [110591, 3],
  [[110592, 110593], 2],
  [[110594, 110878], 2],
  [[110879, 110882], 2],
  [[110883, 110927], 3],
  [[110928, 110930], 2],
  [[110931, 110947], 3],
  [[110948, 110951], 2],
  [[110952, 110959], 3],
  [[110960, 111355], 2],
  [[111356, 113663], 3],
  [[113664, 113770], 2],
  [[113771, 113775], 3],
  [[113776, 113788], 2],
  [[113789, 113791], 3],
  [[113792, 113800], 2],
  [[113801, 113807], 3],
  [[113808, 113817], 2],
  [[113818, 113819], 3],
  [113820, 2],
  [[113821, 113822], 2],
  [113823, 2],
  [[113824, 113827], 7],
  [[113828, 118527], 3],
  [[118528, 118573], 2],
  [[118574, 118575], 3],
  [[118576, 118598], 2],
  [[118599, 118607], 3],
  [[118608, 118723], 2],
  [[118724, 118783], 3],
  [[118784, 119029], 2],
  [[119030, 119039], 3],
  [[119040, 119078], 2],
  [[119079, 119080], 3],
  [119081, 2],
  [[119082, 119133], 2],
  [119134, 1, ""],
  [119135, 1, ""],
  [119136, 1, ""],
  [119137, 1, ""],
  [119138, 1, ""],
  [119139, 1, ""],
  [119140, 1, ""],
  [[119141, 119154], 2],
  [[119155, 119162], 3],
  [[119163, 119226], 2],
  [119227, 1, ""],
  [119228, 1, ""],
  [119229, 1, ""],
  [119230, 1, ""],
  [119231, 1, ""],
  [119232, 1, ""],
  [[119233, 119261], 2],
  [[119262, 119272], 2],
  [[119273, 119274], 2],
  [[119275, 119295], 3],
  [[119296, 119365], 2],
  [[119366, 119519], 3],
  [[119520, 119539], 2],
  [[119540, 119551], 3],
  [[119552, 119638], 2],
  [[119639, 119647], 3],
  [[119648, 119665], 2],
  [[119666, 119672], 2],
  [[119673, 119807], 3],
  [119808, 1, "a"],
  [119809, 1, "b"],
  [119810, 1, "c"],
  [119811, 1, "d"],
  [119812, 1, "e"],
  [119813, 1, "f"],
  [119814, 1, "g"],
  [119815, 1, "h"],
  [119816, 1, "i"],
  [119817, 1, "j"],
  [119818, 1, "k"],
  [119819, 1, "l"],
  [119820, 1, "m"],
  [119821, 1, "n"],
  [119822, 1, "o"],
  [119823, 1, "p"],
  [119824, 1, "q"],
  [119825, 1, "r"],
  [119826, 1, "s"],
  [119827, 1, "t"],
  [119828, 1, "u"],
  [119829, 1, "v"],
  [119830, 1, "w"],
  [119831, 1, "x"],
  [119832, 1, "y"],
  [119833, 1, "z"],
  [119834, 1, "a"],
  [119835, 1, "b"],
  [119836, 1, "c"],
  [119837, 1, "d"],
  [119838, 1, "e"],
  [119839, 1, "f"],
  [119840, 1, "g"],
  [119841, 1, "h"],
  [119842, 1, "i"],
  [119843, 1, "j"],
  [119844, 1, "k"],
  [119845, 1, "l"],
  [119846, 1, "m"],
  [119847, 1, "n"],
  [119848, 1, "o"],
  [119849, 1, "p"],
  [119850, 1, "q"],
  [119851, 1, "r"],
  [119852, 1, "s"],
  [119853, 1, "t"],
  [119854, 1, "u"],
  [119855, 1, "v"],
  [119856, 1, "w"],
  [119857, 1, "x"],
  [119858, 1, "y"],
  [119859, 1, "z"],
  [119860, 1, "a"],
  [119861, 1, "b"],
  [119862, 1, "c"],
  [119863, 1, "d"],
  [119864, 1, "e"],
  [119865, 1, "f"],
  [119866, 1, "g"],
  [119867, 1, "h"],
  [119868, 1, "i"],
  [119869, 1, "j"],
  [119870, 1, "k"],
  [119871, 1, "l"],
  [119872, 1, "m"],
  [119873, 1, "n"],
  [119874, 1, "o"],
  [119875, 1, "p"],
  [119876, 1, "q"],
  [119877, 1, "r"],
  [119878, 1, "s"],
  [119879, 1, "t"],
  [119880, 1, "u"],
  [119881, 1, "v"],
  [119882, 1, "w"],
  [119883, 1, "x"],
  [119884, 1, "y"],
  [119885, 1, "z"],
  [119886, 1, "a"],
  [119887, 1, "b"],
  [119888, 1, "c"],
  [119889, 1, "d"],
  [119890, 1, "e"],
  [119891, 1, "f"],
  [119892, 1, "g"],
  [119893, 3],
  [119894, 1, "i"],
  [119895, 1, "j"],
  [119896, 1, "k"],
  [119897, 1, "l"],
  [119898, 1, "m"],
  [119899, 1, "n"],
  [119900, 1, "o"],
  [119901, 1, "p"],
  [119902, 1, "q"],
  [119903, 1, "r"],
  [119904, 1, "s"],
  [119905, 1, "t"],
  [119906, 1, "u"],
  [119907, 1, "v"],
  [119908, 1, "w"],
  [119909, 1, "x"],
  [119910, 1, "y"],
  [119911, 1, "z"],
  [119912, 1, "a"],
  [119913, 1, "b"],
  [119914, 1, "c"],
  [119915, 1, "d"],
  [119916, 1, "e"],
  [119917, 1, "f"],
  [119918, 1, "g"],
  [119919, 1, "h"],
  [119920, 1, "i"],
  [119921, 1, "j"],
  [119922, 1, "k"],
  [119923, 1, "l"],
  [119924, 1, "m"],
  [119925, 1, "n"],
  [119926, 1, "o"],
  [119927, 1, "p"],
  [119928, 1, "q"],
  [119929, 1, "r"],
  [119930, 1, "s"],
  [119931, 1, "t"],
  [119932, 1, "u"],
  [119933, 1, "v"],
  [119934, 1, "w"],
  [119935, 1, "x"],
  [119936, 1, "y"],
  [119937, 1, "z"],
  [119938, 1, "a"],
  [119939, 1, "b"],
  [119940, 1, "c"],
  [119941, 1, "d"],
  [119942, 1, "e"],
  [119943, 1, "f"],
  [119944, 1, "g"],
  [119945, 1, "h"],
  [119946, 1, "i"],
  [119947, 1, "j"],
  [119948, 1, "k"],
  [119949, 1, "l"],
  [119950, 1, "m"],
  [119951, 1, "n"],
  [119952, 1, "o"],
  [119953, 1, "p"],
  [119954, 1, "q"],
  [119955, 1, "r"],
  [119956, 1, "s"],
  [119957, 1, "t"],
  [119958, 1, "u"],
  [119959, 1, "v"],
  [119960, 1, "w"],
  [119961, 1, "x"],
  [119962, 1, "y"],
  [119963, 1, "z"],
  [119964, 1, "a"],
  [119965, 3],
  [119966, 1, "c"],
  [119967, 1, "d"],
  [[119968, 119969], 3],
  [119970, 1, "g"],
  [[119971, 119972], 3],
  [119973, 1, "j"],
  [119974, 1, "k"],
  [[119975, 119976], 3],
  [119977, 1, "n"],
  [119978, 1, "o"],
  [119979, 1, "p"],
  [119980, 1, "q"],
  [119981, 3],
  [119982, 1, "s"],
  [119983, 1, "t"],
  [119984, 1, "u"],
  [119985, 1, "v"],
  [119986, 1, "w"],
  [119987, 1, "x"],
  [119988, 1, "y"],
  [119989, 1, "z"],
  [119990, 1, "a"],
  [119991, 1, "b"],
  [119992, 1, "c"],
  [119993, 1, "d"],
  [119994, 3],
  [119995, 1, "f"],
  [119996, 3],
  [119997, 1, "h"],
  [119998, 1, "i"],
  [119999, 1, "j"],
  [120000, 1, "k"],
  [120001, 1, "l"],
  [120002, 1, "m"],
  [120003, 1, "n"],
  [120004, 3],
  [120005, 1, "p"],
  [120006, 1, "q"],
  [120007, 1, "r"],
  [120008, 1, "s"],
  [120009, 1, "t"],
  [120010, 1, "u"],
  [120011, 1, "v"],
  [120012, 1, "w"],
  [120013, 1, "x"],
  [120014, 1, "y"],
  [120015, 1, "z"],
  [120016, 1, "a"],
  [120017, 1, "b"],
  [120018, 1, "c"],
  [120019, 1, "d"],
  [120020, 1, "e"],
  [120021, 1, "f"],
  [120022, 1, "g"],
  [120023, 1, "h"],
  [120024, 1, "i"],
  [120025, 1, "j"],
  [120026, 1, "k"],
  [120027, 1, "l"],
  [120028, 1, "m"],
  [120029, 1, "n"],
  [120030, 1, "o"],
  [120031, 1, "p"],
  [120032, 1, "q"],
  [120033, 1, "r"],
  [120034, 1, "s"],
  [120035, 1, "t"],
  [120036, 1, "u"],
  [120037, 1, "v"],
  [120038, 1, "w"],
  [120039, 1, "x"],
  [120040, 1, "y"],
  [120041, 1, "z"],
  [120042, 1, "a"],
  [120043, 1, "b"],
  [120044, 1, "c"],
  [120045, 1, "d"],
  [120046, 1, "e"],
  [120047, 1, "f"],
  [120048, 1, "g"],
  [120049, 1, "h"],
  [120050, 1, "i"],
  [120051, 1, "j"],
  [120052, 1, "k"],
  [120053, 1, "l"],
  [120054, 1, "m"],
  [120055, 1, "n"],
  [120056, 1, "o"],
  [120057, 1, "p"],
  [120058, 1, "q"],
  [120059, 1, "r"],
  [120060, 1, "s"],
  [120061, 1, "t"],
  [120062, 1, "u"],
  [120063, 1, "v"],
  [120064, 1, "w"],
  [120065, 1, "x"],
  [120066, 1, "y"],
  [120067, 1, "z"],
  [120068, 1, "a"],
  [120069, 1, "b"],
  [120070, 3],
  [120071, 1, "d"],
  [120072, 1, "e"],
  [120073, 1, "f"],
  [120074, 1, "g"],
  [[120075, 120076], 3],
  [120077, 1, "j"],
  [120078, 1, "k"],
  [120079, 1, "l"],
  [120080, 1, "m"],
  [120081, 1, "n"],
  [120082, 1, "o"],
  [120083, 1, "p"],
  [120084, 1, "q"],
  [120085, 3],
  [120086, 1, "s"],
  [120087, 1, "t"],
  [120088, 1, "u"],
  [120089, 1, "v"],
  [120090, 1, "w"],
  [120091, 1, "x"],
  [120092, 1, "y"],
  [120093, 3],
  [120094, 1, "a"],
  [120095, 1, "b"],
  [120096, 1, "c"],
  [120097, 1, "d"],
  [120098, 1, "e"],
  [120099, 1, "f"],
  [120100, 1, "g"],
  [120101, 1, "h"],
  [120102, 1, "i"],
  [120103, 1, "j"],
  [120104, 1, "k"],
  [120105, 1, "l"],
  [120106, 1, "m"],
  [120107, 1, "n"],
  [120108, 1, "o"],
  [120109, 1, "p"],
  [120110, 1, "q"],
  [120111, 1, "r"],
  [120112, 1, "s"],
  [120113, 1, "t"],
  [120114, 1, "u"],
  [120115, 1, "v"],
  [120116, 1, "w"],
  [120117, 1, "x"],
  [120118, 1, "y"],
  [120119, 1, "z"],
  [120120, 1, "a"],
  [120121, 1, "b"],
  [120122, 3],
  [120123, 1, "d"],
  [120124, 1, "e"],
  [120125, 1, "f"],
  [120126, 1, "g"],
  [120127, 3],
  [120128, 1, "i"],
  [120129, 1, "j"],
  [120130, 1, "k"],
  [120131, 1, "l"],
  [120132, 1, "m"],
  [120133, 3],
  [120134, 1, "o"],
  [[120135, 120137], 3],
  [120138, 1, "s"],
  [120139, 1, "t"],
  [120140, 1, "u"],
  [120141, 1, "v"],
  [120142, 1, "w"],
  [120143, 1, "x"],
  [120144, 1, "y"],
  [120145, 3],
  [120146, 1, "a"],
  [120147, 1, "b"],
  [120148, 1, "c"],
  [120149, 1, "d"],
  [120150, 1, "e"],
  [120151, 1, "f"],
  [120152, 1, "g"],
  [120153, 1, "h"],
  [120154, 1, "i"],
  [120155, 1, "j"],
  [120156, 1, "k"],
  [120157, 1, "l"],
  [120158, 1, "m"],
  [120159, 1, "n"],
  [120160, 1, "o"],
  [120161, 1, "p"],
  [120162, 1, "q"],
  [120163, 1, "r"],
  [120164, 1, "s"],
  [120165, 1, "t"],
  [120166, 1, "u"],
  [120167, 1, "v"],
  [120168, 1, "w"],
  [120169, 1, "x"],
  [120170, 1, "y"],
  [120171, 1, "z"],
  [120172, 1, "a"],
  [120173, 1, "b"],
  [120174, 1, "c"],
  [120175, 1, "d"],
  [120176, 1, "e"],
  [120177, 1, "f"],
  [120178, 1, "g"],
  [120179, 1, "h"],
  [120180, 1, "i"],
  [120181, 1, "j"],
  [120182, 1, "k"],
  [120183, 1, "l"],
  [120184, 1, "m"],
  [120185, 1, "n"],
  [120186, 1, "o"],
  [120187, 1, "p"],
  [120188, 1, "q"],
  [120189, 1, "r"],
  [120190, 1, "s"],
  [120191, 1, "t"],
  [120192, 1, "u"],
  [120193, 1, "v"],
  [120194, 1, "w"],
  [120195, 1, "x"],
  [120196, 1, "y"],
  [120197, 1, "z"],
  [120198, 1, "a"],
  [120199, 1, "b"],
  [120200, 1, "c"],
  [120201, 1, "d"],
  [120202, 1, "e"],
  [120203, 1, "f"],
  [120204, 1, "g"],
  [120205, 1, "h"],
  [120206, 1, "i"],
  [120207, 1, "j"],
  [120208, 1, "k"],
  [120209, 1, "l"],
  [120210, 1, "m"],
  [120211, 1, "n"],
  [120212, 1, "o"],
  [120213, 1, "p"],
  [120214, 1, "q"],
  [120215, 1, "r"],
  [120216, 1, "s"],
  [120217, 1, "t"],
  [120218, 1, "u"],
  [120219, 1, "v"],
  [120220, 1, "w"],
  [120221, 1, "x"],
  [120222, 1, "y"],
  [120223, 1, "z"],
  [120224, 1, "a"],
  [120225, 1, "b"],
  [120226, 1, "c"],
  [120227, 1, "d"],
  [120228, 1, "e"],
  [120229, 1, "f"],
  [120230, 1, "g"],
  [120231, 1, "h"],
  [120232, 1, "i"],
  [120233, 1, "j"],
  [120234, 1, "k"],
  [120235, 1, "l"],
  [120236, 1, "m"],
  [120237, 1, "n"],
  [120238, 1, "o"],
  [120239, 1, "p"],
  [120240, 1, "q"],
  [120241, 1, "r"],
  [120242, 1, "s"],
  [120243, 1, "t"],
  [120244, 1, "u"],
  [120245, 1, "v"],
  [120246, 1, "w"],
  [120247, 1, "x"],
  [120248, 1, "y"],
  [120249, 1, "z"],
  [120250, 1, "a"],
  [120251, 1, "b"],
  [120252, 1, "c"],
  [120253, 1, "d"],
  [120254, 1, "e"],
  [120255, 1, "f"],
  [120256, 1, "g"],
  [120257, 1, "h"],
  [120258, 1, "i"],
  [120259, 1, "j"],
  [120260, 1, "k"],
  [120261, 1, "l"],
  [120262, 1, "m"],
  [120263, 1, "n"],
  [120264, 1, "o"],
  [120265, 1, "p"],
  [120266, 1, "q"],
  [120267, 1, "r"],
  [120268, 1, "s"],
  [120269, 1, "t"],
  [120270, 1, "u"],
  [120271, 1, "v"],
  [120272, 1, "w"],
  [120273, 1, "x"],
  [120274, 1, "y"],
  [120275, 1, "z"],
  [120276, 1, "a"],
  [120277, 1, "b"],
  [120278, 1, "c"],
  [120279, 1, "d"],
  [120280, 1, "e"],
  [120281, 1, "f"],
  [120282, 1, "g"],
  [120283, 1, "h"],
  [120284, 1, "i"],
  [120285, 1, "j"],
  [120286, 1, "k"],
  [120287, 1, "l"],
  [120288, 1, "m"],
  [120289, 1, "n"],
  [120290, 1, "o"],
  [120291, 1, "p"],
  [120292, 1, "q"],
  [120293, 1, "r"],
  [120294, 1, "s"],
  [120295, 1, "t"],
  [120296, 1, "u"],
  [120297, 1, "v"],
  [120298, 1, "w"],
  [120299, 1, "x"],
  [120300, 1, "y"],
  [120301, 1, "z"],
  [120302, 1, "a"],
  [120303, 1, "b"],
  [120304, 1, "c"],
  [120305, 1, "d"],
  [120306, 1, "e"],
  [120307, 1, "f"],
  [120308, 1, "g"],
  [120309, 1, "h"],
  [120310, 1, "i"],
  [120311, 1, "j"],
  [120312, 1, "k"],
  [120313, 1, "l"],
  [120314, 1, "m"],
  [120315, 1, "n"],
  [120316, 1, "o"],
  [120317, 1, "p"],
  [120318, 1, "q"],
  [120319, 1, "r"],
  [120320, 1, "s"],
  [120321, 1, "t"],
  [120322, 1, "u"],
  [120323, 1, "v"],
  [120324, 1, "w"],
  [120325, 1, "x"],
  [120326, 1, "y"],
  [120327, 1, "z"],
  [120328, 1, "a"],
  [120329, 1, "b"],
  [120330, 1, "c"],
  [120331, 1, "d"],
  [120332, 1, "e"],
  [120333, 1, "f"],
  [120334, 1, "g"],
  [120335, 1, "h"],
  [120336, 1, "i"],
  [120337, 1, "j"],
  [120338, 1, "k"],
  [120339, 1, "l"],
  [120340, 1, "m"],
  [120341, 1, "n"],
  [120342, 1, "o"],
  [120343, 1, "p"],
  [120344, 1, "q"],
  [120345, 1, "r"],
  [120346, 1, "s"],
  [120347, 1, "t"],
  [120348, 1, "u"],
  [120349, 1, "v"],
  [120350, 1, "w"],
  [120351, 1, "x"],
  [120352, 1, "y"],
  [120353, 1, "z"],
  [120354, 1, "a"],
  [120355, 1, "b"],
  [120356, 1, "c"],
  [120357, 1, "d"],
  [120358, 1, "e"],
  [120359, 1, "f"],
  [120360, 1, "g"],
  [120361, 1, "h"],
  [120362, 1, "i"],
  [120363, 1, "j"],
  [120364, 1, "k"],
  [120365, 1, "l"],
  [120366, 1, "m"],
  [120367, 1, "n"],
  [120368, 1, "o"],
  [120369, 1, "p"],
  [120370, 1, "q"],
  [120371, 1, "r"],
  [120372, 1, "s"],
  [120373, 1, "t"],
  [120374, 1, "u"],
  [120375, 1, "v"],
  [120376, 1, "w"],
  [120377, 1, "x"],
  [120378, 1, "y"],
  [120379, 1, "z"],
  [120380, 1, "a"],
  [120381, 1, "b"],
  [120382, 1, "c"],
  [120383, 1, "d"],
  [120384, 1, "e"],
  [120385, 1, "f"],
  [120386, 1, "g"],
  [120387, 1, "h"],
  [120388, 1, "i"],
  [120389, 1, "j"],
  [120390, 1, "k"],
  [120391, 1, "l"],
  [120392, 1, "m"],
  [120393, 1, "n"],
  [120394, 1, "o"],
  [120395, 1, "p"],
  [120396, 1, "q"],
  [120397, 1, "r"],
  [120398, 1, "s"],
  [120399, 1, "t"],
  [120400, 1, "u"],
  [120401, 1, "v"],
  [120402, 1, "w"],
  [120403, 1, "x"],
  [120404, 1, "y"],
  [120405, 1, "z"],
  [120406, 1, "a"],
  [120407, 1, "b"],
  [120408, 1, "c"],
  [120409, 1, "d"],
  [120410, 1, "e"],
  [120411, 1, "f"],
  [120412, 1, "g"],
  [120413, 1, "h"],
  [120414, 1, "i"],
  [120415, 1, "j"],
  [120416, 1, "k"],
  [120417, 1, "l"],
  [120418, 1, "m"],
  [120419, 1, "n"],
  [120420, 1, "o"],
  [120421, 1, "p"],
  [120422, 1, "q"],
  [120423, 1, "r"],
  [120424, 1, "s"],
  [120425, 1, "t"],
  [120426, 1, "u"],
  [120427, 1, "v"],
  [120428, 1, "w"],
  [120429, 1, "x"],
  [120430, 1, "y"],
  [120431, 1, "z"],
  [120432, 1, "a"],
  [120433, 1, "b"],
  [120434, 1, "c"],
  [120435, 1, "d"],
  [120436, 1, "e"],
  [120437, 1, "f"],
  [120438, 1, "g"],
  [120439, 1, "h"],
  [120440, 1, "i"],
  [120441, 1, "j"],
  [120442, 1, "k"],
  [120443, 1, "l"],
  [120444, 1, "m"],
  [120445, 1, "n"],
  [120446, 1, "o"],
  [120447, 1, "p"],
  [120448, 1, "q"],
  [120449, 1, "r"],
  [120450, 1, "s"],
  [120451, 1, "t"],
  [120452, 1, "u"],
  [120453, 1, "v"],
  [120454, 1, "w"],
  [120455, 1, "x"],
  [120456, 1, "y"],
  [120457, 1, "z"],
  [120458, 1, "a"],
  [120459, 1, "b"],
  [120460, 1, "c"],
  [120461, 1, "d"],
  [120462, 1, "e"],
  [120463, 1, "f"],
  [120464, 1, "g"],
  [120465, 1, "h"],
  [120466, 1, "i"],
  [120467, 1, "j"],
  [120468, 1, "k"],
  [120469, 1, "l"],
  [120470, 1, "m"],
  [120471, 1, "n"],
  [120472, 1, "o"],
  [120473, 1, "p"],
  [120474, 1, "q"],
  [120475, 1, "r"],
  [120476, 1, "s"],
  [120477, 1, "t"],
  [120478, 1, "u"],
  [120479, 1, "v"],
  [120480, 1, "w"],
  [120481, 1, "x"],
  [120482, 1, "y"],
  [120483, 1, "z"],
  [120484, 1, ""],
  [120485, 1, ""],
  [[120486, 120487], 3],
  [120488, 1, ""],
  [120489, 1, ""],
  [120490, 1, ""],
  [120491, 1, ""],
  [120492, 1, ""],
  [120493, 1, ""],
  [120494, 1, ""],
  [120495, 1, ""],
  [120496, 1, ""],
  [120497, 1, ""],
  [120498, 1, ""],
  [120499, 1, ""],
  [120500, 1, ""],
  [120501, 1, ""],
  [120502, 1, ""],
  [120503, 1, ""],
  [120504, 1, ""],
  [120505, 1, ""],
  [120506, 1, ""],
  [120507, 1, ""],
  [120508, 1, ""],
  [120509, 1, ""],
  [120510, 1, ""],
  [120511, 1, ""],
  [120512, 1, ""],
  [120513, 1, ""],
  [120514, 1, ""],
  [120515, 1, ""],
  [120516, 1, ""],
  [120517, 1, ""],
  [120518, 1, ""],
  [120519, 1, ""],
  [120520, 1, ""],
  [120521, 1, ""],
  [120522, 1, ""],
  [120523, 1, ""],
  [120524, 1, ""],
  [120525, 1, ""],
  [120526, 1, ""],
  [120527, 1, ""],
  [120528, 1, ""],
  [120529, 1, ""],
  [120530, 1, ""],
  [[120531, 120532], 1, ""],
  [120533, 1, ""],
  [120534, 1, ""],
  [120535, 1, ""],
  [120536, 1, ""],
  [120537, 1, ""],
  [120538, 1, ""],
  [120539, 1, ""],
  [120540, 1, ""],
  [120541, 1, ""],
  [120542, 1, ""],
  [120543, 1, ""],
  [120544, 1, ""],
  [120545, 1, ""],
  [120546, 1, ""],
  [120547, 1, ""],
  [120548, 1, ""],
  [120549, 1, ""],
  [120550, 1, ""],
  [120551, 1, ""],
  [120552, 1, ""],
  [120553, 1, ""],
  [120554, 1, ""],
  [120555, 1, ""],
  [120556, 1, ""],
  [120557, 1, ""],
  [120558, 1, ""],
  [120559, 1, ""],
  [120560, 1, ""],
  [120561, 1, ""],
  [120562, 1, ""],
  [120563, 1, ""],
  [120564, 1, ""],
  [120565, 1, ""],
  [120566, 1, ""],
  [120567, 1, ""],
  [120568, 1, ""],
  [120569, 1, ""],
  [120570, 1, ""],
  [120571, 1, ""],
  [120572, 1, ""],
  [120573, 1, ""],
  [120574, 1, ""],
  [120575, 1, ""],
  [120576, 1, ""],
  [120577, 1, ""],
  [120578, 1, ""],
  [120579, 1, ""],
  [120580, 1, ""],
  [120581, 1, ""],
  [120582, 1, ""],
  [120583, 1, ""],
  [120584, 1, ""],
  [120585, 1, ""],
  [120586, 1, ""],
  [120587, 1, ""],
  [120588, 1, ""],
  [[120589, 120590], 1, ""],
  [120591, 1, ""],
  [120592, 1, ""],
  [120593, 1, ""],
  [120594, 1, ""],
  [120595, 1, ""],
  [120596, 1, ""],
  [120597, 1, ""],
  [120598, 1, ""],
  [120599, 1, ""],
  [120600, 1, ""],
  [120601, 1, ""],
  [120602, 1, ""],
  [120603, 1, ""],
  [120604, 1, ""],
  [120605, 1, ""],
  [120606, 1, ""],
  [120607, 1, ""],
  [120608, 1, ""],
  [120609, 1, ""],
  [120610, 1, ""],
  [120611, 1, ""],
  [120612, 1, ""],
  [120613, 1, ""],
  [120614, 1, ""],
  [120615, 1, ""],
  [120616, 1, ""],
  [120617, 1, ""],
  [120618, 1, ""],
  [120619, 1, ""],
  [120620, 1, ""],
  [120621, 1, ""],
  [120622, 1, ""],
  [120623, 1, ""],
  [120624, 1, ""],
  [120625, 1, ""],
  [120626, 1, ""],
  [120627, 1, ""],
  [120628, 1, ""],
  [120629, 1, ""],
  [120630, 1, ""],
  [120631, 1, ""],
  [120632, 1, ""],
  [120633, 1, ""],
  [120634, 1, ""],
  [120635, 1, ""],
  [120636, 1, ""],
  [120637, 1, ""],
  [120638, 1, ""],
  [120639, 1, ""],
  [120640, 1, ""],
  [120641, 1, ""],
  [120642, 1, ""],
  [120643, 1, ""],
  [120644, 1, ""],
  [120645, 1, ""],
  [120646, 1, ""],
  [[120647, 120648], 1, ""],
  [120649, 1, ""],
  [120650, 1, ""],
  [120651, 1, ""],
  [120652, 1, ""],
  [120653, 1, ""],
  [120654, 1, ""],
  [120655, 1, ""],
  [120656, 1, ""],
  [120657, 1, ""],
  [120658, 1, ""],
  [120659, 1, ""],
  [120660, 1, ""],
  [120661, 1, ""],
  [120662, 1, ""],
  [120663, 1, ""],
  [120664, 1, ""],
  [120665, 1, ""],
  [120666, 1, ""],
  [120667, 1, ""],
  [120668, 1, ""],
  [120669, 1, ""],
  [120670, 1, ""],
  [120671, 1, ""],
  [120672, 1, ""],
  [120673, 1, ""],
  [120674, 1, ""],
  [120675, 1, ""],
  [120676, 1, ""],
  [120677, 1, ""],
  [120678, 1, ""],
  [120679, 1, ""],
  [120680, 1, ""],
  [120681, 1, ""],
  [120682, 1, ""],
  [120683, 1, ""],
  [120684, 1, ""],
  [120685, 1, ""],
  [120686, 1, ""],
  [120687, 1, ""],
  [120688, 1, ""],
  [120689, 1, ""],
  [120690, 1, ""],
  [120691, 1, ""],
  [120692, 1, ""],
  [120693, 1, ""],
  [120694, 1, ""],
  [120695, 1, ""],
  [120696, 1, ""],
  [120697, 1, ""],
  [120698, 1, ""],
  [120699, 1, ""],
  [120700, 1, ""],
  [120701, 1, ""],
  [120702, 1, ""],
  [120703, 1, ""],
  [120704, 1, ""],
  [[120705, 120706], 1, ""],
  [120707, 1, ""],
  [120708, 1, ""],
  [120709, 1, ""],
  [120710, 1, ""],
  [120711, 1, ""],
  [120712, 1, ""],
  [120713, 1, ""],
  [120714, 1, ""],
  [120715, 1, ""],
  [120716, 1, ""],
  [120717, 1, ""],
  [120718, 1, ""],
  [120719, 1, ""],
  [120720, 1, ""],
  [120721, 1, ""],
  [120722, 1, ""],
  [120723, 1, ""],
  [120724, 1, ""],
  [120725, 1, ""],
  [120726, 1, ""],
  [120727, 1, ""],
  [120728, 1, ""],
  [120729, 1, ""],
  [120730, 1, ""],
  [120731, 1, ""],
  [120732, 1, ""],
  [120733, 1, ""],
  [120734, 1, ""],
  [120735, 1, ""],
  [120736, 1, ""],
  [120737, 1, ""],
  [120738, 1, ""],
  [120739, 1, ""],
  [120740, 1, ""],
  [120741, 1, ""],
  [120742, 1, ""],
  [120743, 1, ""],
  [120744, 1, ""],
  [120745, 1, ""],
  [120746, 1, ""],
  [120747, 1, ""],
  [120748, 1, ""],
  [120749, 1, ""],
  [120750, 1, ""],
  [120751, 1, ""],
  [120752, 1, ""],
  [120753, 1, ""],
  [120754, 1, ""],
  [120755, 1, ""],
  [120756, 1, ""],
  [120757, 1, ""],
  [120758, 1, ""],
  [120759, 1, ""],
  [120760, 1, ""],
  [120761, 1, ""],
  [120762, 1, ""],
  [[120763, 120764], 1, ""],
  [120765, 1, ""],
  [120766, 1, ""],
  [120767, 1, ""],
  [120768, 1, ""],
  [120769, 1, ""],
  [120770, 1, ""],
  [120771, 1, ""],
  [120772, 1, ""],
  [120773, 1, ""],
  [120774, 1, ""],
  [120775, 1, ""],
  [120776, 1, ""],
  [120777, 1, ""],
  [[120778, 120779], 1, ""],
  [[120780, 120781], 3],
  [120782, 1, "0"],
  [120783, 1, "1"],
  [120784, 1, "2"],
  [120785, 1, "3"],
  [120786, 1, "4"],
  [120787, 1, "5"],
  [120788, 1, "6"],
  [120789, 1, "7"],
  [120790, 1, "8"],
  [120791, 1, "9"],
  [120792, 1, "0"],
  [120793, 1, "1"],
  [120794, 1, "2"],
  [120795, 1, "3"],
  [120796, 1, "4"],
  [120797, 1, "5"],
  [120798, 1, "6"],
  [120799, 1, "7"],
  [120800, 1, "8"],
  [120801, 1, "9"],
  [120802, 1, "0"],
  [120803, 1, "1"],
  [120804, 1, "2"],
  [120805, 1, "3"],
  [120806, 1, "4"],
  [120807, 1, "5"],
  [120808, 1, "6"],
  [120809, 1, "7"],
  [120810, 1, "8"],
  [120811, 1, "9"],
  [120812, 1, "0"],
  [120813, 1, "1"],
  [120814, 1, "2"],
  [120815, 1, "3"],
  [120816, 1, "4"],
  [120817, 1, "5"],
  [120818, 1, "6"],
  [120819, 1, "7"],
  [120820, 1, "8"],
  [120821, 1, "9"],
  [120822, 1, "0"],
  [120823, 1, "1"],
  [120824, 1, "2"],
  [120825, 1, "3"],
  [120826, 1, "4"],
  [120827, 1, "5"],
  [120828, 1, "6"],
  [120829, 1, "7"],
  [120830, 1, "8"],
  [120831, 1, "9"],
  [[120832, 121343], 2],
  [[121344, 121398], 2],
  [[121399, 121402], 2],
  [[121403, 121452], 2],
  [[121453, 121460], 2],
  [121461, 2],
  [[121462, 121475], 2],
  [121476, 2],
  [[121477, 121483], 2],
  [[121484, 121498], 3],
  [[121499, 121503], 2],
  [121504, 3],
  [[121505, 121519], 2],
  [[121520, 122623], 3],
  [[122624, 122654], 2],
  [[122655, 122879], 3],
  [[122880, 122886], 2],
  [122887, 3],
  [[122888, 122904], 2],
  [[122905, 122906], 3],
  [[122907, 122913], 2],
  [122914, 3],
  [[122915, 122916], 2],
  [122917, 3],
  [[122918, 122922], 2],
  [[122923, 123135], 3],
  [[123136, 123180], 2],
  [[123181, 123183], 3],
  [[123184, 123197], 2],
  [[123198, 123199], 3],
  [[123200, 123209], 2],
  [[123210, 123213], 3],
  [123214, 2],
  [123215, 2],
  [[123216, 123535], 3],
  [[123536, 123566], 2],
  [[123567, 123583], 3],
  [[123584, 123641], 2],
  [[123642, 123646], 3],
  [123647, 2],
  [[123648, 124895], 3],
  [[124896, 124902], 2],
  [124903, 3],
  [[124904, 124907], 2],
  [124908, 3],
  [[124909, 124910], 2],
  [124911, 3],
  [[124912, 124926], 2],
  [124927, 3],
  [[124928, 125124], 2],
  [[125125, 125126], 3],
  [[125127, 125135], 2],
  [[125136, 125142], 2],
  [[125143, 125183], 3],
  [125184, 1, ""],
  [125185, 1, ""],
  [125186, 1, ""],
  [125187, 1, ""],
  [125188, 1, ""],
  [125189, 1, ""],
  [125190, 1, ""],
  [125191, 1, ""],
  [125192, 1, ""],
  [125193, 1, ""],
  [125194, 1, ""],
  [125195, 1, ""],
  [125196, 1, ""],
  [125197, 1, ""],
  [125198, 1, ""],
  [125199, 1, ""],
  [125200, 1, ""],
  [125201, 1, ""],
  [125202, 1, ""],
  [125203, 1, ""],
  [125204, 1, ""],
  [125205, 1, ""],
  [125206, 1, ""],
  [125207, 1, ""],
  [125208, 1, ""],
  [125209, 1, ""],
  [125210, 1, ""],
  [125211, 1, ""],
  [125212, 1, ""],
  [125213, 1, ""],
  [125214, 1, ""],
  [125215, 1, ""],
  [125216, 1, ""],
  [125217, 1, ""],
  [[125218, 125258], 2],
  [125259, 2],
  [[125260, 125263], 3],
  [[125264, 125273], 2],
  [[125274, 125277], 3],
  [[125278, 125279], 2],
  [[125280, 126064], 3],
  [[126065, 126132], 2],
  [[126133, 126208], 3],
  [[126209, 126269], 2],
  [[126270, 126463], 3],
  [126464, 1, ""],
  [126465, 1, ""],
  [126466, 1, ""],
  [126467, 1, ""],
  [126468, 3],
  [126469, 1, ""],
  [126470, 1, ""],
  [126471, 1, ""],
  [126472, 1, ""],
  [126473, 1, ""],
  [126474, 1, ""],
  [126475, 1, ""],
  [126476, 1, ""],
  [126477, 1, ""],
  [126478, 1, ""],
  [126479, 1, ""],
  [126480, 1, ""],
  [126481, 1, ""],
  [126482, 1, ""],
  [126483, 1, ""],
  [126484, 1, ""],
  [126485, 1, ""],
  [126486, 1, ""],
  [126487, 1, ""],
  [126488, 1, ""],
  [126489, 1, ""],
  [126490, 1, ""],
  [126491, 1, ""],
  [126492, 1, ""],
  [126493, 1, ""],
  [126494, 1, ""],
  [126495, 1, ""],
  [126496, 3],
  [126497, 1, ""],
  [126498, 1, ""],
  [126499, 3],
  [126500, 1, ""],
  [[126501, 126502], 3],
  [126503, 1, ""],
  [126504, 3],
  [126505, 1, ""],
  [126506, 1, ""],
  [126507, 1, ""],
  [126508, 1, ""],
  [126509, 1, ""],
  [126510, 1, ""],
  [126511, 1, ""],
  [126512, 1, ""],
  [126513, 1, ""],
  [126514, 1, ""],
  [126515, 3],
  [126516, 1, ""],
  [126517, 1, ""],
  [126518, 1, ""],
  [126519, 1, ""],
  [126520, 3],
  [126521, 1, ""],
  [126522, 3],
  [126523, 1, ""],
  [[126524, 126529], 3],
  [126530, 1, ""],
  [[126531, 126534], 3],
  [126535, 1, ""],
  [126536, 3],
  [126537, 1, ""],
  [126538, 3],
  [126539, 1, ""],
  [126540, 3],
  [126541, 1, ""],
  [126542, 1, ""],
  [126543, 1, ""],
  [126544, 3],
  [126545, 1, ""],
  [126546, 1, ""],
  [126547, 3],
  [126548, 1, ""],
  [[126549, 126550], 3],
  [126551, 1, ""],
  [126552, 3],
  [126553, 1, ""],
  [126554, 3],
  [126555, 1, ""],
  [126556, 3],
  [126557, 1, ""],
  [126558, 3],
  [126559, 1, ""],
  [126560, 3],
  [126561, 1, ""],
  [126562, 1, ""],
  [126563, 3],
  [126564, 1, ""],
  [[126565, 126566], 3],
  [126567, 1, ""],
  [126568, 1, ""],
  [126569, 1, ""],
  [126570, 1, ""],
  [126571, 3],
  [126572, 1, ""],
  [126573, 1, ""],
  [126574, 1, ""],
  [126575, 1, ""],
  [126576, 1, ""],
  [126577, 1, ""],
  [126578, 1, ""],
  [126579, 3],
  [126580, 1, ""],
  [126581, 1, ""],
  [126582, 1, ""],
  [126583, 1, ""],
  [126584, 3],
  [126585, 1, ""],
  [126586, 1, ""],
  [126587, 1, ""],
  [126588, 1, ""],
  [126589, 3],
  [126590, 1, ""],
  [126591, 3],
  [126592, 1, ""],
  [126593, 1, ""],
  [126594, 1, ""],
  [126595, 1, ""],
  [126596, 1, ""],
  [126597, 1, ""],
  [126598, 1, ""],
  [126599, 1, ""],
  [126600, 1, ""],
  [126601, 1, ""],
  [126602, 3],
  [126603, 1, ""],
  [126604, 1, ""],
  [126605, 1, ""],
  [126606, 1, ""],
  [126607, 1, ""],
  [126608, 1, ""],
  [126609, 1, ""],
  [126610, 1, ""],
  [126611, 1, ""],
  [126612, 1, ""],
  [126613, 1, ""],
  [126614, 1, ""],
  [126615, 1, ""],
  [126616, 1, ""],
  [126617, 1, ""],
  [126618, 1, ""],
  [126619, 1, ""],
  [[126620, 126624], 3],
  [126625, 1, ""],
  [126626, 1, ""],
  [126627, 1, ""],
  [126628, 3],
  [126629, 1, ""],
  [126630, 1, ""],
  [126631, 1, ""],
  [126632, 1, ""],
  [126633, 1, ""],
  [126634, 3],
  [126635, 1, ""],
  [126636, 1, ""],
  [126637, 1, ""],
  [126638, 1, ""],
  [126639, 1, ""],
  [126640, 1, ""],
  [126641, 1, ""],
  [126642, 1, ""],
  [126643, 1, ""],
  [126644, 1, ""],
  [126645, 1, ""],
  [126646, 1, ""],
  [126647, 1, ""],
  [126648, 1, ""],
  [126649, 1, ""],
  [126650, 1, ""],
  [126651, 1, ""],
  [[126652, 126703], 3],
  [[126704, 126705], 2],
  [[126706, 126975], 3],
  [[126976, 127019], 2],
  [[127020, 127023], 3],
  [[127024, 127123], 2],
  [[127124, 127135], 3],
  [[127136, 127150], 2],
  [[127151, 127152], 3],
  [[127153, 127166], 2],
  [127167, 2],
  [127168, 3],
  [[127169, 127183], 2],
  [127184, 3],
  [[127185, 127199], 2],
  [[127200, 127221], 2],
  [[127222, 127231], 3],
  [127232, 3],
  [127233, 5, "0,"],
  [127234, 5, "1,"],
  [127235, 5, "2,"],
  [127236, 5, "3,"],
  [127237, 5, "4,"],
  [127238, 5, "5,"],
  [127239, 5, "6,"],
  [127240, 5, "7,"],
  [127241, 5, "8,"],
  [127242, 5, "9,"],
  [[127243, 127244], 2],
  [[127245, 127247], 2],
  [127248, 5, "(a)"],
  [127249, 5, "(b)"],
  [127250, 5, "(c)"],
  [127251, 5, "(d)"],
  [127252, 5, "(e)"],
  [127253, 5, "(f)"],
  [127254, 5, "(g)"],
  [127255, 5, "(h)"],
  [127256, 5, "(i)"],
  [127257, 5, "(j)"],
  [127258, 5, "(k)"],
  [127259, 5, "(l)"],
  [127260, 5, "(m)"],
  [127261, 5, "(n)"],
  [127262, 5, "(o)"],
  [127263, 5, "(p)"],
  [127264, 5, "(q)"],
  [127265, 5, "(r)"],
  [127266, 5, "(s)"],
  [127267, 5, "(t)"],
  [127268, 5, "(u)"],
  [127269, 5, "(v)"],
  [127270, 5, "(w)"],
  [127271, 5, "(x)"],
  [127272, 5, "(y)"],
  [127273, 5, "(z)"],
  [127274, 1, "s"],
  [127275, 1, "c"],
  [127276, 1, "r"],
  [127277, 1, "cd"],
  [127278, 1, "wz"],
  [127279, 2],
  [127280, 1, "a"],
  [127281, 1, "b"],
  [127282, 1, "c"],
  [127283, 1, "d"],
  [127284, 1, "e"],
  [127285, 1, "f"],
  [127286, 1, "g"],
  [127287, 1, "h"],
  [127288, 1, "i"],
  [127289, 1, "j"],
  [127290, 1, "k"],
  [127291, 1, "l"],
  [127292, 1, "m"],
  [127293, 1, "n"],
  [127294, 1, "o"],
  [127295, 1, "p"],
  [127296, 1, "q"],
  [127297, 1, "r"],
  [127298, 1, "s"],
  [127299, 1, "t"],
  [127300, 1, "u"],
  [127301, 1, "v"],
  [127302, 1, "w"],
  [127303, 1, "x"],
  [127304, 1, "y"],
  [127305, 1, "z"],
  [127306, 1, "hv"],
  [127307, 1, "mv"],
  [127308, 1, "sd"],
  [127309, 1, "ss"],
  [127310, 1, "ppv"],
  [127311, 1, "wc"],
  [[127312, 127318], 2],
  [127319, 2],
  [[127320, 127326], 2],
  [127327, 2],
  [[127328, 127337], 2],
  [127338, 1, "mc"],
  [127339, 1, "md"],
  [127340, 1, "mr"],
  [[127341, 127343], 2],
  [[127344, 127352], 2],
  [127353, 2],
  [127354, 2],
  [[127355, 127356], 2],
  [[127357, 127358], 2],
  [127359, 2],
  [[127360, 127369], 2],
  [[127370, 127373], 2],
  [[127374, 127375], 2],
  [127376, 1, "dj"],
  [[127377, 127386], 2],
  [[127387, 127404], 2],
  [127405, 2],
  [[127406, 127461], 3],
  [[127462, 127487], 2],
  [127488, 1, ""],
  [127489, 1, ""],
  [127490, 1, ""],
  [[127491, 127503], 3],
  [127504, 1, ""],
  [127505, 1, ""],
  [127506, 1, ""],
  [127507, 1, ""],
  [127508, 1, ""],
  [127509, 1, ""],
  [127510, 1, ""],
  [127511, 1, ""],
  [127512, 1, ""],
  [127513, 1, ""],
  [127514, 1, ""],
  [127515, 1, ""],
  [127516, 1, ""],
  [127517, 1, ""],
  [127518, 1, ""],
  [127519, 1, ""],
  [127520, 1, ""],
  [127521, 1, ""],
  [127522, 1, ""],
  [127523, 1, ""],
  [127524, 1, ""],
  [127525, 1, ""],
  [127526, 1, ""],
  [127527, 1, ""],
  [127528, 1, ""],
  [127529, 1, ""],
  [127530, 1, ""],
  [127531, 1, ""],
  [127532, 1, ""],
  [127533, 1, ""],
  [127534, 1, ""],
  [127535, 1, ""],
  [127536, 1, ""],
  [127537, 1, ""],
  [127538, 1, ""],
  [127539, 1, ""],
  [127540, 1, ""],
  [127541, 1, ""],
  [127542, 1, ""],
  [127543, 1, ""],
  [127544, 1, ""],
  [127545, 1, ""],
  [127546, 1, ""],
  [127547, 1, ""],
  [[127548, 127551], 3],
  [127552, 1, ""],
  [127553, 1, ""],
  [127554, 1, ""],
  [127555, 1, ""],
  [127556, 1, ""],
  [127557, 1, ""],
  [127558, 1, ""],
  [127559, 1, ""],
  [127560, 1, ""],
  [[127561, 127567], 3],
  [127568, 1, ""],
  [127569, 1, ""],
  [[127570, 127583], 3],
  [[127584, 127589], 2],
  [[127590, 127743], 3],
  [[127744, 127776], 2],
  [[127777, 127788], 2],
  [[127789, 127791], 2],
  [[127792, 127797], 2],
  [127798, 2],
  [[127799, 127868], 2],
  [127869, 2],
  [[127870, 127871], 2],
  [[127872, 127891], 2],
  [[127892, 127903], 2],
  [[127904, 127940], 2],
  [127941, 2],
  [[127942, 127946], 2],
  [[127947, 127950], 2],
  [[127951, 127955], 2],
  [[127956, 127967], 2],
  [[127968, 127984], 2],
  [[127985, 127991], 2],
  [[127992, 127999], 2],
  [[128000, 128062], 2],
  [128063, 2],
  [128064, 2],
  [128065, 2],
  [[128066, 128247], 2],
  [128248, 2],
  [[128249, 128252], 2],
  [[128253, 128254], 2],
  [128255, 2],
  [[128256, 128317], 2],
  [[128318, 128319], 2],
  [[128320, 128323], 2],
  [[128324, 128330], 2],
  [[128331, 128335], 2],
  [[128336, 128359], 2],
  [[128360, 128377], 2],
  [128378, 2],
  [[128379, 128419], 2],
  [128420, 2],
  [[128421, 128506], 2],
  [[128507, 128511], 2],
  [128512, 2],
  [[128513, 128528], 2],
  [128529, 2],
  [[128530, 128532], 2],
  [128533, 2],
  [128534, 2],
  [128535, 2],
  [128536, 2],
  [128537, 2],
  [128538, 2],
  [128539, 2],
  [[128540, 128542], 2],
  [128543, 2],
  [[128544, 128549], 2],
  [[128550, 128551], 2],
  [[128552, 128555], 2],
  [128556, 2],
  [128557, 2],
  [[128558, 128559], 2],
  [[128560, 128563], 2],
  [128564, 2],
  [[128565, 128576], 2],
  [[128577, 128578], 2],
  [[128579, 128580], 2],
  [[128581, 128591], 2],
  [[128592, 128639], 2],
  [[128640, 128709], 2],
  [[128710, 128719], 2],
  [128720, 2],
  [[128721, 128722], 2],
  [[128723, 128724], 2],
  [128725, 2],
  [[128726, 128727], 2],
  [[128728, 128732], 3],
  [[128733, 128735], 2],
  [[128736, 128748], 2],
  [[128749, 128751], 3],
  [[128752, 128755], 2],
  [[128756, 128758], 2],
  [[128759, 128760], 2],
  [128761, 2],
  [128762, 2],
  [[128763, 128764], 2],
  [[128765, 128767], 3],
  [[128768, 128883], 2],
  [[128884, 128895], 3],
  [[128896, 128980], 2],
  [[128981, 128984], 2],
  [[128985, 128991], 3],
  [[128992, 129003], 2],
  [[129004, 129007], 3],
  [129008, 2],
  [[129009, 129023], 3],
  [[129024, 129035], 2],
  [[129036, 129039], 3],
  [[129040, 129095], 2],
  [[129096, 129103], 3],
  [[129104, 129113], 2],
  [[129114, 129119], 3],
  [[129120, 129159], 2],
  [[129160, 129167], 3],
  [[129168, 129197], 2],
  [[129198, 129199], 3],
  [[129200, 129201], 2],
  [[129202, 129279], 3],
  [[129280, 129291], 2],
  [129292, 2],
  [[129293, 129295], 2],
  [[129296, 129304], 2],
  [[129305, 129310], 2],
  [129311, 2],
  [[129312, 129319], 2],
  [[129320, 129327], 2],
  [129328, 2],
  [[129329, 129330], 2],
  [[129331, 129342], 2],
  [129343, 2],
  [[129344, 129355], 2],
  [129356, 2],
  [[129357, 129359], 2],
  [[129360, 129374], 2],
  [[129375, 129387], 2],
  [[129388, 129392], 2],
  [129393, 2],
  [129394, 2],
  [[129395, 129398], 2],
  [[129399, 129400], 2],
  [129401, 2],
  [129402, 2],
  [129403, 2],
  [[129404, 129407], 2],
  [[129408, 129412], 2],
  [[129413, 129425], 2],
  [[129426, 129431], 2],
  [[129432, 129442], 2],
  [[129443, 129444], 2],
  [[129445, 129450], 2],
  [[129451, 129453], 2],
  [[129454, 129455], 2],
  [[129456, 129465], 2],
  [[129466, 129471], 2],
  [129472, 2],
  [[129473, 129474], 2],
  [[129475, 129482], 2],
  [129483, 2],
  [129484, 2],
  [[129485, 129487], 2],
  [[129488, 129510], 2],
  [[129511, 129535], 2],
  [[129536, 129619], 2],
  [[129620, 129631], 3],
  [[129632, 129645], 2],
  [[129646, 129647], 3],
  [[129648, 129651], 2],
  [129652, 2],
  [[129653, 129655], 3],
  [[129656, 129658], 2],
  [[129659, 129660], 2],
  [[129661, 129663], 3],
  [[129664, 129666], 2],
  [[129667, 129670], 2],
  [[129671, 129679], 3],
  [[129680, 129685], 2],
  [[129686, 129704], 2],
  [[129705, 129708], 2],
  [[129709, 129711], 3],
  [[129712, 129718], 2],
  [[129719, 129722], 2],
  [[129723, 129727], 3],
  [[129728, 129730], 2],
  [[129731, 129733], 2],
  [[129734, 129743], 3],
  [[129744, 129750], 2],
  [[129751, 129753], 2],
  [[129754, 129759], 3],
  [[129760, 129767], 2],
  [[129768, 129775], 3],
  [[129776, 129782], 2],
  [[129783, 129791], 3],
  [[129792, 129938], 2],
  [129939, 3],
  [[129940, 129994], 2],
  [[129995, 130031], 3],
  [130032, 1, "0"],
  [130033, 1, "1"],
  [130034, 1, "2"],
  [130035, 1, "3"],
  [130036, 1, "4"],
  [130037, 1, "5"],
  [130038, 1, "6"],
  [130039, 1, "7"],
  [130040, 1, "8"],
  [130041, 1, "9"],
  [[130042, 131069], 3],
  [[131070, 131071], 3],
  [[131072, 173782], 2],
  [[173783, 173789], 2],
  [[173790, 173791], 2],
  [[173792, 173823], 3],
  [[173824, 177972], 2],
  [[177973, 177976], 2],
  [[177977, 177983], 3],
  [[177984, 178205], 2],
  [[178206, 178207], 3],
  [[178208, 183969], 2],
  [[183970, 183983], 3],
  [[183984, 191456], 2],
  [[191457, 194559], 3],
  [194560, 1, ""],
  [194561, 1, ""],
  [194562, 1, ""],
  [194563, 1, ""],
  [194564, 1, ""],
  [194565, 1, ""],
  [194566, 1, ""],
  [194567, 1, ""],
  [194568, 1, ""],
  [194569, 1, ""],
  [194570, 1, ""],
  [194571, 1, ""],
  [194572, 1, ""],
  [194573, 1, ""],
  [194574, 1, ""],
  [194575, 1, ""],
  [194576, 1, ""],
  [194577, 1, ""],
  [194578, 1, ""],
  [194579, 1, ""],
  [194580, 1, ""],
  [194581, 1, ""],
  [194582, 1, ""],
  [194583, 1, ""],
  [194584, 1, ""],
  [194585, 1, ""],
  [194586, 1, ""],
  [194587, 1, ""],
  [194588, 1, ""],
  [194589, 1, ""],
  [194590, 1, ""],
  [194591, 1, ""],
  [194592, 1, ""],
  [194593, 1, ""],
  [194594, 1, ""],
  [194595, 1, ""],
  [194596, 1, ""],
  [194597, 1, ""],
  [194598, 1, ""],
  [194599, 1, ""],
  [194600, 1, ""],
  [194601, 1, ""],
  [194602, 1, ""],
  [194603, 1, ""],
  [194604, 1, ""],
  [194605, 1, ""],
  [194606, 1, ""],
  [194607, 1, ""],
  [194608, 1, ""],
  [[194609, 194611], 1, ""],
  [194612, 1, ""],
  [194613, 1, ""],
  [194614, 1, ""],
  [194615, 1, ""],
  [194616, 1, ""],
  [194617, 1, ""],
  [194618, 1, ""],
  [194619, 1, ""],
  [194620, 1, ""],
  [194621, 1, ""],
  [194622, 1, ""],
  [194623, 1, ""],
  [194624, 1, ""],
  [194625, 1, ""],
  [194626, 1, ""],
  [194627, 1, ""],
  [194628, 1, ""],
  [[194629, 194630], 1, ""],
  [194631, 1, ""],
  [194632, 1, ""],
  [194633, 1, ""],
  [194634, 1, ""],
  [194635, 1, ""],
  [194636, 1, ""],
  [194637, 1, ""],
  [194638, 1, ""],
  [194639, 1, ""],
  [194640, 1, ""],
  [194641, 1, ""],
  [194642, 1, ""],
  [194643, 1, ""],
  [194644, 1, ""],
  [194645, 1, ""],
  [194646, 1, ""],
  [194647, 1, ""],
  [194648, 1, ""],
  [194649, 1, ""],
  [194650, 1, ""],
  [194651, 1, ""],
  [194652, 1, ""],
  [194653, 1, ""],
  [194654, 1, ""],
  [194655, 1, ""],
  [194656, 1, ""],
  [194657, 1, ""],
  [194658, 1, ""],
  [194659, 1, ""],
  [194660, 1, ""],
  [194661, 1, ""],
  [194662, 1, ""],
  [194663, 1, ""],
  [194664, 3],
  [194665, 1, ""],
  [[194666, 194667], 1, ""],
  [194668, 1, ""],
  [194669, 1, ""],
  [194670, 1, ""],
  [194671, 1, ""],
  [194672, 1, ""],
  [194673, 1, ""],
  [194674, 1, ""],
  [194675, 1, ""],
  [194676, 3],
  [194677, 1, ""],
  [194678, 1, ""],
  [194679, 1, ""],
  [194680, 1, ""],
  [194681, 1, ""],
  [194682, 1, ""],
  [194683, 1, ""],
  [194684, 1, ""],
  [194685, 1, ""],
  [194686, 1, ""],
  [194687, 1, ""],
  [194688, 1, ""],
  [194689, 1, ""],
  [194690, 1, ""],
  [194691, 1, ""],
  [194692, 1, ""],
  [194693, 1, ""],
  [194694, 1, ""],
  [194695, 1, ""],
  [194696, 1, ""],
  [194697, 1, ""],
  [194698, 1, ""],
  [194699, 1, ""],
  [194700, 1, ""],
  [194701, 1, ""],
  [194702, 1, ""],
  [194703, 1, ""],
  [194704, 1, ""],
  [[194705, 194706], 1, ""],
  [194707, 1, ""],
  [[194708, 194709], 1, ""],
  [194710, 1, ""],
  [194711, 1, ""],
  [194712, 1, ""],
  [194713, 1, ""],
  [194714, 1, ""],
  [194715, 1, ""],
  [194716, 1, ""],
  [194717, 1, ""],
  [194718, 1, ""],
  [194719, 1, ""],
  [194720, 1, ""],
  [194721, 1, ""],
  [194722, 1, ""],
  [194723, 1, ""],
  [194724, 1, ""],
  [194725, 1, ""],
  [194726, 1, ""],
  [194727, 1, ""],
  [194728, 1, ""],
  [194729, 1, ""],
  [194730, 1, ""],
  [194731, 1, ""],
  [194732, 1, ""],
  [194733, 1, ""],
  [194734, 1, ""],
  [194735, 1, ""],
  [194736, 1, ""],
  [194737, 1, ""],
  [194738, 1, ""],
  [194739, 1, ""],
  [194740, 1, ""],
  [194741, 1, ""],
  [194742, 1, ""],
  [194743, 1, ""],
  [194744, 1, ""],
  [194745, 1, ""],
  [194746, 1, ""],
  [194747, 1, ""],
  [194748, 1, ""],
  [194749, 1, ""],
  [194750, 1, ""],
  [194751, 1, ""],
  [194752, 1, ""],
  [194753, 1, ""],
  [194754, 1, ""],
  [194755, 1, ""],
  [194756, 1, ""],
  [194757, 1, ""],
  [194758, 1, ""],
  [194759, 1, ""],
  [194760, 1, ""],
  [194761, 1, ""],
  [194762, 1, ""],
  [194763, 1, ""],
  [194764, 1, ""],
  [194765, 1, ""],
  [194766, 1, ""],
  [194767, 1, ""],
  [194768, 1, ""],
  [194769, 1, ""],
  [194770, 1, ""],
  [194771, 1, ""],
  [194772, 1, ""],
  [194773, 1, ""],
  [194774, 1, ""],
  [194775, 1, ""],
  [194776, 1, ""],
  [194777, 1, ""],
  [194778, 1, ""],
  [194779, 1, ""],
  [194780, 1, ""],
  [194781, 1, ""],
  [194782, 1, ""],
  [194783, 1, ""],
  [194784, 1, ""],
  [194785, 1, ""],
  [194786, 1, ""],
  [194787, 1, ""],
  [194788, 1, ""],
  [194789, 1, ""],
  [194790, 1, ""],
  [194791, 1, ""],
  [194792, 1, ""],
  [194793, 1, ""],
  [194794, 1, ""],
  [194795, 1, ""],
  [194796, 1, ""],
  [194797, 1, ""],
  [194798, 1, ""],
  [194799, 1, ""],
  [194800, 1, ""],
  [194801, 1, ""],
  [194802, 1, ""],
  [194803, 1, ""],
  [194804, 1, ""],
  [194805, 1, ""],
  [194806, 1, ""],
  [194807, 1, ""],
  [194808, 1, ""],
  [194809, 1, ""],
  [194810, 1, ""],
  [194811, 1, ""],
  [194812, 1, ""],
  [194813, 1, ""],
  [194814, 1, ""],
  [194815, 1, ""],
  [194816, 1, ""],
  [194817, 1, ""],
  [194818, 1, ""],
  [194819, 1, ""],
  [194820, 1, ""],
  [194821, 1, ""],
  [194822, 1, ""],
  [194823, 1, ""],
  [194824, 1, ""],
  [194825, 1, ""],
  [194826, 1, ""],
  [194827, 1, ""],
  [194828, 1, ""],
  [194829, 1, ""],
  [194830, 1, ""],
  [194831, 1, ""],
  [194832, 1, ""],
  [194833, 1, ""],
  [194834, 1, ""],
  [194835, 1, ""],
  [194836, 1, ""],
  [194837, 1, ""],
  [194838, 1, ""],
  [194839, 1, ""],
  [194840, 1, ""],
  [194841, 1, ""],
  [194842, 1, ""],
  [194843, 1, ""],
  [194844, 1, ""],
  [194845, 1, ""],
  [194846, 1, ""],
  [194847, 3],
  [194848, 1, ""],
  [194849, 1, ""],
  [194850, 1, ""],
  [194851, 1, ""],
  [194852, 1, ""],
  [194853, 1, ""],
  [194854, 1, ""],
  [194855, 1, ""],
  [194856, 1, ""],
  [194857, 1, ""],
  [194858, 1, ""],
  [194859, 1, ""],
  [[194860, 194861], 1, ""],
  [194862, 1, ""],
  [194863, 1, ""],
  [194864, 1, ""],
  [194865, 1, ""],
  [194866, 1, ""],
  [194867, 1, ""],
  [194868, 1, ""],
  [194869, 1, ""],
  [194870, 1, ""],
  [194871, 1, ""],
  [194872, 1, ""],
  [194873, 1, ""],
  [194874, 1, ""],
  [194875, 1, ""],
  [194876, 1, ""],
  [194877, 1, ""],
  [194878, 1, ""],
  [194879, 1, ""],
  [194880, 1, ""],
  [194881, 1, ""],
  [194882, 1, ""],
  [194883, 1, ""],
  [194884, 1, ""],
  [194885, 1, ""],
  [[194886, 194887], 1, ""],
  [194888, 1, ""],
  [194889, 1, ""],
  [194890, 1, ""],
  [194891, 1, ""],
  [194892, 1, ""],
  [194893, 1, ""],
  [194894, 1, ""],
  [194895, 1, ""],
  [194896, 1, ""],
  [194897, 1, ""],
  [194898, 1, ""],
  [194899, 1, ""],
  [194900, 1, ""],
  [194901, 1, ""],
  [194902, 1, ""],
  [194903, 1, ""],
  [194904, 1, ""],
  [194905, 1, ""],
  [194906, 1, ""],
  [194907, 1, ""],
  [194908, 1, ""],
  [[194909, 194910], 1, ""],
  [194911, 3],
  [194912, 1, ""],
  [194913, 1, ""],
  [194914, 1, ""],
  [194915, 1, ""],
  [194916, 1, ""],
  [194917, 1, ""],
  [194918, 1, ""],
  [194919, 1, ""],
  [194920, 1, ""],
  [194921, 1, ""],
  [194922, 1, ""],
  [194923, 1, ""],
  [194924, 1, ""],
  [194925, 1, ""],
  [194926, 1, ""],
  [194927, 1, ""],
  [194928, 1, ""],
  [194929, 1, ""],
  [194930, 1, ""],
  [194931, 1, ""],
  [194932, 1, ""],
  [194933, 1, ""],
  [194934, 1, ""],
  [194935, 1, ""],
  [194936, 1, ""],
  [194937, 1, ""],
  [194938, 1, ""],
  [194939, 1, ""],
  [194940, 1, ""],
  [194941, 1, ""],
  [194942, 1, ""],
  [194943, 1, ""],
  [194944, 1, ""],
  [194945, 1, ""],
  [194946, 1, ""],
  [194947, 1, ""],
  [194948, 1, ""],
  [194949, 1, ""],
  [194950, 1, ""],
  [194951, 1, ""],
  [194952, 1, ""],
  [194953, 1, ""],
  [194954, 1, ""],
  [194955, 1, ""],
  [194956, 1, ""],
  [194957, 1, ""],
  [194958, 1, ""],
  [194959, 1, ""],
  [194960, 1, ""],
  [194961, 1, ""],
  [194962, 1, ""],
  [194963, 1, ""],
  [194964, 1, ""],
  [194965, 1, ""],
  [194966, 1, ""],
  [194967, 1, ""],
  [194968, 1, ""],
  [194969, 1, ""],
  [194970, 1, ""],
  [194971, 1, ""],
  [194972, 1, ""],
  [194973, 1, ""],
  [194974, 1, ""],
  [194975, 1, ""],
  [194976, 1, ""],
  [194977, 1, ""],
  [194978, 1, ""],
  [194979, 1, ""],
  [194980, 1, ""],
  [194981, 1, ""],
  [194982, 1, ""],
  [194983, 1, ""],
  [194984, 1, ""],
  [194985, 1, ""],
  [194986, 1, ""],
  [194987, 1, ""],
  [194988, 1, ""],
  [194989, 1, ""],
  [194990, 1, ""],
  [194991, 1, ""],
  [194992, 1, ""],
  [194993, 1, ""],
  [194994, 1, ""],
  [194995, 1, ""],
  [194996, 1, ""],
  [194997, 1, ""],
  [194998, 1, ""],
  [194999, 1, ""],
  [195000, 1, ""],
  [195001, 1, ""],
  [195002, 1, ""],
  [195003, 1, ""],
  [195004, 1, ""],
  [195005, 1, ""],
  [195006, 1, ""],
  [195007, 3],
  [195008, 1, ""],
  [195009, 1, ""],
  [195010, 1, ""],
  [195011, 1, ""],
  [195012, 1, ""],
  [195013, 1, ""],
  [195014, 1, ""],
  [195015, 1, ""],
  [195016, 1, ""],
  [195017, 1, ""],
  [195018, 1, ""],
  [195019, 1, ""],
  [195020, 1, ""],
  [195021, 1, ""],
  [195022, 1, ""],
  [195023, 1, ""],
  [195024, 1, ""],
  [195025, 1, ""],
  [195026, 1, ""],
  [195027, 1, ""],
  [195028, 1, ""],
  [195029, 1, ""],
  [195030, 1, ""],
  [195031, 1, ""],
  [195032, 1, ""],
  [195033, 1, ""],
  [195034, 1, ""],
  [195035, 1, ""],
  [195036, 1, ""],
  [195037, 1, ""],
  [195038, 1, ""],
  [195039, 1, ""],
  [195040, 1, ""],
  [195041, 1, ""],
  [195042, 1, ""],
  [195043, 1, ""],
  [195044, 1, ""],
  [195045, 1, ""],
  [195046, 1, ""],
  [195047, 1, ""],
  [195048, 1, ""],
  [195049, 1, ""],
  [195050, 1, ""],
  [195051, 1, ""],
  [195052, 1, ""],
  [195053, 1, ""],
  [195054, 1, ""],
  [195055, 1, ""],
  [195056, 1, ""],
  [195057, 1, ""],
  [195058, 1, ""],
  [195059, 1, ""],
  [195060, 1, ""],
  [195061, 1, ""],
  [195062, 1, ""],
  [195063, 1, ""],
  [195064, 1, ""],
  [195065, 1, ""],
  [195066, 1, ""],
  [195067, 1, ""],
  [195068, 1, ""],
  [195069, 1, ""],
  [[195070, 195071], 1, ""],
  [195072, 1, ""],
  [195073, 1, ""],
  [195074, 1, ""],
  [195075, 1, ""],
  [195076, 1, ""],
  [195077, 1, ""],
  [195078, 1, ""],
  [195079, 1, ""],
  [195080, 1, ""],
  [195081, 1, ""],
  [195082, 1, ""],
  [195083, 1, ""],
  [195084, 1, ""],
  [195085, 1, ""],
  [195086, 1, ""],
  [195087, 1, ""],
  [195088, 1, ""],
  [195089, 1, ""],
  [195090, 1, ""],
  [195091, 1, ""],
  [195092, 1, ""],
  [195093, 1, ""],
  [195094, 1, ""],
  [195095, 1, ""],
  [195096, 1, ""],
  [195097, 1, ""],
  [195098, 1, ""],
  [195099, 1, ""],
  [195100, 1, ""],
  [195101, 1, ""],
  [[195102, 196605], 3],
  [[196606, 196607], 3],
  [[196608, 201546], 2],
  [[201547, 262141], 3],
  [[262142, 262143], 3],
  [[262144, 327677], 3],
  [[327678, 327679], 3],
  [[327680, 393213], 3],
  [[393214, 393215], 3],
  [[393216, 458749], 3],
  [[458750, 458751], 3],
  [[458752, 524285], 3],
  [[524286, 524287], 3],
  [[524288, 589821], 3],
  [[589822, 589823], 3],
  [[589824, 655357], 3],
  [[655358, 655359], 3],
  [[655360, 720893], 3],
  [[720894, 720895], 3],
  [[720896, 786429], 3],
  [[786430, 786431], 3],
  [[786432, 851965], 3],
  [[851966, 851967], 3],
  [[851968, 917501], 3],
  [[917502, 917503], 3],
  [917504, 3],
  [917505, 3],
  [[917506, 917535], 3],
  [[917536, 917631], 3],
  [[917632, 917759], 3],
  [[917760, 917999], 7],
  [[918000, 983037], 3],
  [[983038, 983039], 3],
  [[983040, 1048573], 3],
  [[1048574, 1048575], 3],
  [[1048576, 1114109], 3],
  [[1114110, 1114111], 3],
];

var statusMapping = {};

var hasRequiredStatusMapping;

function requireStatusMapping() {
  if (hasRequiredStatusMapping) return statusMapping;
  hasRequiredStatusMapping = 1;

  statusMapping.STATUS_MAPPING = {
    mapped: 1,
    valid: 2,
    disallowed: 3,
    disallowed_STD3_valid: 4,
    disallowed_STD3_mapped: 5,
    deviation: 6,
    ignored: 7,
  };
  return statusMapping;
}

var tr46;
var hasRequiredTr46;

function requireTr46() {
  if (hasRequiredTr46) return tr46;
  hasRequiredTr46 = 1;

  const punycode = $nodePunycode;
  const regexes = requireRegexes();
  const mappingTable = require$$2;
  const { STATUS_MAPPING } = requireStatusMapping();

  function containsNonASCII(str) {
    return /[^\x00-\x7F]/u.test(str);
  }

  function findStatus(val, { useSTD3ASCIIRules }) {
    let start = 0;
    let end = mappingTable.length - 1;

    while (start <= end) {
      const mid = Math.floor((start + end) / 2);

      const target = mappingTable[mid];
      const min = Array.isArray(target[0]) ? target[0][0] : target[0];
      const max = Array.isArray(target[0]) ? target[0][1] : target[0];

      if (min <= val && max >= val) {
        if (
          useSTD3ASCIIRules &&
          (target[1] === STATUS_MAPPING.disallowed_STD3_valid ||
            target[1] === STATUS_MAPPING.disallowed_STD3_mapped)
        ) {
          return [STATUS_MAPPING.disallowed, ...target.slice(2)];
        } else if (target[1] === STATUS_MAPPING.disallowed_STD3_valid) {
          return [STATUS_MAPPING.valid, ...target.slice(2)];
        } else if (target[1] === STATUS_MAPPING.disallowed_STD3_mapped) {
          return [STATUS_MAPPING.mapped, ...target.slice(2)];
        }

        return target.slice(1);
      } else if (min > val) {
        end = mid - 1;
      } else {
        start = mid + 1;
      }
    }

    return null;
  }

  function mapChars(domainName, { useSTD3ASCIIRules, processingOption }) {
    let hasError = false;
    let processed = "";

    for (const ch of domainName) {
      const [status, mapping] = findStatus(ch.codePointAt(0), {
        useSTD3ASCIIRules,
      });

      switch (status) {
        case STATUS_MAPPING.disallowed:
          hasError = true;
          processed += ch;
          break;
        case STATUS_MAPPING.ignored:
          break;
        case STATUS_MAPPING.mapped:
          processed += mapping;
          break;
        case STATUS_MAPPING.deviation:
          if (processingOption === "transitional") {
            processed += mapping;
          } else {
            processed += ch;
          }
          break;
        case STATUS_MAPPING.valid:
          processed += ch;
          break;
      }
    }

    return {
      string: processed,
      error: hasError,
    };
  }

  function validateLabel(
    label,
    {
      checkHyphens,
      checkBidi,
      checkJoiners,
      processingOption,
      useSTD3ASCIIRules,
    },
  ) {
    if (label.normalize("NFC") !== label) {
      return false;
    }

    const codePoints = Array.from(label);

    if (checkHyphens) {
      if (
        (codePoints[2] === "-" && codePoints[3] === "-") ||
        label.startsWith("-") ||
        label.endsWith("-")
      ) {
        return false;
      }
    }

    if (
      label.includes(".") ||
      (codePoints.length > 0 && regexes.combiningMarks.test(codePoints[0]))
    ) {
      return false;
    }

    for (const ch of codePoints) {
      const [status] = findStatus(ch.codePointAt(0), { useSTD3ASCIIRules });
      if (
        (processingOption === "transitional" &&
          status !== STATUS_MAPPING.valid) ||
        (processingOption === "nontransitional" &&
          status !== STATUS_MAPPING.valid &&
          status !== STATUS_MAPPING.deviation)
      ) {
        return false;
      }
    }

    // https://tools.ietf.org/html/rfc5892#appendix-A
    if (checkJoiners) {
      let last = 0;
      for (const [i, ch] of codePoints.entries()) {
        if (ch === "\u200C" || ch === "\u200D") {
          if (i > 0) {
            if (regexes.combiningClassVirama.test(codePoints[i - 1])) {
              continue;
            }
            if (ch === "\u200C") {
              // TODO: make this more efficient
              const next = codePoints.indexOf("\u200C", i + 1);
              const test =
                next < 0
                  ? codePoints.slice(last)
                  : codePoints.slice(last, next);
              if (regexes.validZWNJ.test(test.join(""))) {
                last = i + 1;
                continue;
              }
            }
          }
          return false;
        }
      }
    }

    // https://tools.ietf.org/html/rfc5893#section-2
    if (checkBidi) {
      let rtl;

      // 1
      if (regexes.bidiS1LTR.test(codePoints[0])) {
        rtl = false;
      } else if (regexes.bidiS1RTL.test(codePoints[0])) {
        rtl = true;
      } else {
        return false;
      }

      if (rtl) {
        // 2-4
        if (
          !regexes.bidiS2.test(label) ||
          !regexes.bidiS3.test(label) ||
          (regexes.bidiS4EN.test(label) && regexes.bidiS4AN.test(label))
        ) {
          return false;
        }
      } else if (!regexes.bidiS5.test(label) || !regexes.bidiS6.test(label)) {
        // 5-6
        return false;
      }
    }

    return true;
  }

  function isBidiDomain(labels) {
    const domain = labels
      .map((label) => {
        if (label.startsWith("xn--")) {
          try {
            return punycode.decode(label.substring(4));
          } catch (err) {
            return "";
          }
        }
        return label;
      })
      .join(".");
    return regexes.bidiDomain.test(domain);
  }

  function processing(domainName, options) {
    const { processingOption } = options;

    // 1. Map.
    let { string, error } = mapChars(domainName, options);

    // 2. Normalize.
    string = string.normalize("NFC");

    // 3. Break.
    const labels = string.split(".");
    const isBidi = isBidiDomain(labels);

    // 4. Convert/Validate.
    for (const [i, origLabel] of labels.entries()) {
      let label = origLabel;
      let curProcessing = processingOption;
      if (label.startsWith("xn--")) {
        try {
          label = punycode.decode(label.substring(4));
          labels[i] = label;
        } catch (err) {
          error = true;
          continue;
        }
        curProcessing = "nontransitional";
      }

      // No need to validate if we already know there is an error.
      if (error) {
        continue;
      }
      const validation = validateLabel(label, {
        ...options,
        processingOption: curProcessing,
        checkBidi: options.checkBidi && isBidi,
      });
      if (!validation) {
        error = true;
      }
    }

    return {
      string: labels.join("."),
      error,
    };
  }

  function toASCII(
    domainName,
    {
      checkHyphens = false,
      checkBidi = false,
      checkJoiners = false,
      useSTD3ASCIIRules = false,
      processingOption = "nontransitional",
      verifyDNSLength = false,
    } = {},
  ) {
    if (
      processingOption !== "transitional" &&
      processingOption !== "nontransitional"
    ) {
      throw new RangeError(
        "processingOption must be either transitional or nontransitional",
      );
    }

    const result = processing(domainName, {
      processingOption,
      checkHyphens,
      checkBidi,
      checkJoiners,
      useSTD3ASCIIRules,
    });
    let labels = result.string.split(".");
    labels = labels.map((l) => {
      if (containsNonASCII(l)) {
        try {
          return `xn--${punycode.encode(l)}`;
        } catch (e) {
          result.error = true;
        }
      }
      return l;
    });

    if (verifyDNSLength) {
      const total = labels.join(".").length;
      if (total > 253 || total === 0) {
        result.error = true;
      }

      for (let i = 0; i < labels.length; ++i) {
        if (labels[i].length > 63 || labels[i].length === 0) {
          result.error = true;
          break;
        }
      }
    }

    if (result.error) {
      return null;
    }
    return labels.join(".");
  }

  function toUnicode(
    domainName,
    {
      checkHyphens = false,
      checkBidi = false,
      checkJoiners = false,
      useSTD3ASCIIRules = false,
      processingOption = "nontransitional",
    } = {},
  ) {
    const result = processing(domainName, {
      processingOption,
      checkHyphens,
      checkBidi,
      checkJoiners,
      useSTD3ASCIIRules,
    });

    return {
      domain: result.string,
      error: result.error,
    };
  }

  tr46 = {
    toASCII,
    toUnicode,
  };
  return tr46;
}

var infra;
var hasRequiredInfra;

function requireInfra() {
  if (hasRequiredInfra) return infra;
  hasRequiredInfra = 1;

  // Note that we take code points as JS numbers, not JS strings.

  function isASCIIDigit(c) {
    return c >= 0x30 && c <= 0x39;
  }

  function isASCIIAlpha(c) {
    return (c >= 0x41 && c <= 0x5a) || (c >= 0x61 && c <= 0x7a);
  }

  function isASCIIAlphanumeric(c) {
    return isASCIIAlpha(c) || isASCIIDigit(c);
  }

  function isASCIIHex(c) {
    return (
      isASCIIDigit(c) || (c >= 0x41 && c <= 0x46) || (c >= 0x61 && c <= 0x66)
    );
  }

  infra = {
    isASCIIDigit,
    isASCIIAlpha,
    isASCIIAlphanumeric,
    isASCIIHex,
  };
  return infra;
}

var encoding;
var hasRequiredEncoding;

function requireEncoding() {
  if (hasRequiredEncoding) return encoding;
  hasRequiredEncoding = 1;
  const utf8Encoder = new TextEncoder();
  const utf8Decoder = new TextDecoder("utf-8", { ignoreBOM: true });

  function utf8Encode(string) {
    return utf8Encoder.encode(string);
  }

  function utf8DecodeWithoutBOM(bytes) {
    return utf8Decoder.decode(bytes);
  }

  encoding = {
    utf8Encode,
    utf8DecodeWithoutBOM,
  };
  return encoding;
}

var percentEncoding;
var hasRequiredPercentEncoding;

function requirePercentEncoding() {
  if (hasRequiredPercentEncoding) return percentEncoding;
  hasRequiredPercentEncoding = 1;
  const { isASCIIHex } = requireInfra();
  const { utf8Encode } = requireEncoding();

  function p(char) {
    return char.codePointAt(0);
  }

  // https://url.spec.whatwg.org/#percent-encode
  function percentEncode(c) {
    let hex = c.toString(16).toUpperCase();
    if (hex.length === 1) {
      hex = `0${hex}`;
    }

    return `%${hex}`;
  }

  // https://url.spec.whatwg.org/#percent-decode
  function percentDecodeBytes(input) {
    const output = new Uint8Array(input.byteLength);
    let outputIndex = 0;
    for (let i = 0; i < input.byteLength; ++i) {
      const byte = input[i];
      if (byte !== 0x25) {
        output[outputIndex++] = byte;
      } else if (
        byte === 0x25 &&
        (!isASCIIHex(input[i + 1]) || !isASCIIHex(input[i + 2]))
      ) {
        output[outputIndex++] = byte;
      } else {
        const bytePoint = parseInt(
          String.fromCodePoint(input[i + 1], input[i + 2]),
          16,
        );
        output[outputIndex++] = bytePoint;
        i += 2;
      }
    }

    return output.slice(0, outputIndex);
  }

  // https://url.spec.whatwg.org/#string-percent-decode
  function percentDecodeString(input) {
    const bytes = utf8Encode(input);
    return percentDecodeBytes(bytes);
  }

  // https://url.spec.whatwg.org/#c0-control-percent-encode-set
  function isC0ControlPercentEncode(c) {
    return c <= 0x1f || c > 0x7e;
  }

  // https://url.spec.whatwg.org/#fragment-percent-encode-set
  const extraFragmentPercentEncodeSet = new Set([
    p(" "),
    p('"'),
    p("<"),
    p(">"),
    p("`"),
  ]);
  function isFragmentPercentEncode(c) {
    return isC0ControlPercentEncode(c) || extraFragmentPercentEncodeSet.has(c);
  }

  // https://url.spec.whatwg.org/#query-percent-encode-set
  const extraQueryPercentEncodeSet = new Set([
    p(" "),
    p('"'),
    p("#"),
    p("<"),
    p(">"),
  ]);
  function isQueryPercentEncode(c) {
    return isC0ControlPercentEncode(c) || extraQueryPercentEncodeSet.has(c);
  }

  // https://url.spec.whatwg.org/#special-query-percent-encode-set
  function isSpecialQueryPercentEncode(c) {
    return isQueryPercentEncode(c) || c === p("'");
  }

  // https://url.spec.whatwg.org/#path-percent-encode-set
  const extraPathPercentEncodeSet = new Set([p("?"), p("`"), p("{"), p("}")]);
  function isPathPercentEncode(c) {
    return isQueryPercentEncode(c) || extraPathPercentEncodeSet.has(c);
  }

  // https://url.spec.whatwg.org/#userinfo-percent-encode-set
  const extraUserinfoPercentEncodeSet = new Set([
    p("/"),
    p(":"),
    p(";"),
    p("="),
    p("@"),
    p("["),
    p("\\"),
    p("]"),
    p("^"),
    p("|"),
  ]);
  function isUserinfoPercentEncode(c) {
    return isPathPercentEncode(c) || extraUserinfoPercentEncodeSet.has(c);
  }

  // https://url.spec.whatwg.org/#component-percent-encode-set
  const extraComponentPercentEncodeSet = new Set([
    p("$"),
    p("%"),
    p("&"),
    p("+"),
    p(","),
  ]);
  function isComponentPercentEncode(c) {
    return isUserinfoPercentEncode(c) || extraComponentPercentEncodeSet.has(c);
  }

  // https://url.spec.whatwg.org/#application-x-www-form-urlencoded-percent-encode-set
  const extraURLEncodedPercentEncodeSet = new Set([
    p("!"),
    p("'"),
    p("("),
    p(")"),
    p("~"),
  ]);
  function isURLEncodedPercentEncode(c) {
    return (
      isComponentPercentEncode(c) || extraURLEncodedPercentEncodeSet.has(c)
    );
  }

  // https://url.spec.whatwg.org/#code-point-percent-encode-after-encoding
  // https://url.spec.whatwg.org/#utf-8-percent-encode
  // Assuming encoding is always utf-8 allows us to trim one of the logic branches. TODO: support encoding.
  // The "-Internal" variant here has code points as JS strings. The external version used by other files has code points
  // as JS numbers, like the rest of the codebase.
  function utf8PercentEncodeCodePointInternal(
    codePoint,
    percentEncodePredicate,
  ) {
    const bytes = utf8Encode(codePoint);
    let output = "";
    for (const byte of bytes) {
      // Our percentEncodePredicate operates on bytes, not code points, so this is slightly different from the spec.
      if (!percentEncodePredicate(byte)) {
        output += String.fromCharCode(byte);
      } else {
        output += percentEncode(byte);
      }
    }

    return output;
  }

  function utf8PercentEncodeCodePoint(codePoint, percentEncodePredicate) {
    return utf8PercentEncodeCodePointInternal(
      String.fromCodePoint(codePoint),
      percentEncodePredicate,
    );
  }

  // https://url.spec.whatwg.org/#string-percent-encode-after-encoding
  // https://url.spec.whatwg.org/#string-utf-8-percent-encode
  function utf8PercentEncodeString(
    input,
    percentEncodePredicate,
    spaceAsPlus = false,
  ) {
    let output = "";
    for (const codePoint of input) {
      if (spaceAsPlus && codePoint === " ") {
        output += "+";
      } else {
        output += utf8PercentEncodeCodePointInternal(
          codePoint,
          percentEncodePredicate,
        );
      }
    }
    return output;
  }

  percentEncoding = {
    isC0ControlPercentEncode,
    isFragmentPercentEncode,
    isQueryPercentEncode,
    isSpecialQueryPercentEncode,
    isPathPercentEncode,
    isUserinfoPercentEncode,
    isURLEncodedPercentEncode,
    percentDecodeString,
    percentDecodeBytes,
    utf8PercentEncodeString,
    utf8PercentEncodeCodePoint,
  };
  return percentEncoding;
}

var hasRequiredUrlStateMachine;

function requireUrlStateMachine() {
  if (hasRequiredUrlStateMachine) return urlStateMachine.exports;
  hasRequiredUrlStateMachine = 1;
  (function (module) {
    const tr46 = requireTr46();

    const infra = requireInfra();
    const { utf8DecodeWithoutBOM } = requireEncoding();
    const {
      percentDecodeString,
      utf8PercentEncodeCodePoint,
      utf8PercentEncodeString,
      isC0ControlPercentEncode,
      isFragmentPercentEncode,
      isQueryPercentEncode,
      isSpecialQueryPercentEncode,
      isPathPercentEncode,
      isUserinfoPercentEncode,
    } = requirePercentEncoding();

    function p(char) {
      return char.codePointAt(0);
    }

    const specialSchemes = {
      ftp: 21,
      file: null,
      http: 80,
      https: 443,
      ws: 80,
      wss: 443,
    };

    const failure = Symbol("failure");

    function countSymbols(str) {
      return [...str].length;
    }

    function at(input, idx) {
      const c = input[idx];
      return isNaN(c) ? undefined : String.fromCodePoint(c);
    }

    function isSingleDot(buffer) {
      return buffer === "." || buffer.toLowerCase() === "%2e";
    }

    function isDoubleDot(buffer) {
      buffer = buffer.toLowerCase();
      return (
        buffer === ".." ||
        buffer === "%2e." ||
        buffer === ".%2e" ||
        buffer === "%2e%2e"
      );
    }

    function isWindowsDriveLetterCodePoints(cp1, cp2) {
      return infra.isASCIIAlpha(cp1) && (cp2 === p(":") || cp2 === p("|"));
    }

    function isWindowsDriveLetterString(string) {
      return (
        string.length === 2 &&
        infra.isASCIIAlpha(string.codePointAt(0)) &&
        (string[1] === ":" || string[1] === "|")
      );
    }

    function isNormalizedWindowsDriveLetterString(string) {
      return (
        string.length === 2 &&
        infra.isASCIIAlpha(string.codePointAt(0)) &&
        string[1] === ":"
      );
    }

    function containsForbiddenHostCodePoint(string) {
      return (
        string.search(
          /\u0000|\u0009|\u000A|\u000D|\u0020|#|%|\/|:|<|>|\?|@|\[|\\|\]|\^|\|/u,
        ) !== -1
      );
    }

    function containsForbiddenHostCodePointExcludingPercent(string) {
      return (
        string.search(
          /\u0000|\u0009|\u000A|\u000D|\u0020|#|\/|:|<|>|\?|@|\[|\\|\]|\^|\|/u,
        ) !== -1
      );
    }

    function isSpecialScheme(scheme) {
      return specialSchemes[scheme] !== undefined;
    }

    function isSpecial(url) {
      return isSpecialScheme(url.scheme);
    }

    function isNotSpecial(url) {
      return !isSpecialScheme(url.scheme);
    }

    function defaultPort(scheme) {
      return specialSchemes[scheme];
    }

    function parseIPv4Number(input) {
      if (input === "") {
        return failure;
      }

      let R = 10;

      if (
        input.length >= 2 &&
        input.charAt(0) === "0" &&
        input.charAt(1).toLowerCase() === "x"
      ) {
        input = input.substring(2);
        R = 16;
      } else if (input.length >= 2 && input.charAt(0) === "0") {
        input = input.substring(1);
        R = 8;
      }

      if (input === "") {
        return 0;
      }

      let regex = /[^0-7]/u;
      if (R === 10) {
        regex = /[^0-9]/u;
      }
      if (R === 16) {
        regex = /[^0-9A-Fa-f]/u;
      }

      if (regex.test(input)) {
        return failure;
      }

      return parseInt(input, R);
    }

    function parseIPv4(input) {
      const parts = input.split(".");
      if (parts[parts.length - 1] === "") {
        if (parts.length > 1) {
          parts.pop();
        }
      }

      if (parts.length > 4) {
        return failure;
      }

      const numbers = [];
      for (const part of parts) {
        const n = parseIPv4Number(part);
        if (n === failure) {
          return failure;
        }

        numbers.push(n);
      }

      for (let i = 0; i < numbers.length - 1; ++i) {
        if (numbers[i] > 255) {
          return failure;
        }
      }
      if (numbers[numbers.length - 1] >= 256 ** (5 - numbers.length)) {
        return failure;
      }

      let ipv4 = numbers.pop();
      let counter = 0;

      for (const n of numbers) {
        ipv4 += n * 256 ** (3 - counter);
        ++counter;
      }

      return ipv4;
    }

    function serializeIPv4(address) {
      let output = "";
      let n = address;

      for (let i = 1; i <= 4; ++i) {
        output = String(n % 256) + output;
        if (i !== 4) {
          output = `.${output}`;
        }
        n = Math.floor(n / 256);
      }

      return output;
    }

    function parseIPv6(input) {
      const address = [0, 0, 0, 0, 0, 0, 0, 0];
      let pieceIndex = 0;
      let compress = null;
      let pointer = 0;

      input = Array.from(input, (c) => c.codePointAt(0));

      if (input[pointer] === p(":")) {
        if (input[pointer + 1] !== p(":")) {
          return failure;
        }

        pointer += 2;
        ++pieceIndex;
        compress = pieceIndex;
      }

      while (pointer < input.length) {
        if (pieceIndex === 8) {
          return failure;
        }

        if (input[pointer] === p(":")) {
          if (compress !== null) {
            return failure;
          }
          ++pointer;
          ++pieceIndex;
          compress = pieceIndex;
          continue;
        }

        let value = 0;
        let length = 0;

        while (length < 4 && infra.isASCIIHex(input[pointer])) {
          value = value * 0x10 + parseInt(at(input, pointer), 16);
          ++pointer;
          ++length;
        }

        if (input[pointer] === p(".")) {
          if (length === 0) {
            return failure;
          }

          pointer -= length;

          if (pieceIndex > 6) {
            return failure;
          }

          let numbersSeen = 0;

          while (input[pointer] !== undefined) {
            let ipv4Piece = null;

            if (numbersSeen > 0) {
              if (input[pointer] === p(".") && numbersSeen < 4) {
                ++pointer;
              } else {
                return failure;
              }
            }

            if (!infra.isASCIIDigit(input[pointer])) {
              return failure;
            }

            while (infra.isASCIIDigit(input[pointer])) {
              const number = parseInt(at(input, pointer));
              if (ipv4Piece === null) {
                ipv4Piece = number;
              } else if (ipv4Piece === 0) {
                return failure;
              } else {
                ipv4Piece = ipv4Piece * 10 + number;
              }
              if (ipv4Piece > 255) {
                return failure;
              }
              ++pointer;
            }

            address[pieceIndex] = address[pieceIndex] * 0x100 + ipv4Piece;

            ++numbersSeen;

            if (numbersSeen === 2 || numbersSeen === 4) {
              ++pieceIndex;
            }
          }

          if (numbersSeen !== 4) {
            return failure;
          }

          break;
        } else if (input[pointer] === p(":")) {
          ++pointer;
          if (input[pointer] === undefined) {
            return failure;
          }
        } else if (input[pointer] !== undefined) {
          return failure;
        }

        address[pieceIndex] = value;
        ++pieceIndex;
      }

      if (compress !== null) {
        let swaps = pieceIndex - compress;
        pieceIndex = 7;
        while (pieceIndex !== 0 && swaps > 0) {
          const temp = address[compress + swaps - 1];
          address[compress + swaps - 1] = address[pieceIndex];
          address[pieceIndex] = temp;
          --pieceIndex;
          --swaps;
        }
      } else if (compress === null && pieceIndex !== 8) {
        return failure;
      }

      return address;
    }

    function serializeIPv6(address) {
      let output = "";
      const compress = findLongestZeroSequence(address);
      let ignore0 = false;

      for (let pieceIndex = 0; pieceIndex <= 7; ++pieceIndex) {
        if (ignore0 && address[pieceIndex] === 0) {
          continue;
        } else if (ignore0) {
          ignore0 = false;
        }

        if (compress === pieceIndex) {
          const separator = pieceIndex === 0 ? "::" : ":";
          output += separator;
          ignore0 = true;
          continue;
        }

        output += address[pieceIndex].toString(16);

        if (pieceIndex !== 7) {
          output += ":";
        }
      }

      return output;
    }

    function parseHost(input, isNotSpecialArg = false) {
      if (input[0] === "[") {
        if (input[input.length - 1] !== "]") {
          return failure;
        }

        return parseIPv6(input.substring(1, input.length - 1));
      }

      if (isNotSpecialArg) {
        return parseOpaqueHost(input);
      }

      const domain = utf8DecodeWithoutBOM(percentDecodeString(input));
      const asciiDomain = domainToASCII(domain);
      if (asciiDomain === failure) {
        return failure;
      }

      if (containsForbiddenHostCodePoint(asciiDomain)) {
        return failure;
      }

      if (endsInANumber(asciiDomain)) {
        return parseIPv4(asciiDomain);
      }

      return asciiDomain;
    }

    function endsInANumber(input) {
      const parts = input.split(".");
      if (parts[parts.length - 1] === "") {
        if (parts.length === 1) {
          return false;
        }
        parts.pop();
      }

      const last = parts[parts.length - 1];
      if (parseIPv4Number(last) !== failure) {
        return true;
      }

      if (/^[0-9]+$/u.test(last)) {
        return true;
      }

      return false;
    }

    function parseOpaqueHost(input) {
      if (containsForbiddenHostCodePointExcludingPercent(input)) {
        return failure;
      }

      return utf8PercentEncodeString(input, isC0ControlPercentEncode);
    }

    function findLongestZeroSequence(arr) {
      let maxIdx = null;
      let maxLen = 1; // only find elements > 1
      let currStart = null;
      let currLen = 0;

      for (let i = 0; i < arr.length; ++i) {
        if (arr[i] !== 0) {
          if (currLen > maxLen) {
            maxIdx = currStart;
            maxLen = currLen;
          }

          currStart = null;
          currLen = 0;
        } else {
          if (currStart === null) {
            currStart = i;
          }
          ++currLen;
        }
      }

      // if trailing zeros
      if (currLen > maxLen) {
        return currStart;
      }

      return maxIdx;
    }

    function serializeHost(host) {
      if (typeof host === "number") {
        return serializeIPv4(host);
      }

      // IPv6 serializer
      if (host instanceof Array) {
        return `[${serializeIPv6(host)}]`;
      }

      return host;
    }

    function domainToASCII(domain, beStrict = false) {
      const result = tr46.toASCII(domain, {
        checkBidi: true,
        checkHyphens: false,
        checkJoiners: true,
        useSTD3ASCIIRules: beStrict,
        verifyDNSLength: beStrict,
      });
      if (result === null || result === "") {
        return failure;
      }
      return result;
    }

    function trimControlChars(url) {
      return url.replace(
        /^[\u0000-\u001F\u0020]+|[\u0000-\u001F\u0020]+$/gu,
        "",
      );
    }

    function trimTabAndNewline(url) {
      return url.replace(/\u0009|\u000A|\u000D/gu, "");
    }

    function shortenPath(url) {
      const { path } = url;
      if (path.length === 0) {
        return;
      }
      if (
        url.scheme === "file" &&
        path.length === 1 &&
        isNormalizedWindowsDriveLetter(path[0])
      ) {
        return;
      }

      path.pop();
    }

    function includesCredentials(url) {
      return url.username !== "" || url.password !== "";
    }

    function cannotHaveAUsernamePasswordPort(url) {
      return (
        url.host === null ||
        url.host === "" ||
        hasAnOpaquePath(url) ||
        url.scheme === "file"
      );
    }

    function hasAnOpaquePath(url) {
      return typeof url.path === "string";
    }

    function isNormalizedWindowsDriveLetter(string) {
      return /^[A-Za-z]:$/u.test(string);
    }

    function URLStateMachine(
      input,
      base,
      encodingOverride,
      url,
      stateOverride,
    ) {
      this.pointer = 0;
      this.input = input;
      this.base = base || null;
      this.encodingOverride = encodingOverride || "utf-8";
      this.stateOverride = stateOverride;
      this.url = url;
      this.failure = false;
      this.parseError = false;

      if (!this.url) {
        this.url = {
          scheme: "",
          username: "",
          password: "",
          host: null,
          port: null,
          path: [],
          query: null,
          fragment: null,
        };

        const res = trimControlChars(this.input);
        if (res !== this.input) {
          this.parseError = true;
        }
        this.input = res;
      }

      const res = trimTabAndNewline(this.input);
      if (res !== this.input) {
        this.parseError = true;
      }
      this.input = res;

      this.state = stateOverride || "scheme start";

      this.buffer = "";
      this.atFlag = false;
      this.arrFlag = false;
      this.passwordTokenSeenFlag = false;

      this.input = Array.from(this.input, (c) => c.codePointAt(0));

      for (; this.pointer <= this.input.length; ++this.pointer) {
        const c = this.input[this.pointer];
        const cStr = isNaN(c) ? undefined : String.fromCodePoint(c);

        // exec state machine
        const ret = this[`parse ${this.state}`](c, cStr);
        if (!ret) {
          break; // terminate algorithm
        } else if (ret === failure) {
          this.failure = true;
          break;
        }
      }
    }

    URLStateMachine.prototype["parse scheme start"] = function parseSchemeStart(
      c,
      cStr,
    ) {
      if (infra.isASCIIAlpha(c)) {
        this.buffer += cStr.toLowerCase();
        this.state = "scheme";
      } else if (!this.stateOverride) {
        this.state = "no scheme";
        --this.pointer;
      } else {
        this.parseError = true;
        return failure;
      }

      return true;
    };

    URLStateMachine.prototype["parse scheme"] = function parseScheme(c, cStr) {
      if (
        infra.isASCIIAlphanumeric(c) ||
        c === p("+") ||
        c === p("-") ||
        c === p(".")
      ) {
        this.buffer += cStr.toLowerCase();
      } else if (c === p(":")) {
        if (this.stateOverride) {
          if (isSpecial(this.url) && !isSpecialScheme(this.buffer)) {
            return false;
          }

          if (!isSpecial(this.url) && isSpecialScheme(this.buffer)) {
            return false;
          }

          if (
            (includesCredentials(this.url) || this.url.port !== null) &&
            this.buffer === "file"
          ) {
            return false;
          }

          if (this.url.scheme === "file" && this.url.host === "") {
            return false;
          }
        }
        this.url.scheme = this.buffer;
        if (this.stateOverride) {
          if (this.url.port === defaultPort(this.url.scheme)) {
            this.url.port = null;
          }
          return false;
        }
        this.buffer = "";
        if (this.url.scheme === "file") {
          if (
            this.input[this.pointer + 1] !== p("/") ||
            this.input[this.pointer + 2] !== p("/")
          ) {
            this.parseError = true;
          }
          this.state = "file";
        } else if (
          isSpecial(this.url) &&
          this.base !== null &&
          this.base.scheme === this.url.scheme
        ) {
          this.state = "special relative or authority";
        } else if (isSpecial(this.url)) {
          this.state = "special authority slashes";
        } else if (this.input[this.pointer + 1] === p("/")) {
          this.state = "path or authority";
          ++this.pointer;
        } else {
          this.url.path = "";
          this.state = "opaque path";
        }
      } else if (!this.stateOverride) {
        this.buffer = "";
        this.state = "no scheme";
        this.pointer = -1;
      } else {
        this.parseError = true;
        return failure;
      }

      return true;
    };

    URLStateMachine.prototype["parse no scheme"] = function parseNoScheme(c) {
      if (this.base === null || (hasAnOpaquePath(this.base) && c !== p("#"))) {
        return failure;
      } else if (hasAnOpaquePath(this.base) && c === p("#")) {
        this.url.scheme = this.base.scheme;
        this.url.path = this.base.path;
        this.url.query = this.base.query;
        this.url.fragment = "";
        this.state = "fragment";
      } else if (this.base.scheme === "file") {
        this.state = "file";
        --this.pointer;
      } else {
        this.state = "relative";
        --this.pointer;
      }

      return true;
    };

    URLStateMachine.prototype["parse special relative or authority"] =
      function parseSpecialRelativeOrAuthority(c) {
        if (c === p("/") && this.input[this.pointer + 1] === p("/")) {
          this.state = "special authority ignore slashes";
          ++this.pointer;
        } else {
          this.parseError = true;
          this.state = "relative";
          --this.pointer;
        }

        return true;
      };

    URLStateMachine.prototype["parse path or authority"] =
      function parsePathOrAuthority(c) {
        if (c === p("/")) {
          this.state = "authority";
        } else {
          this.state = "path";
          --this.pointer;
        }

        return true;
      };

    URLStateMachine.prototype["parse relative"] = function parseRelative(c) {
      this.url.scheme = this.base.scheme;
      if (c === p("/")) {
        this.state = "relative slash";
      } else if (isSpecial(this.url) && c === p("\\")) {
        this.parseError = true;
        this.state = "relative slash";
      } else {
        this.url.username = this.base.username;
        this.url.password = this.base.password;
        this.url.host = this.base.host;
        this.url.port = this.base.port;
        this.url.path = this.base.path.slice();
        this.url.query = this.base.query;
        if (c === p("?")) {
          this.url.query = "";
          this.state = "query";
        } else if (c === p("#")) {
          this.url.fragment = "";
          this.state = "fragment";
        } else if (!isNaN(c)) {
          this.url.query = null;
          this.url.path.pop();
          this.state = "path";
          --this.pointer;
        }
      }

      return true;
    };

    URLStateMachine.prototype["parse relative slash"] =
      function parseRelativeSlash(c) {
        if (isSpecial(this.url) && (c === p("/") || c === p("\\"))) {
          if (c === p("\\")) {
            this.parseError = true;
          }
          this.state = "special authority ignore slashes";
        } else if (c === p("/")) {
          this.state = "authority";
        } else {
          this.url.username = this.base.username;
          this.url.password = this.base.password;
          this.url.host = this.base.host;
          this.url.port = this.base.port;
          this.state = "path";
          --this.pointer;
        }

        return true;
      };

    URLStateMachine.prototype["parse special authority slashes"] =
      function parseSpecialAuthoritySlashes(c) {
        if (c === p("/") && this.input[this.pointer + 1] === p("/")) {
          this.state = "special authority ignore slashes";
          ++this.pointer;
        } else {
          this.parseError = true;
          this.state = "special authority ignore slashes";
          --this.pointer;
        }

        return true;
      };

    URLStateMachine.prototype["parse special authority ignore slashes"] =
      function parseSpecialAuthorityIgnoreSlashes(c) {
        if (c !== p("/") && c !== p("\\")) {
          this.state = "authority";
          --this.pointer;
        } else {
          this.parseError = true;
        }

        return true;
      };

    URLStateMachine.prototype["parse authority"] = function parseAuthority(
      c,
      cStr,
    ) {
      if (c === p("@")) {
        this.parseError = true;
        if (this.atFlag) {
          this.buffer = `%40${this.buffer}`;
        }
        this.atFlag = true;

        // careful, this is based on buffer and has its own pointer (this.pointer != pointer) and inner chars
        const len = countSymbols(this.buffer);
        for (let pointer = 0; pointer < len; ++pointer) {
          const codePoint = this.buffer.codePointAt(pointer);

          if (codePoint === p(":") && !this.passwordTokenSeenFlag) {
            this.passwordTokenSeenFlag = true;
            continue;
          }
          const encodedCodePoints = utf8PercentEncodeCodePoint(
            codePoint,
            isUserinfoPercentEncode,
          );
          if (this.passwordTokenSeenFlag) {
            this.url.password += encodedCodePoints;
          } else {
            this.url.username += encodedCodePoints;
          }
        }
        this.buffer = "";
      } else if (
        isNaN(c) ||
        c === p("/") ||
        c === p("?") ||
        c === p("#") ||
        (isSpecial(this.url) && c === p("\\"))
      ) {
        if (this.atFlag && this.buffer === "") {
          this.parseError = true;
          return failure;
        }
        this.pointer -= countSymbols(this.buffer) + 1;
        this.buffer = "";
        this.state = "host";
      } else {
        this.buffer += cStr;
      }

      return true;
    };

    URLStateMachine.prototype["parse hostname"] = URLStateMachine.prototype[
      "parse host"
    ] = function parseHostName(c, cStr) {
      if (this.stateOverride && this.url.scheme === "file") {
        --this.pointer;
        this.state = "file host";
      } else if (c === p(":") && !this.arrFlag) {
        if (this.buffer === "") {
          this.parseError = true;
          return failure;
        }

        if (this.stateOverride === "hostname") {
          return false;
        }

        const host = parseHost(this.buffer, isNotSpecial(this.url));
        if (host === failure) {
          return failure;
        }

        this.url.host = host;
        this.buffer = "";
        this.state = "port";
      } else if (
        isNaN(c) ||
        c === p("/") ||
        c === p("?") ||
        c === p("#") ||
        (isSpecial(this.url) && c === p("\\"))
      ) {
        --this.pointer;
        if (isSpecial(this.url) && this.buffer === "") {
          this.parseError = true;
          return failure;
        } else if (
          this.stateOverride &&
          this.buffer === "" &&
          (includesCredentials(this.url) || this.url.port !== null)
        ) {
          this.parseError = true;
          return false;
        }

        const host = parseHost(this.buffer, isNotSpecial(this.url));
        if (host === failure) {
          return failure;
        }

        this.url.host = host;
        this.buffer = "";
        this.state = "path start";
        if (this.stateOverride) {
          return false;
        }
      } else {
        if (c === p("[")) {
          this.arrFlag = true;
        } else if (c === p("]")) {
          this.arrFlag = false;
        }
        this.buffer += cStr;
      }

      return true;
    };

    URLStateMachine.prototype["parse port"] = function parsePort(c, cStr) {
      if (infra.isASCIIDigit(c)) {
        this.buffer += cStr;
      } else if (
        isNaN(c) ||
        c === p("/") ||
        c === p("?") ||
        c === p("#") ||
        (isSpecial(this.url) && c === p("\\")) ||
        this.stateOverride
      ) {
        if (this.buffer !== "") {
          const port = parseInt(this.buffer);
          if (port > 2 ** 16 - 1) {
            this.parseError = true;
            return failure;
          }
          this.url.port = port === defaultPort(this.url.scheme) ? null : port;
          this.buffer = "";
        }
        if (this.stateOverride) {
          return false;
        }
        this.state = "path start";
        --this.pointer;
      } else {
        this.parseError = true;
        return failure;
      }

      return true;
    };

    const fileOtherwiseCodePoints = new Set([p("/"), p("\\"), p("?"), p("#")]);

    function startsWithWindowsDriveLetter(input, pointer) {
      const length = input.length - pointer;
      return (
        length >= 2 &&
        isWindowsDriveLetterCodePoints(input[pointer], input[pointer + 1]) &&
        (length === 2 || fileOtherwiseCodePoints.has(input[pointer + 2]))
      );
    }

    URLStateMachine.prototype["parse file"] = function parseFile(c) {
      this.url.scheme = "file";
      this.url.host = "";

      if (c === p("/") || c === p("\\")) {
        if (c === p("\\")) {
          this.parseError = true;
        }
        this.state = "file slash";
      } else if (this.base !== null && this.base.scheme === "file") {
        this.url.host = this.base.host;
        this.url.path = this.base.path.slice();
        this.url.query = this.base.query;
        if (c === p("?")) {
          this.url.query = "";
          this.state = "query";
        } else if (c === p("#")) {
          this.url.fragment = "";
          this.state = "fragment";
        } else if (!isNaN(c)) {
          this.url.query = null;
          if (!startsWithWindowsDriveLetter(this.input, this.pointer)) {
            shortenPath(this.url);
          } else {
            this.parseError = true;
            this.url.path = [];
          }

          this.state = "path";
          --this.pointer;
        }
      } else {
        this.state = "path";
        --this.pointer;
      }

      return true;
    };

    URLStateMachine.prototype["parse file slash"] = function parseFileSlash(c) {
      if (c === p("/") || c === p("\\")) {
        if (c === p("\\")) {
          this.parseError = true;
        }
        this.state = "file host";
      } else {
        if (this.base !== null && this.base.scheme === "file") {
          if (
            !startsWithWindowsDriveLetter(this.input, this.pointer) &&
            isNormalizedWindowsDriveLetterString(this.base.path[0])
          ) {
            this.url.path.push(this.base.path[0]);
          }
          this.url.host = this.base.host;
        }
        this.state = "path";
        --this.pointer;
      }

      return true;
    };

    URLStateMachine.prototype["parse file host"] = function parseFileHost(
      c,
      cStr,
    ) {
      if (
        isNaN(c) ||
        c === p("/") ||
        c === p("\\") ||
        c === p("?") ||
        c === p("#")
      ) {
        --this.pointer;
        if (!this.stateOverride && isWindowsDriveLetterString(this.buffer)) {
          this.parseError = true;
          this.state = "path";
        } else if (this.buffer === "") {
          this.url.host = "";
          if (this.stateOverride) {
            return false;
          }
          this.state = "path start";
        } else {
          let host = parseHost(this.buffer, isNotSpecial(this.url));
          if (host === failure) {
            return failure;
          }
          if (host === "localhost") {
            host = "";
          }
          this.url.host = host;

          if (this.stateOverride) {
            return false;
          }

          this.buffer = "";
          this.state = "path start";
        }
      } else {
        this.buffer += cStr;
      }

      return true;
    };

    URLStateMachine.prototype["parse path start"] = function parsePathStart(c) {
      if (isSpecial(this.url)) {
        if (c === p("\\")) {
          this.parseError = true;
        }
        this.state = "path";

        if (c !== p("/") && c !== p("\\")) {
          --this.pointer;
        }
      } else if (!this.stateOverride && c === p("?")) {
        this.url.query = "";
        this.state = "query";
      } else if (!this.stateOverride && c === p("#")) {
        this.url.fragment = "";
        this.state = "fragment";
      } else if (c !== undefined) {
        this.state = "path";
        if (c !== p("/")) {
          --this.pointer;
        }
      } else if (this.stateOverride && this.url.host === null) {
        this.url.path.push("");
      }

      return true;
    };

    URLStateMachine.prototype["parse path"] = function parsePath(c) {
      if (
        isNaN(c) ||
        c === p("/") ||
        (isSpecial(this.url) && c === p("\\")) ||
        (!this.stateOverride && (c === p("?") || c === p("#")))
      ) {
        if (isSpecial(this.url) && c === p("\\")) {
          this.parseError = true;
        }

        if (isDoubleDot(this.buffer)) {
          shortenPath(this.url);
          if (c !== p("/") && !(isSpecial(this.url) && c === p("\\"))) {
            this.url.path.push("");
          }
        } else if (
          isSingleDot(this.buffer) &&
          c !== p("/") &&
          !(isSpecial(this.url) && c === p("\\"))
        ) {
          this.url.path.push("");
        } else if (!isSingleDot(this.buffer)) {
          if (
            this.url.scheme === "file" &&
            this.url.path.length === 0 &&
            isWindowsDriveLetterString(this.buffer)
          ) {
            this.buffer = `${this.buffer[0]}:`;
          }
          this.url.path.push(this.buffer);
        }
        this.buffer = "";
        if (c === p("?")) {
          this.url.query = "";
          this.state = "query";
        }
        if (c === p("#")) {
          this.url.fragment = "";
          this.state = "fragment";
        }
      } else {
        // TODO: If c is not a URL code point and not "%", parse error.

        if (
          c === p("%") &&
          (!infra.isASCIIHex(this.input[this.pointer + 1]) ||
            !infra.isASCIIHex(this.input[this.pointer + 2]))
        ) {
          this.parseError = true;
        }

        this.buffer += utf8PercentEncodeCodePoint(c, isPathPercentEncode);
      }

      return true;
    };

    URLStateMachine.prototype["parse opaque path"] = function parseOpaquePath(
      c,
    ) {
      if (c === p("?")) {
        this.url.query = "";
        this.state = "query";
      } else if (c === p("#")) {
        this.url.fragment = "";
        this.state = "fragment";
      } else {
        // TODO: Add: not a URL code point
        if (!isNaN(c) && c !== p("%")) {
          this.parseError = true;
        }

        if (
          c === p("%") &&
          (!infra.isASCIIHex(this.input[this.pointer + 1]) ||
            !infra.isASCIIHex(this.input[this.pointer + 2]))
        ) {
          this.parseError = true;
        }

        if (!isNaN(c)) {
          this.url.path += utf8PercentEncodeCodePoint(
            c,
            isC0ControlPercentEncode,
          );
        }
      }

      return true;
    };

    URLStateMachine.prototype["parse query"] = function parseQuery(c, cStr) {
      if (
        !isSpecial(this.url) ||
        this.url.scheme === "ws" ||
        this.url.scheme === "wss"
      ) {
        this.encodingOverride = "utf-8";
      }

      if ((!this.stateOverride && c === p("#")) || isNaN(c)) {
        const queryPercentEncodePredicate = isSpecial(this.url)
          ? isSpecialQueryPercentEncode
          : isQueryPercentEncode;
        this.url.query += utf8PercentEncodeString(
          this.buffer,
          queryPercentEncodePredicate,
        );

        this.buffer = "";

        if (c === p("#")) {
          this.url.fragment = "";
          this.state = "fragment";
        }
      } else if (!isNaN(c)) {
        // TODO: If c is not a URL code point and not "%", parse error.

        if (
          c === p("%") &&
          (!infra.isASCIIHex(this.input[this.pointer + 1]) ||
            !infra.isASCIIHex(this.input[this.pointer + 2]))
        ) {
          this.parseError = true;
        }

        this.buffer += cStr;
      }

      return true;
    };

    URLStateMachine.prototype["parse fragment"] = function parseFragment(c) {
      if (!isNaN(c)) {
        // TODO: If c is not a URL code point and not "%", parse error.
        if (
          c === p("%") &&
          (!infra.isASCIIHex(this.input[this.pointer + 1]) ||
            !infra.isASCIIHex(this.input[this.pointer + 2]))
        ) {
          this.parseError = true;
        }

        this.url.fragment += utf8PercentEncodeCodePoint(
          c,
          isFragmentPercentEncode,
        );
      }

      return true;
    };

    function serializeURL(url, excludeFragment) {
      let output = `${url.scheme}:`;
      if (url.host !== null) {
        output += "//";

        if (url.username !== "" || url.password !== "") {
          output += url.username;
          if (url.password !== "") {
            output += `:${url.password}`;
          }
          output += "@";
        }

        output += serializeHost(url.host);

        if (url.port !== null) {
          output += `:${url.port}`;
        }
      }

      if (
        url.host === null &&
        !hasAnOpaquePath(url) &&
        url.path.length > 1 &&
        url.path[0] === ""
      ) {
        output += "/.";
      }
      output += serializePath(url);

      if (url.query !== null) {
        output += `?${url.query}`;
      }

      if (!excludeFragment && url.fragment !== null) {
        output += `#${url.fragment}`;
      }

      return output;
    }

    function serializeOrigin(tuple) {
      let result = `${tuple.scheme}://`;
      result += serializeHost(tuple.host);

      if (tuple.port !== null) {
        result += `:${tuple.port}`;
      }

      return result;
    }

    function serializePath(url) {
      if (hasAnOpaquePath(url)) {
        return url.path;
      }

      let output = "";
      for (const segment of url.path) {
        output += `/${segment}`;
      }
      return output;
    }

    module.exports.serializeURL = serializeURL;

    module.exports.serializePath = serializePath;

    module.exports.serializeURLOrigin = function (url) {
      // https://url.spec.whatwg.org/#concept-url-origin
      switch (url.scheme) {
        case "blob":
          try {
            return module.exports.serializeURLOrigin(
              module.exports.parseURL(serializePath(url)),
            );
          } catch (e) {
            // serializing an opaque origin returns "null"
            return "null";
          }
        case "ftp":
        case "http":
        case "https":
        case "ws":
        case "wss":
          return serializeOrigin({
            scheme: url.scheme,
            host: url.host,
            port: url.port,
          });
        case "file":
          // The spec says:
          // > Unfortunate as it is, this is left as an exercise to the reader. When in doubt, return a new opaque origin.
          // Browsers tested so far:
          // - Chrome says "file://", but treats file: URLs as cross-origin for most (all?) purposes; see e.g.
          //   https://bugs.chromium.org/p/chromium/issues/detail?id=37586
          // - Firefox says "null", but treats file: URLs as same-origin sometimes based on directory stuff; see
          //   https://developer.mozilla.org/en-US/docs/Archive/Misc_top_level/Same-origin_policy_for_file:_URIs
          return "null";
        default:
          // serializing an opaque origin returns "null"
          return "null";
      }
    };

    module.exports.basicURLParse = function (input, options) {
      if (options === undefined) {
        options = {};
      }

      const usm = new URLStateMachine(
        input,
        options.baseURL,
        options.encodingOverride,
        options.url,
        options.stateOverride,
      );
      if (usm.failure) {
        return null;
      }

      return usm.url;
    };

    module.exports.setTheUsername = function (url, username) {
      url.username = utf8PercentEncodeString(username, isUserinfoPercentEncode);
    };

    module.exports.setThePassword = function (url, password) {
      url.password = utf8PercentEncodeString(password, isUserinfoPercentEncode);
    };

    module.exports.serializeHost = serializeHost;

    module.exports.cannotHaveAUsernamePasswordPort =
      cannotHaveAUsernamePasswordPort;

    module.exports.hasAnOpaquePath = hasAnOpaquePath;

    module.exports.serializeInteger = function (integer) {
      return String(integer);
    };

    module.exports.parseURL = function (input, options) {
      if (options === undefined) {
        options = {};
      }

      // We don't handle blobs, so this just delegates:
      return module.exports.basicURLParse(input, {
        baseURL: options.baseURL,
        encodingOverride: options.encodingOverride,
      });
    };
  })(urlStateMachine);
  return urlStateMachine.exports;
}

var urlencoded;
var hasRequiredUrlencoded;

function requireUrlencoded() {
  if (hasRequiredUrlencoded) return urlencoded;
  hasRequiredUrlencoded = 1;
  const { utf8Encode, utf8DecodeWithoutBOM } = requireEncoding();
  const {
    percentDecodeBytes,
    utf8PercentEncodeString,
    isURLEncodedPercentEncode,
  } = requirePercentEncoding();

  function p(char) {
    return char.codePointAt(0);
  }

  // https://url.spec.whatwg.org/#concept-urlencoded-parser
  function parseUrlencoded(input) {
    const sequences = strictlySplitByteSequence(input, p("&"));
    const output = [];
    for (const bytes of sequences) {
      if (bytes.length === 0) {
        continue;
      }

      let name, value;
      const indexOfEqual = bytes.indexOf(p("="));

      if (indexOfEqual >= 0) {
        name = bytes.slice(0, indexOfEqual);
        value = bytes.slice(indexOfEqual + 1);
      } else {
        name = bytes;
        value = new Uint8Array(0);
      }

      name = replaceByteInByteSequence(name, 0x2b, 0x20);
      value = replaceByteInByteSequence(value, 0x2b, 0x20);

      const nameString = utf8DecodeWithoutBOM(percentDecodeBytes(name));
      const valueString = utf8DecodeWithoutBOM(percentDecodeBytes(value));

      output.push([nameString, valueString]);
    }
    return output;
  }

  // https://url.spec.whatwg.org/#concept-urlencoded-string-parser
  function parseUrlencodedString(input) {
    return parseUrlencoded(utf8Encode(input));
  }

  // https://url.spec.whatwg.org/#concept-urlencoded-serializer
  function serializeUrlencoded(tuples, encodingOverride = undefined) {
    let encoding = "utf-8";
    if (encodingOverride !== undefined) {
      // TODO "get the output encoding", i.e. handle encoding labels vs. names.
      encoding = encodingOverride;
    }

    let output = "";
    for (const [i, tuple] of tuples.entries()) {
      // TODO: handle encoding override

      const name = utf8PercentEncodeString(
        tuple[0],
        isURLEncodedPercentEncode,
        true,
      );

      let value = tuple[1];
      if (tuple.length > 2 && tuple[2] !== undefined) {
        if (tuple[2] === "hidden" && name === "_charset_") {
          value = encoding;
        } else if (tuple[2] === "file") {
          // value is a File object
          value = value.name;
        }
      }

      value = utf8PercentEncodeString(value, isURLEncodedPercentEncode, true);

      if (i !== 0) {
        output += "&";
      }
      output += `${name}=${value}`;
    }
    return output;
  }

  function strictlySplitByteSequence(buf, cp) {
    const list = [];
    let last = 0;
    let i = buf.indexOf(cp);
    while (i >= 0) {
      list.push(buf.slice(last, i));
      last = i + 1;
      i = buf.indexOf(cp, last);
    }
    if (last !== buf.length) {
      list.push(buf.slice(last));
    }
    return list;
  }

  function replaceByteInByteSequence(buf, from, to) {
    let i = buf.indexOf(from);
    while (i >= 0) {
      buf[i] = to;
      i = buf.indexOf(from, i + 1);
    }
    return buf;
  }

  urlencoded = {
    parseUrlencodedString,
    serializeUrlencoded,
  };
  return urlencoded;
}

var URLSearchParams = {};

var _Function = {};

var hasRequired_Function;

function require_Function() {
  if (hasRequired_Function) return _Function;
  hasRequired_Function = 1;

  const conversions = requireLib$1();
  const utils = requireUtils();

  _Function.convert = (
    globalObject,
    value,
    { context = "The provided value" } = {},
  ) => {
    if (typeof value !== "function") {
      throw new globalObject.TypeError(context + " is not a function");
    }

    function invokeTheCallbackFunction(...args) {
      const thisArg = utils.tryWrapperForImpl(this);
      let callResult;

      for (let i = 0; i < args.length; i++) {
        args[i] = utils.tryWrapperForImpl(args[i]);
      }

      callResult = Reflect.apply(value, thisArg, args);

      callResult = conversions["any"](callResult, {
        context: context,
        globals: globalObject,
      });

      return callResult;
    }

    invokeTheCallbackFunction.construct = (...args) => {
      for (let i = 0; i < args.length; i++) {
        args[i] = utils.tryWrapperForImpl(args[i]);
      }

      let callResult = Reflect.construct(value, args);

      callResult = conversions["any"](callResult, {
        context: context,
        globals: globalObject,
      });

      return callResult;
    };

    invokeTheCallbackFunction[utils.wrapperSymbol] = value;
    invokeTheCallbackFunction.objectReference = value;

    return invokeTheCallbackFunction;
  };
  return _Function;
}

var URLSearchParamsImpl = {};

var hasRequiredURLSearchParamsImpl;

function requireURLSearchParamsImpl() {
  if (hasRequiredURLSearchParamsImpl) return URLSearchParamsImpl;
  hasRequiredURLSearchParamsImpl = 1;
  const urlencoded = requireUrlencoded();

  URLSearchParamsImpl.implementation = class URLSearchParamsImpl {
    constructor(globalObject, constructorArgs, { doNotStripQMark = false }) {
      let init = constructorArgs[0];
      this._list = [];
      this._url = null;

      if (!doNotStripQMark && typeof init === "string" && init[0] === "?") {
        init = init.slice(1);
      }

      if (Array.isArray(init)) {
        for (const pair of init) {
          if (pair.length !== 2) {
            throw new TypeError(
              "Failed to construct 'URLSearchParams': parameter 1 sequence's element does not " +
                "contain exactly two elements.",
            );
          }
          this._list.push([pair[0], pair[1]]);
        }
      } else if (
        typeof init === "object" &&
        Object.getPrototypeOf(init) === null
      ) {
        for (const name of Object.keys(init)) {
          const value = init[name];
          this._list.push([name, value]);
        }
      } else {
        this._list = urlencoded.parseUrlencodedString(init);
      }
    }

    _updateSteps() {
      if (this._url !== null) {
        let query = urlencoded.serializeUrlencoded(this._list);
        if (query === "") {
          query = null;
        }
        this._url._url.query = query;
      }
    }

    append(name, value) {
      this._list.push([name, value]);
      this._updateSteps();
    }

    delete(name) {
      let i = 0;
      while (i < this._list.length) {
        if (this._list[i][0] === name) {
          this._list.splice(i, 1);
        } else {
          i++;
        }
      }
      this._updateSteps();
    }

    get(name) {
      for (const tuple of this._list) {
        if (tuple[0] === name) {
          return tuple[1];
        }
      }
      return null;
    }

    getAll(name) {
      const output = [];
      for (const tuple of this._list) {
        if (tuple[0] === name) {
          output.push(tuple[1]);
        }
      }
      return output;
    }

    has(name) {
      for (const tuple of this._list) {
        if (tuple[0] === name) {
          return true;
        }
      }
      return false;
    }

    set(name, value) {
      let found = false;
      let i = 0;
      while (i < this._list.length) {
        if (this._list[i][0] === name) {
          if (found) {
            this._list.splice(i, 1);
          } else {
            found = true;
            this._list[i][1] = value;
            i++;
          }
        } else {
          i++;
        }
      }
      if (!found) {
        this._list.push([name, value]);
      }
      this._updateSteps();
    }

    sort() {
      this._list.sort((a, b) => {
        if (a[0] < b[0]) {
          return -1;
        }
        if (a[0] > b[0]) {
          return 1;
        }
        return 0;
      });

      this._updateSteps();
    }

    [Symbol.iterator]() {
      return this._list[Symbol.iterator]();
    }

    toString() {
      return urlencoded.serializeUrlencoded(this._list);
    }
  };
  return URLSearchParamsImpl;
}

var hasRequiredURLSearchParams;

function requireURLSearchParams() {
  if (hasRequiredURLSearchParams) return URLSearchParams;
  hasRequiredURLSearchParams = 1;
  (function (exports) {
    const conversions = requireLib$1();
    const utils = requireUtils();

    const Function = require_Function();
    const newObjectInRealm = utils.newObjectInRealm;
    const implSymbol = utils.implSymbol;
    const ctorRegistrySymbol = utils.ctorRegistrySymbol;

    const interfaceName = "URLSearchParams";

    exports.is = (value) => {
      return (
        utils.isObject(value) &&
        utils.hasOwn(value, implSymbol) &&
        value[implSymbol] instanceof Impl.implementation
      );
    };
    exports.isImpl = (value) => {
      return utils.isObject(value) && value instanceof Impl.implementation;
    };
    exports.convert = (
      globalObject,
      value,
      { context = "The provided value" } = {},
    ) => {
      if (exports.is(value)) {
        return utils.implForWrapper(value);
      }
      throw new globalObject.TypeError(
        `${context} is not of type 'URLSearchParams'.`,
      );
    };

    exports.createDefaultIterator = (globalObject, target, kind) => {
      const ctorRegistry = globalObject[ctorRegistrySymbol];
      const iteratorPrototype = ctorRegistry["URLSearchParams Iterator"];
      const iterator = Object.create(iteratorPrototype);
      Object.defineProperty(iterator, utils.iterInternalSymbol, {
        value: { target, kind, index: 0 },
        configurable: true,
      });
      return iterator;
    };

    function makeWrapper(globalObject, newTarget) {
      let proto;
      if (newTarget !== undefined) {
        proto = newTarget.prototype;
      }

      if (!utils.isObject(proto)) {
        proto = globalObject[ctorRegistrySymbol]["URLSearchParams"].prototype;
      }

      return Object.create(proto);
    }

    exports.create = (globalObject, constructorArgs, privateData) => {
      const wrapper = makeWrapper(globalObject);
      return exports.setup(wrapper, globalObject, constructorArgs, privateData);
    };

    exports.createImpl = (globalObject, constructorArgs, privateData) => {
      const wrapper = exports.create(
        globalObject,
        constructorArgs,
        privateData,
      );
      return utils.implForWrapper(wrapper);
    };

    exports._internalSetup = (wrapper, globalObject) => {};

    exports.setup = (
      wrapper,
      globalObject,
      constructorArgs = [],
      privateData = {},
    ) => {
      privateData.wrapper = wrapper;

      exports._internalSetup(wrapper, globalObject);
      Object.defineProperty(wrapper, implSymbol, {
        value: new Impl.implementation(
          globalObject,
          constructorArgs,
          privateData,
        ),
        configurable: true,
      });

      wrapper[implSymbol][utils.wrapperSymbol] = wrapper;
      if (Impl.init) {
        Impl.init(wrapper[implSymbol]);
      }
      return wrapper;
    };

    exports.new = (globalObject, newTarget) => {
      const wrapper = makeWrapper(globalObject, newTarget);

      exports._internalSetup(wrapper, globalObject);
      Object.defineProperty(wrapper, implSymbol, {
        value: Object.create(Impl.implementation.prototype),
        configurable: true,
      });

      wrapper[implSymbol][utils.wrapperSymbol] = wrapper;
      if (Impl.init) {
        Impl.init(wrapper[implSymbol]);
      }
      return wrapper[implSymbol];
    };

    const exposed = new Set(["Window", "Worker"]);

    exports.install = (globalObject, globalNames) => {
      if (!globalNames.some((globalName) => exposed.has(globalName))) {
        return;
      }

      const ctorRegistry = utils.initCtorRegistry(globalObject);
      class URLSearchParams {
        constructor() {
          const args = [];
          {
            let curArg = arguments[0];
            if (curArg !== undefined) {
              if (utils.isObject(curArg)) {
                if (curArg[Symbol.iterator] !== undefined) {
                  if (!utils.isObject(curArg)) {
                    throw new globalObject.TypeError(
                      "Failed to construct 'URLSearchParams': parameter 1" +
                        " sequence" +
                        " is not an iterable object.",
                    );
                  } else {
                    const V = [];
                    const tmp = curArg;
                    for (let nextItem of tmp) {
                      if (!utils.isObject(nextItem)) {
                        throw new globalObject.TypeError(
                          "Failed to construct 'URLSearchParams': parameter 1" +
                            " sequence" +
                            "'s element" +
                            " is not an iterable object.",
                        );
                      } else {
                        const V = [];
                        const tmp = nextItem;
                        for (let nextItem of tmp) {
                          nextItem = conversions["USVString"](nextItem, {
                            context:
                              "Failed to construct 'URLSearchParams': parameter 1" +
                              " sequence" +
                              "'s element" +
                              "'s element",
                            globals: globalObject,
                          });

                          V.push(nextItem);
                        }
                        nextItem = V;
                      }

                      V.push(nextItem);
                    }
                    curArg = V;
                  }
                } else {
                  if (!utils.isObject(curArg)) {
                    throw new globalObject.TypeError(
                      "Failed to construct 'URLSearchParams': parameter 1" +
                        " record" +
                        " is not an object.",
                    );
                  } else {
                    const result = Object.create(null);
                    for (const key of Reflect.ownKeys(curArg)) {
                      const desc = Object.getOwnPropertyDescriptor(curArg, key);
                      if (desc && desc.enumerable) {
                        let typedKey = key;

                        typedKey = conversions["USVString"](typedKey, {
                          context:
                            "Failed to construct 'URLSearchParams': parameter 1" +
                            " record" +
                            "'s key",
                          globals: globalObject,
                        });

                        let typedValue = curArg[key];

                        typedValue = conversions["USVString"](typedValue, {
                          context:
                            "Failed to construct 'URLSearchParams': parameter 1" +
                            " record" +
                            "'s value",
                          globals: globalObject,
                        });

                        result[typedKey] = typedValue;
                      }
                    }
                    curArg = result;
                  }
                }
              } else {
                curArg = conversions["USVString"](curArg, {
                  context: "Failed to construct 'URLSearchParams': parameter 1",
                  globals: globalObject,
                });
              }
            } else {
              curArg = "";
            }
            args.push(curArg);
          }
          return exports.setup(
            Object.create(new.target.prototype),
            globalObject,
            args,
          );
        }

        append(name, value) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'append' called on an object that is not a valid instance of URLSearchParams.",
            );
          }

          if (arguments.length < 2) {
            throw new globalObject.TypeError(
              `Failed to execute 'append' on 'URLSearchParams': 2 arguments required, but only ${arguments.length} present.`,
            );
          }
          const args = [];
          {
            let curArg = arguments[0];
            curArg = conversions["USVString"](curArg, {
              context:
                "Failed to execute 'append' on 'URLSearchParams': parameter 1",
              globals: globalObject,
            });
            args.push(curArg);
          }
          {
            let curArg = arguments[1];
            curArg = conversions["USVString"](curArg, {
              context:
                "Failed to execute 'append' on 'URLSearchParams': parameter 2",
              globals: globalObject,
            });
            args.push(curArg);
          }
          return utils.tryWrapperForImpl(esValue[implSymbol].append(...args));
        }

        delete(name) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'delete' called on an object that is not a valid instance of URLSearchParams.",
            );
          }

          if (arguments.length < 1) {
            throw new globalObject.TypeError(
              `Failed to execute 'delete' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`,
            );
          }
          const args = [];
          {
            let curArg = arguments[0];
            curArg = conversions["USVString"](curArg, {
              context:
                "Failed to execute 'delete' on 'URLSearchParams': parameter 1",
              globals: globalObject,
            });
            args.push(curArg);
          }
          return utils.tryWrapperForImpl(esValue[implSymbol].delete(...args));
        }

        get(name) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get' called on an object that is not a valid instance of URLSearchParams.",
            );
          }

          if (arguments.length < 1) {
            throw new globalObject.TypeError(
              `Failed to execute 'get' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`,
            );
          }
          const args = [];
          {
            let curArg = arguments[0];
            curArg = conversions["USVString"](curArg, {
              context:
                "Failed to execute 'get' on 'URLSearchParams': parameter 1",
              globals: globalObject,
            });
            args.push(curArg);
          }
          return esValue[implSymbol].get(...args);
        }

        getAll(name) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'getAll' called on an object that is not a valid instance of URLSearchParams.",
            );
          }

          if (arguments.length < 1) {
            throw new globalObject.TypeError(
              `Failed to execute 'getAll' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`,
            );
          }
          const args = [];
          {
            let curArg = arguments[0];
            curArg = conversions["USVString"](curArg, {
              context:
                "Failed to execute 'getAll' on 'URLSearchParams': parameter 1",
              globals: globalObject,
            });
            args.push(curArg);
          }
          return utils.tryWrapperForImpl(esValue[implSymbol].getAll(...args));
        }

        has(name) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'has' called on an object that is not a valid instance of URLSearchParams.",
            );
          }

          if (arguments.length < 1) {
            throw new globalObject.TypeError(
              `Failed to execute 'has' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`,
            );
          }
          const args = [];
          {
            let curArg = arguments[0];
            curArg = conversions["USVString"](curArg, {
              context:
                "Failed to execute 'has' on 'URLSearchParams': parameter 1",
              globals: globalObject,
            });
            args.push(curArg);
          }
          return esValue[implSymbol].has(...args);
        }

        set(name, value) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set' called on an object that is not a valid instance of URLSearchParams.",
            );
          }

          if (arguments.length < 2) {
            throw new globalObject.TypeError(
              `Failed to execute 'set' on 'URLSearchParams': 2 arguments required, but only ${arguments.length} present.`,
            );
          }
          const args = [];
          {
            let curArg = arguments[0];
            curArg = conversions["USVString"](curArg, {
              context:
                "Failed to execute 'set' on 'URLSearchParams': parameter 1",
              globals: globalObject,
            });
            args.push(curArg);
          }
          {
            let curArg = arguments[1];
            curArg = conversions["USVString"](curArg, {
              context:
                "Failed to execute 'set' on 'URLSearchParams': parameter 2",
              globals: globalObject,
            });
            args.push(curArg);
          }
          return utils.tryWrapperForImpl(esValue[implSymbol].set(...args));
        }

        sort() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'sort' called on an object that is not a valid instance of URLSearchParams.",
            );
          }

          return utils.tryWrapperForImpl(esValue[implSymbol].sort());
        }

        toString() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'toString' called on an object that is not a valid instance of URLSearchParams.",
            );
          }

          return esValue[implSymbol].toString();
        }

        keys() {
          if (!exports.is(this)) {
            throw new globalObject.TypeError(
              "'keys' called on an object that is not a valid instance of URLSearchParams.",
            );
          }
          return exports.createDefaultIterator(globalObject, this, "key");
        }

        values() {
          if (!exports.is(this)) {
            throw new globalObject.TypeError(
              "'values' called on an object that is not a valid instance of URLSearchParams.",
            );
          }
          return exports.createDefaultIterator(globalObject, this, "value");
        }

        entries() {
          if (!exports.is(this)) {
            throw new globalObject.TypeError(
              "'entries' called on an object that is not a valid instance of URLSearchParams.",
            );
          }
          return exports.createDefaultIterator(globalObject, this, "key+value");
        }

        forEach(callback) {
          if (!exports.is(this)) {
            throw new globalObject.TypeError(
              "'forEach' called on an object that is not a valid instance of URLSearchParams.",
            );
          }
          if (arguments.length < 1) {
            throw new globalObject.TypeError(
              "Failed to execute 'forEach' on 'iterable': 1 argument required, but only 0 present.",
            );
          }
          callback = Function.convert(globalObject, callback, {
            context:
              "Failed to execute 'forEach' on 'iterable': The callback provided as parameter 1",
          });
          const thisArg = arguments[1];
          let pairs = Array.from(this[implSymbol]);
          let i = 0;
          while (i < pairs.length) {
            const [key, value] = pairs[i].map(utils.tryWrapperForImpl);
            callback.call(thisArg, value, key, this);
            pairs = Array.from(this[implSymbol]);
            i++;
          }
        }
      }
      Object.defineProperties(URLSearchParams.prototype, {
        append: { enumerable: true },
        delete: { enumerable: true },
        get: { enumerable: true },
        getAll: { enumerable: true },
        has: { enumerable: true },
        set: { enumerable: true },
        sort: { enumerable: true },
        toString: { enumerable: true },
        keys: { enumerable: true },
        values: { enumerable: true },
        entries: { enumerable: true },
        forEach: { enumerable: true },
        [Symbol.toStringTag]: { value: "URLSearchParams", configurable: true },
        [Symbol.iterator]: {
          value: URLSearchParams.prototype.entries,
          configurable: true,
          writable: true,
        },
      });
      ctorRegistry[interfaceName] = URLSearchParams;

      ctorRegistry["URLSearchParams Iterator"] = Object.create(
        ctorRegistry["%IteratorPrototype%"],
        {
          [Symbol.toStringTag]: {
            configurable: true,
            value: "URLSearchParams Iterator",
          },
        },
      );
      utils.define(ctorRegistry["URLSearchParams Iterator"], {
        next() {
          const internal = this && this[utils.iterInternalSymbol];
          if (!internal) {
            throw new globalObject.TypeError(
              "next() called on a value that is not a URLSearchParams iterator object",
            );
          }

          const { target, kind, index } = internal;
          const values = Array.from(target[implSymbol]);
          const len = values.length;
          if (index >= len) {
            return newObjectInRealm(globalObject, {
              value: undefined,
              done: true,
            });
          }

          const pair = values[index];
          internal.index = index + 1;
          return newObjectInRealm(
            globalObject,
            utils.iteratorResult(pair.map(utils.tryWrapperForImpl), kind),
          );
        },
      });

      Object.defineProperty(globalObject, interfaceName, {
        configurable: true,
        writable: true,
        value: URLSearchParams,
      });
    };

    const Impl = requireURLSearchParamsImpl();
  })(URLSearchParams);
  return URLSearchParams;
}

var hasRequiredURLImpl;

function requireURLImpl() {
  if (hasRequiredURLImpl) return URLImpl;
  hasRequiredURLImpl = 1;
  const usm = requireUrlStateMachine();
  const urlencoded = requireUrlencoded();
  const URLSearchParams = requireURLSearchParams();

  URLImpl.implementation = class URLImpl {
    constructor(globalObject, constructorArgs) {
      const url = constructorArgs[0];
      const base = constructorArgs[1];

      let parsedBase = null;
      if (base !== undefined) {
        parsedBase = usm.basicURLParse(base);
        if (parsedBase === null) {
          throw new TypeError(`Invalid base URL: ${base}`);
        }
      }

      const parsedURL = usm.basicURLParse(url, { baseURL: parsedBase });
      if (parsedURL === null) {
        throw new TypeError(`Invalid URL: ${url}`);
      }

      const query = parsedURL.query !== null ? parsedURL.query : "";

      this._url = parsedURL;

      // We cannot invoke the "new URLSearchParams object" algorithm without going through the constructor, which strips
      // question mark by default. Therefore the doNotStripQMark hack is used.
      this._query = URLSearchParams.createImpl(globalObject, [query], {
        doNotStripQMark: true,
      });
      this._query._url = this;
    }

    get href() {
      return usm.serializeURL(this._url);
    }

    set href(v) {
      const parsedURL = usm.basicURLParse(v);
      if (parsedURL === null) {
        throw new TypeError(`Invalid URL: ${v}`);
      }

      this._url = parsedURL;

      this._query._list.splice(0);
      const { query } = parsedURL;
      if (query !== null) {
        this._query._list = urlencoded.parseUrlencodedString(query);
      }
    }

    get origin() {
      return usm.serializeURLOrigin(this._url);
    }

    get protocol() {
      return `${this._url.scheme}:`;
    }

    set protocol(v) {
      usm.basicURLParse(`${v}:`, {
        url: this._url,
        stateOverride: "scheme start",
      });
    }

    get username() {
      return this._url.username;
    }

    set username(v) {
      if (usm.cannotHaveAUsernamePasswordPort(this._url)) {
        return;
      }

      usm.setTheUsername(this._url, v);
    }

    get password() {
      return this._url.password;
    }

    set password(v) {
      if (usm.cannotHaveAUsernamePasswordPort(this._url)) {
        return;
      }

      usm.setThePassword(this._url, v);
    }

    get host() {
      const url = this._url;

      if (url.host === null) {
        return "";
      }

      if (url.port === null) {
        return usm.serializeHost(url.host);
      }

      return `${usm.serializeHost(url.host)}:${usm.serializeInteger(url.port)}`;
    }

    set host(v) {
      if (usm.hasAnOpaquePath(this._url)) {
        return;
      }

      usm.basicURLParse(v, { url: this._url, stateOverride: "host" });
    }

    get hostname() {
      if (this._url.host === null) {
        return "";
      }

      return usm.serializeHost(this._url.host);
    }

    set hostname(v) {
      if (usm.hasAnOpaquePath(this._url)) {
        return;
      }

      usm.basicURLParse(v, { url: this._url, stateOverride: "hostname" });
    }

    get port() {
      if (this._url.port === null) {
        return "";
      }

      return usm.serializeInteger(this._url.port);
    }

    set port(v) {
      if (usm.cannotHaveAUsernamePasswordPort(this._url)) {
        return;
      }

      if (v === "") {
        this._url.port = null;
      } else {
        usm.basicURLParse(v, { url: this._url, stateOverride: "port" });
      }
    }

    get pathname() {
      return usm.serializePath(this._url);
    }

    set pathname(v) {
      if (usm.hasAnOpaquePath(this._url)) {
        return;
      }

      this._url.path = [];
      usm.basicURLParse(v, { url: this._url, stateOverride: "path start" });
    }

    get search() {
      if (this._url.query === null || this._url.query === "") {
        return "";
      }

      return `?${this._url.query}`;
    }

    set search(v) {
      const url = this._url;

      if (v === "") {
        url.query = null;
        this._query._list = [];
        return;
      }

      const input = v[0] === "?" ? v.substring(1) : v;
      url.query = "";
      usm.basicURLParse(input, { url, stateOverride: "query" });
      this._query._list = urlencoded.parseUrlencodedString(input);
    }

    get searchParams() {
      return this._query;
    }

    get hash() {
      if (this._url.fragment === null || this._url.fragment === "") {
        return "";
      }

      return `#${this._url.fragment}`;
    }

    set hash(v) {
      if (v === "") {
        this._url.fragment = null;
        return;
      }

      const input = v[0] === "#" ? v.substring(1) : v;
      this._url.fragment = "";
      usm.basicURLParse(input, { url: this._url, stateOverride: "fragment" });
    }

    toJSON() {
      return this.href;
    }
  };
  return URLImpl;
}

var hasRequiredURL;

function requireURL() {
  if (hasRequiredURL) return URL$1;
  hasRequiredURL = 1;
  (function (exports) {
    const conversions = requireLib$1();
    const utils = requireUtils();

    const implSymbol = utils.implSymbol;
    const ctorRegistrySymbol = utils.ctorRegistrySymbol;

    const interfaceName = "URL";

    exports.is = (value) => {
      return (
        utils.isObject(value) &&
        utils.hasOwn(value, implSymbol) &&
        value[implSymbol] instanceof Impl.implementation
      );
    };
    exports.isImpl = (value) => {
      return utils.isObject(value) && value instanceof Impl.implementation;
    };
    exports.convert = (
      globalObject,
      value,
      { context = "The provided value" } = {},
    ) => {
      if (exports.is(value)) {
        return utils.implForWrapper(value);
      }
      throw new globalObject.TypeError(`${context} is not of type 'URL'.`);
    };

    function makeWrapper(globalObject, newTarget) {
      let proto;
      if (newTarget !== undefined) {
        proto = newTarget.prototype;
      }

      if (!utils.isObject(proto)) {
        proto = globalObject[ctorRegistrySymbol]["URL"].prototype;
      }

      return Object.create(proto);
    }

    exports.create = (globalObject, constructorArgs, privateData) => {
      const wrapper = makeWrapper(globalObject);
      return exports.setup(wrapper, globalObject, constructorArgs, privateData);
    };

    exports.createImpl = (globalObject, constructorArgs, privateData) => {
      const wrapper = exports.create(
        globalObject,
        constructorArgs,
        privateData,
      );
      return utils.implForWrapper(wrapper);
    };

    exports._internalSetup = (wrapper, globalObject) => {};

    exports.setup = (
      wrapper,
      globalObject,
      constructorArgs = [],
      privateData = {},
    ) => {
      privateData.wrapper = wrapper;

      exports._internalSetup(wrapper, globalObject);
      Object.defineProperty(wrapper, implSymbol, {
        value: new Impl.implementation(
          globalObject,
          constructorArgs,
          privateData,
        ),
        configurable: true,
      });

      wrapper[implSymbol][utils.wrapperSymbol] = wrapper;
      if (Impl.init) {
        Impl.init(wrapper[implSymbol]);
      }
      return wrapper;
    };

    exports.new = (globalObject, newTarget) => {
      const wrapper = makeWrapper(globalObject, newTarget);

      exports._internalSetup(wrapper, globalObject);
      Object.defineProperty(wrapper, implSymbol, {
        value: Object.create(Impl.implementation.prototype),
        configurable: true,
      });

      wrapper[implSymbol][utils.wrapperSymbol] = wrapper;
      if (Impl.init) {
        Impl.init(wrapper[implSymbol]);
      }
      return wrapper[implSymbol];
    };

    const exposed = new Set(["Window", "Worker"]);

    exports.install = (globalObject, globalNames) => {
      if (!globalNames.some((globalName) => exposed.has(globalName))) {
        return;
      }

      const ctorRegistry = utils.initCtorRegistry(globalObject);
      class URL {
        constructor(url) {
          if (arguments.length < 1) {
            throw new globalObject.TypeError(
              `Failed to construct 'URL': 1 argument required, but only ${arguments.length} present.`,
            );
          }
          const args = [];
          {
            let curArg = arguments[0];
            curArg = conversions["USVString"](curArg, {
              context: "Failed to construct 'URL': parameter 1",
              globals: globalObject,
            });
            args.push(curArg);
          }
          {
            let curArg = arguments[1];
            if (curArg !== undefined) {
              curArg = conversions["USVString"](curArg, {
                context: "Failed to construct 'URL': parameter 2",
                globals: globalObject,
              });
            }
            args.push(curArg);
          }
          return exports.setup(
            Object.create(new.target.prototype),
            globalObject,
            args,
          );
        }

        toJSON() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'toJSON' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol].toJSON();
        }

        get href() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get href' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["href"];
        }

        set href(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set href' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'href' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["href"] = V;
        }

        toString() {
          const esValue = this;
          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'toString' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["href"];
        }

        get origin() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get origin' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["origin"];
        }

        get protocol() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get protocol' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["protocol"];
        }

        set protocol(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set protocol' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'protocol' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["protocol"] = V;
        }

        get username() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get username' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["username"];
        }

        set username(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set username' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'username' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["username"] = V;
        }

        get password() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get password' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["password"];
        }

        set password(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set password' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'password' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["password"] = V;
        }

        get host() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get host' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["host"];
        }

        set host(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set host' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'host' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["host"] = V;
        }

        get hostname() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get hostname' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["hostname"];
        }

        set hostname(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set hostname' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'hostname' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["hostname"] = V;
        }

        get port() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get port' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["port"];
        }

        set port(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set port' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'port' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["port"] = V;
        }

        get pathname() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get pathname' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["pathname"];
        }

        set pathname(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set pathname' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'pathname' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["pathname"] = V;
        }

        get search() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get search' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["search"];
        }

        set search(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set search' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'search' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["search"] = V;
        }

        get searchParams() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get searchParams' called on an object that is not a valid instance of URL.",
            );
          }

          return utils.getSameObject(this, "searchParams", () => {
            return utils.tryWrapperForImpl(esValue[implSymbol]["searchParams"]);
          });
        }

        get hash() {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'get hash' called on an object that is not a valid instance of URL.",
            );
          }

          return esValue[implSymbol]["hash"];
        }

        set hash(V) {
          const esValue =
            this !== null && this !== undefined ? this : globalObject;

          if (!exports.is(esValue)) {
            throw new globalObject.TypeError(
              "'set hash' called on an object that is not a valid instance of URL.",
            );
          }

          V = conversions["USVString"](V, {
            context:
              "Failed to set the 'hash' property on 'URL': The provided value",
            globals: globalObject,
          });

          esValue[implSymbol]["hash"] = V;
        }
      }
      Object.defineProperties(URL.prototype, {
        toJSON: { enumerable: true },
        href: { enumerable: true },
        toString: { enumerable: true },
        origin: { enumerable: true },
        protocol: { enumerable: true },
        username: { enumerable: true },
        password: { enumerable: true },
        host: { enumerable: true },
        hostname: { enumerable: true },
        port: { enumerable: true },
        pathname: { enumerable: true },
        search: { enumerable: true },
        searchParams: { enumerable: true },
        hash: { enumerable: true },
        [Symbol.toStringTag]: { value: "URL", configurable: true },
      });
      ctorRegistry[interfaceName] = URL;

      Object.defineProperty(globalObject, interfaceName, {
        configurable: true,
        writable: true,
        value: URL,
      });

      if (globalNames.includes("Window")) {
        Object.defineProperty(globalObject, "webkitURL", {
          configurable: true,
          writable: true,
          value: URL,
        });
      }
    };

    const Impl = requireURLImpl();
  })(URL$1);
  return URL$1;
}

var hasRequiredWebidl2jsWrapper;

function requireWebidl2jsWrapper() {
  if (hasRequiredWebidl2jsWrapper) return webidl2jsWrapper;
  hasRequiredWebidl2jsWrapper = 1;

  const URL = requireURL();
  const URLSearchParams = requireURLSearchParams();

  webidl2jsWrapper.URL = URL;
  webidl2jsWrapper.URLSearchParams = URLSearchParams;
  return webidl2jsWrapper;
}

var hasRequiredWhatwgUrl;

function requireWhatwgUrl() {
  if (hasRequiredWhatwgUrl) return whatwgUrl;
  hasRequiredWhatwgUrl = 1;

  const { URL, URLSearchParams } = requireWebidl2jsWrapper();
  const urlStateMachine = requireUrlStateMachine();
  const percentEncoding = requirePercentEncoding();

  const sharedGlobalObject = { Array, Object, Promise, String, TypeError };
  URL.install(sharedGlobalObject, ["Window"]);
  URLSearchParams.install(sharedGlobalObject, ["Window"]);

  whatwgUrl.URL = sharedGlobalObject.URL;
  whatwgUrl.URLSearchParams = sharedGlobalObject.URLSearchParams;

  whatwgUrl.parseURL = urlStateMachine.parseURL;
  whatwgUrl.basicURLParse = urlStateMachine.basicURLParse;
  whatwgUrl.serializeURL = urlStateMachine.serializeURL;
  whatwgUrl.serializePath = urlStateMachine.serializePath;
  whatwgUrl.serializeHost = urlStateMachine.serializeHost;
  whatwgUrl.serializeInteger = urlStateMachine.serializeInteger;
  whatwgUrl.serializeURLOrigin = urlStateMachine.serializeURLOrigin;
  whatwgUrl.setTheUsername = urlStateMachine.setTheUsername;
  whatwgUrl.setThePassword = urlStateMachine.setThePassword;
  whatwgUrl.cannotHaveAUsernamePasswordPort =
    urlStateMachine.cannotHaveAUsernamePasswordPort;
  whatwgUrl.hasAnOpaquePath = urlStateMachine.hasAnOpaquePath;

  whatwgUrl.percentDecodeString = percentEncoding.percentDecodeString;
  whatwgUrl.percentDecodeBytes = percentEncoding.percentDecodeBytes;
  return whatwgUrl;
}

var redact = {};

var hasRequiredRedact;

function requireRedact() {
  if (hasRequiredRedact) return redact;
  hasRequiredRedact = 1;
  var __createBinding =
    (commonjsGlobal && commonjsGlobal.__createBinding) ||
    (Object.create
      ? function (o, m, k, k2) {
          if (k2 === undefined) k2 = k;
          var desc = Object.getOwnPropertyDescriptor(m, k);
          if (
            !desc ||
            ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)
          ) {
            desc = {
              enumerable: true,
              get: function () {
                return m[k];
              },
            };
          }
          Object.defineProperty(o, k2, desc);
        }
      : function (o, m, k, k2) {
          if (k2 === undefined) k2 = k;
          o[k2] = m[k];
        });
  var __setModuleDefault =
    (commonjsGlobal && commonjsGlobal.__setModuleDefault) ||
    (Object.create
      ? function (o, v) {
          Object.defineProperty(o, "default", { enumerable: true, value: v });
        }
      : function (o, v) {
          o["default"] = v;
        });
  var __importStar =
    (commonjsGlobal && commonjsGlobal.__importStar) ||
    function (mod) {
      if (mod && mod.__esModule) return mod;
      var result = {};
      if (mod != null)
        for (var k in mod)
          if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k))
            __createBinding(result, mod, k);
      __setModuleDefault(result, mod);
      return result;
    };
  Object.defineProperty(redact, "__esModule", { value: true });
  redact.redactConnectionString = redact.redactValidConnectionString = void 0;
  const index_1 = __importStar(requireLib());
  function redactValidConnectionString(inputUrl, options) {
    var _a, _b;
    const url = inputUrl.clone();
    const replacementString =
      (_a =
        options === null || options === void 0
          ? void 0
          : options.replacementString) !== null && _a !== void 0
        ? _a
        : "_credentials_";
    const redactUsernames =
      (_b =
        options === null || options === void 0
          ? void 0
          : options.redactUsernames) !== null && _b !== void 0
        ? _b
        : true;
    if ((url.username || url.password) && redactUsernames) {
      url.username = replacementString;
      url.password = "";
    } else if (url.password) {
      url.password = replacementString;
    }
    if (url.searchParams.has("authMechanismProperties")) {
      const props = new index_1.CommaAndColonSeparatedRecord(
        url.searchParams.get("authMechanismProperties"),
      );
      if (props.get("AWS_SESSION_TOKEN")) {
        props.set("AWS_SESSION_TOKEN", replacementString);
        url.searchParams.set("authMechanismProperties", props.toString());
      }
    }
    if (url.searchParams.has("tlsCertificateKeyFilePassword")) {
      url.searchParams.set("tlsCertificateKeyFilePassword", replacementString);
    }
    if (url.searchParams.has("proxyUsername") && redactUsernames) {
      url.searchParams.set("proxyUsername", replacementString);
    }
    if (url.searchParams.has("proxyPassword")) {
      url.searchParams.set("proxyPassword", replacementString);
    }
    return url;
  }
  redact.redactValidConnectionString = redactValidConnectionString;
  function redactConnectionString(uri, options) {
    var _a, _b;
    const replacementString =
      (_a =
        options === null || options === void 0
          ? void 0
          : options.replacementString) !== null && _a !== void 0
        ? _a
        : "<credentials>";
    const redactUsernames =
      (_b =
        options === null || options === void 0
          ? void 0
          : options.redactUsernames) !== null && _b !== void 0
        ? _b
        : true;
    let parsed;
    try {
      parsed = new index_1.default(uri);
    } catch (_c) {}
    if (parsed) {
      options = { ...options, replacementString: "___credentials___" };
      return parsed
        .redact(options)
        .toString()
        .replace(/___credentials___/g, replacementString);
    }
    const R = replacementString;
    const replacements = [
      (uri) =>
        uri.replace(
          redactUsernames ? /(\/\/)(.*)(@)/g : /(\/\/[^@]*:)(.*)(@)/g,
          `$1${R}$3`,
        ),
      (uri) => uri.replace(/(AWS_SESSION_TOKEN(:|%3A))([^,&]+)/gi, `$1${R}`),
      (uri) =>
        uri.replace(/(tlsCertificateKeyFilePassword=)([^&]+)/gi, `$1${R}`),
      (uri) =>
        redactUsernames
          ? uri.replace(/(proxyUsername=)([^&]+)/gi, `$1${R}`)
          : uri,
      (uri) => uri.replace(/(proxyPassword=)([^&]+)/gi, `$1${R}`),
    ];
    for (const replacer of replacements) {
      uri = replacer(uri);
    }
    return uri;
  }
  redact.redactConnectionString = redactConnectionString;

  return redact;
}

var hasRequiredLib;

function requireLib() {
  if (hasRequiredLib) return lib$1;
  hasRequiredLib = 1;
  (function (exports) {
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.CommaAndColonSeparatedRecord =
      exports.ConnectionString =
      exports.redactConnectionString =
        void 0;
    const whatwg_url_1 = requireWhatwgUrl();
    const redact_1 = requireRedact();
    Object.defineProperty(exports, "redactConnectionString", {
      enumerable: true,
      get: function () {
        return redact_1.redactConnectionString;
      },
    });
    const DUMMY_HOSTNAME = "__this_is_a_placeholder__";
    function connectionStringHasValidScheme(connectionString) {
      return (
        connectionString.startsWith("mongodb://") ||
        connectionString.startsWith("mongodb+srv://")
      );
    }
    const HOSTS_REGEX =
      /^(?<protocol>[^/]+):\/\/(?:(?<username>[^:@]*)(?::(?<password>[^@]*))?@)?(?<hosts>(?!:)[^/?@]*)(?<rest>.*)/;
    class CaseInsensitiveMap extends Map {
      delete(name) {
        return super.delete(this._normalizeKey(name));
      }
      get(name) {
        return super.get(this._normalizeKey(name));
      }
      has(name) {
        return super.has(this._normalizeKey(name));
      }
      set(name, value) {
        return super.set(this._normalizeKey(name), value);
      }
      _normalizeKey(name) {
        name = `${name}`;
        for (const key of this.keys()) {
          if (key.toLowerCase() === name.toLowerCase()) {
            name = key;
            break;
          }
        }
        return name;
      }
    }
    function caseInsenstiveURLSearchParams(Ctor) {
      return class CaseInsenstiveURLSearchParams extends Ctor {
        append(name, value) {
          return super.append(this._normalizeKey(name), value);
        }
        delete(name) {
          return super.delete(this._normalizeKey(name));
        }
        get(name) {
          return super.get(this._normalizeKey(name));
        }
        getAll(name) {
          return super.getAll(this._normalizeKey(name));
        }
        has(name) {
          return super.has(this._normalizeKey(name));
        }
        set(name, value) {
          return super.set(this._normalizeKey(name), value);
        }
        keys() {
          return super.keys();
        }
        values() {
          return super.values();
        }
        entries() {
          return super.entries();
        }
        [Symbol.iterator]() {
          return super[Symbol.iterator]();
        }
        _normalizeKey(name) {
          return CaseInsensitiveMap.prototype._normalizeKey.call(this, name);
        }
      };
    }
    class URLWithoutHost extends whatwg_url_1.URL {}
    class MongoParseError extends Error {
      get name() {
        return "MongoParseError";
      }
    }
    class ConnectionString extends URLWithoutHost {
      constructor(uri, options = {}) {
        var _a;
        const { looseValidation } = options;
        if (!looseValidation && !connectionStringHasValidScheme(uri)) {
          throw new MongoParseError(
            'Invalid scheme, expected connection string to start with "mongodb://" or "mongodb+srv://"',
          );
        }
        const match = uri.match(HOSTS_REGEX);
        if (!match) {
          throw new MongoParseError(`Invalid connection string "${uri}"`);
        }
        const { protocol, username, password, hosts, rest } =
          (_a = match.groups) !== null && _a !== void 0 ? _a : {};
        if (!looseValidation) {
          if (!protocol || !hosts) {
            throw new MongoParseError(
              `Protocol and host list are required in "${uri}"`,
            );
          }
          const illegalCharacters = /[:/?#[\]@]/gi;
          if (
            username === null || username === void 0
              ? void 0
              : username.match(illegalCharacters)
          ) {
            throw new MongoParseError(
              `Username contains unescaped characters ${username}`,
            );
          }
          if (!username || !password) {
            const uriWithoutProtocol = uri.replace(`${protocol}://`, "");
            if (
              uriWithoutProtocol.startsWith("@") ||
              uriWithoutProtocol.startsWith(":")
            ) {
              throw new MongoParseError("URI contained empty userinfo section");
            }
          }
          if (
            password === null || password === void 0
              ? void 0
              : password.match(illegalCharacters)
          ) {
            throw new MongoParseError("Password contains unescaped characters");
          }
        }
        let authString = "";
        if (typeof username === "string") authString += username;
        if (typeof password === "string") authString += `:${password}`;
        if (authString) authString += "@";
        try {
          super(
            `${protocol.toLowerCase()}://${authString}${DUMMY_HOSTNAME}${rest}`,
          );
        } catch (err) {
          if (looseValidation) {
            new ConnectionString(uri, {
              ...options,
              looseValidation: false,
            });
          }
          if (typeof err.message === "string") {
            err.message = err.message.replace(DUMMY_HOSTNAME, hosts);
          }
          throw err;
        }
        this._hosts = hosts.split(",");
        if (!looseValidation) {
          if (this.isSRV && this.hosts.length !== 1) {
            throw new MongoParseError(
              "mongodb+srv URI cannot have multiple service names",
            );
          }
          if (this.isSRV && this.hosts.some((host) => host.includes(":"))) {
            throw new MongoParseError(
              "mongodb+srv URI cannot have port number",
            );
          }
        }
        if (!this.pathname) {
          this.pathname = "/";
        }
        Object.setPrototypeOf(
          this.searchParams,
          caseInsenstiveURLSearchParams(this.searchParams.constructor)
            .prototype,
        );
      }
      get host() {
        return DUMMY_HOSTNAME;
      }
      set host(_ignored) {
        throw new Error("No single host for connection string");
      }
      get hostname() {
        return DUMMY_HOSTNAME;
      }
      set hostname(_ignored) {
        throw new Error("No single host for connection string");
      }
      get port() {
        return "";
      }
      set port(_ignored) {
        throw new Error("No single host for connection string");
      }
      get href() {
        return this.toString();
      }
      set href(_ignored) {
        throw new Error("Cannot set href for connection strings");
      }
      get isSRV() {
        return this.protocol.includes("srv");
      }
      get hosts() {
        return this._hosts;
      }
      set hosts(list) {
        this._hosts = list;
      }
      toString() {
        return super.toString().replace(DUMMY_HOSTNAME, this.hosts.join(","));
      }
      clone() {
        return new ConnectionString(this.toString(), {
          looseValidation: true,
        });
      }
      redact(options) {
        return (0, redact_1.redactValidConnectionString)(this, options);
      }
      typedSearchParams() {
        return this.searchParams;
      }
      [Symbol.for("nodejs.util.inspect.custom")]() {
        const {
          href,
          origin,
          protocol,
          username,
          password,
          hosts,
          pathname,
          search,
          searchParams,
          hash,
        } = this;
        return {
          href,
          origin,
          protocol,
          username,
          password,
          hosts,
          pathname,
          search,
          searchParams,
          hash,
        };
      }
    }
    exports.ConnectionString = ConnectionString;
    class CommaAndColonSeparatedRecord extends CaseInsensitiveMap {
      constructor(from) {
        super();
        for (const entry of (from !== null && from !== void 0
          ? from
          : ""
        ).split(",")) {
          if (!entry) continue;
          const colonIndex = entry.indexOf(":");
          if (colonIndex === -1) {
            this.set(entry, "");
          } else {
            this.set(entry.slice(0, colonIndex), entry.slice(colonIndex + 1));
          }
        }
      }
      toString() {
        return [...this].map((entry) => entry.join(":")).join(",");
      }
    }
    exports.CommaAndColonSeparatedRecord = CommaAndColonSeparatedRecord;
    exports.default = ConnectionString;
  })(lib$1);
  return lib$1;
}

var client_metadata = {};

const name = "mongodb";
const version = "6.2.0";
const description = "The official MongoDB driver for Node.js";
const main = "lib/index.js";
const files = ["lib", "src", "etc/prepare.js", "mongodb.d.ts", "tsconfig.json"];
const types = "mongodb.d.ts";
const repository = {
  type: "git",
  url: "git@github.com:mongodb/node-mongodb-native.git",
};
const keywords = ["mongodb", "driver", "official"];
const author = {
  name: "The MongoDB NodeJS Team",
  email: "dbx-node@mongodb.com",
};
const dependencies = {
  "@mongodb-js/saslprep": "^1.1.0",
  bson: "^6.2.0",
  "mongodb-connection-string-url": "^2.6.0",
};
const peerDependencies = {
  "@aws-sdk/credential-providers": "^3.188.0",
  "@mongodb-js/zstd": "^1.1.0",
  "gcp-metadata": "^5.2.0",
  kerberos: "^2.0.1",
  "mongodb-client-encryption": ">=6.0.0 <7",
  snappy: "^7.2.2",
  socks: "^2.7.1",
};
const peerDependenciesMeta = {
  "@aws-sdk/credential-providers": { optional: true },
  "@mongodb-js/zstd": { optional: true },
  kerberos: { optional: true },
  snappy: { optional: true },
  "mongodb-client-encryption": { optional: true },
  "gcp-metadata": { optional: true },
  socks: { optional: true },
};
const devDependencies = {
  "@iarna/toml": "^2.2.5",
  "@istanbuljs/nyc-config-typescript": "^1.0.2",
  "@microsoft/api-extractor": "^7.36.4",
  "@microsoft/tsdoc-config": "^0.16.2",
  "@mongodb-js/zstd": "^1.1.0",
  "@octokit/core": "^4.2.4",
  "@types/chai": "^4.3.5",
  "@types/chai-subset": "^1.3.3",
  "@types/express": "^4.17.17",
  "@types/kerberos": "^1.1.2",
  "@types/mocha": "^10.0.1",
  "@types/node": "^20.5.9",
  "@types/saslprep": "^1.0.1",
  "@types/semver": "^7.5.0",
  "@types/sinon": "^10.0.16",
  "@types/sinon-chai": "^3.2.9",
  "@types/whatwg-url": "^11.0.0",
  "@typescript-eslint/eslint-plugin": "^5.62.0",
  "@typescript-eslint/parser": "^5.62.0",
  chai: "^4.3.7",
  "chai-subset": "^1.6.0",
  chalk: "^4.1.2",
  eslint: "^8.48.0",
  "eslint-config-prettier": "^8.10.0",
  "eslint-plugin-import": "^2.28.1",
  "eslint-plugin-prettier": "^4.2.1",
  "eslint-plugin-simple-import-sort": "^10.0.0",
  "eslint-plugin-tsdoc": "^0.2.17",
  "eslint-plugin-unused-imports": "^2.0.0",
  express: "^4.18.2",
  "gcp-metadata": "^5.2.0",
  "js-yaml": "^4.1.0",
  mocha: "^10.2.0",
  "mocha-sinon": "^2.1.2",
  "mongodb-client-encryption": "^6.0.0",
  "mongodb-legacy": "^6.0.0",
  nyc: "^15.1.0",
  prettier: "^2.8.8",
  semver: "^7.5.4",
  sinon: "^15.2.0",
  "sinon-chai": "^3.7.0",
  snappy: "^7.2.2",
  socks: "^2.7.1",
  "source-map-support": "^0.5.21",
  "ts-node": "^10.9.1",
  tsd: "^0.28.1",
  typescript: "^5.0.4",
  "typescript-cached-transpile": "^0.0.6",
  "v8-heapsnapshot": "^1.3.1",
  yargs: "^17.7.2",
};
const license = "Apache-2.0";
const engines = { node: ">=16.20.1" };
const bugs = { url: "https://jira.mongodb.org/projects/NODE/issues/" };
const homepage = "https://github.com/mongodb/node-mongodb-native";
const scripts = {
  "build:evergreen": "node .evergreen/generate_evergreen_tasks.js",
  "build:ts": "node ./node_modules/typescript/bin/tsc",
  "build:dts":
    "npm run build:ts && api-extractor run && node etc/clean_definition_files.cjs && eslint mongodb.d.ts --fix",
  "build:docs": "./etc/docs/build.ts",
  "build:typedoc": "typedoc",
  "build:nightly": "node ./.github/scripts/nightly.mjs",
  "check:bench": "node test/benchmarks/driverBench",
  "check:coverage": "nyc npm run test:all",
  "check:integration-coverage": "nyc npm run check:test",
  "check:lambda":
    "mocha --config test/mocha_lambda.json test/integration/node-specific/examples/handler.test.js",
  "check:lambda:aws":
    "mocha --config test/mocha_lambda.json test/integration/node-specific/examples/aws_handler.test.js",
  "check:lint":
    "npm run build:dts && npm run check:dts && npm run check:eslint && npm run check:tsd",
  "check:eslint":
    "eslint -v && eslint --max-warnings=0 --ext '.js,.ts' src test",
  "check:tsd": "tsd --version && tsd",
  "check:dependencies": "mocha test/action/dependency.test.ts",
  "check:dts":
    "node ./node_modules/typescript/bin/tsc --noEmit mongodb.d.ts && tsd",
  "check:search-indexes":
    "nyc mocha --config test/mocha_mongodb.json test/manual/search-index-management.prose.test.ts",
  "check:test": "mocha --config test/mocha_mongodb.json test/integration",
  "check:unit": "mocha test/unit",
  "check:ts":
    "node ./node_modules/typescript/bin/tsc -v && node ./node_modules/typescript/bin/tsc --noEmit",
  "check:atlas":
    "mocha --config test/manual/mocharc.json test/manual/atlas_connectivity.test.js",
  "check:drivers-atlas-testing":
    "mocha --config test/mocha_mongodb.json test/atlas/drivers_atlas_testing.test.ts",
  "check:adl":
    "mocha --config test/mocha_mongodb.json test/manual/atlas-data-lake-testing",
  "check:aws":
    "nyc mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_aws.test.ts",
  "check:oidc":
    "mocha --config test/mocha_mongodb.json test/manual/mongodb_oidc.prose.test.ts",
  "check:oidc-azure":
    "mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_oidc_azure.prose.test.ts",
  "check:ocsp":
    "mocha --config test/manual/mocharc.json test/manual/ocsp_support.test.js",
  "check:kerberos":
    "nyc mocha --config test/manual/mocharc.json test/manual/kerberos.test.ts",
  "check:tls":
    "mocha --config test/manual/mocharc.json test/manual/tls_support.test.ts",
  "check:ldap":
    "nyc mocha --config test/manual/mocharc.json test/manual/ldap.test.js",
  "check:socks5":
    "mocha --config test/manual/mocharc.json test/manual/socks5.test.ts",
  "check:csfle":
    "mocha --config test/mocha_mongodb.json test/integration/client-side-encryption",
  "check:snappy": "mocha test/unit/assorted/snappy.test.js",
  "fix:eslint": "npm run check:eslint -- --fix",
  prepare: "node etc/prepare.js",
  "preview:docs": "ts-node etc/docs/preview.ts",
  test: "npm run check:lint && npm run test:all",
  "test:all": "npm run check:unit && npm run check:test",
  "update:docs": "npm run build:docs -- --yes",
};
const tsd = {
  directory: "test/types",
  compilerOptions: {
    strict: true,
    target: "esnext",
    module: "commonjs",
    moduleResolution: "node",
  },
};
const require$$4 = {
  name: name,
  version: version,
  description: description,
  main: main,
  files: files,
  types: types,
  repository: repository,
  keywords: keywords,
  author: author,
  dependencies: dependencies,
  peerDependencies: peerDependencies,
  peerDependenciesMeta: peerDependenciesMeta,
  devDependencies: devDependencies,
  license: license,
  engines: engines,
  bugs: bugs,
  homepage: homepage,
  scripts: scripts,
  tsd: tsd,
};

Object.defineProperty(client_metadata, "__esModule", { value: true });
client_metadata.getFAASEnv =
  client_metadata.makeClientMetadata =
  client_metadata.LimitedSizeDocument =
    void 0;
const os = $nodeOs;
const process$2 = process;
const bson_1$7 = bson$2;
const error_1$j = error;
// eslint-disable-next-line @typescript-eslint/no-var-requires
const NODE_DRIVER_VERSION = require$$4.version;
/** @internal */
class LimitedSizeDocument {
  constructor(maxSize) {
    this.maxSize = maxSize;
    this.document = new Map();
    /** BSON overhead: Int32 + Null byte */
    this.documentSize = 5;
  }
  /** Only adds key/value if the bsonByteLength is less than MAX_SIZE */
  ifItFitsItSits(key, value) {
    // The BSON byteLength of the new element is the same as serializing it to its own document
    // subtracting the document size int32 and the null terminator.
    const newElementSize =
      bson_1$7.BSON.serialize(new Map().set(key, value)).byteLength - 5;
    if (newElementSize + this.documentSize > this.maxSize) {
      return false;
    }
    this.documentSize += newElementSize;
    this.document.set(key, value);
    return true;
  }
  toObject() {
    return bson_1$7.BSON.deserialize(bson_1$7.BSON.serialize(this.document), {
      promoteLongs: false,
      promoteBuffers: false,
      promoteValues: false,
      useBigInt64: false,
    });
  }
}
client_metadata.LimitedSizeDocument = LimitedSizeDocument;
/**
 * From the specs:
 * Implementors SHOULD cumulatively update fields in the following order until the document is under the size limit:
 * 1. Omit fields from `env` except `env.name`.
 * 2. Omit fields from `os` except `os.type`.
 * 3. Omit the `env` document entirely.
 * 4. Truncate `platform`. -- special we do not truncate this field
 */
function makeClientMetadata(options) {
  const metadataDocument = new LimitedSizeDocument(512);
  const { appName = "" } = options;
  // Add app name first, it must be sent
  if (appName.length > 0) {
    const name =
      Buffer.byteLength(appName, "utf8") <= 128
        ? options.appName
        : Buffer.from(appName, "utf8").subarray(0, 128).toString("utf8");
    metadataDocument.ifItFitsItSits("application", { name });
  }
  const { name = "", version = "", platform = "" } = options.driverInfo;
  const driverInfo = {
    name: name.length > 0 ? `nodejs|${name}` : "nodejs",
    version:
      version.length > 0
        ? `${NODE_DRIVER_VERSION}|${version}`
        : NODE_DRIVER_VERSION,
  };
  if (!metadataDocument.ifItFitsItSits("driver", driverInfo)) {
    throw new error_1$j.MongoInvalidArgumentError(
      "Unable to include driverInfo name and version, metadata cannot exceed 512 bytes",
    );
  }
  let runtimeInfo = getRuntimeInfo();
  if (platform.length > 0) {
    runtimeInfo = `${runtimeInfo}|${platform}`;
  }
  if (!metadataDocument.ifItFitsItSits("platform", runtimeInfo)) {
    throw new error_1$j.MongoInvalidArgumentError(
      "Unable to include driverInfo platform, metadata cannot exceed 512 bytes",
    );
  }
  // Note: order matters, os.type is last so it will be removed last if we're at maxSize
  const osInfo = new Map()
    .set("name", process$2.platform)
    .set("architecture", process$2.arch)
    .set("version", os.release())
    .set("type", os.type());
  if (!metadataDocument.ifItFitsItSits("os", osInfo)) {
    for (const key of osInfo.keys()) {
      osInfo.delete(key);
      if (osInfo.size === 0) break;
      if (metadataDocument.ifItFitsItSits("os", osInfo)) break;
    }
  }
  const faasEnv = getFAASEnv();
  if (faasEnv != null) {
    if (!metadataDocument.ifItFitsItSits("env", faasEnv)) {
      for (const key of faasEnv.keys()) {
        faasEnv.delete(key);
        if (faasEnv.size === 0) break;
        if (metadataDocument.ifItFitsItSits("env", faasEnv)) break;
      }
    }
  }
  return metadataDocument.toObject();
}
client_metadata.makeClientMetadata = makeClientMetadata;
/**
 * Collects FaaS metadata.
 * - `name` MUST be the last key in the Map returned.
 */
function getFAASEnv() {
  const {
    AWS_EXECUTION_ENV = "",
    AWS_LAMBDA_RUNTIME_API = "",
    FUNCTIONS_WORKER_RUNTIME = "",
    K_SERVICE = "",
    FUNCTION_NAME = "",
    VERCEL = "",
    AWS_LAMBDA_FUNCTION_MEMORY_SIZE = "",
    AWS_REGION = "",
    FUNCTION_MEMORY_MB = "",
    FUNCTION_REGION = "",
    FUNCTION_TIMEOUT_SEC = "",
    VERCEL_REGION = "",
  } = process$2.env;
  const isAWSFaaS =
    AWS_EXECUTION_ENV.startsWith("AWS_Lambda_") ||
    AWS_LAMBDA_RUNTIME_API.length > 0;
  const isAzureFaaS = FUNCTIONS_WORKER_RUNTIME.length > 0;
  const isGCPFaaS = K_SERVICE.length > 0 || FUNCTION_NAME.length > 0;
  const isVercelFaaS = VERCEL.length > 0;
  // Note: order matters, name must always be the last key
  const faasEnv = new Map();
  // When isVercelFaaS is true so is isAWSFaaS; Vercel inherits the AWS env
  if (isVercelFaaS && !(isAzureFaaS || isGCPFaaS)) {
    if (VERCEL_REGION.length > 0) {
      faasEnv.set("region", VERCEL_REGION);
    }
    faasEnv.set("name", "vercel");
    return faasEnv;
  }
  if (isAWSFaaS && !(isAzureFaaS || isGCPFaaS || isVercelFaaS)) {
    if (AWS_REGION.length > 0) {
      faasEnv.set("region", AWS_REGION);
    }
    if (
      AWS_LAMBDA_FUNCTION_MEMORY_SIZE.length > 0 &&
      Number.isInteger(+AWS_LAMBDA_FUNCTION_MEMORY_SIZE)
    ) {
      faasEnv.set(
        "memory_mb",
        new bson_1$7.Int32(AWS_LAMBDA_FUNCTION_MEMORY_SIZE),
      );
    }
    faasEnv.set("name", "aws.lambda");
    return faasEnv;
  }
  if (isAzureFaaS && !(isGCPFaaS || isAWSFaaS || isVercelFaaS)) {
    faasEnv.set("name", "azure.func");
    return faasEnv;
  }
  if (isGCPFaaS && !(isAzureFaaS || isAWSFaaS || isVercelFaaS)) {
    if (FUNCTION_REGION.length > 0) {
      faasEnv.set("region", FUNCTION_REGION);
    }
    if (
      FUNCTION_MEMORY_MB.length > 0 &&
      Number.isInteger(+FUNCTION_MEMORY_MB)
    ) {
      faasEnv.set("memory_mb", new bson_1$7.Int32(FUNCTION_MEMORY_MB));
    }
    if (
      FUNCTION_TIMEOUT_SEC.length > 0 &&
      Number.isInteger(+FUNCTION_TIMEOUT_SEC)
    ) {
      faasEnv.set("timeout_sec", new bson_1$7.Int32(FUNCTION_TIMEOUT_SEC));
    }
    faasEnv.set("name", "gcp.func");
    return faasEnv;
  }
  return null;
}
client_metadata.getFAASEnv = getFAASEnv;
/**
 * @internal
 * Get current JavaScript runtime platform
 *
 * NOTE: The version information fetching is intentionally written defensively
 * to avoid having a released driver version that becomes incompatible
 * with a future change to these global objects.
 */
function getRuntimeInfo() {
  if ("Deno" in globalThis) {
    const version =
      typeof Deno?.version?.deno === "string"
        ? Deno?.version?.deno
        : "0.0.0-unknown";
    return `Deno v${version}, ${os.endianness()}`;
  }
  if ("Bun" in globalThis) {
    const version =
      typeof Bun?.version === "string" ? Bun?.version : "0.0.0-unknown";
    return `Bun v${version}, ${os.endianness()}`;
  }
  return `Node.js ${process$2.version}, ${os.endianness()}`;
}

var compression = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.decompress =
    exports.compress =
    exports.uncompressibleCommands =
    exports.Compressor =
      void 0;
  const util_1 = $noteUtil;
  const zlib = $nodeZlib;
  const constants_1 = constants;
  const deps_1 = deps;
  const error_1 = error;
  /** @public */
  exports.Compressor = Object.freeze({
    none: 0,
    snappy: 1,
    zlib: 2,
    zstd: 3,
  });
  exports.uncompressibleCommands = new Set([
    constants_1.LEGACY_HELLO_COMMAND,
    "saslStart",
    "saslContinue",
    "getnonce",
    "authenticate",
    "createUser",
    "updateUser",
    "copydbSaslStart",
    "copydbgetnonce",
    "copydb",
  ]);
  const ZSTD_COMPRESSION_LEVEL = 3;
  const zlibInflate = (0, util_1.promisify)(zlib.inflate.bind(zlib));
  const zlibDeflate = (0, util_1.promisify)(zlib.deflate.bind(zlib));
  let zstd;
  let Snappy = null;
  function loadSnappy() {
    if (Snappy == null) {
      const snappyImport = (0, deps_1.getSnappy)();
      if ("kModuleError" in snappyImport) {
        throw snappyImport.kModuleError;
      }
      Snappy = snappyImport;
    }
    return Snappy;
  }
  // Facilitate compressing a message using an agreed compressor
  async function compress(options, dataToBeCompressed) {
    const zlibOptions = {};
    switch (options.agreedCompressor) {
      case "snappy": {
        Snappy ??= loadSnappy();
        return Snappy.compress(dataToBeCompressed);
      }
      case "zstd": {
        loadZstd();
        if ("kModuleError" in zstd) {
          throw zstd["kModuleError"];
        }
        return zstd.compress(dataToBeCompressed, ZSTD_COMPRESSION_LEVEL);
      }
      case "zlib": {
        if (options.zlibCompressionLevel) {
          zlibOptions.level = options.zlibCompressionLevel;
        }
        return zlibDeflate(dataToBeCompressed, zlibOptions);
      }
      default: {
        throw new error_1.MongoInvalidArgumentError(
          `Unknown compressor ${options.agreedCompressor} failed to compress`,
        );
      }
    }
  }
  exports.compress = compress;
  // Decompress a message using the given compressor
  async function decompress(compressorID, compressedData) {
    if (
      compressorID !== exports.Compressor.snappy &&
      compressorID !== exports.Compressor.zstd &&
      compressorID !== exports.Compressor.zlib &&
      compressorID !== exports.Compressor.none
    ) {
      throw new error_1.MongoDecompressionError(
        `Server sent message compressed using an unsupported compressor. (Received compressor ID ${compressorID})`,
      );
    }
    switch (compressorID) {
      case exports.Compressor.snappy: {
        Snappy ??= loadSnappy();
        return Snappy.uncompress(compressedData, { asBuffer: true });
      }
      case exports.Compressor.zstd: {
        loadZstd();
        if ("kModuleError" in zstd) {
          throw zstd["kModuleError"];
        }
        return zstd.decompress(compressedData);
      }
      case exports.Compressor.zlib: {
        return zlibInflate(compressedData);
      }
      default: {
        return compressedData;
      }
    }
  }
  exports.decompress = decompress;
  /**
   * Load ZStandard if it is not already set.
   */
  function loadZstd() {
    if (!zstd) {
      zstd = (0, deps_1.getZstdLibrary)();
    }
  }
})(compression);

var encrypter = {};

var auto_encrypter = {};

var crypto_callbacks = {};

Object.defineProperty(crypto_callbacks, "__esModule", { value: true });
crypto_callbacks.hmacSha256Hook =
  crypto_callbacks.hmacSha512Hook =
  crypto_callbacks.aes256CtrDecryptHook =
  crypto_callbacks.aes256CtrEncryptHook =
  crypto_callbacks.aes256CbcDecryptHook =
  crypto_callbacks.aes256CbcEncryptHook =
  crypto_callbacks.signRsaSha256Hook =
  crypto_callbacks.makeHmacHook =
  crypto_callbacks.sha256Hook =
  crypto_callbacks.randomHook =
  crypto_callbacks.makeAES256Hook =
    void 0;
const crypto$3 = $nodeCrypto;
function makeAES256Hook(method, mode) {
  return function (key, iv, input, output) {
    let result;
    try {
      const cipher = crypto$3[method](mode, key, iv);
      cipher.setAutoPadding(false);
      result = cipher.update(input);
      const final = cipher.final();
      if (final.length > 0) {
        result = Buffer.concat([result, final]);
      }
    } catch (e) {
      return e;
    }
    result.copy(output);
    return result.length;
  };
}
crypto_callbacks.makeAES256Hook = makeAES256Hook;
function randomHook(buffer, count) {
  try {
    crypto$3.randomFillSync(buffer, 0, count);
  } catch (e) {
    return e;
  }
  return count;
}
crypto_callbacks.randomHook = randomHook;
function sha256Hook(input, output) {
  let result;
  try {
    result = crypto$3.createHash("sha256").update(input).digest();
  } catch (e) {
    return e;
  }
  result.copy(output);
  return result.length;
}
crypto_callbacks.sha256Hook = sha256Hook;
function makeHmacHook(algorithm) {
  return (key, input, output) => {
    let result;
    try {
      result = crypto$3.createHmac(algorithm, key).update(input).digest();
    } catch (e) {
      return e;
    }
    result.copy(output);
    return result.length;
  };
}
crypto_callbacks.makeHmacHook = makeHmacHook;
function signRsaSha256Hook(key, input, output) {
  let result;
  try {
    const signer = crypto$3.createSign("sha256WithRSAEncryption");
    const privateKey = Buffer.from(
      `-----BEGIN PRIVATE KEY-----\n${key.toString(
        "base64",
      )}\n-----END PRIVATE KEY-----\n`,
    );
    result = signer.update(input).end().sign(privateKey);
  } catch (e) {
    return e;
  }
  result.copy(output);
  return result.length;
}
crypto_callbacks.signRsaSha256Hook = signRsaSha256Hook;
crypto_callbacks.aes256CbcEncryptHook = makeAES256Hook(
  "createCipheriv",
  "aes-256-cbc",
);
crypto_callbacks.aes256CbcDecryptHook = makeAES256Hook(
  "createDecipheriv",
  "aes-256-cbc",
);
crypto_callbacks.aes256CtrEncryptHook = makeAES256Hook(
  "createCipheriv",
  "aes-256-ctr",
);
crypto_callbacks.aes256CtrDecryptHook = makeAES256Hook(
  "createDecipheriv",
  "aes-256-ctr",
);
crypto_callbacks.hmacSha512Hook = makeHmacHook("sha512");
crypto_callbacks.hmacSha256Hook = makeHmacHook("sha256");

var errors$1 = {};

Object.defineProperty(errors$1, "__esModule", { value: true });
errors$1.MongoCryptKMSRequestNetworkTimeoutError =
  errors$1.MongoCryptAzureKMSRequestError =
  errors$1.MongoCryptCreateEncryptedCollectionError =
  errors$1.MongoCryptCreateDataKeyError =
  errors$1.MongoCryptInvalidArgumentError =
  errors$1.MongoCryptError =
    void 0;
const error_1$i = error;
/**
 * @public
 * An error indicating that something went wrong specifically with MongoDB Client Encryption
 */
let MongoCryptError$1 = class MongoCryptError extends error_1$i.MongoError {
  /**
   * **Do not use this constructor!**
   *
   * Meant for internal use only.
   *
   * @remarks
   * This class is only meant to be constructed within the driver. This constructor is
   * not subject to semantic versioning compatibility guarantees and may change at any time.
   *
   * @public
   **/
  constructor(message, options = {}) {
    super(message, options);
  }
  get name() {
    return "MongoCryptError";
  }
};
errors$1.MongoCryptError = MongoCryptError$1;
/**
 * @public
 *
 * An error indicating an invalid argument was provided to an encryption API.
 */
let MongoCryptInvalidArgumentError$1 = class MongoCryptInvalidArgumentError extends MongoCryptError$1 {
  /**
   * **Do not use this constructor!**
   *
   * Meant for internal use only.
   *
   * @remarks
   * This class is only meant to be constructed within the driver. This constructor is
   * not subject to semantic versioning compatibility guarantees and may change at any time.
   *
   * @public
   **/
  constructor(message) {
    super(message);
  }
  get name() {
    return "MongoCryptInvalidArgumentError";
  }
};
errors$1.MongoCryptInvalidArgumentError = MongoCryptInvalidArgumentError$1;
/**
 * @public
 * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create data keys
 */
let MongoCryptCreateDataKeyError$1 = class MongoCryptCreateDataKeyError extends MongoCryptError$1 {
  /**
   * **Do not use this constructor!**
   *
   * Meant for internal use only.
   *
   * @remarks
   * This class is only meant to be constructed within the driver. This constructor is
   * not subject to semantic versioning compatibility guarantees and may change at any time.
   *
   * @public
   **/
  constructor(encryptedFields, { cause }) {
    super(`Unable to complete creating data keys: ${cause.message}`, { cause });
    this.encryptedFields = encryptedFields;
  }
  get name() {
    return "MongoCryptCreateDataKeyError";
  }
};
errors$1.MongoCryptCreateDataKeyError = MongoCryptCreateDataKeyError$1;
/**
 * @public
 * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create a collection
 */
let MongoCryptCreateEncryptedCollectionError$1 = class MongoCryptCreateEncryptedCollectionError extends MongoCryptError$1 {
  /**
   * **Do not use this constructor!**
   *
   * Meant for internal use only.
   *
   * @remarks
   * This class is only meant to be constructed within the driver. This constructor is
   * not subject to semantic versioning compatibility guarantees and may change at any time.
   *
   * @public
   **/
  constructor(encryptedFields, { cause }) {
    super(`Unable to create collection: ${cause.message}`, { cause });
    this.encryptedFields = encryptedFields;
  }
  get name() {
    return "MongoCryptCreateEncryptedCollectionError";
  }
};
errors$1.MongoCryptCreateEncryptedCollectionError =
  MongoCryptCreateEncryptedCollectionError$1;
/**
 * @public
 * An error indicating that mongodb-client-encryption failed to auto-refresh Azure KMS credentials.
 */
let MongoCryptAzureKMSRequestError$1 = class MongoCryptAzureKMSRequestError extends MongoCryptError$1 {
  /**
   * **Do not use this constructor!**
   *
   * Meant for internal use only.
   *
   * @remarks
   * This class is only meant to be constructed within the driver. This constructor is
   * not subject to semantic versioning compatibility guarantees and may change at any time.
   *
   * @public
   **/
  constructor(message, body) {
    super(message);
    this.body = body;
  }
  get name() {
    return "MongoCryptAzureKMSRequestError";
  }
};
errors$1.MongoCryptAzureKMSRequestError = MongoCryptAzureKMSRequestError$1;
/** @public */
let MongoCryptKMSRequestNetworkTimeoutError$1 = class MongoCryptKMSRequestNetworkTimeoutError extends MongoCryptError$1 {
  get name() {
    return "MongoCryptKMSRequestNetworkTimeoutError";
  }
};
errors$1.MongoCryptKMSRequestNetworkTimeoutError =
  MongoCryptKMSRequestNetworkTimeoutError$1;

var mongocryptd_manager = {};

Object.defineProperty(mongocryptd_manager, "__esModule", { value: true });
mongocryptd_manager.MongocryptdManager = void 0;
const error_1$h = error;
/**
 * @internal
 * An internal class that handles spawning a mongocryptd.
 */
class MongocryptdManager {
  constructor(extraOptions = {}) {
    this.uri =
      typeof extraOptions.mongocryptdURI === "string" &&
      extraOptions.mongocryptdURI.length > 0
        ? extraOptions.mongocryptdURI
        : MongocryptdManager.DEFAULT_MONGOCRYPTD_URI;
    this.bypassSpawn = !!extraOptions.mongocryptdBypassSpawn;
    this.spawnPath = extraOptions.mongocryptdSpawnPath || "";
    this.spawnArgs = [];
    if (Array.isArray(extraOptions.mongocryptdSpawnArgs)) {
      this.spawnArgs = this.spawnArgs.concat(extraOptions.mongocryptdSpawnArgs);
    }
    if (
      this.spawnArgs
        .filter((arg) => typeof arg === "string")
        .every((arg) => arg.indexOf("--idleShutdownTimeoutSecs") < 0)
    ) {
      this.spawnArgs.push("--idleShutdownTimeoutSecs", "60");
    }
  }
  /**
   * Will check to see if a mongocryptd is up. If it is not up, it will attempt
   * to spawn a mongocryptd in a detached process, and then wait for it to be up.
   */
  async spawn() {
    const cmdName = this.spawnPath || "mongocryptd";
    // eslint-disable-next-line @typescript-eslint/no-var-requires
    const { spawn } = $nodeChildProcess;
    // Spawned with stdio: ignore and detached: true
    // to ensure child can outlive parent.
    this._child = spawn(cmdName, this.spawnArgs, {
      stdio: "ignore",
      detached: true,
    });
    this._child.on("error", () => {
      // From the FLE spec:
      // "The stdout and stderr of the spawned process MUST not be exposed in the driver
      // (e.g. redirect to /dev/null). Users can pass the argument --logpath to
      // extraOptions.mongocryptdSpawnArgs if they need to inspect mongocryptd logs.
      // If spawning is necessary, the driver MUST spawn mongocryptd whenever server
      // selection on the MongoClient to mongocryptd fails. If the MongoClient fails to
      // connect after spawning, the server selection error is propagated to the user."
      // The AutoEncrypter and MongoCryptdManager should work together to spawn
      // mongocryptd whenever necessary.  Additionally, the `mongocryptd` intentionally
      // shuts down after 60s and gets respawned when necessary.  We rely on server
      // selection timeouts when connecting to the `mongocryptd` to inform users that something
      // has been configured incorrectly.  For those reasons, we suppress stderr from
      // the `mongocryptd` process and immediately unref the process.
    });
    // unref child to remove handle from event loop
    this._child.unref();
  }
  /**
   * @returns the result of `fn` or rejects with an error.
   */
  async withRespawn(fn) {
    try {
      const result = await fn();
      return result;
    } catch (err) {
      // If we are not bypassing spawning, then we should retry once on a MongoTimeoutError (server selection error)
      const shouldSpawn =
        err instanceof error_1$h.MongoNetworkTimeoutError && !this.bypassSpawn;
      if (!shouldSpawn) {
        throw err;
      }
    }
    await this.spawn();
    const result = await fn();
    return result;
  }
}
MongocryptdManager.DEFAULT_MONGOCRYPTD_URI = "mongodb://localhost:27020";
mongocryptd_manager.MongocryptdManager = MongocryptdManager;

var providers = {};

var aws = {};

Object.defineProperty(aws, "__esModule", { value: true });
aws.loadAWSCredentials = void 0;
const deps_1$4 = deps;
/**
 * @internal
 */
async function loadAWSCredentials(kmsProviders) {
  const credentialProvider = (0, deps_1$4.getAwsCredentialProvider)();
  if ("kModuleError" in credentialProvider) {
    return kmsProviders;
  }
  const { fromNodeProviderChain } = credentialProvider;
  const provider = fromNodeProviderChain();
  // The state machine is the only place calling this so it will
  // catch if there is a rejection here.
  const aws = await provider();
  return { ...kmsProviders, aws };
}
aws.loadAWSCredentials = loadAWSCredentials;

var azure = {};

var utils = {};

Object.defineProperty(utils, "__esModule", { value: true });
utils.get = void 0;
const http = $nodeHttp;
const timers_1$2 = $nodeTimers;
const errors_1$2 = errors$1;
/**
 * @internal
 */
function get(url, options = {}) {
  return new Promise((resolve, reject) => {
    /* eslint-disable prefer-const */
    let timeoutId;
    const request = http
      .get(url, options, (response) => {
        response.setEncoding("utf8");
        let body = "";
        response.on("data", (chunk) => (body += chunk));
        response.on("end", () => {
          (0, timers_1$2.clearTimeout)(timeoutId);
          resolve({ status: response.statusCode, body });
        });
      })
      .on("error", (error) => {
        (0, timers_1$2.clearTimeout)(timeoutId);
        reject(error);
      })
      .end();
    timeoutId = (0, timers_1$2.setTimeout)(() => {
      request.destroy(
        new errors_1$2.MongoCryptKMSRequestNetworkTimeoutError(
          `request timed out after 10 seconds`,
        ),
      );
    }, 10000);
  });
}
utils.get = get;

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.loadAzureCredentials =
    exports.fetchAzureKMSToken =
    exports.prepareRequest =
    exports.tokenCache =
    exports.AzureCredentialCache =
      void 0;
  const errors_1 = errors$1;
  const utils_1 = utils;
  const MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS = 6000;
  /**
   * @internal
   */
  class AzureCredentialCache {
    constructor() {
      this.cachedToken = null;
    }
    async getToken() {
      if (this.cachedToken == null || this.needsRefresh(this.cachedToken)) {
        this.cachedToken = await this._getToken();
      }
      return { accessToken: this.cachedToken.accessToken };
    }
    needsRefresh(token) {
      const timeUntilExpirationMS = token.expiresOnTimestamp - Date.now();
      return timeUntilExpirationMS <= MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS;
    }
    /**
     * exposed for testing
     */
    resetCache() {
      this.cachedToken = null;
    }
    /**
     * exposed for testing
     */
    _getToken() {
      return fetchAzureKMSToken();
    }
  }
  exports.AzureCredentialCache = AzureCredentialCache;
  /** @internal */
  exports.tokenCache = new AzureCredentialCache();
  /** @internal */
  async function parseResponse(response) {
    const { status, body: rawBody } = response;
    const body = (() => {
      try {
        return JSON.parse(rawBody);
      } catch {
        throw new errors_1.MongoCryptAzureKMSRequestError(
          "Malformed JSON body in GET request.",
        );
      }
    })();
    if (status !== 200) {
      throw new errors_1.MongoCryptAzureKMSRequestError(
        "Unable to complete request.",
        body,
      );
    }
    if (!body.access_token) {
      throw new errors_1.MongoCryptAzureKMSRequestError(
        "Malformed response body - missing field `access_token`.",
      );
    }
    if (!body.expires_in) {
      throw new errors_1.MongoCryptAzureKMSRequestError(
        "Malformed response body - missing field `expires_in`.",
      );
    }
    const expiresInMS = Number(body.expires_in) * 1000;
    if (Number.isNaN(expiresInMS)) {
      throw new errors_1.MongoCryptAzureKMSRequestError(
        "Malformed response body - unable to parse int from `expires_in` field.",
      );
    }
    return {
      accessToken: body.access_token,
      expiresOnTimestamp: Date.now() + expiresInMS,
    };
  }
  /**
   * @internal
   *
   * parses any options provided by prose tests to `fetchAzureKMSToken` and merges them with
   * the default values for headers and the request url.
   */
  function prepareRequest(options) {
    const url = new URL(
      options.url?.toString() ??
        "http://169.254.169.254/metadata/identity/oauth2/token",
    );
    url.searchParams.append("api-version", "2018-02-01");
    url.searchParams.append("resource", "https://vault.azure.net");
    const headers = {
      ...options.headers,
      "Content-Type": "application/json",
      Metadata: true,
    };
    return { headers, url };
  }
  exports.prepareRequest = prepareRequest;
  /**
   * @internal
   *
   * `AzureKMSRequestOptions` allows prose tests to modify the http request sent to the idms
   * servers.  This is required to simulate different server conditions.  No options are expected to
   * be set outside of tests.
   *
   * exposed for CSFLE
   * [prose test 18](https://github.com/mongodb/specifications/tree/master/source/client-side-encryption/tests#azure-imds-credentials)
   */
  async function fetchAzureKMSToken(options = {}) {
    const { headers, url } = prepareRequest(options);
    const response = await (0, utils_1.get)(url, { headers }).catch((error) => {
      if (error instanceof errors_1.MongoCryptKMSRequestNetworkTimeoutError) {
        throw new errors_1.MongoCryptAzureKMSRequestError(
          `[Azure KMS] ${error.message}`,
        );
      }
      throw error;
    });
    return parseResponse(response);
  }
  exports.fetchAzureKMSToken = fetchAzureKMSToken;
  /**
   * @internal
   *
   * @throws Will reject with a `MongoCryptError` if the http request fails or the http response is malformed.
   */
  async function loadAzureCredentials(kmsProviders) {
    const azure = await exports.tokenCache.getToken();
    return { ...kmsProviders, azure };
  }
  exports.loadAzureCredentials = loadAzureCredentials;
})(azure);

var gcp = {};

Object.defineProperty(gcp, "__esModule", { value: true });
gcp.loadGCPCredentials = void 0;
const deps_1$3 = deps;
/** @internal */
async function loadGCPCredentials(kmsProviders) {
  const gcpMetadata = (0, deps_1$3.getGcpMetadata)();
  if ("kModuleError" in gcpMetadata) {
    return kmsProviders;
  }
  const { access_token: accessToken } = await gcpMetadata.instance({
    property: "service-accounts/default/token",
  });
  return { ...kmsProviders, gcp: { accessToken } };
}
gcp.loadGCPCredentials = loadGCPCredentials;

Object.defineProperty(providers, "__esModule", { value: true });
providers.refreshKMSCredentials = providers.isEmptyCredentials = void 0;
const aws_1 = aws;
const azure_1 = azure;
const gcp_1 = gcp;
/**
 * Auto credential fetching should only occur when the provider is defined on the kmsProviders map
 * and the settings are an empty object.
 *
 * This is distinct from a nullish provider key.
 *
 * @internal - exposed for testing purposes only
 */
function isEmptyCredentials(providerName, kmsProviders) {
  const provider = kmsProviders[providerName];
  if (provider == null) {
    return false;
  }
  return typeof provider === "object" && Object.keys(provider).length === 0;
}
providers.isEmptyCredentials = isEmptyCredentials;
/**
 * Load cloud provider credentials for the user provided KMS providers.
 * Credentials will only attempt to get loaded if they do not exist
 * and no existing credentials will get overwritten.
 *
 * @internal
 */
async function refreshKMSCredentials(kmsProviders) {
  let finalKMSProviders = kmsProviders;
  if (isEmptyCredentials("aws", kmsProviders)) {
    finalKMSProviders = await (0, aws_1.loadAWSCredentials)(finalKMSProviders);
  }
  if (isEmptyCredentials("gcp", kmsProviders)) {
    finalKMSProviders = await (0, gcp_1.loadGCPCredentials)(finalKMSProviders);
  }
  if (isEmptyCredentials("azure", kmsProviders)) {
    finalKMSProviders = await (0, azure_1.loadAzureCredentials)(
      finalKMSProviders,
    );
  }
  return finalKMSProviders;
}
providers.refreshKMSCredentials = refreshKMSCredentials;

var state_machine = {};

Object.defineProperty(state_machine, "__esModule", { value: true });
state_machine.StateMachine = void 0;
const fs$1 = $nodeFsPromises;
const net = $nodeNet;
const tls = $nodeTls;
const bson_1$6 = bson$2;
const deps_1$2 = deps;
const utils_1$c = utils$2;
const errors_1$1 = errors$1;
let socks = null;
function loadSocks() {
  if (socks == null) {
    const socksImport = (0, deps_1$2.getSocks)();
    if ("kModuleError" in socksImport) {
      throw socksImport.kModuleError;
    }
    socks = socksImport;
  }
  return socks;
}
// libmongocrypt states
const MONGOCRYPT_CTX_ERROR = 0;
const MONGOCRYPT_CTX_NEED_MONGO_COLLINFO = 1;
const MONGOCRYPT_CTX_NEED_MONGO_MARKINGS = 2;
const MONGOCRYPT_CTX_NEED_MONGO_KEYS = 3;
const MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS = 7;
const MONGOCRYPT_CTX_NEED_KMS = 4;
const MONGOCRYPT_CTX_READY = 5;
const MONGOCRYPT_CTX_DONE = 6;
const HTTPS_PORT = 443;
const stateToString = new Map([
  [MONGOCRYPT_CTX_ERROR, "MONGOCRYPT_CTX_ERROR"],
  [MONGOCRYPT_CTX_NEED_MONGO_COLLINFO, "MONGOCRYPT_CTX_NEED_MONGO_COLLINFO"],
  [MONGOCRYPT_CTX_NEED_MONGO_MARKINGS, "MONGOCRYPT_CTX_NEED_MONGO_MARKINGS"],
  [MONGOCRYPT_CTX_NEED_MONGO_KEYS, "MONGOCRYPT_CTX_NEED_MONGO_KEYS"],
  [MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS, "MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS"],
  [MONGOCRYPT_CTX_NEED_KMS, "MONGOCRYPT_CTX_NEED_KMS"],
  [MONGOCRYPT_CTX_READY, "MONGOCRYPT_CTX_READY"],
  [MONGOCRYPT_CTX_DONE, "MONGOCRYPT_CTX_DONE"],
]);
const INSECURE_TLS_OPTIONS = [
  "tlsInsecure",
  "tlsAllowInvalidCertificates",
  "tlsAllowInvalidHostnames",
  // These options are disallowed by the spec, so we explicitly filter them out if provided, even
  // though the StateMachine does not declare support for these options.
  "tlsDisableOCSPEndpointCheck",
  "tlsDisableCertificateRevocationCheck",
];
/**
 * Helper function for logging. Enabled by setting the environment flag MONGODB_CRYPT_DEBUG.
 * @param msg - Anything you want to be logged.
 */
function debug(msg) {
  if (process.env.MONGODB_CRYPT_DEBUG) {
    // eslint-disable-next-line no-console
    console.error(msg);
  }
}
/**
 * @internal
 * An internal class that executes across a MongoCryptContext until either
 * a finishing state or an error is reached. Do not instantiate directly.
 */
class StateMachine {
  constructor(
    options,
    bsonOptions = (0, bson_1$6.pluckBSONSerializeOptions)(options),
  ) {
    this.options = options;
    this.bsonOptions = bsonOptions;
  }
  /**
   * Executes the state machine according to the specification
   */
  async execute(executor, context) {
    const keyVaultNamespace = executor._keyVaultNamespace;
    const keyVaultClient = executor._keyVaultClient;
    const metaDataClient = executor._metaDataClient;
    const mongocryptdClient = executor._mongocryptdClient;
    const mongocryptdManager = executor._mongocryptdManager;
    let result = null;
    while (
      context.state !== MONGOCRYPT_CTX_DONE &&
      context.state !== MONGOCRYPT_CTX_ERROR
    ) {
      debug(
        `[context#${context.id}] ${
          stateToString.get(context.state) || context.state
        }`,
      );
      switch (context.state) {
        case MONGOCRYPT_CTX_NEED_MONGO_COLLINFO: {
          const filter = (0, bson_1$6.deserialize)(
            context.nextMongoOperation(),
          );
          if (!metaDataClient) {
            throw new errors_1$1.MongoCryptError(
              "unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_COLLINFO but metadata client is undefined",
            );
          }
          const collInfo = await this.fetchCollectionInfo(
            metaDataClient,
            context.ns,
            filter,
          );
          if (collInfo) {
            context.addMongoOperationResponse(collInfo);
          }
          context.finishMongoOperation();
          break;
        }
        case MONGOCRYPT_CTX_NEED_MONGO_MARKINGS: {
          const command = context.nextMongoOperation();
          if (!mongocryptdClient) {
            throw new errors_1$1.MongoCryptError(
              "unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_MARKINGS but mongocryptdClient is undefined",
            );
          }
          // When we are using the shared library, we don't have a mongocryptd manager.
          const markedCommand = mongocryptdManager
            ? await mongocryptdManager.withRespawn(
                this.markCommand.bind(
                  this,
                  mongocryptdClient,
                  context.ns,
                  command,
                ),
              )
            : await this.markCommand(mongocryptdClient, context.ns, command);
          context.addMongoOperationResponse(markedCommand);
          context.finishMongoOperation();
          break;
        }
        case MONGOCRYPT_CTX_NEED_MONGO_KEYS: {
          const filter = context.nextMongoOperation();
          const keys = await this.fetchKeys(
            keyVaultClient,
            keyVaultNamespace,
            filter,
          );
          if (keys.length === 0) {
            // This is kind of a hack.  For `rewrapManyDataKey`, we have tests that
            // guarantee that when there are no matching keys, `rewrapManyDataKey` returns
            // nothing.  We also have tests for auto encryption that guarantee for `encrypt`
            // we return an error when there are no matching keys.  This error is generated in
            // subsequent iterations of the state machine.
            // Some apis (`encrypt`) throw if there are no filter matches and others (`rewrapManyDataKey`)
            // do not.  We set the result manually here, and let the state machine continue.  `libmongocrypt`
            // will inform us if we need to error by setting the state to `MONGOCRYPT_CTX_ERROR` but
            // otherwise we'll return `{ v: [] }`.
            result = { v: [] };
          }
          for await (const key of keys) {
            context.addMongoOperationResponse((0, bson_1$6.serialize)(key));
          }
          context.finishMongoOperation();
          break;
        }
        case MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS: {
          const kmsProviders = await executor.askForKMSCredentials();
          context.provideKMSProviders((0, bson_1$6.serialize)(kmsProviders));
          break;
        }
        case MONGOCRYPT_CTX_NEED_KMS: {
          const requests = Array.from(this.requests(context));
          await Promise.all(requests);
          context.finishKMSRequests();
          break;
        }
        case MONGOCRYPT_CTX_READY: {
          const finalizedContext = context.finalize();
          // @ts-expect-error finalize can change the state, check for error
          if (context.state === MONGOCRYPT_CTX_ERROR) {
            const message = context.status.message || "Finalization error";
            throw new errors_1$1.MongoCryptError(message);
          }
          result = (0, bson_1$6.deserialize)(finalizedContext, this.options);
          break;
        }
        default:
          throw new errors_1$1.MongoCryptError(
            `Unknown state: ${context.state}`,
          );
      }
    }
    if (context.state === MONGOCRYPT_CTX_ERROR || result == null) {
      const message = context.status.message;
      if (!message) {
        debug(
          `unidentifiable error in MongoCrypt - received an error status from \`libmongocrypt\` but received no error message.`,
        );
      }
      throw new errors_1$1.MongoCryptError(
        message ??
          "unidentifiable error in MongoCrypt - received an error status from `libmongocrypt` but received no error message.",
      );
    }
    return result;
  }
  /**
   * Handles the request to the KMS service. Exposed for testing purposes. Do not directly invoke.
   * @param kmsContext - A C++ KMS context returned from the bindings
   * @returns A promise that resolves when the KMS reply has be fully parsed
   */
  kmsRequest(request) {
    const parsedUrl = request.endpoint.split(":");
    const port =
      parsedUrl[1] != null ? Number.parseInt(parsedUrl[1], 10) : HTTPS_PORT;
    const options = {
      host: parsedUrl[0],
      servername: parsedUrl[0],
      port,
    };
    const message = request.message;
    // TODO(NODE-3959): We can adopt `for-await on(socket, 'data')` with logic to control abort
    // eslint-disable-next-line @typescript-eslint/no-misused-promises, no-async-promise-executor
    return new Promise(async (resolve, reject) => {
      const buffer = new utils_1$c.BufferPool();
      // eslint-disable-next-line prefer-const
      let socket;
      let rawSocket;
      function destroySockets() {
        for (const sock of [socket, rawSocket]) {
          if (sock) {
            sock.removeAllListeners();
            sock.destroy();
          }
        }
      }
      function ontimeout() {
        destroySockets();
        reject(new errors_1$1.MongoCryptError("KMS request timed out"));
      }
      function onerror(err) {
        destroySockets();
        const mcError = new errors_1$1.MongoCryptError("KMS request failed", {
          cause: err,
        });
        reject(mcError);
      }
      if (this.options.proxyOptions && this.options.proxyOptions.proxyHost) {
        rawSocket = net.connect({
          host: this.options.proxyOptions.proxyHost,
          port: this.options.proxyOptions.proxyPort || 1080,
        });
        rawSocket.on("timeout", ontimeout);
        rawSocket.on("error", onerror);
        try {
          // eslint-disable-next-line @typescript-eslint/no-var-requires
          const events = require("events");
          await events.once(rawSocket, "connect");
          socks ??= loadSocks();
          options.socket = (
            await socks.SocksClient.createConnection({
              existing_socket: rawSocket,
              command: "connect",
              destination: { host: options.host, port: options.port },
              proxy: {
                // host and port are ignored because we pass existing_socket
                host: "iLoveJavaScript",
                port: 0,
                type: 5,
                userId: this.options.proxyOptions.proxyUsername,
                password: this.options.proxyOptions.proxyPassword,
              },
            })
          ).socket;
        } catch (err) {
          return onerror(err);
        }
      }
      const tlsOptions = this.options.tlsOptions;
      if (tlsOptions) {
        const kmsProvider = request.kmsProvider;
        const providerTlsOptions = tlsOptions[kmsProvider];
        if (providerTlsOptions) {
          const error = this.validateTlsOptions(
            kmsProvider,
            providerTlsOptions,
          );
          if (error) reject(error);
          try {
            await this.setTlsOptions(providerTlsOptions, options);
          } catch (error) {
            return onerror(error);
          }
        }
      }
      socket = tls.connect(options, () => {
        socket.write(message);
      });
      socket.once("timeout", ontimeout);
      socket.once("error", onerror);
      socket.on("data", (data) => {
        buffer.append(data);
        while (request.bytesNeeded > 0 && buffer.length) {
          const bytesNeeded = Math.min(request.bytesNeeded, buffer.length);
          request.addResponse(buffer.read(bytesNeeded));
        }
        if (request.bytesNeeded <= 0) {
          // There's no need for any more activity on this socket at this point.
          destroySockets();
          resolve();
        }
      });
    });
  }
  *requests(context) {
    for (
      let request = context.nextKMSRequest();
      request != null;
      request = context.nextKMSRequest()
    ) {
      yield this.kmsRequest(request);
    }
  }
  /**
   * Validates the provided TLS options are secure.
   *
   * @param kmsProvider - The KMS provider name.
   * @param tlsOptions - The client TLS options for the provider.
   *
   * @returns An error if any option is invalid.
   */
  validateTlsOptions(kmsProvider, tlsOptions) {
    const tlsOptionNames = Object.keys(tlsOptions);
    for (const option of INSECURE_TLS_OPTIONS) {
      if (tlsOptionNames.includes(option)) {
        return new errors_1$1.MongoCryptError(
          `Insecure TLS options prohibited for ${kmsProvider}: ${option}`,
        );
      }
    }
  }
  /**
   * Sets only the valid secure TLS options.
   *
   * @param tlsOptions - The client TLS options for the provider.
   * @param options - The existing connection options.
   */
  async setTlsOptions(tlsOptions, options) {
    if (tlsOptions.tlsCertificateKeyFile) {
      const cert = await fs$1.readFile(tlsOptions.tlsCertificateKeyFile);
      options.cert = options.key = cert;
    }
    if (tlsOptions.tlsCAFile) {
      options.ca = await fs$1.readFile(tlsOptions.tlsCAFile);
    }
    if (tlsOptions.tlsCertificateKeyFilePassword) {
      options.passphrase = tlsOptions.tlsCertificateKeyFilePassword;
    }
  }
  /**
   * Fetches collection info for a provided namespace, when libmongocrypt
   * enters the `MONGOCRYPT_CTX_NEED_MONGO_COLLINFO` state. The result is
   * used to inform libmongocrypt of the schema associated with this
   * namespace. Exposed for testing purposes. Do not directly invoke.
   *
   * @param client - A MongoClient connected to the topology
   * @param ns - The namespace to list collections from
   * @param filter - A filter for the listCollections command
   * @param callback - Invoked with the info of the requested collection, or with an error
   */
  async fetchCollectionInfo(client, ns, filter) {
    const { db } = utils_1$c.MongoDBCollectionNamespace.fromString(ns);
    const collections = await client
      .db(db)
      .listCollections(filter, {
        promoteLongs: false,
        promoteValues: false,
      })
      .toArray();
    const info =
      collections.length > 0 ? (0, bson_1$6.serialize)(collections[0]) : null;
    return info;
  }
  /**
   * Calls to the mongocryptd to provide markings for a command.
   * Exposed for testing purposes. Do not directly invoke.
   * @param client - A MongoClient connected to a mongocryptd
   * @param ns - The namespace (database.collection) the command is being executed on
   * @param command - The command to execute.
   * @param callback - Invoked with the serialized and marked bson command, or with an error
   */
  async markCommand(client, ns, command) {
    const options = { promoteLongs: false, promoteValues: false };
    const { db } = utils_1$c.MongoDBCollectionNamespace.fromString(ns);
    const rawCommand = (0, bson_1$6.deserialize)(command, options);
    const response = await client.db(db).command(rawCommand, options);
    return (0, bson_1$6.serialize)(response, this.bsonOptions);
  }
  /**
   * Requests keys from the keyVault collection on the topology.
   * Exposed for testing purposes. Do not directly invoke.
   * @param client - A MongoClient connected to the topology
   * @param keyVaultNamespace - The namespace (database.collection) of the keyVault Collection
   * @param filter - The filter for the find query against the keyVault Collection
   * @param callback - Invoked with the found keys, or with an error
   */
  fetchKeys(client, keyVaultNamespace, filter) {
    const { db: dbName, collection: collectionName } =
      utils_1$c.MongoDBCollectionNamespace.fromString(keyVaultNamespace);
    return client
      .db(dbName)
      .collection(collectionName, { readConcern: { level: "majority" } })
      .find((0, bson_1$6.deserialize)(filter))
      .toArray();
  }
}
state_machine.StateMachine = StateMachine;

var hasRequiredAuto_encrypter;

function requireAuto_encrypter() {
  if (hasRequiredAuto_encrypter) return auto_encrypter;
  hasRequiredAuto_encrypter = 1;
  var _a;
  Object.defineProperty(auto_encrypter, "__esModule", { value: true });
  auto_encrypter.AutoEncrypter = auto_encrypter.AutoEncryptionLoggerLevel =
    void 0;
  const bson_1 = bson$2;
  const deps_1 = deps;
  const error_1 = error;
  const mongo_client_1 = requireMongo_client();
  const utils_1 = utils$2;
  const cryptoCallbacks = crypto_callbacks;
  const errors_1 = errors$1;
  const mongocryptd_manager_1 = mongocryptd_manager;
  const providers_1 = providers;
  const state_machine_1 = state_machine;
  /** @public */
  auto_encrypter.AutoEncryptionLoggerLevel = Object.freeze({
    FatalError: 0,
    Error: 1,
    Warning: 2,
    Info: 3,
    Trace: 4,
  });
  // Typescript errors if we index objects with `Symbol.for(...)`, so
  // to avoid TS errors we pull them out into variables.  Then we can type
  // the objects (and class) that we expect to see them on and prevent TS
  // errors.
  /** @internal */
  const kDecorateResult = Symbol.for("@@mdb.decorateDecryptionResult");
  /** @internal */
  const kDecoratedKeys = Symbol.for("@@mdb.decryptedKeys");
  /**
   * @internal An internal class to be used by the driver for auto encryption
   * **NOTE**: Not meant to be instantiated directly, this is for internal use only.
   */
  class AutoEncrypter {
    /** @internal */
    static getMongoCrypt() {
      const encryption = (0, deps_1.getMongoDBClientEncryption)();
      if ("kModuleError" in encryption) {
        throw encryption.kModuleError;
      }
      return encryption.MongoCrypt;
    }
    /**
     * Create an AutoEncrypter
     *
     * **Note**: Do not instantiate this class directly. Rather, supply the relevant options to a MongoClient
     *
     * **Note**: Supplying `options.schemaMap` provides more security than relying on JSON Schemas obtained from the server.
     * It protects against a malicious server advertising a false JSON Schema, which could trick the client into sending unencrypted data that should be encrypted.
     * Schemas supplied in the schemaMap only apply to configuring automatic encryption for Client-Side Field Level Encryption.
     * Other validation rules in the JSON schema will not be enforced by the driver and will result in an error.
     *
     * @example <caption>Create an AutoEncrypter that makes use of mongocryptd</caption>
     * ```ts
     * // Enabling autoEncryption via a MongoClient using mongocryptd
     * const { MongoClient } = require('mongodb');
     * const client = new MongoClient(URL, {
     *   autoEncryption: {
     *     kmsProviders: {
     *       aws: {
     *         accessKeyId: AWS_ACCESS_KEY,
     *         secretAccessKey: AWS_SECRET_KEY
     *       }
     *     }
     *   }
     * });
     * ```
     *
     * await client.connect();
     * // From here on, the client will be encrypting / decrypting automatically
     * @example <caption>Create an AutoEncrypter that makes use of libmongocrypt's CSFLE shared library</caption>
     * ```ts
     * // Enabling autoEncryption via a MongoClient using CSFLE shared library
     * const { MongoClient } = require('mongodb');
     * const client = new MongoClient(URL, {
     *   autoEncryption: {
     *     kmsProviders: {
     *       aws: {}
     *     },
     *     extraOptions: {
     *       cryptSharedLibPath: '/path/to/local/crypt/shared/lib',
     *       cryptSharedLibRequired: true
     *     }
     *   }
     * });
     * ```
     *
     * await client.connect();
     * // From here on, the client will be encrypting / decrypting automatically
     */
    constructor(client, options) {
      /**
       * Used by devtools to enable decorating decryption results.
       *
       * When set and enabled, `decrypt` will automatically recursively
       * traverse a decrypted document and if a field has been decrypted,
       * it will mark it as decrypted.  Compass uses this to determine which
       * fields were decrypted.
       */
      this[_a] = false;
      this._client = client;
      this._bypassEncryption = options.bypassAutoEncryption === true;
      this._keyVaultNamespace = options.keyVaultNamespace || "admin.datakeys";
      this._keyVaultClient = options.keyVaultClient || client;
      this._metaDataClient = options.metadataClient || client;
      this._proxyOptions = options.proxyOptions || {};
      this._tlsOptions = options.tlsOptions || {};
      this._kmsProviders = options.kmsProviders || {};
      const mongoCryptOptions = {
        cryptoCallbacks,
      };
      if (options.schemaMap) {
        mongoCryptOptions.schemaMap = Buffer.isBuffer(options.schemaMap)
          ? options.schemaMap
          : (0, bson_1.serialize)(options.schemaMap);
      }
      if (options.encryptedFieldsMap) {
        mongoCryptOptions.encryptedFieldsMap = Buffer.isBuffer(
          options.encryptedFieldsMap,
        )
          ? options.encryptedFieldsMap
          : (0, bson_1.serialize)(options.encryptedFieldsMap);
      }
      mongoCryptOptions.kmsProviders = !Buffer.isBuffer(this._kmsProviders)
        ? (0, bson_1.serialize)(this._kmsProviders)
        : this._kmsProviders;
      if (options.options?.logger) {
        mongoCryptOptions.logger = options.options.logger;
      }
      if (options.extraOptions && options.extraOptions.cryptSharedLibPath) {
        mongoCryptOptions.cryptSharedLibPath =
          options.extraOptions.cryptSharedLibPath;
      }
      if (options.bypassQueryAnalysis) {
        mongoCryptOptions.bypassQueryAnalysis = options.bypassQueryAnalysis;
      }
      this._bypassMongocryptdAndCryptShared =
        this._bypassEncryption || !!options.bypassQueryAnalysis;
      if (
        options.extraOptions &&
        options.extraOptions.cryptSharedLibSearchPaths
      ) {
        // Only for driver testing
        mongoCryptOptions.cryptSharedLibSearchPaths =
          options.extraOptions.cryptSharedLibSearchPaths;
      } else if (!this._bypassMongocryptdAndCryptShared) {
        mongoCryptOptions.cryptSharedLibSearchPaths = ["$SYSTEM"];
      }
      const MongoCrypt = AutoEncrypter.getMongoCrypt();
      this._mongocrypt = new MongoCrypt(mongoCryptOptions);
      this._contextCounter = 0;
      if (
        options.extraOptions &&
        options.extraOptions.cryptSharedLibRequired &&
        !this.cryptSharedLibVersionInfo
      ) {
        throw new errors_1.MongoCryptInvalidArgumentError(
          "`cryptSharedLibRequired` set but no crypt_shared library loaded",
        );
      }
      // Only instantiate mongocryptd manager/client once we know for sure
      // that we are not using the CSFLE shared library.
      if (
        !this._bypassMongocryptdAndCryptShared &&
        !this.cryptSharedLibVersionInfo
      ) {
        this._mongocryptdManager = new mongocryptd_manager_1.MongocryptdManager(
          options.extraOptions,
        );
        const clientOptions = {
          serverSelectionTimeoutMS: 10000,
        };
        if (
          options.extraOptions == null ||
          typeof options.extraOptions.mongocryptdURI !== "string"
        ) {
          clientOptions.family = 4;
        }
        this._mongocryptdClient = new mongo_client_1.MongoClient(
          this._mongocryptdManager.uri,
          clientOptions,
        );
      }
    }
    /**
     * Initializes the auto encrypter by spawning a mongocryptd and connecting to it.
     *
     * This function is a no-op when bypassSpawn is set or the crypt shared library is used.
     */
    async init() {
      if (
        this._bypassMongocryptdAndCryptShared ||
        this.cryptSharedLibVersionInfo
      ) {
        return;
      }
      if (!this._mongocryptdManager) {
        throw new error_1.MongoRuntimeError(
          "Reached impossible state: mongocryptdManager is undefined when neither bypassSpawn nor the shared lib are specified.",
        );
      }
      if (!this._mongocryptdClient) {
        throw new error_1.MongoRuntimeError(
          "Reached impossible state: mongocryptdClient is undefined when neither bypassSpawn nor the shared lib are specified.",
        );
      }
      if (!this._mongocryptdManager.bypassSpawn) {
        await this._mongocryptdManager.spawn();
      }
      try {
        const client = await this._mongocryptdClient.connect();
        return client;
      } catch (error) {
        const { message } = error;
        if (
          message &&
          (message.match(/timed out after/) || message.match(/ENOTFOUND/))
        ) {
          throw new error_1.MongoRuntimeError(
            "Unable to connect to `mongocryptd`, please make sure it is running or in your PATH for auto-spawn",
            { cause: error },
          );
        }
        throw error;
      }
    }
    /**
     * Cleans up the `_mongocryptdClient`, if present.
     */
    async teardown(force) {
      await this._mongocryptdClient?.close(force);
    }
    /**
     * Encrypt a command for a given namespace.
     */
    async encrypt(ns, cmd, options = {}) {
      if (this._bypassEncryption) {
        // If `bypassAutoEncryption` has been specified, don't encrypt
        return cmd;
      }
      const commandBuffer = Buffer.isBuffer(cmd)
        ? cmd
        : (0, bson_1.serialize)(cmd, options);
      const context = this._mongocrypt.makeEncryptionContext(
        utils_1.MongoDBCollectionNamespace.fromString(ns).db,
        commandBuffer,
      );
      context.id = this._contextCounter++;
      context.ns = ns;
      context.document = cmd;
      const stateMachine = new state_machine_1.StateMachine({
        promoteValues: false,
        promoteLongs: false,
        proxyOptions: this._proxyOptions,
        tlsOptions: this._tlsOptions,
      });
      return stateMachine.execute(this, context);
    }
    /**
     * Decrypt a command response
     */
    async decrypt(response, options = {}) {
      const buffer = Buffer.isBuffer(response)
        ? response
        : (0, bson_1.serialize)(response, options);
      const context = this._mongocrypt.makeDecryptionContext(buffer);
      context.id = this._contextCounter++;
      const stateMachine = new state_machine_1.StateMachine({
        ...options,
        proxyOptions: this._proxyOptions,
        tlsOptions: this._tlsOptions,
      });
      const decorateResult = this[kDecorateResult];
      const result = await stateMachine.execute(this, context);
      if (decorateResult) {
        decorateDecryptionResult(result, response);
      }
      return result;
    }
    /**
     * Ask the user for KMS credentials.
     *
     * This returns anything that looks like the kmsProviders original input
     * option. It can be empty, and any provider specified here will override
     * the original ones.
     */
    async askForKMSCredentials() {
      return (0, providers_1.refreshKMSCredentials)(this._kmsProviders);
    }
    /**
     * Return the current libmongocrypt's CSFLE shared library version
     * as `{ version: bigint, versionStr: string }`, or `null` if no CSFLE
     * shared library was loaded.
     */
    get cryptSharedLibVersionInfo() {
      return this._mongocrypt.cryptSharedLibVersionInfo;
    }
    static get libmongocryptVersion() {
      return AutoEncrypter.getMongoCrypt().libmongocryptVersion;
    }
  }
  auto_encrypter.AutoEncrypter = AutoEncrypter;
  _a = kDecorateResult;
  /**
   * Recurse through the (identically-shaped) `decrypted` and `original`
   * objects and attach a `decryptedKeys` property on each sub-object that
   * contained encrypted fields. Because we only call this on BSON responses,
   * we do not need to worry about circular references.
   *
   * @internal
   */
  function decorateDecryptionResult(
    decrypted,
    original,
    isTopLevelDecorateCall = true,
  ) {
    if (isTopLevelDecorateCall) {
      // The original value could have been either a JS object or a BSON buffer
      if (Buffer.isBuffer(original)) {
        original = (0, bson_1.deserialize)(original);
      }
      if (Buffer.isBuffer(decrypted)) {
        throw new error_1.MongoRuntimeError(
          "Expected result of decryption to be deserialized BSON object",
        );
      }
    }
    if (!decrypted || typeof decrypted !== "object") return;
    for (const k of Object.keys(decrypted)) {
      const originalValue = original[k];
      // An object was decrypted by libmongocrypt if and only if it was
      // a BSON Binary object with subtype 6.
      if (
        originalValue &&
        originalValue._bsontype === "Binary" &&
        originalValue.sub_type === 6
      ) {
        if (!decrypted[kDecoratedKeys]) {
          Object.defineProperty(decrypted, kDecoratedKeys, {
            value: [],
            configurable: true,
            enumerable: false,
            writable: false,
          });
        }
        // this is defined in the preceding if-statement
        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
        decrypted[kDecoratedKeys].push(k);
        // Do not recurse into this decrypted value. It could be a sub-document/array,
        // in which case there is no original value associated with its subfields.
        continue;
      }
      decorateDecryptionResult(decrypted[k], originalValue, false);
    }
  }

  return auto_encrypter;
}

var hasRequiredEncrypter;

function requireEncrypter() {
  if (hasRequiredEncrypter) return encrypter;
  hasRequiredEncrypter = 1;
  Object.defineProperty(encrypter, "__esModule", { value: true });
  encrypter.Encrypter = void 0;
  const util_1 = $noteUtil;
  const auto_encrypter_1 = requireAuto_encrypter();
  const constants_1 = constants;
  const deps_1 = deps;
  const error_1 = error;
  const mongo_client_1 = requireMongo_client();
  /** @internal */
  const kInternalClient = Symbol("internalClient");
  /** @internal */
  class Encrypter {
    constructor(client, uri, options) {
      if (typeof options.autoEncryption !== "object") {
        throw new error_1.MongoInvalidArgumentError(
          'Option "autoEncryption" must be specified',
        );
      }
      // initialize to null, if we call getInternalClient, we may set this it is important to not overwrite those function calls.
      this[kInternalClient] = null;
      this.bypassAutoEncryption = !!options.autoEncryption.bypassAutoEncryption;
      this.needsConnecting = false;
      if (
        options.maxPoolSize === 0 &&
        options.autoEncryption.keyVaultClient == null
      ) {
        options.autoEncryption.keyVaultClient = client;
      } else if (options.autoEncryption.keyVaultClient == null) {
        options.autoEncryption.keyVaultClient = this.getInternalClient(
          client,
          uri,
          options,
        );
      }
      if (this.bypassAutoEncryption) {
        options.autoEncryption.metadataClient = undefined;
      } else if (options.maxPoolSize === 0) {
        options.autoEncryption.metadataClient = client;
      } else {
        options.autoEncryption.metadataClient = this.getInternalClient(
          client,
          uri,
          options,
        );
      }
      if (options.proxyHost) {
        options.autoEncryption.proxyOptions = {
          proxyHost: options.proxyHost,
          proxyPort: options.proxyPort,
          proxyUsername: options.proxyUsername,
          proxyPassword: options.proxyPassword,
        };
      }
      this.autoEncrypter = new auto_encrypter_1.AutoEncrypter(
        client,
        options.autoEncryption,
      );
    }
    getInternalClient(client, uri, options) {
      // TODO(NODE-4144): Remove new variable for type narrowing
      let internalClient = this[kInternalClient];
      if (internalClient == null) {
        const clonedOptions = {};
        for (const key of [
          ...Object.getOwnPropertyNames(options),
          ...Object.getOwnPropertySymbols(options),
        ]) {
          if (
            [
              "autoEncryption",
              "minPoolSize",
              "servers",
              "caseTranslate",
              "dbName",
            ].includes(key)
          )
            continue;
          Reflect.set(clonedOptions, key, Reflect.get(options, key));
        }
        clonedOptions.minPoolSize = 0;
        internalClient = new mongo_client_1.MongoClient(uri, clonedOptions);
        this[kInternalClient] = internalClient;
        for (const eventName of constants_1.MONGO_CLIENT_EVENTS) {
          for (const listener of client.listeners(eventName)) {
            internalClient.on(eventName, listener);
          }
        }
        client.on("newListener", (eventName, listener) => {
          internalClient?.on(eventName, listener);
        });
        this.needsConnecting = true;
      }
      return internalClient;
    }
    async connectInternalClient() {
      // TODO(NODE-4144): Remove new variable for type narrowing
      const internalClient = this[kInternalClient];
      if (this.needsConnecting && internalClient != null) {
        this.needsConnecting = false;
        await internalClient.connect();
      }
    }
    closeCallback(client, force, callback) {
      (0, util_1.callbackify)(this.close.bind(this))(client, force, callback);
    }
    async close(client, force) {
      const maybeError = await this.autoEncrypter
        .teardown(!!force)
        .catch((e) => e);
      const internalClient = this[kInternalClient];
      if (internalClient != null && client !== internalClient) {
        return internalClient.close(force);
      }
      if (maybeError) {
        throw maybeError;
      }
    }
    static checkForMongoCrypt() {
      const mongodbClientEncryption = (0, deps_1.getMongoDBClientEncryption)();
      if ("kModuleError" in mongodbClientEncryption) {
        throw new error_1.MongoMissingDependencyError(
          "Auto-encryption requested, but the module is not installed. " +
            "Please add `mongodb-client-encryption` as a dependency of your project",
        );
      }
    }
  }
  encrypter.Encrypter = Encrypter;

  return encrypter;
}

var mongo_logger = {};

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.MongoLogger =
    exports.stringifyWithMaxLen =
    exports.createStdioLogger =
    exports.MongoLoggableComponent =
    exports.SEVERITY_LEVEL_MAP =
    exports.DEFAULT_MAX_DOCUMENT_LENGTH =
    exports.SeverityLevel =
      void 0;
  const bson_1 = bson$1;
  const util_1 = $noteUtil;
  const constants_1 = constants;
  const utils_1 = utils$2;
  /** @internal */
  exports.SeverityLevel = Object.freeze({
    EMERGENCY: "emergency",
    ALERT: "alert",
    CRITICAL: "critical",
    ERROR: "error",
    WARNING: "warn",
    NOTICE: "notice",
    INFORMATIONAL: "info",
    DEBUG: "debug",
    TRACE: "trace",
    OFF: "off",
  });
  /** @internal */
  exports.DEFAULT_MAX_DOCUMENT_LENGTH = 1000;
  /** @internal */
  class SeverityLevelMap extends Map {
    constructor(entries) {
      const newEntries = [];
      for (const [level, value] of entries) {
        newEntries.push([value, level]);
      }
      newEntries.push(...entries);
      super(newEntries);
    }
    getNumericSeverityLevel(severity) {
      return this.get(severity);
    }
    getSeverityLevelName(level) {
      return this.get(level);
    }
  }
  /** @internal */
  exports.SEVERITY_LEVEL_MAP = new SeverityLevelMap([
    [exports.SeverityLevel.OFF, -Infinity],
    [exports.SeverityLevel.EMERGENCY, 0],
    [exports.SeverityLevel.ALERT, 1],
    [exports.SeverityLevel.CRITICAL, 2],
    [exports.SeverityLevel.ERROR, 3],
    [exports.SeverityLevel.WARNING, 4],
    [exports.SeverityLevel.NOTICE, 5],
    [exports.SeverityLevel.INFORMATIONAL, 6],
    [exports.SeverityLevel.DEBUG, 7],
    [exports.SeverityLevel.TRACE, 8],
  ]);
  /** @internal */
  exports.MongoLoggableComponent = Object.freeze({
    COMMAND: "command",
    TOPOLOGY: "topology",
    SERVER_SELECTION: "serverSelection",
    CONNECTION: "connection",
  });
  /**
   * Parses a string as one of SeverityLevel
   *
   * @param s - the value to be parsed
   * @returns one of SeverityLevel if value can be parsed as such, otherwise null
   */
  function parseSeverityFromString(s) {
    const validSeverities = Object.values(exports.SeverityLevel);
    const lowerSeverity = s?.toLowerCase();
    if (lowerSeverity != null && validSeverities.includes(lowerSeverity)) {
      return lowerSeverity;
    }
    return null;
  }
  /** @internal */
  function createStdioLogger(stream) {
    return {
      write: (log) => {
        stream.write(
          (0, util_1.inspect)(log, { compact: true, breakLength: Infinity }),
          "utf-8",
        );
        return;
      },
    };
  }
  exports.createStdioLogger = createStdioLogger;
  /**
   * resolves the MONGODB_LOG_PATH and mongodbLogPath options from the environment and the
   * mongo client options respectively. The mongodbLogPath can be either 'stdout', 'stderr', a NodeJS
   * Writable or an object which has a `write` method with the signature:
   * ```ts
   * write(log: Log): void
   * ```
   *
   * @returns the MongoDBLogWritable object to write logs to
   */
  function resolveLogPath({ MONGODB_LOG_PATH }, { mongodbLogPath }) {
    if (
      typeof mongodbLogPath === "string" &&
      /^stderr$/i.test(mongodbLogPath)
    ) {
      return createStdioLogger(process.stderr);
    }
    if (
      typeof mongodbLogPath === "string" &&
      /^stdout$/i.test(mongodbLogPath)
    ) {
      return createStdioLogger(process.stdout);
    }
    if (
      typeof mongodbLogPath === "object" &&
      typeof mongodbLogPath?.write === "function"
    ) {
      return mongodbLogPath;
    }
    if (MONGODB_LOG_PATH && /^stderr$/i.test(MONGODB_LOG_PATH)) {
      return createStdioLogger(process.stderr);
    }
    if (MONGODB_LOG_PATH && /^stdout$/i.test(MONGODB_LOG_PATH)) {
      return createStdioLogger(process.stdout);
    }
    return createStdioLogger(process.stderr);
  }
  function compareSeverity(s0, s1) {
    const s0Num = exports.SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s0);
    const s1Num = exports.SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s1);
    return s0Num < s1Num ? -1 : s0Num > s1Num ? 1 : 0;
  }
  /** @internal */
  function stringifyWithMaxLen(value, maxDocumentLength) {
    const ejson = bson_1.EJSON.stringify(value);
    return maxDocumentLength !== 0 && ejson.length > maxDocumentLength
      ? `${ejson.slice(0, maxDocumentLength)}...`
      : ejson;
  }
  exports.stringifyWithMaxLen = stringifyWithMaxLen;
  function isLogConvertible(obj) {
    const objAsLogConvertible = obj;
    // eslint-disable-next-line no-restricted-syntax
    return (
      objAsLogConvertible.toLog !== undefined &&
      typeof objAsLogConvertible.toLog === "function"
    );
  }
  function attachCommandFields(log, commandEvent) {
    log.commandName = commandEvent.commandName;
    log.requestId = commandEvent.requestId;
    log.driverConnectionId = commandEvent?.connectionId;
    const { host, port } = utils_1.HostAddress.fromString(
      commandEvent.address,
    ).toHostPort();
    log.serverHost = host;
    log.serverPort = port;
    if (commandEvent?.serviceId) {
      log.serviceId = commandEvent.serviceId.toHexString();
    }
    return log;
  }
  function attachConnectionFields(log, connectionPoolEvent) {
    const { host, port } = utils_1.HostAddress.fromString(
      connectionPoolEvent.address,
    ).toHostPort();
    log.serverHost = host;
    log.serverPort = port;
    return log;
  }
  function defaultLogTransform(
    logObject,
    maxDocumentLength = exports.DEFAULT_MAX_DOCUMENT_LENGTH,
  ) {
    let log = Object.create(null);
    switch (logObject.name) {
      case constants_1.COMMAND_STARTED:
        log = attachCommandFields(log, logObject);
        log.message = "Command started";
        log.command = stringifyWithMaxLen(logObject.command, maxDocumentLength);
        log.databaseName = logObject.databaseName;
        return log;
      case constants_1.COMMAND_SUCCEEDED:
        log = attachCommandFields(log, logObject);
        log.message = "Command succeeded";
        log.durationMS = logObject.duration;
        log.reply = stringifyWithMaxLen(logObject.reply, maxDocumentLength);
        return log;
      case constants_1.COMMAND_FAILED:
        log = attachCommandFields(log, logObject);
        log.message = "Command failed";
        log.durationMS = logObject.duration;
        log.failure = logObject.failure;
        return log;
      case constants_1.CONNECTION_POOL_CREATED:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection pool created";
        if (logObject.options) {
          const {
            maxIdleTimeMS,
            minPoolSize,
            maxPoolSize,
            maxConnecting,
            waitQueueTimeoutMS,
          } = logObject.options;
          log = {
            ...log,
            maxIdleTimeMS,
            minPoolSize,
            maxPoolSize,
            maxConnecting,
            waitQueueTimeoutMS,
          };
        }
        return log;
      case constants_1.CONNECTION_POOL_READY:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection pool ready";
        return log;
      case constants_1.CONNECTION_POOL_CLEARED:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection pool cleared";
        if (logObject.serviceId?._bsontype === "ObjectId") {
          log.serviceId = logObject.serviceId.toHexString();
        }
        return log;
      case constants_1.CONNECTION_POOL_CLOSED:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection pool closed";
        return log;
      case constants_1.CONNECTION_CREATED:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection created";
        log.driverConnectionId = logObject.connectionId;
        return log;
      case constants_1.CONNECTION_READY:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection ready";
        log.driverConnectionId = logObject.connectionId;
        return log;
      case constants_1.CONNECTION_CLOSED:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection closed";
        log.driverConnectionId = logObject.connectionId;
        switch (logObject.reason) {
          case "stale":
            log.reason = "Connection became stale because the pool was cleared";
            break;
          case "idle":
            log.reason =
              "Connection has been available but unused for longer than the configured max idle time";
            break;
          case "error":
            log.reason = "An error occurred while using the connection";
            if (logObject.error) {
              log.error = logObject.error;
            }
            break;
          case "poolClosed":
            log.reason = "Connection pool was closed";
            break;
          default:
            log.reason = `Unknown close reason: ${logObject.reason}`;
        }
        return log;
      case constants_1.CONNECTION_CHECK_OUT_STARTED:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection checkout started";
        return log;
      case constants_1.CONNECTION_CHECK_OUT_FAILED:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection checkout failed";
        switch (logObject.reason) {
          case "poolClosed":
            log.reason = "Connection pool was closed";
            break;
          case "timeout":
            log.reason =
              "Wait queue timeout elapsed without a connection becoming available";
            break;
          case "connectionError":
            log.reason =
              "An error occurred while trying to establish a new connection";
            if (logObject.error) {
              log.error = logObject.error;
            }
            break;
          default:
            log.reason = `Unknown close reason: ${logObject.reason}`;
        }
        return log;
      case constants_1.CONNECTION_CHECKED_OUT:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection checked out";
        log.driverConnectionId = logObject.connectionId;
        return log;
      case constants_1.CONNECTION_CHECKED_IN:
        log = attachConnectionFields(log, logObject);
        log.message = "Connection checked in";
        log.driverConnectionId = logObject.connectionId;
        return log;
      default:
        for (const [key, value] of Object.entries(logObject)) {
          if (value != null) log[key] = value;
        }
    }
    return log;
  }
  /** @internal */
  class MongoLogger {
    constructor(options) {
      /**
       * This method should be used when logging errors that do not have a public driver API for
       * reporting errors.
       */
      this.error = this.log.bind(this, "error");
      /**
       * This method should be used to log situations where undesirable application behaviour might
       * occur. For example, failing to end sessions on `MongoClient.close`.
       */
      this.warn = this.log.bind(this, "warn");
      /**
       * This method should be used to report high-level information about normal driver behaviour.
       * For example, the creation of a `MongoClient`.
       */
      this.info = this.log.bind(this, "info");
      /**
       * This method should be used to report information that would be helpful when debugging an
       * application. For example, a command starting, succeeding or failing.
       */
      this.debug = this.log.bind(this, "debug");
      /**
       * This method should be used to report fine-grained details related to logic flow. For example,
       * entering and exiting a function body.
       */
      this.trace = this.log.bind(this, "trace");
      this.componentSeverities = options.componentSeverities;
      this.maxDocumentLength = options.maxDocumentLength;
      this.logDestination = options.logDestination;
    }
    log(severity, component, message) {
      if (compareSeverity(severity, this.componentSeverities[component]) > 0)
        return;
      let logMessage = { t: new Date(), c: component, s: severity };
      if (typeof message === "string") {
        logMessage.message = message;
      } else if (typeof message === "object") {
        if (isLogConvertible(message)) {
          logMessage = { ...logMessage, ...message.toLog() };
        } else {
          logMessage = {
            ...logMessage,
            ...defaultLogTransform(message, this.maxDocumentLength),
          };
        }
      }
      this.logDestination.write(logMessage);
    }
    /**
     * Merges options set through environment variables and the MongoClient, preferring environment
     * variables when both are set, and substituting defaults for values not set. Options set in
     * constructor take precedence over both environment variables and MongoClient options.
     *
     * @remarks
     * When parsing component severity levels, invalid values are treated as unset and replaced with
     * the default severity.
     *
     * @param envOptions - options set for the logger from the environment
     * @param clientOptions - options set for the logger in the MongoClient options
     * @returns a MongoLoggerOptions object to be used when instantiating a new MongoLogger
     */
    static resolveOptions(envOptions, clientOptions) {
      // client options take precedence over env options
      const combinedOptions = {
        ...envOptions,
        ...clientOptions,
        mongodbLogPath: resolveLogPath(envOptions, clientOptions),
      };
      const defaultSeverity =
        parseSeverityFromString(combinedOptions.MONGODB_LOG_ALL) ??
        exports.SeverityLevel.OFF;
      return {
        componentSeverities: {
          command:
            parseSeverityFromString(combinedOptions.MONGODB_LOG_COMMAND) ??
            defaultSeverity,
          topology:
            parseSeverityFromString(combinedOptions.MONGODB_LOG_TOPOLOGY) ??
            defaultSeverity,
          serverSelection:
            parseSeverityFromString(
              combinedOptions.MONGODB_LOG_SERVER_SELECTION,
            ) ?? defaultSeverity,
          connection:
            parseSeverityFromString(combinedOptions.MONGODB_LOG_CONNECTION) ??
            defaultSeverity,
          default: defaultSeverity,
        },
        maxDocumentLength:
          (0, utils_1.parseUnsignedInteger)(
            combinedOptions.MONGODB_LOG_MAX_DOCUMENT_LENGTH,
          ) ?? 1000,
        logDestination: combinedOptions.mongodbLogPath,
      };
    }
  }
  exports.MongoLogger = MongoLogger;
})(mongo_logger);

var hasRequiredConnection_string;

function requireConnection_string() {
  if (hasRequiredConnection_string) return connection_string;
  hasRequiredConnection_string = 1;
  (function (exports) {
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.FEATURE_FLAGS =
      exports.DEFAULT_OPTIONS =
      exports.OPTIONS =
      exports.parseOptions =
      exports.resolveSRVRecord =
        void 0;
    const dns = $nodeDns;
    const mongodb_connection_string_url_1 = requireLib();
    const url_1 = $nodeUrl;
    const mongo_credentials_1 = mongo_credentials;
    const providers_1 = providers$1;
    const client_metadata_1 = client_metadata;
    const compression_1 = compression;
    const encrypter_1 = requireEncrypter();
    const error_1 = error;
    const mongo_client_1 = requireMongo_client();
    const mongo_logger_1 = mongo_logger;
    const read_concern_1 = read_concern;
    const read_preference_1 = read_preference;
    const utils_1 = utils$2;
    const write_concern_1 = write_concern;
    const VALID_TXT_RECORDS = ["authSource", "replicaSet", "loadBalanced"];
    const LB_SINGLE_HOST_ERROR =
      "loadBalanced option only supported with a single host in the URI";
    const LB_REPLICA_SET_ERROR =
      "loadBalanced option not supported with a replicaSet option";
    const LB_DIRECT_CONNECTION_ERROR =
      "loadBalanced option not supported when directConnection is provided";
    /**
     * Lookup a `mongodb+srv` connection string, combine the parts and reparse it as a normal
     * connection string.
     *
     * @param uri - The connection string to parse
     * @param options - Optional user provided connection string options
     */
    async function resolveSRVRecord(options) {
      if (typeof options.srvHost !== "string") {
        throw new error_1.MongoAPIError('Option "srvHost" must not be empty');
      }
      if (options.srvHost.split(".").length < 3) {
        // TODO(NODE-3484): Replace with MongoConnectionStringError
        throw new error_1.MongoAPIError(
          "URI must include hostname, domain name, and tld",
        );
      }
      // Resolve the SRV record and use the result as the list of hosts to connect to.
      const lookupAddress = options.srvHost;
      const addresses = await dns.promises.resolveSrv(
        `_${options.srvServiceName}._tcp.${lookupAddress}`,
      );
      if (addresses.length === 0) {
        throw new error_1.MongoAPIError("No addresses found at host");
      }
      for (const { name } of addresses) {
        if (!(0, utils_1.matchesParentDomain)(name, lookupAddress)) {
          throw new error_1.MongoAPIError(
            "Server record does not share hostname with parent URI",
          );
        }
      }
      const hostAddresses = addresses.map((r) =>
        utils_1.HostAddress.fromString(`${r.name}:${r.port ?? 27017}`),
      );
      validateLoadBalancedOptions(hostAddresses, options, true);
      // Resolve TXT record and add options from there if they exist.
      let record;
      try {
        record = await dns.promises.resolveTxt(lookupAddress);
      } catch (error) {
        if (error.code !== "ENODATA" && error.code !== "ENOTFOUND") {
          throw error;
        }
        return hostAddresses;
      }
      if (record.length > 1) {
        throw new error_1.MongoParseError("Multiple text records not allowed");
      }
      const txtRecordOptions = new url_1.URLSearchParams(record[0].join(""));
      const txtRecordOptionKeys = [...txtRecordOptions.keys()];
      if (txtRecordOptionKeys.some((key) => !VALID_TXT_RECORDS.includes(key))) {
        throw new error_1.MongoParseError(
          `Text record may only set any of: ${VALID_TXT_RECORDS.join(", ")}`,
        );
      }
      if (
        VALID_TXT_RECORDS.some((option) => txtRecordOptions.get(option) === "")
      ) {
        throw new error_1.MongoParseError(
          "Cannot have empty URI params in DNS TXT Record",
        );
      }
      const source = txtRecordOptions.get("authSource") ?? undefined;
      const replicaSet = txtRecordOptions.get("replicaSet") ?? undefined;
      const loadBalanced = txtRecordOptions.get("loadBalanced") ?? undefined;
      if (
        !options.userSpecifiedAuthSource &&
        source &&
        options.credentials &&
        !providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(
          options.credentials.mechanism,
        )
      ) {
        options.credentials = mongo_credentials_1.MongoCredentials.merge(
          options.credentials,
          { source },
        );
      }
      if (!options.userSpecifiedReplicaSet && replicaSet) {
        options.replicaSet = replicaSet;
      }
      if (loadBalanced === "true") {
        options.loadBalanced = true;
      }
      if (options.replicaSet && options.srvMaxHosts > 0) {
        throw new error_1.MongoParseError(
          "Cannot combine replicaSet option with srvMaxHosts",
        );
      }
      validateLoadBalancedOptions(hostAddresses, options, true);
      return hostAddresses;
    }
    exports.resolveSRVRecord = resolveSRVRecord;
    /**
     * Checks if TLS options are valid
     *
     * @param allOptions - All options provided by user or included in default options map
     * @throws MongoAPIError if TLS options are invalid
     */
    function checkTLSOptions(allOptions) {
      if (!allOptions) return;
      const check = (a, b) => {
        if (allOptions.has(a) && allOptions.has(b)) {
          throw new error_1.MongoAPIError(
            `The '${a}' option cannot be used with the '${b}' option`,
          );
        }
      };
      check("tlsInsecure", "tlsAllowInvalidCertificates");
      check("tlsInsecure", "tlsAllowInvalidHostnames");
      check("tlsInsecure", "tlsDisableCertificateRevocationCheck");
      check("tlsInsecure", "tlsDisableOCSPEndpointCheck");
      check(
        "tlsAllowInvalidCertificates",
        "tlsDisableCertificateRevocationCheck",
      );
      check("tlsAllowInvalidCertificates", "tlsDisableOCSPEndpointCheck");
      check(
        "tlsDisableCertificateRevocationCheck",
        "tlsDisableOCSPEndpointCheck",
      );
    }
    function getBoolean(name, value) {
      if (typeof value === "boolean") return value;
      switch (value) {
        case "true":
          return true;
        case "false":
          return false;
        default:
          throw new error_1.MongoParseError(
            `${name} must be either "true" or "false"`,
          );
      }
    }
    function getIntFromOptions(name, value) {
      const parsedInt = (0, utils_1.parseInteger)(value);
      if (parsedInt != null) {
        return parsedInt;
      }
      throw new error_1.MongoParseError(
        `Expected ${name} to be stringified int value, got: ${value}`,
      );
    }
    function getUIntFromOptions(name, value) {
      const parsedValue = getIntFromOptions(name, value);
      if (parsedValue < 0) {
        throw new error_1.MongoParseError(
          `${name} can only be a positive int value, got: ${value}`,
        );
      }
      return parsedValue;
    }
    function* entriesFromString(value) {
      if (value === "") {
        return;
      }
      const keyValuePairs = value.split(",");
      for (const keyValue of keyValuePairs) {
        const [key, value] = keyValue.split(/:(.*)/);
        if (value == null) {
          throw new error_1.MongoParseError(
            "Cannot have undefined values in key value pairs",
          );
        }
        yield [key, value];
      }
    }
    class CaseInsensitiveMap extends Map {
      constructor(entries = []) {
        super(entries.map(([k, v]) => [k.toLowerCase(), v]));
      }
      has(k) {
        return super.has(k.toLowerCase());
      }
      get(k) {
        return super.get(k.toLowerCase());
      }
      set(k, v) {
        return super.set(k.toLowerCase(), v);
      }
      delete(k) {
        return super.delete(k.toLowerCase());
      }
    }
    function parseOptions(uri, mongoClient = undefined, options = {}) {
      if (
        mongoClient != null &&
        !(mongoClient instanceof mongo_client_1.MongoClient)
      ) {
        options = mongoClient;
        mongoClient = undefined;
      }
      // validate BSONOptions
      if (
        options.useBigInt64 &&
        typeof options.promoteLongs === "boolean" &&
        !options.promoteLongs
      ) {
        throw new error_1.MongoAPIError(
          "Must request either bigint or Long for int64 deserialization",
        );
      }
      if (
        options.useBigInt64 &&
        typeof options.promoteValues === "boolean" &&
        !options.promoteValues
      ) {
        throw new error_1.MongoAPIError(
          "Must request either bigint or Long for int64 deserialization",
        );
      }
      const url = new mongodb_connection_string_url_1.default(uri);
      const { hosts, isSRV } = url;
      const mongoOptions = Object.create(null);
      // Feature flags
      for (const flag of Object.getOwnPropertySymbols(options)) {
        if (exports.FEATURE_FLAGS.has(flag)) {
          mongoOptions[flag] = options[flag];
        }
      }
      mongoOptions.hosts = isSRV
        ? []
        : hosts.map(utils_1.HostAddress.fromString);
      const urlOptions = new CaseInsensitiveMap();
      if (url.pathname !== "/" && url.pathname !== "") {
        const dbName = decodeURIComponent(
          url.pathname[0] === "/" ? url.pathname.slice(1) : url.pathname,
        );
        if (dbName) {
          urlOptions.set("dbName", [dbName]);
        }
      }
      if (url.username !== "") {
        const auth = {
          username: decodeURIComponent(url.username),
        };
        if (typeof url.password === "string") {
          auth.password = decodeURIComponent(url.password);
        }
        urlOptions.set("auth", [auth]);
      }
      for (const key of url.searchParams.keys()) {
        const values = url.searchParams.getAll(key);
        const isReadPreferenceTags = /readPreferenceTags/i.test(key);
        if (!isReadPreferenceTags && values.length > 1) {
          throw new error_1.MongoInvalidArgumentError(
            `URI option "${key}" cannot appear more than once in the connection string`,
          );
        }
        if (!isReadPreferenceTags && values.includes("")) {
          throw new error_1.MongoAPIError(
            `URI option "${key}" cannot be specified with no value`,
          );
        }
        if (!urlOptions.has(key)) {
          urlOptions.set(key, values);
        }
      }
      const objectOptions = new CaseInsensitiveMap(
        Object.entries(options).filter(([, v]) => v != null),
      );
      // Validate options that can only be provided by one of uri or object
      if (urlOptions.has("serverApi")) {
        throw new error_1.MongoParseError(
          "URI cannot contain `serverApi`, it can only be passed to the client",
        );
      }
      const uriMechanismProperties = urlOptions.get("authMechanismProperties");
      if (uriMechanismProperties) {
        for (const property of uriMechanismProperties) {
          if (/(^|,)ALLOWED_HOSTS:/.test(property)) {
            throw new error_1.MongoParseError(
              "Auth mechanism property ALLOWED_HOSTS is not allowed in the connection string.",
            );
          }
        }
      }
      if (objectOptions.has("loadBalanced")) {
        throw new error_1.MongoParseError(
          "loadBalanced is only a valid option in the URI",
        );
      }
      // All option collection
      const allProvidedOptions = new CaseInsensitiveMap();
      const allProvidedKeys = new Set([
        ...urlOptions.keys(),
        ...objectOptions.keys(),
      ]);
      for (const key of allProvidedKeys) {
        const values = [];
        const objectOptionValue = objectOptions.get(key);
        if (objectOptionValue != null) {
          values.push(objectOptionValue);
        }
        const urlValues = urlOptions.get(key) ?? [];
        values.push(...urlValues);
        allProvidedOptions.set(key, values);
      }
      if (allProvidedOptions.has("tls") || allProvidedOptions.has("ssl")) {
        const tlsAndSslOpts = (allProvidedOptions.get("tls") || [])
          .concat(allProvidedOptions.get("ssl") || [])
          .map(getBoolean.bind(null, "tls/ssl"));
        if (new Set(tlsAndSslOpts).size !== 1) {
          throw new error_1.MongoParseError(
            "All values of tls/ssl must be the same.",
          );
        }
      }
      checkTLSOptions(allProvidedOptions);
      const unsupportedOptions = (0, utils_1.setDifference)(
        allProvidedKeys,
        Array.from(Object.keys(exports.OPTIONS)).map((s) => s.toLowerCase()),
      );
      if (unsupportedOptions.size !== 0) {
        const optionWord = unsupportedOptions.size > 1 ? "options" : "option";
        const isOrAre = unsupportedOptions.size > 1 ? "are" : "is";
        throw new error_1.MongoParseError(
          `${optionWord} ${Array.from(unsupportedOptions).join(
            ", ",
          )} ${isOrAre} not supported`,
        );
      }
      // Option parsing and setting
      for (const [key, descriptor] of Object.entries(exports.OPTIONS)) {
        const values = allProvidedOptions.get(key);
        if (!values || values.length === 0) {
          if (exports.DEFAULT_OPTIONS.has(key)) {
            setOption(mongoOptions, key, descriptor, [
              exports.DEFAULT_OPTIONS.get(key),
            ]);
          }
        } else {
          const { deprecated } = descriptor;
          if (deprecated) {
            const deprecatedMsg =
              typeof deprecated === "string" ? `: ${deprecated}` : "";
            (0, utils_1.emitWarning)(
              `${key} is a deprecated option${deprecatedMsg}`,
            );
          }
          setOption(mongoOptions, key, descriptor, values);
        }
      }
      if (mongoOptions.credentials) {
        const isGssapi =
          mongoOptions.credentials.mechanism ===
          providers_1.AuthMechanism.MONGODB_GSSAPI;
        const isX509 =
          mongoOptions.credentials.mechanism ===
          providers_1.AuthMechanism.MONGODB_X509;
        const isAws =
          mongoOptions.credentials.mechanism ===
          providers_1.AuthMechanism.MONGODB_AWS;
        const isOidc =
          mongoOptions.credentials.mechanism ===
          providers_1.AuthMechanism.MONGODB_OIDC;
        if (
          (isGssapi || isX509) &&
          allProvidedOptions.has("authSource") &&
          mongoOptions.credentials.source !== "$external"
        ) {
          // If authSource was explicitly given and its incorrect, we error
          throw new error_1.MongoParseError(
            `authMechanism ${mongoOptions.credentials.mechanism} requires an authSource of '$external'`,
          );
        }
        if (
          !(isGssapi || isX509 || isAws || isOidc) &&
          mongoOptions.dbName &&
          !allProvidedOptions.has("authSource")
        ) {
          // inherit the dbName unless GSSAPI or X509, then silently ignore dbName
          // and there was no specific authSource given
          mongoOptions.credentials = mongo_credentials_1.MongoCredentials.merge(
            mongoOptions.credentials,
            {
              source: mongoOptions.dbName,
            },
          );
        }
        if (
          isAws &&
          mongoOptions.credentials.username &&
          !mongoOptions.credentials.password
        ) {
          throw new error_1.MongoMissingCredentialsError(
            `When using ${mongoOptions.credentials.mechanism} password must be set when a username is specified`,
          );
        }
        mongoOptions.credentials.validate();
        // Check if the only auth related option provided was authSource, if so we can remove credentials
        if (
          mongoOptions.credentials.password === "" &&
          mongoOptions.credentials.username === "" &&
          mongoOptions.credentials.mechanism ===
            providers_1.AuthMechanism.MONGODB_DEFAULT &&
          Object.keys(mongoOptions.credentials.mechanismProperties).length === 0
        ) {
          delete mongoOptions.credentials;
        }
      }
      if (!mongoOptions.dbName) {
        // dbName default is applied here because of the credential validation above
        mongoOptions.dbName = "test";
      }
      validateLoadBalancedOptions(hosts, mongoOptions, isSRV);
      if (mongoClient && mongoOptions.autoEncryption) {
        encrypter_1.Encrypter.checkForMongoCrypt();
        mongoOptions.encrypter = new encrypter_1.Encrypter(
          mongoClient,
          uri,
          options,
        );
        mongoOptions.autoEncrypter = mongoOptions.encrypter.autoEncrypter;
      }
      // Potential SRV Overrides and SRV connection string validations
      mongoOptions.userSpecifiedAuthSource =
        objectOptions.has("authSource") || urlOptions.has("authSource");
      mongoOptions.userSpecifiedReplicaSet =
        objectOptions.has("replicaSet") || urlOptions.has("replicaSet");
      if (isSRV) {
        // SRV Record is resolved upon connecting
        mongoOptions.srvHost = hosts[0];
        if (mongoOptions.directConnection) {
          throw new error_1.MongoAPIError(
            "SRV URI does not support directConnection",
          );
        }
        if (
          mongoOptions.srvMaxHosts > 0 &&
          typeof mongoOptions.replicaSet === "string"
        ) {
          throw new error_1.MongoParseError(
            "Cannot use srvMaxHosts option with replicaSet",
          );
        }
        // SRV turns on TLS by default, but users can override and turn it off
        const noUserSpecifiedTLS =
          !objectOptions.has("tls") && !urlOptions.has("tls");
        const noUserSpecifiedSSL =
          !objectOptions.has("ssl") && !urlOptions.has("ssl");
        if (noUserSpecifiedTLS && noUserSpecifiedSSL) {
          mongoOptions.tls = true;
        }
      } else {
        const userSpecifiedSrvOptions =
          urlOptions.has("srvMaxHosts") ||
          objectOptions.has("srvMaxHosts") ||
          urlOptions.has("srvServiceName") ||
          objectOptions.has("srvServiceName");
        if (userSpecifiedSrvOptions) {
          throw new error_1.MongoParseError(
            "Cannot use srvMaxHosts or srvServiceName with a non-srv connection string",
          );
        }
      }
      if (mongoOptions.directConnection && mongoOptions.hosts.length !== 1) {
        throw new error_1.MongoParseError(
          "directConnection option requires exactly one host",
        );
      }
      if (
        !mongoOptions.proxyHost &&
        (mongoOptions.proxyPort ||
          mongoOptions.proxyUsername ||
          mongoOptions.proxyPassword)
      ) {
        throw new error_1.MongoParseError(
          "Must specify proxyHost if other proxy options are passed",
        );
      }
      if (
        (mongoOptions.proxyUsername && !mongoOptions.proxyPassword) ||
        (!mongoOptions.proxyUsername && mongoOptions.proxyPassword)
      ) {
        throw new error_1.MongoParseError(
          "Can only specify both of proxy username/password or neither",
        );
      }
      const proxyOptions = [
        "proxyHost",
        "proxyPort",
        "proxyUsername",
        "proxyPassword",
      ].map((key) => urlOptions.get(key) ?? []);
      if (proxyOptions.some((options) => options.length > 1)) {
        throw new error_1.MongoParseError(
          "Proxy options cannot be specified multiple times in the connection string",
        );
      }
      const loggerFeatureFlag = Symbol.for("@@mdb.enableMongoLogger");
      mongoOptions[loggerFeatureFlag] =
        mongoOptions[loggerFeatureFlag] ?? false;
      let loggerEnvOptions = {};
      let loggerClientOptions = {};
      if (mongoOptions[loggerFeatureFlag]) {
        loggerEnvOptions = {
          MONGODB_LOG_COMMAND: process.env.MONGODB_LOG_COMMAND,
          MONGODB_LOG_TOPOLOGY: process.env.MONGODB_LOG_TOPOLOGY,
          MONGODB_LOG_SERVER_SELECTION:
            process.env.MONGODB_LOG_SERVER_SELECTION,
          MONGODB_LOG_CONNECTION: process.env.MONGODB_LOG_CONNECTION,
          MONGODB_LOG_ALL: process.env.MONGODB_LOG_ALL,
          MONGODB_LOG_MAX_DOCUMENT_LENGTH:
            process.env.MONGODB_LOG_MAX_DOCUMENT_LENGTH,
          MONGODB_LOG_PATH: process.env.MONGODB_LOG_PATH,
          ...mongoOptions[Symbol.for("@@mdb.internalLoggerConfig")],
        };
        loggerClientOptions = {
          mongodbLogPath: mongoOptions.mongodbLogPath,
        };
      }
      mongoOptions.mongoLoggerOptions =
        mongo_logger_1.MongoLogger.resolveOptions(
          loggerEnvOptions,
          loggerClientOptions,
        );
      mongoOptions.metadata = (0, client_metadata_1.makeClientMetadata)(
        mongoOptions,
      );
      return mongoOptions;
    }
    exports.parseOptions = parseOptions;
    /**
     * #### Throws if LB mode is true:
     * - hosts contains more than one host
     * - there is a replicaSet name set
     * - directConnection is set
     * - if srvMaxHosts is used when an srv connection string is passed in
     *
     * @throws MongoParseError
     */
    function validateLoadBalancedOptions(hosts, mongoOptions, isSrv) {
      if (mongoOptions.loadBalanced) {
        if (hosts.length > 1) {
          throw new error_1.MongoParseError(LB_SINGLE_HOST_ERROR);
        }
        if (mongoOptions.replicaSet) {
          throw new error_1.MongoParseError(LB_REPLICA_SET_ERROR);
        }
        if (mongoOptions.directConnection) {
          throw new error_1.MongoParseError(LB_DIRECT_CONNECTION_ERROR);
        }
        if (isSrv && mongoOptions.srvMaxHosts > 0) {
          throw new error_1.MongoParseError(
            "Cannot limit srv hosts with loadBalanced enabled",
          );
        }
      }
      return;
    }
    function setOption(mongoOptions, key, descriptor, values) {
      const { target, type, transform } = descriptor;
      const name = target ?? key;
      switch (type) {
        case "boolean":
          mongoOptions[name] = getBoolean(name, values[0]);
          break;
        case "int":
          mongoOptions[name] = getIntFromOptions(name, values[0]);
          break;
        case "uint":
          mongoOptions[name] = getUIntFromOptions(name, values[0]);
          break;
        case "string":
          if (values[0] == null) {
            break;
          }
          mongoOptions[name] = String(values[0]);
          break;
        case "record":
          if (!(0, utils_1.isRecord)(values[0])) {
            throw new error_1.MongoParseError(`${name} must be an object`);
          }
          mongoOptions[name] = values[0];
          break;
        case "any":
          mongoOptions[name] = values[0];
          break;
        default: {
          if (!transform) {
            throw new error_1.MongoParseError(
              "Descriptors missing a type must define a transform",
            );
          }
          const transformValue = transform({
            name,
            options: mongoOptions,
            values,
          });
          mongoOptions[name] = transformValue;
          break;
        }
      }
    }
    exports.OPTIONS = {
      appName: {
        type: "string",
      },
      auth: {
        target: "credentials",
        transform({ name, options, values: [value] }) {
          if (!(0, utils_1.isRecord)(value, ["username", "password"])) {
            throw new error_1.MongoParseError(
              `${name} must be an object with 'username' and 'password' properties`,
            );
          }
          return mongo_credentials_1.MongoCredentials.merge(
            options.credentials,
            {
              username: value.username,
              password: value.password,
            },
          );
        },
      },
      authMechanism: {
        target: "credentials",
        transform({ options, values: [value] }) {
          const mechanisms = Object.values(providers_1.AuthMechanism);
          const [mechanism] = mechanisms.filter((m) =>
            m.match(RegExp(String.raw`\b${value}\b`, "i")),
          );
          if (!mechanism) {
            throw new error_1.MongoParseError(
              `authMechanism one of ${mechanisms}, got ${value}`,
            );
          }
          let source = options.credentials?.source;
          if (
            mechanism === providers_1.AuthMechanism.MONGODB_PLAIN ||
            providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(mechanism)
          ) {
            // some mechanisms have '$external' as the Auth Source
            source = "$external";
          }
          let password = options.credentials?.password;
          if (
            mechanism === providers_1.AuthMechanism.MONGODB_X509 &&
            password === ""
          ) {
            password = undefined;
          }
          return mongo_credentials_1.MongoCredentials.merge(
            options.credentials,
            {
              mechanism,
              source,
              password,
            },
          );
        },
      },
      authMechanismProperties: {
        target: "credentials",
        transform({ options, values }) {
          // We can have a combination of options passed in the URI and options passed
          // as an object to the MongoClient. So we must transform the string options
          // as well as merge them together with a potentially provided object.
          let mechanismProperties = Object.create(null);
          for (const optionValue of values) {
            if (typeof optionValue === "string") {
              for (const [key, value] of entriesFromString(optionValue)) {
                try {
                  mechanismProperties[key] = getBoolean(key, value);
                } catch {
                  mechanismProperties[key] = value;
                }
              }
            } else {
              if (!(0, utils_1.isRecord)(optionValue)) {
                throw new error_1.MongoParseError(
                  "AuthMechanismProperties must be an object",
                );
              }
              mechanismProperties = { ...optionValue };
            }
          }
          return mongo_credentials_1.MongoCredentials.merge(
            options.credentials,
            {
              mechanismProperties,
            },
          );
        },
      },
      authSource: {
        target: "credentials",
        transform({ options, values: [value] }) {
          const source = String(value);
          return mongo_credentials_1.MongoCredentials.merge(
            options.credentials,
            { source },
          );
        },
      },
      autoEncryption: {
        type: "record",
      },
      bsonRegExp: {
        type: "boolean",
      },
      serverApi: {
        target: "serverApi",
        transform({ values: [version] }) {
          const serverApiToValidate =
            typeof version === "string" ? { version } : version;
          const versionToValidate =
            serverApiToValidate && serverApiToValidate.version;
          if (!versionToValidate) {
            throw new error_1.MongoParseError(
              `Invalid \`serverApi\` property; must specify a version from the following enum: ["${Object.values(
                mongo_client_1.ServerApiVersion,
              ).join('", "')}"]`,
            );
          }
          if (
            !Object.values(mongo_client_1.ServerApiVersion).some(
              (v) => v === versionToValidate,
            )
          ) {
            throw new error_1.MongoParseError(
              `Invalid server API version=${versionToValidate}; must be in the following enum: ["${Object.values(
                mongo_client_1.ServerApiVersion,
              ).join('", "')}"]`,
            );
          }
          return serverApiToValidate;
        },
      },
      checkKeys: {
        type: "boolean",
      },
      compressors: {
        default: "none",
        target: "compressors",
        transform({ values }) {
          const compressionList = new Set();
          for (const compVal of values) {
            const compValArray =
              typeof compVal === "string" ? compVal.split(",") : compVal;
            if (!Array.isArray(compValArray)) {
              throw new error_1.MongoInvalidArgumentError(
                "compressors must be an array or a comma-delimited list of strings",
              );
            }
            for (const c of compValArray) {
              if (Object.keys(compression_1.Compressor).includes(String(c))) {
                compressionList.add(String(c));
              } else {
                throw new error_1.MongoInvalidArgumentError(
                  `${c} is not a valid compression mechanism. Must be one of: ${Object.keys(
                    compression_1.Compressor,
                  )}.`,
                );
              }
            }
          }
          return [...compressionList];
        },
      },
      connectTimeoutMS: {
        default: 30000,
        type: "uint",
      },
      dbName: {
        type: "string",
      },
      directConnection: {
        default: false,
        type: "boolean",
      },
      driverInfo: {
        default: {},
        type: "record",
      },
      enableUtf8Validation: { type: "boolean", default: true },
      family: {
        transform({ name, values: [value] }) {
          const transformValue = getIntFromOptions(name, value);
          if (transformValue === 4 || transformValue === 6) {
            return transformValue;
          }
          throw new error_1.MongoParseError(
            `Option 'family' must be 4 or 6 got ${transformValue}.`,
          );
        },
      },
      fieldsAsRaw: {
        type: "record",
      },
      forceServerObjectId: {
        default: false,
        type: "boolean",
      },
      fsync: {
        deprecated: "Please use journal instead",
        target: "writeConcern",
        transform({ name, options, values: [value] }) {
          const wc = write_concern_1.WriteConcern.fromOptions({
            writeConcern: {
              ...options.writeConcern,
              fsync: getBoolean(name, value),
            },
          });
          if (!wc)
            throw new error_1.MongoParseError(
              `Unable to make a writeConcern from fsync=${value}`,
            );
          return wc;
        },
      },
      heartbeatFrequencyMS: {
        default: 10000,
        type: "uint",
      },
      ignoreUndefined: {
        type: "boolean",
      },
      j: {
        deprecated: "Please use journal instead",
        target: "writeConcern",
        transform({ name, options, values: [value] }) {
          const wc = write_concern_1.WriteConcern.fromOptions({
            writeConcern: {
              ...options.writeConcern,
              journal: getBoolean(name, value),
            },
          });
          if (!wc)
            throw new error_1.MongoParseError(
              `Unable to make a writeConcern from journal=${value}`,
            );
          return wc;
        },
      },
      journal: {
        target: "writeConcern",
        transform({ name, options, values: [value] }) {
          const wc = write_concern_1.WriteConcern.fromOptions({
            writeConcern: {
              ...options.writeConcern,
              journal: getBoolean(name, value),
            },
          });
          if (!wc)
            throw new error_1.MongoParseError(
              `Unable to make a writeConcern from journal=${value}`,
            );
          return wc;
        },
      },
      loadBalanced: {
        default: false,
        type: "boolean",
      },
      localThresholdMS: {
        default: 15,
        type: "uint",
      },
      maxConnecting: {
        default: 2,
        transform({ name, values: [value] }) {
          const maxConnecting = getUIntFromOptions(name, value);
          if (maxConnecting === 0) {
            throw new error_1.MongoInvalidArgumentError(
              "maxConnecting must be > 0 if specified",
            );
          }
          return maxConnecting;
        },
      },
      maxIdleTimeMS: {
        default: 0,
        type: "uint",
      },
      maxPoolSize: {
        default: 100,
        type: "uint",
      },
      maxStalenessSeconds: {
        target: "readPreference",
        transform({ name, options, values: [value] }) {
          const maxStalenessSeconds = getUIntFromOptions(name, value);
          if (options.readPreference) {
            return read_preference_1.ReadPreference.fromOptions({
              readPreference: {
                ...options.readPreference,
                maxStalenessSeconds,
              },
            });
          } else {
            return new read_preference_1.ReadPreference(
              "secondary",
              undefined,
              { maxStalenessSeconds },
            );
          }
        },
      },
      minInternalBufferSize: {
        type: "uint",
      },
      minPoolSize: {
        default: 0,
        type: "uint",
      },
      minHeartbeatFrequencyMS: {
        default: 500,
        type: "uint",
      },
      monitorCommands: {
        default: false,
        type: "boolean",
      },
      name: {
        target: "driverInfo",
        transform({ values: [value], options }) {
          return { ...options.driverInfo, name: String(value) };
        },
      },
      noDelay: {
        default: true,
        type: "boolean",
      },
      pkFactory: {
        default: utils_1.DEFAULT_PK_FACTORY,
        transform({ values: [value] }) {
          if (
            (0, utils_1.isRecord)(value, ["createPk"]) &&
            typeof value.createPk === "function"
          ) {
            return value;
          }
          throw new error_1.MongoParseError(
            `Option pkFactory must be an object with a createPk function, got ${value}`,
          );
        },
      },
      promoteBuffers: {
        type: "boolean",
      },
      promoteLongs: {
        type: "boolean",
      },
      promoteValues: {
        type: "boolean",
      },
      useBigInt64: {
        type: "boolean",
      },
      proxyHost: {
        type: "string",
      },
      proxyPassword: {
        type: "string",
      },
      proxyPort: {
        type: "uint",
      },
      proxyUsername: {
        type: "string",
      },
      raw: {
        default: false,
        type: "boolean",
      },
      readConcern: {
        transform({ values: [value], options }) {
          if (
            value instanceof read_concern_1.ReadConcern ||
            (0, utils_1.isRecord)(value, ["level"])
          ) {
            return read_concern_1.ReadConcern.fromOptions({
              ...options.readConcern,
              ...value,
            });
          }
          throw new error_1.MongoParseError(
            `ReadConcern must be an object, got ${JSON.stringify(value)}`,
          );
        },
      },
      readConcernLevel: {
        target: "readConcern",
        transform({ values: [level], options }) {
          return read_concern_1.ReadConcern.fromOptions({
            ...options.readConcern,
            level: level,
          });
        },
      },
      readPreference: {
        default: read_preference_1.ReadPreference.primary,
        transform({ values: [value], options }) {
          if (value instanceof read_preference_1.ReadPreference) {
            return read_preference_1.ReadPreference.fromOptions({
              readPreference: { ...options.readPreference, ...value },
              ...value,
            });
          }
          if ((0, utils_1.isRecord)(value, ["mode"])) {
            const rp = read_preference_1.ReadPreference.fromOptions({
              readPreference: { ...options.readPreference, ...value },
              ...value,
            });
            if (rp) return rp;
            else
              throw new error_1.MongoParseError(
                `Cannot make read preference from ${JSON.stringify(value)}`,
              );
          }
          if (typeof value === "string") {
            const rpOpts = {
              hedge: options.readPreference?.hedge,
              maxStalenessSeconds: options.readPreference?.maxStalenessSeconds,
            };
            return new read_preference_1.ReadPreference(
              value,
              options.readPreference?.tags,
              rpOpts,
            );
          }
          throw new error_1.MongoParseError(
            `Unknown ReadPreference value: ${value}`,
          );
        },
      },
      readPreferenceTags: {
        target: "readPreference",
        transform({ values, options }) {
          const tags = Array.isArray(values[0]) ? values[0] : values;
          const readPreferenceTags = [];
          for (const tag of tags) {
            const readPreferenceTag = Object.create(null);
            if (typeof tag === "string") {
              for (const [k, v] of entriesFromString(tag)) {
                readPreferenceTag[k] = v;
              }
            }
            if ((0, utils_1.isRecord)(tag)) {
              for (const [k, v] of Object.entries(tag)) {
                readPreferenceTag[k] = v;
              }
            }
            readPreferenceTags.push(readPreferenceTag);
          }
          return read_preference_1.ReadPreference.fromOptions({
            readPreference: options.readPreference,
            readPreferenceTags,
          });
        },
      },
      replicaSet: {
        type: "string",
      },
      retryReads: {
        default: true,
        type: "boolean",
      },
      retryWrites: {
        default: true,
        type: "boolean",
      },
      serializeFunctions: {
        type: "boolean",
      },
      serverSelectionTimeoutMS: {
        default: 30000,
        type: "uint",
      },
      servername: {
        type: "string",
      },
      socketTimeoutMS: {
        default: 0,
        type: "uint",
      },
      srvMaxHosts: {
        type: "uint",
        default: 0,
      },
      srvServiceName: {
        type: "string",
        default: "mongodb",
      },
      ssl: {
        target: "tls",
        type: "boolean",
      },
      tls: {
        type: "boolean",
      },
      tlsAllowInvalidCertificates: {
        target: "rejectUnauthorized",
        transform({ name, values: [value] }) {
          // allowInvalidCertificates is the inverse of rejectUnauthorized
          return !getBoolean(name, value);
        },
      },
      tlsAllowInvalidHostnames: {
        target: "checkServerIdentity",
        transform({ name, values: [value] }) {
          // tlsAllowInvalidHostnames means setting the checkServerIdentity function to a noop
          return getBoolean(name, value) ? () => undefined : undefined;
        },
      },
      tlsCAFile: {
        type: "string",
      },
      tlsCRLFile: {
        type: "string",
      },
      tlsCertificateKeyFile: {
        type: "string",
      },
      tlsCertificateKeyFilePassword: {
        target: "passphrase",
        type: "any",
      },
      tlsInsecure: {
        transform({ name, options, values: [value] }) {
          const tlsInsecure = getBoolean(name, value);
          if (tlsInsecure) {
            options.checkServerIdentity = () => undefined;
            options.rejectUnauthorized = false;
          } else {
            options.checkServerIdentity = options.tlsAllowInvalidHostnames
              ? () => undefined
              : undefined;
            options.rejectUnauthorized = options.tlsAllowInvalidCertificates
              ? false
              : true;
          }
          return tlsInsecure;
        },
      },
      w: {
        target: "writeConcern",
        transform({ values: [value], options }) {
          return write_concern_1.WriteConcern.fromOptions({
            writeConcern: { ...options.writeConcern, w: value },
          });
        },
      },
      waitQueueTimeoutMS: {
        default: 0,
        type: "uint",
      },
      writeConcern: {
        target: "writeConcern",
        transform({ values: [value], options }) {
          if (
            (0, utils_1.isRecord)(value) ||
            value instanceof write_concern_1.WriteConcern
          ) {
            return write_concern_1.WriteConcern.fromOptions({
              writeConcern: {
                ...options.writeConcern,
                ...value,
              },
            });
          } else if (value === "majority" || typeof value === "number") {
            return write_concern_1.WriteConcern.fromOptions({
              writeConcern: {
                ...options.writeConcern,
                w: value,
              },
            });
          }
          throw new error_1.MongoParseError(
            `Invalid WriteConcern cannot parse: ${JSON.stringify(value)}`,
          );
        },
      },
      wtimeout: {
        deprecated: "Please use wtimeoutMS instead",
        target: "writeConcern",
        transform({ values: [value], options }) {
          const wc = write_concern_1.WriteConcern.fromOptions({
            writeConcern: {
              ...options.writeConcern,
              wtimeout: getUIntFromOptions("wtimeout", value),
            },
          });
          if (wc) return wc;
          throw new error_1.MongoParseError(
            `Cannot make WriteConcern from wtimeout`,
          );
        },
      },
      wtimeoutMS: {
        target: "writeConcern",
        transform({ values: [value], options }) {
          const wc = write_concern_1.WriteConcern.fromOptions({
            writeConcern: {
              ...options.writeConcern,
              wtimeoutMS: getUIntFromOptions("wtimeoutMS", value),
            },
          });
          if (wc) return wc;
          throw new error_1.MongoParseError(
            `Cannot make WriteConcern from wtimeout`,
          );
        },
      },
      zlibCompressionLevel: {
        default: 0,
        type: "int",
      },
      // Custom types for modifying core behavior
      connectionType: { type: "any" },
      srvPoller: { type: "any" },
      // Accepted NodeJS Options
      minDHSize: { type: "any" },
      pskCallback: { type: "any" },
      secureContext: { type: "any" },
      enableTrace: { type: "any" },
      requestCert: { type: "any" },
      rejectUnauthorized: { type: "any" },
      checkServerIdentity: { type: "any" },
      ALPNProtocols: { type: "any" },
      SNICallback: { type: "any" },
      session: { type: "any" },
      requestOCSP: { type: "any" },
      localAddress: { type: "any" },
      localPort: { type: "any" },
      hints: { type: "any" },
      lookup: { type: "any" },
      ca: { type: "any" },
      cert: { type: "any" },
      ciphers: { type: "any" },
      crl: { type: "any" },
      ecdhCurve: { type: "any" },
      key: { type: "any" },
      passphrase: { type: "any" },
      pfx: { type: "any" },
      secureProtocol: { type: "any" },
      index: { type: "any" },
      // Legacy options from v3 era
      useNewUrlParser: {
        type: "boolean",
        deprecated:
          "useNewUrlParser has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version",
      },
      useUnifiedTopology: {
        type: "boolean",
        deprecated:
          "useUnifiedTopology has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version",
      },
      // MongoLogger
      // TODO(NODE-4849): Tighten the type of mongodbLogPath
      mongodbLogPath: { type: "any" },
    };
    exports.DEFAULT_OPTIONS = new CaseInsensitiveMap(
      Object.entries(exports.OPTIONS)
        .filter(([, descriptor]) => descriptor.default != null)
        .map(([k, d]) => [k, d.default]),
    );
    /**
     * Set of permitted feature flags
     * @internal
     */
    exports.FEATURE_FLAGS = new Set([
      Symbol.for("@@mdb.skipPingOnConnect"),
      Symbol.for("@@mdb.enableMongoLogger"),
      Symbol.for("@@mdb.internalLoggerConfig"),
    ]);
  })(connection_string);
  return connection_string;
}

var topology = {};

var events = {};

Object.defineProperty(events, "__esModule", { value: true });
events.ServerHeartbeatFailedEvent =
  events.ServerHeartbeatSucceededEvent =
  events.ServerHeartbeatStartedEvent =
  events.TopologyClosedEvent =
  events.TopologyOpeningEvent =
  events.TopologyDescriptionChangedEvent =
  events.ServerClosedEvent =
  events.ServerOpeningEvent =
  events.ServerDescriptionChangedEvent =
    void 0;
/**
 * Emitted when server description changes, but does NOT include changes to the RTT.
 * @public
 * @category Event
 */
let ServerDescriptionChangedEvent$1 = class ServerDescriptionChangedEvent {
  /** @internal */
  constructor(topologyId, address, previousDescription, newDescription) {
    this.topologyId = topologyId;
    this.address = address;
    this.previousDescription = previousDescription;
    this.newDescription = newDescription;
  }
};
events.ServerDescriptionChangedEvent = ServerDescriptionChangedEvent$1;
/**
 * Emitted when server is initialized.
 * @public
 * @category Event
 */
let ServerOpeningEvent$1 = class ServerOpeningEvent {
  /** @internal */
  constructor(topologyId, address) {
    this.topologyId = topologyId;
    this.address = address;
  }
};
events.ServerOpeningEvent = ServerOpeningEvent$1;
/**
 * Emitted when server is closed.
 * @public
 * @category Event
 */
let ServerClosedEvent$1 = class ServerClosedEvent {
  /** @internal */
  constructor(topologyId, address) {
    this.topologyId = topologyId;
    this.address = address;
  }
};
events.ServerClosedEvent = ServerClosedEvent$1;
/**
 * Emitted when topology description changes.
 * @public
 * @category Event
 */
let TopologyDescriptionChangedEvent$1 = class TopologyDescriptionChangedEvent {
  /** @internal */
  constructor(topologyId, previousDescription, newDescription) {
    this.topologyId = topologyId;
    this.previousDescription = previousDescription;
    this.newDescription = newDescription;
  }
};
events.TopologyDescriptionChangedEvent = TopologyDescriptionChangedEvent$1;
/**
 * Emitted when topology is initialized.
 * @public
 * @category Event
 */
let TopologyOpeningEvent$1 = class TopologyOpeningEvent {
  /** @internal */
  constructor(topologyId) {
    this.topologyId = topologyId;
  }
};
events.TopologyOpeningEvent = TopologyOpeningEvent$1;
/**
 * Emitted when topology is closed.
 * @public
 * @category Event
 */
let TopologyClosedEvent$1 = class TopologyClosedEvent {
  /** @internal */
  constructor(topologyId) {
    this.topologyId = topologyId;
  }
};
events.TopologyClosedEvent = TopologyClosedEvent$1;
/**
 * Emitted when the server monitors hello command is started - immediately before
 * the hello command is serialized into raw BSON and written to the socket.
 *
 * @public
 * @category Event
 */
let ServerHeartbeatStartedEvent$1 = class ServerHeartbeatStartedEvent {
  /** @internal */
  constructor(connectionId, awaited) {
    this.connectionId = connectionId;
    this.awaited = awaited;
  }
};
events.ServerHeartbeatStartedEvent = ServerHeartbeatStartedEvent$1;
/**
 * Emitted when the server monitors hello succeeds.
 * @public
 * @category Event
 */
let ServerHeartbeatSucceededEvent$1 = class ServerHeartbeatSucceededEvent {
  /** @internal */
  constructor(connectionId, duration, reply, awaited) {
    this.connectionId = connectionId;
    this.duration = duration;
    this.reply = reply ?? {};
    this.awaited = awaited;
  }
};
events.ServerHeartbeatSucceededEvent = ServerHeartbeatSucceededEvent$1;
/**
 * Emitted when the server monitors hello fails, either with an ok: 0 or a socket exception.
 * @public
 * @category Event
 */
let ServerHeartbeatFailedEvent$1 = class ServerHeartbeatFailedEvent {
  /** @internal */
  constructor(connectionId, duration, failure, awaited) {
    this.connectionId = connectionId;
    this.duration = duration;
    this.failure = failure;
    this.awaited = awaited;
  }
};
events.ServerHeartbeatFailedEvent = ServerHeartbeatFailedEvent$1;

var server = {};

var connection = {};

var command_monitoring_events = {};

var commands = {};

Object.defineProperty(commands, "__esModule", { value: true });
commands.BinMsg = commands.Msg = commands.Response = commands.Query = void 0;
const BSON$2 = bson$2;
const error_1$g = error;
const read_preference_1 = read_preference;
const constants_1$3 = constants$1;
// Incrementing request id
let _requestId = 0;
// Query flags
const OPTS_TAILABLE_CURSOR = 2;
const OPTS_SECONDARY = 4;
const OPTS_OPLOG_REPLAY = 8;
const OPTS_NO_CURSOR_TIMEOUT = 16;
const OPTS_AWAIT_DATA = 32;
const OPTS_EXHAUST = 64;
const OPTS_PARTIAL = 128;
// Response flags
const CURSOR_NOT_FOUND = 1;
const QUERY_FAILURE = 2;
const SHARD_CONFIG_STALE = 4;
const AWAIT_CAPABLE = 8;
/**************************************************************
 * QUERY
 **************************************************************/
/** @internal */
class Query {
  constructor(databaseName, query, options) {
    this.databaseName = databaseName;
    this.query = query;
    // Basic options needed to be passed in
    // TODO(NODE-3483): Replace with MongoCommandError
    const ns = `${databaseName}.$cmd`;
    if (typeof databaseName !== "string") {
      throw new error_1$g.MongoRuntimeError(
        "Database name must be a string for a query",
      );
    }
    // TODO(NODE-3483): Replace with MongoCommandError
    if (query == null)
      throw new error_1$g.MongoRuntimeError(
        "A query document must be specified for query",
      );
    // Validate that we are not passing 0x00 in the collection name
    if (ns.indexOf("\x00") !== -1) {
      // TODO(NODE-3483): Use MongoNamespace static method
      throw new error_1$g.MongoRuntimeError(
        "Namespace cannot contain a null character",
      );
    }
    // Basic options
    this.ns = ns;
    // Additional options
    this.numberToSkip = options.numberToSkip || 0;
    this.numberToReturn = options.numberToReturn || 0;
    this.returnFieldSelector = options.returnFieldSelector || undefined;
    this.requestId = Query.getRequestId();
    // special case for pre-3.2 find commands, delete ASAP
    this.pre32Limit = options.pre32Limit;
    // Serialization option
    this.serializeFunctions =
      typeof options.serializeFunctions === "boolean"
        ? options.serializeFunctions
        : false;
    this.ignoreUndefined =
      typeof options.ignoreUndefined === "boolean"
        ? options.ignoreUndefined
        : false;
    this.maxBsonSize = options.maxBsonSize || 1024 * 1024 * 16;
    this.checkKeys =
      typeof options.checkKeys === "boolean" ? options.checkKeys : false;
    this.batchSize = this.numberToReturn;
    // Flags
    this.tailable = false;
    this.secondaryOk =
      typeof options.secondaryOk === "boolean" ? options.secondaryOk : false;
    this.oplogReplay = false;
    this.noCursorTimeout = false;
    this.awaitData = false;
    this.exhaust = false;
    this.partial = false;
  }
  /** Assign next request Id. */
  incRequestId() {
    this.requestId = _requestId++;
  }
  /** Peek next request Id. */
  nextRequestId() {
    return _requestId + 1;
  }
  /** Increment then return next request Id. */
  static getRequestId() {
    return ++_requestId;
  }
  // Uses a single allocated buffer for the process, avoiding multiple memory allocations
  toBin() {
    const buffers = [];
    let projection = null;
    // Set up the flags
    let flags = 0;
    if (this.tailable) {
      flags |= OPTS_TAILABLE_CURSOR;
    }
    if (this.secondaryOk) {
      flags |= OPTS_SECONDARY;
    }
    if (this.oplogReplay) {
      flags |= OPTS_OPLOG_REPLAY;
    }
    if (this.noCursorTimeout) {
      flags |= OPTS_NO_CURSOR_TIMEOUT;
    }
    if (this.awaitData) {
      flags |= OPTS_AWAIT_DATA;
    }
    if (this.exhaust) {
      flags |= OPTS_EXHAUST;
    }
    if (this.partial) {
      flags |= OPTS_PARTIAL;
    }
    // If batchSize is different to this.numberToReturn
    if (this.batchSize !== this.numberToReturn)
      this.numberToReturn = this.batchSize;
    // Allocate write protocol header buffer
    const header = Buffer.alloc(
      4 * 4 + // Header
        4 + // Flags
        Buffer.byteLength(this.ns) +
        1 + // namespace
        4 + // numberToSkip
        4, // numberToReturn
    );
    // Add header to buffers
    buffers.push(header);
    // Serialize the query
    const query = BSON$2.serialize(this.query, {
      checkKeys: this.checkKeys,
      serializeFunctions: this.serializeFunctions,
      ignoreUndefined: this.ignoreUndefined,
    });
    // Add query document
    buffers.push(query);
    if (
      this.returnFieldSelector &&
      Object.keys(this.returnFieldSelector).length > 0
    ) {
      // Serialize the projection document
      projection = BSON$2.serialize(this.returnFieldSelector, {
        checkKeys: this.checkKeys,
        serializeFunctions: this.serializeFunctions,
        ignoreUndefined: this.ignoreUndefined,
      });
      // Add projection document
      buffers.push(projection);
    }
    // Total message size
    const totalLength =
      header.length + query.length + (projection ? projection.length : 0);
    // Set up the index
    let index = 4;
    // Write total document length
    header[3] = (totalLength >> 24) & 0xff;
    header[2] = (totalLength >> 16) & 0xff;
    header[1] = (totalLength >> 8) & 0xff;
    header[0] = totalLength & 0xff;
    // Write header information requestId
    header[index + 3] = (this.requestId >> 24) & 0xff;
    header[index + 2] = (this.requestId >> 16) & 0xff;
    header[index + 1] = (this.requestId >> 8) & 0xff;
    header[index] = this.requestId & 0xff;
    index = index + 4;
    // Write header information responseTo
    header[index + 3] = (0 >> 24) & 0xff;
    header[index + 2] = (0 >> 16) & 0xff;
    header[index + 1] = (0 >> 8) & 0xff;
    header[index] = 0 & 0xff;
    index = index + 4;
    // Write header information OP_QUERY
    header[index + 3] = (constants_1$3.OP_QUERY >> 24) & 0xff;
    header[index + 2] = (constants_1$3.OP_QUERY >> 16) & 0xff;
    header[index + 1] = (constants_1$3.OP_QUERY >> 8) & 0xff;
    header[index] = constants_1$3.OP_QUERY & 0xff;
    index = index + 4;
    // Write header information flags
    header[index + 3] = (flags >> 24) & 0xff;
    header[index + 2] = (flags >> 16) & 0xff;
    header[index + 1] = (flags >> 8) & 0xff;
    header[index] = flags & 0xff;
    index = index + 4;
    // Write collection name
    index = index + header.write(this.ns, index, "utf8") + 1;
    header[index - 1] = 0;
    // Write header information flags numberToSkip
    header[index + 3] = (this.numberToSkip >> 24) & 0xff;
    header[index + 2] = (this.numberToSkip >> 16) & 0xff;
    header[index + 1] = (this.numberToSkip >> 8) & 0xff;
    header[index] = this.numberToSkip & 0xff;
    index = index + 4;
    // Write header information flags numberToReturn
    header[index + 3] = (this.numberToReturn >> 24) & 0xff;
    header[index + 2] = (this.numberToReturn >> 16) & 0xff;
    header[index + 1] = (this.numberToReturn >> 8) & 0xff;
    header[index] = this.numberToReturn & 0xff;
    index = index + 4;
    // Return the buffers
    return buffers;
  }
}
commands.Query = Query;
/** @internal */
class Response {
  constructor(message, msgHeader, msgBody, opts) {
    this.documents = new Array(0);
    this.parsed = false;
    this.raw = message;
    this.data = msgBody;
    this.opts = opts ?? {
      useBigInt64: false,
      promoteLongs: true,
      promoteValues: true,
      promoteBuffers: false,
      bsonRegExp: false,
    };
    // Read the message header
    this.length = msgHeader.length;
    this.requestId = msgHeader.requestId;
    this.responseTo = msgHeader.responseTo;
    this.opCode = msgHeader.opCode;
    this.fromCompressed = msgHeader.fromCompressed;
    // Flag values
    this.useBigInt64 =
      typeof this.opts.useBigInt64 === "boolean"
        ? this.opts.useBigInt64
        : false;
    this.promoteLongs =
      typeof this.opts.promoteLongs === "boolean"
        ? this.opts.promoteLongs
        : true;
    this.promoteValues =
      typeof this.opts.promoteValues === "boolean"
        ? this.opts.promoteValues
        : true;
    this.promoteBuffers =
      typeof this.opts.promoteBuffers === "boolean"
        ? this.opts.promoteBuffers
        : false;
    this.bsonRegExp =
      typeof this.opts.bsonRegExp === "boolean" ? this.opts.bsonRegExp : false;
  }
  isParsed() {
    return this.parsed;
  }
  parse(options) {
    // Don't parse again if not needed
    if (this.parsed) return;
    options = options ?? {};
    // Allow the return of raw documents instead of parsing
    const raw = options.raw || false;
    const documentsReturnedIn = options.documentsReturnedIn || null;
    const useBigInt64 = options.useBigInt64 ?? this.opts.useBigInt64;
    const promoteLongs = options.promoteLongs ?? this.opts.promoteLongs;
    const promoteValues = options.promoteValues ?? this.opts.promoteValues;
    const promoteBuffers = options.promoteBuffers ?? this.opts.promoteBuffers;
    const bsonRegExp = options.bsonRegExp ?? this.opts.bsonRegExp;
    let bsonSize;
    // Set up the options
    const _options = {
      useBigInt64,
      promoteLongs,
      promoteValues,
      promoteBuffers,
      bsonRegExp,
    };
    // Position within OP_REPLY at which documents start
    // (See https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#wire-op-reply)
    this.index = 20;
    // Read the message body
    this.responseFlags = this.data.readInt32LE(0);
    this.cursorId = new BSON$2.Long(
      this.data.readInt32LE(4),
      this.data.readInt32LE(8),
    );
    this.startingFrom = this.data.readInt32LE(12);
    this.numberReturned = this.data.readInt32LE(16);
    // Preallocate document array
    this.documents = new Array(this.numberReturned);
    this.cursorNotFound = (this.responseFlags & CURSOR_NOT_FOUND) !== 0;
    this.queryFailure = (this.responseFlags & QUERY_FAILURE) !== 0;
    this.shardConfigStale = (this.responseFlags & SHARD_CONFIG_STALE) !== 0;
    this.awaitCapable = (this.responseFlags & AWAIT_CAPABLE) !== 0;
    // Parse Body
    for (let i = 0; i < this.numberReturned; i++) {
      bsonSize =
        this.data[this.index] |
        (this.data[this.index + 1] << 8) |
        (this.data[this.index + 2] << 16) |
        (this.data[this.index + 3] << 24);
      // If we have raw results specified slice the return document
      if (raw) {
        this.documents[i] = this.data.slice(this.index, this.index + bsonSize);
      } else {
        this.documents[i] = BSON$2.deserialize(
          this.data.slice(this.index, this.index + bsonSize),
          _options,
        );
      }
      // Adjust the index
      this.index = this.index + bsonSize;
    }
    if (this.documents.length === 1 && documentsReturnedIn != null && raw) {
      const fieldsAsRaw = {};
      fieldsAsRaw[documentsReturnedIn] = true;
      _options.fieldsAsRaw = fieldsAsRaw;
      const doc = BSON$2.deserialize(this.documents[0], _options);
      this.documents = [doc];
    }
    // Set parsed
    this.parsed = true;
  }
}
commands.Response = Response;
// Implementation of OP_MSG spec:
// https://github.com/mongodb/specifications/blob/master/source/message/OP_MSG.rst
//
// struct Section {
//   uint8 payloadType;
//   union payload {
//       document  document; // payloadType == 0
//       struct sequence { // payloadType == 1
//           int32      size;
//           cstring    identifier;
//           document*  documents;
//       };
//   };
// };
// struct OP_MSG {
//   struct MsgHeader {
//       int32  messageLength;
//       int32  requestID;
//       int32  responseTo;
//       int32  opCode = 2013;
//   };
//   uint32      flagBits;
//   Section+    sections;
//   [uint32     checksum;]
// };
// Msg Flags
const OPTS_CHECKSUM_PRESENT = 1;
const OPTS_MORE_TO_COME = 2;
const OPTS_EXHAUST_ALLOWED = 1 << 16;
/** @internal */
class Msg {
  constructor(databaseName, command, options) {
    this.databaseName = databaseName;
    this.command = command;
    this.options = options;
    // Basic options needed to be passed in
    if (command == null)
      throw new error_1$g.MongoInvalidArgumentError(
        "Query document must be specified for query",
      );
    // Basic options
    this.command.$db = databaseName;
    if (
      options.readPreference &&
      options.readPreference.mode !== read_preference_1.ReadPreference.PRIMARY
    ) {
      this.command.$readPreference = options.readPreference.toJSON();
    }
    // Ensure empty options
    this.options = options ?? {};
    // Additional options
    this.requestId = options.requestId ? options.requestId : Msg.getRequestId();
    // Serialization option
    this.serializeFunctions =
      typeof options.serializeFunctions === "boolean"
        ? options.serializeFunctions
        : false;
    this.ignoreUndefined =
      typeof options.ignoreUndefined === "boolean"
        ? options.ignoreUndefined
        : false;
    this.checkKeys =
      typeof options.checkKeys === "boolean" ? options.checkKeys : false;
    this.maxBsonSize = options.maxBsonSize || 1024 * 1024 * 16;
    // flags
    this.checksumPresent = false;
    this.moreToCome = options.moreToCome || false;
    this.exhaustAllowed =
      typeof options.exhaustAllowed === "boolean"
        ? options.exhaustAllowed
        : false;
  }
  toBin() {
    const buffers = [];
    let flags = 0;
    if (this.checksumPresent) {
      flags |= OPTS_CHECKSUM_PRESENT;
    }
    if (this.moreToCome) {
      flags |= OPTS_MORE_TO_COME;
    }
    if (this.exhaustAllowed) {
      flags |= OPTS_EXHAUST_ALLOWED;
    }
    const header = Buffer.alloc(
      4 * 4 + // Header
        4, // Flags
    );
    buffers.push(header);
    let totalLength = header.length;
    const command = this.command;
    totalLength += this.makeDocumentSegment(buffers, command);
    header.writeInt32LE(totalLength, 0); // messageLength
    header.writeInt32LE(this.requestId, 4); // requestID
    header.writeInt32LE(0, 8); // responseTo
    header.writeInt32LE(constants_1$3.OP_MSG, 12); // opCode
    header.writeUInt32LE(flags, 16); // flags
    return buffers;
  }
  makeDocumentSegment(buffers, document) {
    const payloadTypeBuffer = Buffer.alloc(1);
    payloadTypeBuffer[0] = 0;
    const documentBuffer = this.serializeBson(document);
    buffers.push(payloadTypeBuffer);
    buffers.push(documentBuffer);
    return payloadTypeBuffer.length + documentBuffer.length;
  }
  serializeBson(document) {
    return BSON$2.serialize(document, {
      checkKeys: this.checkKeys,
      serializeFunctions: this.serializeFunctions,
      ignoreUndefined: this.ignoreUndefined,
    });
  }
  static getRequestId() {
    _requestId = (_requestId + 1) & 0x7fffffff;
    return _requestId;
  }
}
commands.Msg = Msg;
/** @internal */
class BinMsg {
  constructor(message, msgHeader, msgBody, opts) {
    this.parsed = false;
    this.raw = message;
    this.data = msgBody;
    this.opts = opts ?? {
      useBigInt64: false,
      promoteLongs: true,
      promoteValues: true,
      promoteBuffers: false,
      bsonRegExp: false,
    };
    // Read the message header
    this.length = msgHeader.length;
    this.requestId = msgHeader.requestId;
    this.responseTo = msgHeader.responseTo;
    this.opCode = msgHeader.opCode;
    this.fromCompressed = msgHeader.fromCompressed;
    // Read response flags
    this.responseFlags = msgBody.readInt32LE(0);
    this.checksumPresent = (this.responseFlags & OPTS_CHECKSUM_PRESENT) !== 0;
    this.moreToCome = (this.responseFlags & OPTS_MORE_TO_COME) !== 0;
    this.exhaustAllowed = (this.responseFlags & OPTS_EXHAUST_ALLOWED) !== 0;
    this.useBigInt64 =
      typeof this.opts.useBigInt64 === "boolean"
        ? this.opts.useBigInt64
        : false;
    this.promoteLongs =
      typeof this.opts.promoteLongs === "boolean"
        ? this.opts.promoteLongs
        : true;
    this.promoteValues =
      typeof this.opts.promoteValues === "boolean"
        ? this.opts.promoteValues
        : true;
    this.promoteBuffers =
      typeof this.opts.promoteBuffers === "boolean"
        ? this.opts.promoteBuffers
        : false;
    this.bsonRegExp =
      typeof this.opts.bsonRegExp === "boolean" ? this.opts.bsonRegExp : false;
    this.documents = [];
  }
  isParsed() {
    return this.parsed;
  }
  parse(options) {
    // Don't parse again if not needed
    if (this.parsed) return;
    options = options ?? {};
    this.index = 4;
    // Allow the return of raw documents instead of parsing
    const raw = options.raw || false;
    const documentsReturnedIn = options.documentsReturnedIn || null;
    const useBigInt64 = options.useBigInt64 ?? this.opts.useBigInt64;
    const promoteLongs = options.promoteLongs ?? this.opts.promoteLongs;
    const promoteValues = options.promoteValues ?? this.opts.promoteValues;
    const promoteBuffers = options.promoteBuffers ?? this.opts.promoteBuffers;
    const bsonRegExp = options.bsonRegExp ?? this.opts.bsonRegExp;
    const validation = this.parseBsonSerializationOptions(options);
    // Set up the options
    const bsonOptions = {
      useBigInt64,
      promoteLongs,
      promoteValues,
      promoteBuffers,
      bsonRegExp,
      validation,
      // Due to the strictness of the BSON libraries validation option we need this cast
    };
    while (this.index < this.data.length) {
      const payloadType = this.data.readUInt8(this.index++);
      if (payloadType === 0) {
        const bsonSize = this.data.readUInt32LE(this.index);
        const bin = this.data.slice(this.index, this.index + bsonSize);
        this.documents.push(raw ? bin : BSON$2.deserialize(bin, bsonOptions));
        this.index += bsonSize;
      } else if (payloadType === 1) {
        // It was decided that no driver makes use of payload type 1
        // TODO(NODE-3483): Replace with MongoDeprecationError
        throw new error_1$g.MongoRuntimeError(
          "OP_MSG Payload Type 1 detected unsupported protocol",
        );
      }
    }
    if (this.documents.length === 1 && documentsReturnedIn != null && raw) {
      const fieldsAsRaw = {};
      fieldsAsRaw[documentsReturnedIn] = true;
      bsonOptions.fieldsAsRaw = fieldsAsRaw;
      const doc = BSON$2.deserialize(this.documents[0], bsonOptions);
      this.documents = [doc];
    }
    this.parsed = true;
  }
  parseBsonSerializationOptions({ enableUtf8Validation }) {
    if (enableUtf8Validation === false) {
      return { utf8: false };
    }
    return { utf8: { writeErrors: false } };
  }
}
commands.BinMsg = BinMsg;

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.SENSITIVE_COMMANDS =
    exports.CommandFailedEvent =
    exports.CommandSucceededEvent =
    exports.CommandStartedEvent =
      void 0;
  const constants_1 = constants;
  const utils_1 = utils$2;
  const commands_1 = commands;
  /**
   * An event indicating the start of a given command
   * @public
   * @category Event
   */
  class CommandStartedEvent {
    /**
     * Create a started event
     *
     * @internal
     * @param pool - the pool that originated the command
     * @param command - the command
     */
    constructor(connection, command) {
      /** @internal */
      this.name = constants_1.COMMAND_STARTED;
      const cmd = extractCommand(command);
      const commandName = extractCommandName(cmd);
      const { address, connectionId, serviceId } =
        extractConnectionDetails(connection);
      // TODO: remove in major revision, this is not spec behavior
      if (exports.SENSITIVE_COMMANDS.has(commandName)) {
        this.commandObj = {};
        this.commandObj[commandName] = true;
      }
      this.address = address;
      this.connectionId = connectionId;
      this.serviceId = serviceId;
      this.requestId = command.requestId;
      this.databaseName = command.databaseName;
      this.commandName = commandName;
      this.command = maybeRedact(commandName, cmd, cmd);
    }
    /* @internal */
    get hasServiceId() {
      return !!this.serviceId;
    }
  }
  exports.CommandStartedEvent = CommandStartedEvent;
  /**
   * An event indicating the success of a given command
   * @public
   * @category Event
   */
  class CommandSucceededEvent {
    /**
     * Create a succeeded event
     *
     * @internal
     * @param pool - the pool that originated the command
     * @param command - the command
     * @param reply - the reply for this command from the server
     * @param started - a high resolution tuple timestamp of when the command was first sent, to calculate duration
     */
    constructor(connection, command, reply, started) {
      /** @internal */
      this.name = constants_1.COMMAND_SUCCEEDED;
      const cmd = extractCommand(command);
      const commandName = extractCommandName(cmd);
      const { address, connectionId, serviceId } =
        extractConnectionDetails(connection);
      this.address = address;
      this.connectionId = connectionId;
      this.serviceId = serviceId;
      this.requestId = command.requestId;
      this.commandName = commandName;
      this.duration = (0, utils_1.calculateDurationInMs)(started);
      this.reply = maybeRedact(commandName, cmd, extractReply(command, reply));
    }
    /* @internal */
    get hasServiceId() {
      return !!this.serviceId;
    }
  }
  exports.CommandSucceededEvent = CommandSucceededEvent;
  /**
   * An event indicating the failure of a given command
   * @public
   * @category Event
   */
  class CommandFailedEvent {
    /**
     * Create a failure event
     *
     * @internal
     * @param pool - the pool that originated the command
     * @param command - the command
     * @param error - the generated error or a server error response
     * @param started - a high resolution tuple timestamp of when the command was first sent, to calculate duration
     */
    constructor(connection, command, error, started) {
      /** @internal */
      this.name = constants_1.COMMAND_FAILED;
      const cmd = extractCommand(command);
      const commandName = extractCommandName(cmd);
      const { address, connectionId, serviceId } =
        extractConnectionDetails(connection);
      this.address = address;
      this.connectionId = connectionId;
      this.serviceId = serviceId;
      this.requestId = command.requestId;
      this.commandName = commandName;
      this.duration = (0, utils_1.calculateDurationInMs)(started);
      this.failure = maybeRedact(commandName, cmd, error);
    }
    /* @internal */
    get hasServiceId() {
      return !!this.serviceId;
    }
  }
  exports.CommandFailedEvent = CommandFailedEvent;
  /**
   * Commands that we want to redact because of the sensitive nature of their contents
   * @internal
   */
  exports.SENSITIVE_COMMANDS = new Set([
    "authenticate",
    "saslStart",
    "saslContinue",
    "getnonce",
    "createUser",
    "updateUser",
    "copydbgetnonce",
    "copydbsaslstart",
    "copydb",
  ]);
  const HELLO_COMMANDS = new Set([
    "hello",
    constants_1.LEGACY_HELLO_COMMAND,
    constants_1.LEGACY_HELLO_COMMAND_CAMEL_CASE,
  ]);
  // helper methods
  const extractCommandName = (commandDoc) => Object.keys(commandDoc)[0];
  const namespace = (command) => command.ns;
  const collectionName = (command) => command.ns.split(".")[1];
  const maybeRedact = (commandName, commandDoc, result) =>
    exports.SENSITIVE_COMMANDS.has(commandName) ||
    (HELLO_COMMANDS.has(commandName) && commandDoc.speculativeAuthenticate)
      ? {}
      : result;
  const LEGACY_FIND_QUERY_MAP = {
    $query: "filter",
    $orderby: "sort",
    $hint: "hint",
    $comment: "comment",
    $maxScan: "maxScan",
    $max: "max",
    $min: "min",
    $returnKey: "returnKey",
    $showDiskLoc: "showRecordId",
    $maxTimeMS: "maxTimeMS",
    $snapshot: "snapshot",
  };
  const LEGACY_FIND_OPTIONS_MAP = {
    numberToSkip: "skip",
    numberToReturn: "batchSize",
    returnFieldSelector: "projection",
  };
  const OP_QUERY_KEYS = [
    "tailable",
    "oplogReplay",
    "noCursorTimeout",
    "awaitData",
    "partial",
    "exhaust",
  ];
  /** Extract the actual command from the query, possibly up-converting if it's a legacy format */
  function extractCommand(command) {
    if (command instanceof commands_1.Msg) {
      return (0, utils_1.deepCopy)(command.command);
    }
    if (command.query?.$query) {
      let result;
      if (command.ns === "admin.$cmd") {
        // up-convert legacy command
        result = Object.assign({}, command.query.$query);
      } else {
        // up-convert legacy find command
        result = { find: collectionName(command) };
        Object.keys(LEGACY_FIND_QUERY_MAP).forEach((key) => {
          if (command.query[key] != null) {
            result[LEGACY_FIND_QUERY_MAP[key]] = (0, utils_1.deepCopy)(
              command.query[key],
            );
          }
        });
      }
      Object.keys(LEGACY_FIND_OPTIONS_MAP).forEach((key) => {
        const legacyKey = key;
        if (command[legacyKey] != null) {
          result[LEGACY_FIND_OPTIONS_MAP[legacyKey]] = (0, utils_1.deepCopy)(
            command[legacyKey],
          );
        }
      });
      OP_QUERY_KEYS.forEach((key) => {
        if (command[key]) {
          result[key] = command[key];
        }
      });
      if (command.pre32Limit != null) {
        result.limit = command.pre32Limit;
      }
      if (command.query.$explain) {
        return { explain: result };
      }
      return result;
    }
    const clonedQuery = {};
    const clonedCommand = {};
    if (command.query) {
      for (const k in command.query) {
        clonedQuery[k] = (0, utils_1.deepCopy)(command.query[k]);
      }
      clonedCommand.query = clonedQuery;
    }
    for (const k in command) {
      if (k === "query") continue;
      clonedCommand[k] = (0, utils_1.deepCopy)(command[k]);
    }
    return command.query ? clonedQuery : clonedCommand;
  }
  function extractReply(command, reply) {
    if (!reply) {
      return reply;
    }
    if (command instanceof commands_1.Msg) {
      return (0, utils_1.deepCopy)(reply.result ? reply.result : reply);
    }
    // is this a legacy find command?
    if (command.query && command.query.$query != null) {
      return {
        ok: 1,
        cursor: {
          id: (0, utils_1.deepCopy)(reply.cursorId),
          ns: namespace(command),
          firstBatch: (0, utils_1.deepCopy)(reply.documents),
        },
      };
    }
    return (0, utils_1.deepCopy)(reply.result ? reply.result : reply);
  }
  function extractConnectionDetails(connection) {
    let connectionId;
    if ("id" in connection) {
      connectionId = connection.id;
    }
    return {
      address: connection.address,
      serviceId: connection.serviceId,
      connectionId,
    };
  }
})(command_monitoring_events);

var message_stream = {};

Object.defineProperty(message_stream, "__esModule", { value: true });
message_stream.MessageStream = void 0;
const stream_1$2 = $nodeStream;
const error_1$f = error;
const utils_1$b = utils$2;
const commands_1$1 = commands;
const compression_1 = compression;
const constants_1$2 = constants$1;
const MESSAGE_HEADER_SIZE = 16;
const COMPRESSION_DETAILS_SIZE = 9; // originalOpcode + uncompressedSize, compressorID
const kDefaultMaxBsonMessageSize = 1024 * 1024 * 16 * 4;
/** @internal */
const kBuffer = Symbol("buffer");
/**
 * A duplex stream that is capable of reading and writing raw wire protocol messages, with
 * support for optional compression
 * @internal
 */
class MessageStream extends stream_1$2.Duplex {
  constructor(options = {}) {
    super(options);
    /** @internal */
    this.isMonitoringConnection = false;
    this.maxBsonMessageSize =
      options.maxBsonMessageSize || kDefaultMaxBsonMessageSize;
    this[kBuffer] = new utils_1$b.BufferPool();
  }
  get buffer() {
    return this[kBuffer];
  }
  _write(chunk, _, callback) {
    this[kBuffer].append(chunk);
    processIncomingData(this, callback);
  }
  _read(/* size */) {
    // NOTE: This implementation is empty because we explicitly push data to be read
    //       when `writeMessage` is called.
    return;
  }
  writeCommand(command, operationDescription) {
    const agreedCompressor = operationDescription.agreedCompressor ?? "none";
    if (agreedCompressor === "none" || !canCompress(command)) {
      const data = command.toBin();
      this.push(Array.isArray(data) ? Buffer.concat(data) : data);
      return;
    }
    // otherwise, compress the message
    const concatenatedOriginalCommandBuffer = Buffer.concat(command.toBin());
    const messageToBeCompressed =
      concatenatedOriginalCommandBuffer.slice(MESSAGE_HEADER_SIZE);
    // Extract information needed for OP_COMPRESSED from the uncompressed message
    const originalCommandOpCode =
      concatenatedOriginalCommandBuffer.readInt32LE(12);
    const options = {
      agreedCompressor,
      zlibCompressionLevel: operationDescription.zlibCompressionLevel ?? 0,
    };
    // Compress the message body
    (0, compression_1.compress)(options, messageToBeCompressed).then(
      (compressedMessage) => {
        // Create the msgHeader of OP_COMPRESSED
        const msgHeader = Buffer.alloc(MESSAGE_HEADER_SIZE);
        msgHeader.writeInt32LE(
          MESSAGE_HEADER_SIZE +
            COMPRESSION_DETAILS_SIZE +
            compressedMessage.length,
          0,
        ); // messageLength
        msgHeader.writeInt32LE(command.requestId, 4); // requestID
        msgHeader.writeInt32LE(0, 8); // responseTo (zero)
        msgHeader.writeInt32LE(constants_1$2.OP_COMPRESSED, 12); // opCode
        // Create the compression details of OP_COMPRESSED
        const compressionDetails = Buffer.alloc(COMPRESSION_DETAILS_SIZE);
        compressionDetails.writeInt32LE(originalCommandOpCode, 0); // originalOpcode
        compressionDetails.writeInt32LE(messageToBeCompressed.length, 4); // Size of the uncompressed compressedMessage, excluding the MsgHeader
        compressionDetails.writeUInt8(
          compression_1.Compressor[agreedCompressor],
          8,
        ); // compressorID
        this.push(
          Buffer.concat([msgHeader, compressionDetails, compressedMessage]),
        );
      },
      (error) => {
        operationDescription.cb(error);
      },
    );
  }
}
message_stream.MessageStream = MessageStream;
// Return whether a command contains an uncompressible command term
// Will return true if command contains no uncompressible command terms
function canCompress(command) {
  const commandDoc =
    command instanceof commands_1$1.Msg ? command.command : command.query;
  const commandName = Object.keys(commandDoc)[0];
  return !compression_1.uncompressibleCommands.has(commandName);
}
function processIncomingData(stream, callback) {
  const buffer = stream[kBuffer];
  const sizeOfMessage = buffer.getInt32();
  if (sizeOfMessage == null) {
    return callback();
  }
  if (sizeOfMessage < 0) {
    return callback(
      new error_1$f.MongoParseError(`Invalid message size: ${sizeOfMessage}`),
    );
  }
  if (sizeOfMessage > stream.maxBsonMessageSize) {
    return callback(
      new error_1$f.MongoParseError(
        `Invalid message size: ${sizeOfMessage}, max allowed: ${stream.maxBsonMessageSize}`,
      ),
    );
  }
  if (sizeOfMessage > buffer.length) {
    return callback();
  }
  const message = buffer.read(sizeOfMessage);
  const messageHeader = {
    length: message.readInt32LE(0),
    requestId: message.readInt32LE(4),
    responseTo: message.readInt32LE(8),
    opCode: message.readInt32LE(12),
  };
  const monitorHasAnotherHello = () => {
    if (stream.isMonitoringConnection) {
      // Can we read the next message size?
      const sizeOfMessage = buffer.getInt32();
      if (sizeOfMessage != null && sizeOfMessage <= buffer.length) {
        return true;
      }
    }
    return false;
  };
  let ResponseType =
    messageHeader.opCode === constants_1$2.OP_MSG
      ? commands_1$1.BinMsg
      : commands_1$1.Response;
  if (messageHeader.opCode !== constants_1$2.OP_COMPRESSED) {
    const messageBody = message.subarray(MESSAGE_HEADER_SIZE);
    // If we are a monitoring connection message stream and
    // there is more in the buffer that can be read, skip processing since we
    // want the last hello command response that is in the buffer.
    if (monitorHasAnotherHello()) {
      return processIncomingData(stream, callback);
    }
    stream.emit(
      "message",
      new ResponseType(message, messageHeader, messageBody),
    );
    if (buffer.length >= 4) {
      return processIncomingData(stream, callback);
    }
    return callback();
  }
  messageHeader.fromCompressed = true;
  messageHeader.opCode = message.readInt32LE(MESSAGE_HEADER_SIZE);
  messageHeader.length = message.readInt32LE(MESSAGE_HEADER_SIZE + 4);
  const compressorID = message[MESSAGE_HEADER_SIZE + 8];
  const compressedBuffer = message.slice(MESSAGE_HEADER_SIZE + 9);
  // recalculate based on wrapped opcode
  ResponseType =
    messageHeader.opCode === constants_1$2.OP_MSG
      ? commands_1$1.BinMsg
      : commands_1$1.Response;
  (0, compression_1.decompress)(compressorID, compressedBuffer).then(
    (messageBody) => {
      if (messageBody.length !== messageHeader.length) {
        return callback(
          new error_1$f.MongoDecompressionError(
            "Message body and message header must be the same length",
          ),
        );
      }
      // If we are a monitoring connection message stream and
      // there is more in the buffer that can be read, skip processing since we
      // want the last hello command response that is in the buffer.
      if (monitorHasAnotherHello()) {
        return processIncomingData(stream, callback);
      }
      stream.emit(
        "message",
        new ResponseType(message, messageHeader, messageBody),
      );
      if (buffer.length >= 4) {
        return processIncomingData(stream, callback);
      }
      return callback();
    },
    (error) => {
      return callback(error);
    },
  );
}

var stream_description = {};

Object.defineProperty(stream_description, "__esModule", { value: true });
stream_description.StreamDescription = void 0;
const common_1 = common$1;
const server_description_1 = server_description;
const RESPONSE_FIELDS = [
  "minWireVersion",
  "maxWireVersion",
  "maxBsonObjectSize",
  "maxMessageSizeBytes",
  "maxWriteBatchSize",
  "logicalSessionTimeoutMinutes",
];
/** @public */
class StreamDescription {
  constructor(address, options) {
    this.address = address;
    this.type = common_1.ServerType.Unknown;
    this.minWireVersion = undefined;
    this.maxWireVersion = undefined;
    this.maxBsonObjectSize = 16777216;
    this.maxMessageSizeBytes = 48000000;
    this.maxWriteBatchSize = 100000;
    this.logicalSessionTimeoutMinutes = options?.logicalSessionTimeoutMinutes;
    this.loadBalanced = !!options?.loadBalanced;
    this.compressors =
      options && options.compressors && Array.isArray(options.compressors)
        ? options.compressors
        : [];
  }
  receiveResponse(response) {
    if (response == null) {
      return;
    }
    this.type = (0, server_description_1.parseServerType)(response);
    for (const field of RESPONSE_FIELDS) {
      if (response[field] != null) {
        this[field] = response[field];
      }
      // testing case
      if ("__nodejs_mock_server__" in response) {
        this.__nodejs_mock_server__ = response["__nodejs_mock_server__"];
      }
    }
    if (response.compression) {
      this.compressor = this.compressors.filter((c) =>
        response.compression?.includes(c),
      )[0];
    }
  }
}
stream_description.StreamDescription = StreamDescription;

Object.defineProperty(connection, "__esModule", { value: true });
connection.hasSessionSupport =
  connection.CryptoConnection =
  connection.Connection =
    void 0;
const timers_1$1 = $nodeTimers;
const util_1$2 = $noteUtil;
const constants_1$1 = constants;
const error_1$e = error;
const mongo_types_1$2 = mongo_types;
const sessions_1 = sessions;
const utils_1$a = utils$2;
const command_monitoring_events_1 = command_monitoring_events;
const commands_1 = commands;
const message_stream_1 = message_stream;
const stream_description_1 = stream_description;
const shared_1 = shared;
/** @internal */
const kStream = Symbol("stream");
/** @internal */
const kQueue = Symbol("queue");
/** @internal */
const kMessageStream = Symbol("messageStream");
/** @internal */
const kGeneration = Symbol("generation");
/** @internal */
const kLastUseTime = Symbol("lastUseTime");
/** @internal */
const kClusterTime = Symbol("clusterTime");
/** @internal */
const kDescription = Symbol("description");
/** @internal */
const kHello = Symbol("hello");
/** @internal */
const kAutoEncrypter = Symbol("autoEncrypter");
/** @internal */
const kDelayedTimeoutId = Symbol("delayedTimeoutId");
const INVALID_QUEUE_SIZE =
  "Connection internal queue contains more than 1 operation description";
/** @internal */
class Connection extends mongo_types_1$2.TypedEventEmitter {
  constructor(stream, options) {
    super();
    this.commandAsync = (0, util_1$2.promisify)((ns, cmd, options, callback) =>
      this.command(ns, cmd, options, callback),
    );
    this.id = options.id;
    this.address = streamIdentifier(stream, options);
    this.socketTimeoutMS = options.socketTimeoutMS ?? 0;
    this.monitorCommands = options.monitorCommands;
    this.serverApi = options.serverApi;
    this.closed = false;
    this[kHello] = null;
    this[kClusterTime] = null;
    this[kDescription] = new stream_description_1.StreamDescription(
      this.address,
      options,
    );
    this[kGeneration] = options.generation;
    this[kLastUseTime] = (0, utils_1$a.now)();
    // setup parser stream and message handling
    this[kQueue] = new Map();
    this[kMessageStream] = new message_stream_1.MessageStream({
      ...options,
      maxBsonMessageSize: this.hello?.maxBsonMessageSize,
    });
    this[kStream] = stream;
    this[kDelayedTimeoutId] = null;
    this[kMessageStream].on("message", (message) => this.onMessage(message));
    this[kMessageStream].on("error", (error) => this.onError(error));
    this[kStream].on("close", () => this.onClose());
    this[kStream].on("timeout", () => this.onTimeout());
    this[kStream].on("error", () => {
      /* ignore errors, listen to `close` instead */
    });
    // hook the message stream up to the passed in stream
    this[kStream].pipe(this[kMessageStream]);
    this[kMessageStream].pipe(this[kStream]);
  }
  get description() {
    return this[kDescription];
  }
  get hello() {
    return this[kHello];
  }
  // the `connect` method stores the result of the handshake hello on the connection
  set hello(response) {
    this[kDescription].receiveResponse(response);
    this[kDescription] = Object.freeze(this[kDescription]);
    // TODO: remove this, and only use the `StreamDescription` in the future
    this[kHello] = response;
  }
  // Set the whether the message stream is for a monitoring connection.
  set isMonitoringConnection(value) {
    this[kMessageStream].isMonitoringConnection = value;
  }
  get isMonitoringConnection() {
    return this[kMessageStream].isMonitoringConnection;
  }
  get serviceId() {
    return this.hello?.serviceId;
  }
  get loadBalanced() {
    return this.description.loadBalanced;
  }
  get generation() {
    return this[kGeneration] || 0;
  }
  set generation(generation) {
    this[kGeneration] = generation;
  }
  get idleTime() {
    return (0, utils_1$a.calculateDurationInMs)(this[kLastUseTime]);
  }
  get clusterTime() {
    return this[kClusterTime];
  }
  get stream() {
    return this[kStream];
  }
  markAvailable() {
    this[kLastUseTime] = (0, utils_1$a.now)();
  }
  onError(error) {
    this.cleanup(true, error);
  }
  onClose() {
    const message = `connection ${this.id} to ${this.address} closed`;
    this.cleanup(true, new error_1$e.MongoNetworkError(message));
  }
  onTimeout() {
    this[kDelayedTimeoutId] = (0, timers_1$1.setTimeout)(() => {
      const message = `connection ${this.id} to ${this.address} timed out`;
      const beforeHandshake = this.hello == null;
      this.cleanup(
        true,
        new error_1$e.MongoNetworkTimeoutError(message, { beforeHandshake }),
      );
    }, 1).unref(); // No need for this timer to hold the event loop open
  }
  onMessage(message) {
    const delayedTimeoutId = this[kDelayedTimeoutId];
    if (delayedTimeoutId != null) {
      (0, timers_1$1.clearTimeout)(delayedTimeoutId);
      this[kDelayedTimeoutId] = null;
    }
    const socketTimeoutMS = this[kStream].timeout ?? 0;
    this[kStream].setTimeout(0);
    // always emit the message, in case we are streaming
    this.emit("message", message);
    let operationDescription = this[kQueue].get(message.responseTo);
    if (!operationDescription && this.isMonitoringConnection) {
      // This is how we recover when the initial hello's requestId is not
      // the responseTo when hello responses have been skipped:
      // First check if the map is of invalid size
      if (this[kQueue].size > 1) {
        this.cleanup(true, new error_1$e.MongoRuntimeError(INVALID_QUEUE_SIZE));
      } else {
        // Get the first orphaned operation description.
        const entry = this[kQueue].entries().next();
        if (entry.value != null) {
          const [requestId, orphaned] = entry.value;
          // If the orphaned operation description exists then set it.
          operationDescription = orphaned;
          // Remove the entry with the bad request id from the queue.
          this[kQueue].delete(requestId);
        }
      }
    }
    if (!operationDescription) {
      return;
    }
    const callback = operationDescription.cb;
    // SERVER-45775: For exhaust responses we should be able to use the same requestId to
    // track response, however the server currently synthetically produces remote requests
    // making the `responseTo` change on each response
    this[kQueue].delete(message.responseTo);
    if ("moreToCome" in message && message.moreToCome) {
      // If the operation description check above does find an orphaned
      // description and sets the operationDescription then this line will put one
      // back in the queue with the correct requestId and will resolve not being able
      // to find the next one via the responseTo of the next streaming hello.
      this[kQueue].set(message.requestId, operationDescription);
      this[kStream].setTimeout(socketTimeoutMS);
    }
    try {
      // Pass in the entire description because it has BSON parsing options
      message.parse(operationDescription);
    } catch (err) {
      // If this error is generated by our own code, it will already have the correct class applied
      // if it is not, then it is coming from a catastrophic data parse failure or the BSON library
      // in either case, it should not be wrapped
      callback(err);
      return;
    }
    if (message.documents[0]) {
      const document = message.documents[0];
      const session = operationDescription.session;
      if (session) {
        (0, sessions_1.updateSessionFromResponse)(session, document);
      }
      if (document.$clusterTime) {
        this[kClusterTime] = document.$clusterTime;
        this.emit(Connection.CLUSTER_TIME_RECEIVED, document.$clusterTime);
      }
      if (document.writeConcernError) {
        callback(
          new error_1$e.MongoWriteConcernError(
            document.writeConcernError,
            document,
          ),
          document,
        );
        return;
      }
      if (
        document.ok === 0 ||
        document.$err ||
        document.errmsg ||
        document.code
      ) {
        callback(new error_1$e.MongoServerError(document));
        return;
      }
    }
    callback(undefined, message.documents[0]);
  }
  destroy(options, callback) {
    if (this.closed) {
      process.nextTick(() => callback?.());
      return;
    }
    if (typeof callback === "function") {
      this.once("close", () => process.nextTick(() => callback()));
    }
    // load balanced mode requires that these listeners remain on the connection
    // after cleanup on timeouts, errors or close so we remove them before calling
    // cleanup.
    this.removeAllListeners(Connection.PINNED);
    this.removeAllListeners(Connection.UNPINNED);
    const message = `connection ${this.id} to ${this.address} closed`;
    this.cleanup(options.force, new error_1$e.MongoNetworkError(message));
  }
  /**
   * A method that cleans up the connection.  When `force` is true, this method
   * forcibly destroys the socket.
   *
   * If an error is provided, any in-flight operations will be closed with the error.
   *
   * This method does nothing if the connection is already closed.
   */
  cleanup(force, error) {
    if (this.closed) {
      return;
    }
    this.closed = true;
    const completeCleanup = () => {
      for (const op of this[kQueue].values()) {
        op.cb(error);
      }
      this[kQueue].clear();
      this.emit(Connection.CLOSE);
    };
    this[kStream].removeAllListeners();
    this[kMessageStream].removeAllListeners();
    this[kMessageStream].destroy();
    if (force) {
      this[kStream].destroy();
      completeCleanup();
      return;
    }
    if (!this[kStream].writableEnded) {
      this[kStream].end(() => {
        this[kStream].destroy();
        completeCleanup();
      });
    } else {
      completeCleanup();
    }
  }
  command(ns, command, options, callback) {
    let cmd = { ...command };
    const readPreference = (0, shared_1.getReadPreference)(options);
    const shouldUseOpMsg = supportsOpMsg(this);
    const session = options?.session;
    let clusterTime = this.clusterTime;
    if (this.serverApi) {
      const { version, strict, deprecationErrors } = this.serverApi;
      cmd.apiVersion = version;
      if (strict != null) cmd.apiStrict = strict;
      if (deprecationErrors != null)
        cmd.apiDeprecationErrors = deprecationErrors;
    }
    if (hasSessionSupport(this) && session) {
      if (
        session.clusterTime &&
        clusterTime &&
        session.clusterTime.clusterTime.greaterThan(clusterTime.clusterTime)
      ) {
        clusterTime = session.clusterTime;
      }
      const err = (0, sessions_1.applySession)(session, cmd, options);
      if (err) {
        return callback(err);
      }
    } else if (session?.explicit) {
      return callback(
        new error_1$e.MongoCompatibilityError(
          "Current topology does not support sessions",
        ),
      );
    }
    // if we have a known cluster time, gossip it
    if (clusterTime) {
      cmd.$clusterTime = clusterTime;
    }
    if (
      (0, shared_1.isSharded)(this) &&
      !shouldUseOpMsg &&
      readPreference &&
      readPreference.mode !== "primary"
    ) {
      cmd = {
        $query: cmd,
        $readPreference: readPreference.toJSON(),
      };
    }
    const commandOptions = Object.assign(
      {
        numberToSkip: 0,
        numberToReturn: -1,
        checkKeys: false,
        // This value is not overridable
        secondaryOk: readPreference.secondaryOk(),
      },
      options,
    );
    const message = shouldUseOpMsg
      ? new commands_1.Msg(ns.db, cmd, commandOptions)
      : new commands_1.Query(ns.db, cmd, commandOptions);
    try {
      write(this, message, commandOptions, callback);
    } catch (err) {
      callback(err);
    }
  }
}
/** @event */
Connection.COMMAND_STARTED = constants_1$1.COMMAND_STARTED;
/** @event */
Connection.COMMAND_SUCCEEDED = constants_1$1.COMMAND_SUCCEEDED;
/** @event */
Connection.COMMAND_FAILED = constants_1$1.COMMAND_FAILED;
/** @event */
Connection.CLUSTER_TIME_RECEIVED = constants_1$1.CLUSTER_TIME_RECEIVED;
/** @event */
Connection.CLOSE = constants_1$1.CLOSE;
/** @event */
Connection.MESSAGE = constants_1$1.MESSAGE;
/** @event */
Connection.PINNED = constants_1$1.PINNED;
/** @event */
Connection.UNPINNED = constants_1$1.UNPINNED;
connection.Connection = Connection;
/** @internal */
class CryptoConnection extends Connection {
  constructor(stream, options) {
    super(stream, options);
    this[kAutoEncrypter] = options.autoEncrypter;
  }
  /** @internal @override */
  command(ns, cmd, options, callback) {
    const autoEncrypter = this[kAutoEncrypter];
    if (!autoEncrypter) {
      return callback(
        new error_1$e.MongoMissingDependencyError(
          "No AutoEncrypter available for encryption",
        ),
      );
    }
    const serverWireVersion = (0, utils_1$a.maxWireVersion)(this);
    if (serverWireVersion === 0) {
      // This means the initial handshake hasn't happened yet
      return super.command(ns, cmd, options, callback);
    }
    if (serverWireVersion < 8) {
      callback(
        new error_1$e.MongoCompatibilityError(
          "Auto-encryption requires a minimum MongoDB version of 4.2",
        ),
      );
      return;
    }
    // Save sort or indexKeys based on the command being run
    // the encrypt API serializes our JS objects to BSON to pass to the native code layer
    // and then deserializes the encrypted result, the protocol level components
    // of the command (ex. sort) are then converted to JS objects potentially losing
    // import key order information. These fields are never encrypted so we can save the values
    // from before the encryption and replace them after encryption has been performed
    const sort = cmd.find || cmd.findAndModify ? cmd.sort : null;
    const indexKeys = cmd.createIndexes
      ? cmd.indexes.map((index) => index.key)
      : null;
    autoEncrypter.encrypt(ns.toString(), cmd, options).then(
      (encrypted) => {
        // Replace the saved values
        if (sort != null && (cmd.find || cmd.findAndModify)) {
          encrypted.sort = sort;
        }
        if (indexKeys != null && cmd.createIndexes) {
          for (const [offset, index] of indexKeys.entries()) {
            // @ts-expect-error `encrypted` is a generic "command", but we've narrowed for only `createIndexes` commands here
            encrypted.indexes[offset].key = index;
          }
        }
        super.command(ns, encrypted, options, (err, response) => {
          if (err || response == null) {
            callback(err, response);
            return;
          }
          autoEncrypter.decrypt(response, options).then(
            (res) => callback(undefined, res),
            (err) => callback(err),
          );
        });
      },
      (err) => {
        if (err) {
          callback(err, null);
        }
      },
    );
  }
}
connection.CryptoConnection = CryptoConnection;
/** @internal */
function hasSessionSupport(conn) {
  const description = conn.description;
  return description.logicalSessionTimeoutMinutes != null;
}
connection.hasSessionSupport = hasSessionSupport;
function supportsOpMsg(conn) {
  const description = conn.description;
  if (description == null) {
    return false;
  }
  return (
    (0, utils_1$a.maxWireVersion)(conn) >= 6 &&
    !description.__nodejs_mock_server__
  );
}
function streamIdentifier(stream, options) {
  if (options.proxyHost) {
    // If proxy options are specified, the properties of `stream` itself
    // will not accurately reflect what endpoint this is connected to.
    return options.hostAddress.toString();
  }
  const { remoteAddress, remotePort } = stream;
  if (typeof remoteAddress === "string" && typeof remotePort === "number") {
    return utils_1$a.HostAddress.fromHostPort(
      remoteAddress,
      remotePort,
    ).toString();
  }
  return (0, utils_1$a.uuidV4)().toString("hex");
}
function write(conn, command, options, callback) {
  options = options ?? {};
  const operationDescription = {
    requestId: command.requestId,
    cb: callback,
    session: options.session,
    noResponse:
      typeof options.noResponse === "boolean" ? options.noResponse : false,
    documentsReturnedIn: options.documentsReturnedIn,
    // for BSON parsing
    useBigInt64:
      typeof options.useBigInt64 === "boolean" ? options.useBigInt64 : false,
    promoteLongs:
      typeof options.promoteLongs === "boolean" ? options.promoteLongs : true,
    promoteValues:
      typeof options.promoteValues === "boolean" ? options.promoteValues : true,
    promoteBuffers:
      typeof options.promoteBuffers === "boolean"
        ? options.promoteBuffers
        : false,
    bsonRegExp:
      typeof options.bsonRegExp === "boolean" ? options.bsonRegExp : false,
    enableUtf8Validation:
      typeof options.enableUtf8Validation === "boolean"
        ? options.enableUtf8Validation
        : true,
    raw: typeof options.raw === "boolean" ? options.raw : false,
    started: 0,
  };
  if (conn[kDescription] && conn[kDescription].compressor) {
    operationDescription.agreedCompressor = conn[kDescription].compressor;
    if (conn[kDescription].zlibCompressionLevel) {
      operationDescription.zlibCompressionLevel =
        conn[kDescription].zlibCompressionLevel;
    }
  }
  if (typeof options.socketTimeoutMS === "number") {
    conn[kStream].setTimeout(options.socketTimeoutMS);
  } else if (conn.socketTimeoutMS !== 0) {
    conn[kStream].setTimeout(conn.socketTimeoutMS);
  }
  // if command monitoring is enabled we need to modify the callback here
  if (conn.monitorCommands) {
    conn.emit(
      Connection.COMMAND_STARTED,
      new command_monitoring_events_1.CommandStartedEvent(conn, command),
    );
    operationDescription.started = (0, utils_1$a.now)();
    operationDescription.cb = (err, reply) => {
      // Command monitoring spec states that if ok is 1, then we must always emit
      // a command succeeded event, even if there's an error. Write concern errors
      // will have an ok: 1 in their reply.
      if (err && reply?.ok !== 1) {
        conn.emit(
          Connection.COMMAND_FAILED,
          new command_monitoring_events_1.CommandFailedEvent(
            conn,
            command,
            err,
            operationDescription.started,
          ),
        );
      } else {
        if (reply && (reply.ok === 0 || reply.$err)) {
          conn.emit(
            Connection.COMMAND_FAILED,
            new command_monitoring_events_1.CommandFailedEvent(
              conn,
              command,
              reply,
              operationDescription.started,
            ),
          );
        } else {
          conn.emit(
            Connection.COMMAND_SUCCEEDED,
            new command_monitoring_events_1.CommandSucceededEvent(
              conn,
              command,
              reply,
              operationDescription.started,
            ),
          );
        }
      }
      if (typeof callback === "function") {
        // Since we're passing through the reply with the write concern error now, we
        // need it not to be provided to the original callback in this case so
        // retryability does not get tricked into thinking the command actually
        // succeeded.
        callback(
          err,
          err instanceof error_1$e.MongoWriteConcernError ? undefined : reply,
        );
      }
    };
  }
  if (!operationDescription.noResponse) {
    conn[kQueue].set(operationDescription.requestId, operationDescription);
  }
  try {
    conn[kMessageStream].writeCommand(command, operationDescription);
  } catch (e) {
    if (!operationDescription.noResponse) {
      conn[kQueue].delete(operationDescription.requestId);
      operationDescription.cb(e);
      return;
    }
  }
  if (operationDescription.noResponse) {
    operationDescription.cb();
  }
}

var connection_pool = {};

var connect = {};

var mongocr = {};

Object.defineProperty(mongocr, "__esModule", { value: true });
mongocr.MongoCR = void 0;
const crypto$2 = $nodeCrypto;
const error_1$d = error;
const utils_1$9 = utils$2;
const auth_provider_1$4 = auth_provider;
class MongoCR extends auth_provider_1$4.AuthProvider {
  async auth(authContext) {
    const { connection, credentials } = authContext;
    if (!credentials) {
      throw new error_1$d.MongoMissingCredentialsError(
        "AuthContext must provide credentials.",
      );
    }
    const { username, password, source } = credentials;
    const { nonce } = await connection.commandAsync(
      (0, utils_1$9.ns)(`${source}.$cmd`),
      { getnonce: 1 },
      undefined,
    );
    const hashPassword = crypto$2
      .createHash("md5")
      .update(`${username}:mongo:${password}`, "utf8")
      .digest("hex");
    // Final key
    const key = crypto$2
      .createHash("md5")
      .update(`${nonce}${username}${hashPassword}`, "utf8")
      .digest("hex");
    const authenticateCommand = {
      authenticate: 1,
      user: username,
      nonce,
      key,
    };
    await connection.commandAsync(
      (0, utils_1$9.ns)(`${source}.$cmd`),
      authenticateCommand,
      undefined,
    );
  }
}
mongocr.MongoCR = MongoCR;

var mongodb_aws = {};

Object.defineProperty(mongodb_aws, "__esModule", { value: true });
mongodb_aws.MongoDBAWS = void 0;
const crypto$1 = $nodeCrypto;
const process$1 = process;
const util_1$1 = $noteUtil;
const BSON$1 = bson$2;
const deps_1$1 = deps;
const error_1$c = error;
const utils_1$8 = utils$2;
const auth_provider_1$3 = auth_provider;
const mongo_credentials_1 = mongo_credentials;
const providers_1$3 = providers$1;
/**
 * The following regions use the global AWS STS endpoint, sts.amazonaws.com, by default
 * https://docs.aws.amazon.com/sdkref/latest/guide/feature-sts-regionalized-endpoints.html
 */
const LEGACY_REGIONS = new Set([
  "ap-northeast-1",
  "ap-south-1",
  "ap-southeast-1",
  "ap-southeast-2",
  "aws-global",
  "ca-central-1",
  "eu-central-1",
  "eu-north-1",
  "eu-west-1",
  "eu-west-2",
  "eu-west-3",
  "sa-east-1",
  "us-east-1",
  "us-east-2",
  "us-west-1",
  "us-west-2",
]);
const ASCII_N = 110;
const AWS_RELATIVE_URI = "http://169.254.170.2";
const AWS_EC2_URI = "http://169.254.169.254";
const AWS_EC2_PATH = "/latest/meta-data/iam/security-credentials";
const bsonOptions = {
  useBigInt64: false,
  promoteLongs: true,
  promoteValues: true,
  promoteBuffers: false,
  bsonRegExp: false,
};
class MongoDBAWS extends auth_provider_1$3.AuthProvider {
  constructor() {
    super();
    this.randomBytesAsync = (0, util_1$1.promisify)(crypto$1.randomBytes);
  }
  async auth(authContext) {
    const { connection } = authContext;
    if (!authContext.credentials) {
      throw new error_1$c.MongoMissingCredentialsError(
        "AuthContext must provide credentials.",
      );
    }
    if ("kModuleError" in deps_1$1.aws4) {
      throw deps_1$1.aws4["kModuleError"];
    }
    const { sign } = deps_1$1.aws4;
    if ((0, utils_1$8.maxWireVersion)(connection) < 9) {
      throw new error_1$c.MongoCompatibilityError(
        "MONGODB-AWS authentication requires MongoDB version 4.4 or later",
      );
    }
    if (!authContext.credentials.username) {
      authContext.credentials = await makeTempCredentials(
        authContext.credentials,
      );
    }
    const { credentials } = authContext;
    const accessKeyId = credentials.username;
    const secretAccessKey = credentials.password;
    const sessionToken = credentials.mechanismProperties.AWS_SESSION_TOKEN;
    // If all three defined, include sessionToken, else include username and pass, else no credentials
    const awsCredentials =
      accessKeyId && secretAccessKey && sessionToken
        ? { accessKeyId, secretAccessKey, sessionToken }
        : accessKeyId && secretAccessKey
        ? { accessKeyId, secretAccessKey }
        : undefined;
    const db = credentials.source;
    const nonce = await this.randomBytesAsync(32);
    const saslStart = {
      saslStart: 1,
      mechanism: "MONGODB-AWS",
      payload: BSON$1.serialize({ r: nonce, p: ASCII_N }, bsonOptions),
    };
    const saslStartResponse = await connection.commandAsync(
      (0, utils_1$8.ns)(`${db}.$cmd`),
      saslStart,
      undefined,
    );
    const serverResponse = BSON$1.deserialize(
      saslStartResponse.payload.buffer,
      bsonOptions,
    );
    const host = serverResponse.h;
    const serverNonce = serverResponse.s.buffer;
    if (serverNonce.length !== 64) {
      // TODO(NODE-3483)
      throw new error_1$c.MongoRuntimeError(
        `Invalid server nonce length ${serverNonce.length}, expected 64`,
      );
    }
    if (
      !utils_1$8.ByteUtils.equals(
        serverNonce.subarray(0, nonce.byteLength),
        nonce,
      )
    ) {
      // throw because the serverNonce's leading 32 bytes must equal the client nonce's 32 bytes
      // https://github.com/mongodb/specifications/blob/875446db44aade414011731840831f38a6c668df/source/auth/auth.rst#id11
      // TODO(NODE-3483)
      throw new error_1$c.MongoRuntimeError(
        "Server nonce does not begin with client nonce",
      );
    }
    if (host.length < 1 || host.length > 255 || host.indexOf("..") !== -1) {
      // TODO(NODE-3483)
      throw new error_1$c.MongoRuntimeError(
        `Server returned an invalid host: "${host}"`,
      );
    }
    const body = "Action=GetCallerIdentity&Version=2011-06-15";
    const options = sign(
      {
        method: "POST",
        host,
        region: deriveRegion(serverResponse.h),
        service: "sts",
        headers: {
          "Content-Type": "application/x-www-form-urlencoded",
          "Content-Length": body.length,
          "X-MongoDB-Server-Nonce": utils_1$8.ByteUtils.toBase64(serverNonce),
          "X-MongoDB-GS2-CB-Flag": "n",
        },
        path: "/",
        body,
      },
      awsCredentials,
    );
    const payload = {
      a: options.headers.Authorization,
      d: options.headers["X-Amz-Date"],
    };
    if (sessionToken) {
      payload.t = sessionToken;
    }
    const saslContinue = {
      saslContinue: 1,
      conversationId: 1,
      payload: BSON$1.serialize(payload, bsonOptions),
    };
    await connection.commandAsync(
      (0, utils_1$8.ns)(`${db}.$cmd`),
      saslContinue,
      undefined,
    );
  }
}
MongoDBAWS.credentialProvider = null;
mongodb_aws.MongoDBAWS = MongoDBAWS;
async function makeTempCredentials(credentials) {
  function makeMongoCredentialsFromAWSTemp(creds) {
    if (!creds.AccessKeyId || !creds.SecretAccessKey || !creds.Token) {
      throw new error_1$c.MongoMissingCredentialsError(
        "Could not obtain temporary MONGODB-AWS credentials",
      );
    }
    return new mongo_credentials_1.MongoCredentials({
      username: creds.AccessKeyId,
      password: creds.SecretAccessKey,
      source: credentials.source,
      mechanism: providers_1$3.AuthMechanism.MONGODB_AWS,
      mechanismProperties: {
        AWS_SESSION_TOKEN: creds.Token,
      },
    });
  }
  MongoDBAWS.credentialProvider ??= (0, deps_1$1.getAwsCredentialProvider)();
  // Check if the AWS credential provider from the SDK is present. If not,
  // use the old method.
  if ("kModuleError" in MongoDBAWS.credentialProvider) {
    // If the environment variable AWS_CONTAINER_CREDENTIALS_RELATIVE_URI
    // is set then drivers MUST assume that it was set by an AWS ECS agent
    if (process$1.env.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI) {
      return makeMongoCredentialsFromAWSTemp(
        await (0, utils_1$8.request)(
          `${AWS_RELATIVE_URI}${process$1.env.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI}`,
        ),
      );
    }
    // Otherwise assume we are on an EC2 instance
    // get a token
    const token = await (0, utils_1$8.request)(
      `${AWS_EC2_URI}/latest/api/token`,
      {
        method: "PUT",
        json: false,
        headers: { "X-aws-ec2-metadata-token-ttl-seconds": 30 },
      },
    );
    // get role name
    const roleName = await (0, utils_1$8.request)(
      `${AWS_EC2_URI}/${AWS_EC2_PATH}`,
      {
        json: false,
        headers: { "X-aws-ec2-metadata-token": token },
      },
    );
    // get temp credentials
    const creds = await (0, utils_1$8.request)(
      `${AWS_EC2_URI}/${AWS_EC2_PATH}/${roleName}`,
      {
        headers: { "X-aws-ec2-metadata-token": token },
      },
    );
    return makeMongoCredentialsFromAWSTemp(creds);
  } else {
    let { AWS_STS_REGIONAL_ENDPOINTS = "", AWS_REGION = "" } = process$1.env;
    AWS_STS_REGIONAL_ENDPOINTS = AWS_STS_REGIONAL_ENDPOINTS.toLowerCase();
    AWS_REGION = AWS_REGION.toLowerCase();
    /** The option setting should work only for users who have explicit settings in their environment, the driver should not encode "defaults" */
    const awsRegionSettingsExist =
      AWS_REGION.length !== 0 && AWS_STS_REGIONAL_ENDPOINTS.length !== 0;
    /**
     * If AWS_STS_REGIONAL_ENDPOINTS is set to regional, users are opting into the new behavior of respecting the region settings
     *
     * If AWS_STS_REGIONAL_ENDPOINTS is set to legacy, then "old" regions need to keep using the global setting.
     * Technically the SDK gets this wrong, it reaches out to 'sts.us-east-1.amazonaws.com' when it should be 'sts.amazonaws.com'.
     * That is not our bug to fix here. We leave that up to the SDK.
     */
    const useRegionalSts =
      AWS_STS_REGIONAL_ENDPOINTS === "regional" ||
      (AWS_STS_REGIONAL_ENDPOINTS === "legacy" &&
        !LEGACY_REGIONS.has(AWS_REGION));
    const provider =
      awsRegionSettingsExist && useRegionalSts
        ? MongoDBAWS.credentialProvider.fromNodeProviderChain({
            clientConfig: { region: AWS_REGION },
          })
        : MongoDBAWS.credentialProvider.fromNodeProviderChain();
    /*
     * Creates a credential provider that will attempt to find credentials from the
     * following sources (listed in order of precedence):
     *
     * - Environment variables exposed via process.env
     * - SSO credentials from token cache
     * - Web identity token credentials
     * - Shared credentials and config ini files
     * - The EC2/ECS Instance Metadata Service
     */
    try {
      const creds = await provider();
      return makeMongoCredentialsFromAWSTemp({
        AccessKeyId: creds.accessKeyId,
        SecretAccessKey: creds.secretAccessKey,
        Token: creds.sessionToken,
        Expiration: creds.expiration,
      });
    } catch (error) {
      throw new error_1$c.MongoAWSError(error.message);
    }
  }
}
function deriveRegion(host) {
  const parts = host.split(".");
  if (parts.length === 1 || parts[1] === "amazonaws") {
    return "us-east-1";
  }
  return parts[1];
}

var mongodb_oidc = {};

var aws_service_workflow = {};

var service_workflow = {};

Object.defineProperty(service_workflow, "__esModule", { value: true });
service_workflow.commandDocument = service_workflow.ServiceWorkflow = void 0;
const bson_1$5 = bson$1;
const utils_1$7 = utils$2;
const providers_1$2 = providers$1;
/**
 * Common behaviour for OIDC device workflows.
 * @internal
 */
class ServiceWorkflow {
  /**
   * Execute the workflow. Looks for AWS_WEB_IDENTITY_TOKEN_FILE in the environment
   * and then attempts to read the token from that path.
   */
  async execute(connection, credentials) {
    const token = await this.getToken(credentials);
    const command = commandDocument(token);
    return connection.commandAsync(
      (0, utils_1$7.ns)(credentials.source),
      command,
      undefined,
    );
  }
  /**
   * Get the document to add for speculative authentication.
   */
  async speculativeAuth(credentials) {
    const token = await this.getToken(credentials);
    const document = commandDocument(token);
    document.db = credentials.source;
    return { speculativeAuthenticate: document };
  }
}
service_workflow.ServiceWorkflow = ServiceWorkflow;
/**
 * Create the saslStart command document.
 */
function commandDocument(token) {
  return {
    saslStart: 1,
    mechanism: providers_1$2.AuthMechanism.MONGODB_OIDC,
    payload: bson_1$5.BSON.serialize({ jwt: token }),
  };
}
service_workflow.commandDocument = commandDocument;

Object.defineProperty(aws_service_workflow, "__esModule", { value: true });
aws_service_workflow.AwsServiceWorkflow = void 0;
const fs = $nodeFs;
const error_1$b = error;
const service_workflow_1$1 = service_workflow;
/** Error for when the token is missing in the environment. */
const TOKEN_MISSING_ERROR =
  "AWS_WEB_IDENTITY_TOKEN_FILE must be set in the environment.";
/**
 * Device workflow implementation for AWS.
 *
 * @internal
 */
class AwsServiceWorkflow extends service_workflow_1$1.ServiceWorkflow {
  constructor() {
    super();
  }
  /**
   * Get the token from the environment.
   */
  async getToken() {
    const tokenFile = process.env.AWS_WEB_IDENTITY_TOKEN_FILE;
    if (!tokenFile) {
      throw new error_1$b.MongoAWSError(TOKEN_MISSING_ERROR);
    }
    return fs.promises.readFile(tokenFile, "utf8");
  }
}
aws_service_workflow.AwsServiceWorkflow = AwsServiceWorkflow;

var azure_service_workflow = {};

var azure_token_cache = {};

var cache = {};

Object.defineProperty(cache, "__esModule", { value: true });
cache.Cache = cache.ExpiringCacheEntry = void 0;
/* 5 minutes in milliseconds */
const EXPIRATION_BUFFER_MS = 300000;
/**
 * An entry in a cache that can expire in a certain amount of time.
 */
class ExpiringCacheEntry {
  /**
   * Create a new expiring token entry.
   */
  constructor(expiration) {
    this.expiration = this.expirationTime(expiration);
  }
  /**
   * The entry is still valid if the expiration is more than
   * 5 minutes from the expiration time.
   */
  isValid() {
    return this.expiration - Date.now() > EXPIRATION_BUFFER_MS;
  }
  /**
   * Get an expiration time in milliseconds past epoch.
   */
  expirationTime(expiresInSeconds) {
    return Date.now() + expiresInSeconds * 1000;
  }
}
cache.ExpiringCacheEntry = ExpiringCacheEntry;
/**
 * Base class for OIDC caches.
 */
class Cache {
  /**
   * Create a new cache.
   */
  constructor() {
    this.entries = new Map();
  }
  /**
   * Clear the cache.
   */
  clear() {
    this.entries.clear();
  }
  /**
   * Create a cache key from the address and username.
   */
  hashedCacheKey(address, username, callbackHash) {
    return JSON.stringify([address, username, callbackHash]);
  }
}
cache.Cache = Cache;

Object.defineProperty(azure_token_cache, "__esModule", { value: true });
azure_token_cache.AzureTokenCache = azure_token_cache.AzureTokenEntry = void 0;
const cache_1$2 = cache;
/** @internal */
class AzureTokenEntry extends cache_1$2.ExpiringCacheEntry {
  /**
   * Instantiate the entry.
   */
  constructor(token, expiration) {
    super(expiration);
    this.token = token;
  }
}
azure_token_cache.AzureTokenEntry = AzureTokenEntry;
/**
 * A cache of access tokens from Azure.
 * @internal
 */
class AzureTokenCache extends cache_1$2.Cache {
  /**
   * Add an entry to the cache.
   */
  addEntry(tokenAudience, token) {
    const entry = new AzureTokenEntry(token.access_token, token.expires_in);
    this.entries.set(tokenAudience, entry);
    return entry;
  }
  /**
   * Create a cache key.
   */
  cacheKey(tokenAudience) {
    return tokenAudience;
  }
  /**
   * Delete an entry from the cache.
   */
  deleteEntry(tokenAudience) {
    this.entries.delete(tokenAudience);
  }
  /**
   * Get an Azure token entry from the cache.
   */
  getEntry(tokenAudience) {
    return this.entries.get(tokenAudience);
  }
}
azure_token_cache.AzureTokenCache = AzureTokenCache;

Object.defineProperty(azure_service_workflow, "__esModule", { value: true });
azure_service_workflow.AzureServiceWorkflow = void 0;
const error_1$a = error;
const utils_1$6 = utils$2;
const azure_token_cache_1 = azure_token_cache;
const service_workflow_1 = service_workflow;
/** Base URL for getting Azure tokens. */
const AZURE_BASE_URL =
  "http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01";
/** Azure request headers. */
const AZURE_HEADERS = Object.freeze({
  Metadata: "true",
  Accept: "application/json",
});
/** Invalid endpoint result error. */
const ENDPOINT_RESULT_ERROR =
  "Azure endpoint did not return a value with only access_token and expires_in properties";
/** Error for when the token audience is missing in the environment. */
const TOKEN_AUDIENCE_MISSING_ERROR =
  "TOKEN_AUDIENCE must be set in the auth mechanism properties when PROVIDER_NAME is azure.";
/**
 * Device workflow implementation for Azure.
 *
 * @internal
 */
class AzureServiceWorkflow extends service_workflow_1.ServiceWorkflow {
  constructor() {
    super(...arguments);
    this.cache = new azure_token_cache_1.AzureTokenCache();
  }
  /**
   * Get the token from the environment.
   */
  async getToken(credentials) {
    const tokenAudience = credentials?.mechanismProperties.TOKEN_AUDIENCE;
    if (!tokenAudience) {
      throw new error_1$a.MongoAzureError(TOKEN_AUDIENCE_MISSING_ERROR);
    }
    let token;
    const entry = this.cache.getEntry(tokenAudience);
    if (entry?.isValid()) {
      token = entry.token;
    } else {
      this.cache.deleteEntry(tokenAudience);
      const response = await getAzureTokenData(tokenAudience);
      if (!isEndpointResultValid(response)) {
        throw new error_1$a.MongoAzureError(ENDPOINT_RESULT_ERROR);
      }
      this.cache.addEntry(tokenAudience, response);
      token = response.access_token;
    }
    return token;
  }
}
azure_service_workflow.AzureServiceWorkflow = AzureServiceWorkflow;
/**
 * Hit the Azure endpoint to get the token data.
 */
async function getAzureTokenData(tokenAudience) {
  const url = `${AZURE_BASE_URL}&resource=${tokenAudience}`;
  const data = await (0, utils_1$6.request)(url, {
    json: true,
    headers: AZURE_HEADERS,
  });
  return data;
}
/**
 * Determines if a result returned from the endpoint is valid.
 * This means the result is not nullish, contains the access_token required field
 * and the expires_in required field.
 */
function isEndpointResultValid(token) {
  if (token == null || typeof token !== "object") return false;
  return "access_token" in token && "expires_in" in token;
}

var callback_workflow = {};

var callback_lock_cache = {};

Object.defineProperty(callback_lock_cache, "__esModule", { value: true });
callback_lock_cache.CallbackLockCache = void 0;
const error_1$9 = error;
const cache_1$1 = cache;
/** Error message for when request callback is missing. */
const REQUEST_CALLBACK_REQUIRED_ERROR =
  "Auth mechanism property REQUEST_TOKEN_CALLBACK is required.";
/* Counter for function "hashes".*/
let FN_HASH_COUNTER = 0;
/* No function present function */
const NO_FUNCTION = async () => ({ accessToken: "test" });
/* The map of function hashes */
const FN_HASHES = new WeakMap();
/* Put the no function hash in the map. */
FN_HASHES.set(NO_FUNCTION, FN_HASH_COUNTER);
/**
 * A cache of request and refresh callbacks per server/user.
 */
class CallbackLockCache extends cache_1$1.Cache {
  /**
   * Get the callbacks for the connection and credentials. If an entry does not
   * exist a new one will get set.
   */
  getEntry(connection, credentials) {
    const requestCallback =
      credentials.mechanismProperties.REQUEST_TOKEN_CALLBACK;
    const refreshCallback =
      credentials.mechanismProperties.REFRESH_TOKEN_CALLBACK;
    if (!requestCallback) {
      throw new error_1$9.MongoInvalidArgumentError(
        REQUEST_CALLBACK_REQUIRED_ERROR,
      );
    }
    const callbackHash = hashFunctions(requestCallback, refreshCallback);
    const key = this.cacheKey(
      connection.address,
      credentials.username,
      callbackHash,
    );
    const entry = this.entries.get(key);
    if (entry) {
      return entry;
    }
    return this.addEntry(key, callbackHash, requestCallback, refreshCallback);
  }
  /**
   * Set locked callbacks on for connection and credentials.
   */
  addEntry(key, callbackHash, requestCallback, refreshCallback) {
    const entry = {
      requestCallback: withLock(requestCallback),
      refreshCallback: refreshCallback ? withLock(refreshCallback) : undefined,
      callbackHash: callbackHash,
    };
    this.entries.set(key, entry);
    return entry;
  }
  /**
   * Create a cache key from the address and username.
   */
  cacheKey(address, username, callbackHash) {
    return this.hashedCacheKey(address, username, callbackHash);
  }
}
callback_lock_cache.CallbackLockCache = CallbackLockCache;
/**
 * Ensure the callback is only executed one at a time.
 */
function withLock(callback) {
  let lock = Promise.resolve();
  return async (info, context) => {
    await lock;
    lock = lock.then(() => callback(info, context));
    return lock;
  };
}
/**
 * Get the hash string for the request and refresh functions.
 */
function hashFunctions(requestFn, refreshFn) {
  let requestHash = FN_HASHES.get(requestFn);
  let refreshHash = FN_HASHES.get(refreshFn ?? NO_FUNCTION);
  if (requestHash == null) {
    // Create a new one for the function and put it in the map.
    FN_HASH_COUNTER++;
    requestHash = FN_HASH_COUNTER;
    FN_HASHES.set(requestFn, FN_HASH_COUNTER);
  }
  if (refreshHash == null && refreshFn) {
    // Create a new one for the function and put it in the map.
    FN_HASH_COUNTER++;
    refreshHash = FN_HASH_COUNTER;
    FN_HASHES.set(refreshFn, FN_HASH_COUNTER);
  }
  return `${requestHash}-${refreshHash}`;
}

var token_entry_cache = {};

Object.defineProperty(token_entry_cache, "__esModule", { value: true });
token_entry_cache.TokenEntryCache = token_entry_cache.TokenEntry = void 0;
const cache_1 = cache;
/* Default expiration is now for when no expiration provided */
const DEFAULT_EXPIRATION_SECS = 0;
/** @internal */
class TokenEntry extends cache_1.ExpiringCacheEntry {
  /**
   * Instantiate the entry.
   */
  constructor(tokenResult, serverInfo, expiration) {
    super(expiration);
    this.tokenResult = tokenResult;
    this.serverInfo = serverInfo;
  }
}
token_entry_cache.TokenEntry = TokenEntry;
/**
 * Cache of OIDC token entries.
 * @internal
 */
class TokenEntryCache extends cache_1.Cache {
  /**
   * Set an entry in the token cache.
   */
  addEntry(address, username, callbackHash, tokenResult, serverInfo) {
    const entry = new TokenEntry(
      tokenResult,
      serverInfo,
      tokenResult.expiresInSeconds ?? DEFAULT_EXPIRATION_SECS,
    );
    this.entries.set(this.cacheKey(address, username, callbackHash), entry);
    return entry;
  }
  /**
   * Delete an entry from the cache.
   */
  deleteEntry(address, username, callbackHash) {
    this.entries.delete(this.cacheKey(address, username, callbackHash));
  }
  /**
   * Get an entry from the cache.
   */
  getEntry(address, username, callbackHash) {
    return this.entries.get(this.cacheKey(address, username, callbackHash));
  }
  /**
   * Delete all expired entries from the cache.
   */
  deleteExpiredEntries() {
    for (const [key, entry] of this.entries) {
      if (!entry.isValid()) {
        this.entries.delete(key);
      }
    }
  }
  /**
   * Create a cache key from the address and username.
   */
  cacheKey(address, username, callbackHash) {
    return this.hashedCacheKey(address, username, callbackHash);
  }
}
token_entry_cache.TokenEntryCache = TokenEntryCache;

Object.defineProperty(callback_workflow, "__esModule", { value: true });
callback_workflow.CallbackWorkflow = void 0;
const bson_1$4 = bson$1;
const error_1$8 = error;
const utils_1$5 = utils$2;
const providers_1$1 = providers$1;
const callback_lock_cache_1 = callback_lock_cache;
const token_entry_cache_1 = token_entry_cache;
/** The current version of OIDC implementation. */
const OIDC_VERSION = 0;
/** 5 minutes in seconds */
const TIMEOUT_S = 300;
/** Properties allowed on results of callbacks. */
const RESULT_PROPERTIES = ["accessToken", "expiresInSeconds", "refreshToken"];
/** Error message when the callback result is invalid. */
const CALLBACK_RESULT_ERROR =
  "User provided OIDC callbacks must return a valid object with an accessToken.";
/**
 * OIDC implementation of a callback based workflow.
 * @internal
 */
class CallbackWorkflow {
  /**
   * Instantiate the workflow
   */
  constructor() {
    this.cache = new token_entry_cache_1.TokenEntryCache();
    this.callbackCache = new callback_lock_cache_1.CallbackLockCache();
  }
  /**
   * Get the document to add for speculative authentication. This also needs
   * to add a db field from the credentials source.
   */
  async speculativeAuth(credentials) {
    const document = startCommandDocument(credentials);
    document.db = credentials.source;
    return { speculativeAuthenticate: document };
  }
  /**
   * Execute the OIDC callback workflow.
   */
  async execute(connection, credentials, reauthenticating, response) {
    // Get the callbacks with locks from the callback lock cache.
    const { requestCallback, refreshCallback, callbackHash } =
      this.callbackCache.getEntry(connection, credentials);
    // Look for an existing entry in the cache.
    const entry = this.cache.getEntry(
      connection.address,
      credentials.username,
      callbackHash,
    );
    let result;
    if (entry) {
      // Reauthentication cannot use a token from the cache since the server has
      // stated it is invalid by the request for reauthentication.
      if (entry.isValid() && !reauthenticating) {
        // Presence of a valid cache entry means we can skip to the finishing step.
        result = await this.finishAuthentication(
          connection,
          credentials,
          entry.tokenResult,
          response?.speculativeAuthenticate?.conversationId,
        );
      } else {
        // Presence of an expired cache entry means we must fetch a new one and
        // then execute the final step.
        const tokenResult = await this.fetchAccessToken(
          connection,
          credentials,
          entry.serverInfo,
          reauthenticating,
          callbackHash,
          requestCallback,
          refreshCallback,
        );
        try {
          result = await this.finishAuthentication(
            connection,
            credentials,
            tokenResult,
            reauthenticating
              ? undefined
              : response?.speculativeAuthenticate?.conversationId,
          );
        } catch (error) {
          // If we are reauthenticating and this errors with reauthentication
          // required, we need to do the entire process over again and clear
          // the cache entry.
          if (
            reauthenticating &&
            error instanceof error_1$8.MongoError &&
            error.code === error_1$8.MONGODB_ERROR_CODES.Reauthenticate
          ) {
            this.cache.deleteEntry(
              connection.address,
              credentials.username,
              callbackHash,
            );
            result = await this.execute(
              connection,
              credentials,
              reauthenticating,
            );
          } else {
            throw error;
          }
        }
      }
    } else {
      // No entry in the cache requires us to do all authentication steps
      // from start to finish, including getting a fresh token for the cache.
      const startDocument = await this.startAuthentication(
        connection,
        credentials,
        reauthenticating,
        response,
      );
      const conversationId = startDocument.conversationId;
      const serverResult = bson_1$4.BSON.deserialize(
        startDocument.payload.buffer,
      );
      const tokenResult = await this.fetchAccessToken(
        connection,
        credentials,
        serverResult,
        reauthenticating,
        callbackHash,
        requestCallback,
        refreshCallback,
      );
      result = await this.finishAuthentication(
        connection,
        credentials,
        tokenResult,
        conversationId,
      );
    }
    return result;
  }
  /**
   * Starts the callback authentication process. If there is a speculative
   * authentication document from the initial handshake, then we will use that
   * value to get the issuer, otherwise we will send the saslStart command.
   */
  async startAuthentication(
    connection,
    credentials,
    reauthenticating,
    response,
  ) {
    let result;
    if (!reauthenticating && response?.speculativeAuthenticate) {
      result = response.speculativeAuthenticate;
    } else {
      result = await connection.commandAsync(
        (0, utils_1$5.ns)(credentials.source),
        startCommandDocument(credentials),
        undefined,
      );
    }
    return result;
  }
  /**
   * Finishes the callback authentication process.
   */
  async finishAuthentication(
    connection,
    credentials,
    tokenResult,
    conversationId,
  ) {
    const result = await connection.commandAsync(
      (0, utils_1$5.ns)(credentials.source),
      finishCommandDocument(tokenResult.accessToken, conversationId),
      undefined,
    );
    return result;
  }
  /**
   * Fetches an access token using either the request or refresh callbacks and
   * puts it in the cache.
   */
  async fetchAccessToken(
    connection,
    credentials,
    serverInfo,
    reauthenticating,
    callbackHash,
    requestCallback,
    refreshCallback,
  ) {
    // Get the token from the cache.
    const entry = this.cache.getEntry(
      connection.address,
      credentials.username,
      callbackHash,
    );
    let result;
    const context = { timeoutSeconds: TIMEOUT_S, version: OIDC_VERSION };
    // Check if there's a token in the cache.
    if (entry) {
      // If the cache entry is valid, return the token result.
      if (entry.isValid() && !reauthenticating) {
        return entry.tokenResult;
      }
      // If the cache entry is not valid, remove it from the cache and first attempt
      // to use the refresh callback to get a new token. If no refresh callback
      // exists, then fallback to the request callback.
      if (refreshCallback) {
        context.refreshToken = entry.tokenResult.refreshToken;
        result = await refreshCallback(serverInfo, context);
      } else {
        result = await requestCallback(serverInfo, context);
      }
    } else {
      // With no token in the cache we use the request callback.
      result = await requestCallback(serverInfo, context);
    }
    // Validate that the result returned by the callback is acceptable. If it is not
    // we must clear the token result from the cache.
    if (isCallbackResultInvalid(result)) {
      this.cache.deleteEntry(
        connection.address,
        credentials.username,
        callbackHash,
      );
      throw new error_1$8.MongoMissingCredentialsError(CALLBACK_RESULT_ERROR);
    }
    // Cleanup the cache.
    this.cache.deleteExpiredEntries();
    // Put the new entry into the cache.
    this.cache.addEntry(
      connection.address,
      credentials.username || "",
      callbackHash,
      result,
      serverInfo,
    );
    return result;
  }
}
callback_workflow.CallbackWorkflow = CallbackWorkflow;
/**
 * Generate the finishing command document for authentication. Will be a
 * saslStart or saslContinue depending on the presence of a conversation id.
 */
function finishCommandDocument(token, conversationId) {
  if (conversationId != null && typeof conversationId === "number") {
    return {
      saslContinue: 1,
      conversationId: conversationId,
      payload: new bson_1$4.Binary(bson_1$4.BSON.serialize({ jwt: token })),
    };
  }
  // saslContinue requires a conversationId in the command to be valid so in this
  // case the server allows "step two" to actually be a saslStart with the token
  // as the jwt since the use of the cached value has no correlating conversating
  // on the particular connection.
  return {
    saslStart: 1,
    mechanism: providers_1$1.AuthMechanism.MONGODB_OIDC,
    payload: new bson_1$4.Binary(bson_1$4.BSON.serialize({ jwt: token })),
  };
}
/**
 * Determines if a result returned from a request or refresh callback
 * function is invalid. This means the result is nullish, doesn't contain
 * the accessToken required field, and does not contain extra fields.
 */
function isCallbackResultInvalid(tokenResult) {
  if (tokenResult == null || typeof tokenResult !== "object") return true;
  if (!("accessToken" in tokenResult)) return true;
  return !Object.getOwnPropertyNames(tokenResult).every((prop) =>
    RESULT_PROPERTIES.includes(prop),
  );
}
/**
 * Generate the saslStart command document.
 */
function startCommandDocument(credentials) {
  const payload = {};
  if (credentials.username) {
    payload.n = credentials.username;
  }
  return {
    saslStart: 1,
    autoAuthorize: 1,
    mechanism: providers_1$1.AuthMechanism.MONGODB_OIDC,
    payload: new bson_1$4.Binary(bson_1$4.BSON.serialize(payload)),
  };
}

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.MongoDBOIDC = exports.OIDC_WORKFLOWS = void 0;
  const error_1 = error;
  const auth_provider_1 = auth_provider;
  const aws_service_workflow_1 = aws_service_workflow;
  const azure_service_workflow_1 = azure_service_workflow;
  const callback_workflow_1 = callback_workflow;
  /** Error when credentials are missing. */
  const MISSING_CREDENTIALS_ERROR = "AuthContext must provide credentials.";
  /** @internal */
  exports.OIDC_WORKFLOWS = new Map();
  exports.OIDC_WORKFLOWS.set(
    "callback",
    new callback_workflow_1.CallbackWorkflow(),
  );
  exports.OIDC_WORKFLOWS.set(
    "aws",
    new aws_service_workflow_1.AwsServiceWorkflow(),
  );
  exports.OIDC_WORKFLOWS.set(
    "azure",
    new azure_service_workflow_1.AzureServiceWorkflow(),
  );
  /**
   * OIDC auth provider.
   * @experimental
   */
  class MongoDBOIDC extends auth_provider_1.AuthProvider {
    /**
     * Instantiate the auth provider.
     */
    constructor() {
      super();
    }
    /**
     * Authenticate using OIDC
     */
    async auth(authContext) {
      const { connection, reauthenticating, response } = authContext;
      const credentials = getCredentials(authContext);
      const workflow = getWorkflow(credentials);
      await workflow.execute(
        connection,
        credentials,
        reauthenticating,
        response,
      );
    }
    /**
     * Add the speculative auth for the initial handshake.
     */
    async prepare(handshakeDoc, authContext) {
      const credentials = getCredentials(authContext);
      const workflow = getWorkflow(credentials);
      const result = await workflow.speculativeAuth(credentials);
      return { ...handshakeDoc, ...result };
    }
  }
  exports.MongoDBOIDC = MongoDBOIDC;
  /**
   * Get credentials from the auth context, throwing if they do not exist.
   */
  function getCredentials(authContext) {
    const { credentials } = authContext;
    if (!credentials) {
      throw new error_1.MongoMissingCredentialsError(MISSING_CREDENTIALS_ERROR);
    }
    return credentials;
  }
  /**
   * Gets either a device workflow or callback workflow.
   */
  function getWorkflow(credentials) {
    const providerName = credentials.mechanismProperties.PROVIDER_NAME;
    const workflow = exports.OIDC_WORKFLOWS.get(providerName || "callback");
    if (!workflow) {
      throw new error_1.MongoInvalidArgumentError(
        `Could not load workflow for provider ${credentials.mechanismProperties.PROVIDER_NAME}`,
      );
    }
    return workflow;
  }
})(mongodb_oidc);

var plain = {};

Object.defineProperty(plain, "__esModule", { value: true });
plain.Plain = void 0;
const bson_1$3 = bson$2;
const error_1$7 = error;
const utils_1$4 = utils$2;
const auth_provider_1$2 = auth_provider;
class Plain extends auth_provider_1$2.AuthProvider {
  async auth(authContext) {
    const { connection, credentials } = authContext;
    if (!credentials) {
      throw new error_1$7.MongoMissingCredentialsError(
        "AuthContext must provide credentials.",
      );
    }
    const { username, password } = credentials;
    const payload = new bson_1$3.Binary(
      Buffer.from(`\x00${username}\x00${password}`),
    );
    const command = {
      saslStart: 1,
      mechanism: "PLAIN",
      payload: payload,
      autoAuthorize: 1,
    };
    await connection.commandAsync(
      (0, utils_1$4.ns)("$external.$cmd"),
      command,
      undefined,
    );
  }
}
plain.Plain = Plain;

var scram = {};

var memoryCodePoints = {};

var memoryPager = Pager;

function Pager(pageSize, opts) {
  if (!(this instanceof Pager)) return new Pager(pageSize, opts);

  this.length = 0;
  this.updates = [];
  this.path = new Uint16Array(4);
  this.pages = new Array(32768);
  this.maxPages = this.pages.length;
  this.level = 0;
  this.pageSize = pageSize || 1024;
  this.deduplicate = opts ? opts.deduplicate : null;
  this.zeros = this.deduplicate ? alloc$1(this.deduplicate.length) : null;
}

Pager.prototype.updated = function (page) {
  while (
    this.deduplicate &&
    page.buffer[page.deduplicate] === this.deduplicate[page.deduplicate]
  ) {
    page.deduplicate++;
    if (page.deduplicate === this.deduplicate.length) {
      page.deduplicate = 0;
      if (page.buffer.equals && page.buffer.equals(this.deduplicate))
        page.buffer = this.deduplicate;
      break;
    }
  }
  if (page.updated || !this.updates) return;
  page.updated = true;
  this.updates.push(page);
};

Pager.prototype.lastUpdate = function () {
  if (!this.updates || !this.updates.length) return null;
  var page = this.updates.pop();
  page.updated = false;
  return page;
};

Pager.prototype._array = function (i, noAllocate) {
  if (i >= this.maxPages) {
    if (noAllocate) return;
    grow(this, i);
  }

  factor(i, this.path);

  var arr = this.pages;

  for (var j = this.level; j > 0; j--) {
    var p = this.path[j];
    var next = arr[p];

    if (!next) {
      if (noAllocate) return;
      next = arr[p] = new Array(32768);
    }

    arr = next;
  }

  return arr;
};

Pager.prototype.get = function (i, noAllocate) {
  var arr = this._array(i, noAllocate);
  var first = this.path[0];
  var page = arr && arr[first];

  if (!page && !noAllocate) {
    page = arr[first] = new Page(i, alloc$1(this.pageSize));
    if (i >= this.length) this.length = i + 1;
  }

  if (
    page &&
    page.buffer === this.deduplicate &&
    this.deduplicate &&
    !noAllocate
  ) {
    page.buffer = copy(page.buffer);
    page.deduplicate = 0;
  }

  return page;
};

Pager.prototype.set = function (i, buf) {
  var arr = this._array(i, false);
  var first = this.path[0];

  if (i >= this.length) this.length = i + 1;

  if (!buf || (this.zeros && buf.equals && buf.equals(this.zeros))) {
    arr[first] = undefined;
    return;
  }

  if (this.deduplicate && buf.equals && buf.equals(this.deduplicate)) {
    buf = this.deduplicate;
  }

  var page = arr[first];
  var b = truncate(buf, this.pageSize);

  if (page) page.buffer = b;
  else arr[first] = new Page(i, b);
};

Pager.prototype.toBuffer = function () {
  var list = new Array(this.length);
  var empty = alloc$1(this.pageSize);
  var ptr = 0;

  while (ptr < list.length) {
    var arr = this._array(ptr, true);
    for (var i = 0; i < 32768 && ptr < list.length; i++) {
      list[ptr++] = arr && arr[i] ? arr[i].buffer : empty;
    }
  }

  return Buffer.concat(list);
};

function grow(pager, index) {
  while (pager.maxPages < index) {
    var old = pager.pages;
    pager.pages = new Array(32768);
    pager.pages[0] = old;
    pager.level++;
    pager.maxPages *= 32768;
  }
}

function truncate(buf, len) {
  if (buf.length === len) return buf;
  if (buf.length > len) return buf.slice(0, len);
  var cpy = alloc$1(len);
  buf.copy(cpy);
  return cpy;
}

function alloc$1(size) {
  if (Buffer.alloc) return Buffer.alloc(size);
  var buf = new Buffer(size);
  buf.fill(0);
  return buf;
}

function copy(buf) {
  var cpy = Buffer.allocUnsafe
    ? Buffer.allocUnsafe(buf.length)
    : new Buffer(buf.length);
  buf.copy(cpy);
  return cpy;
}

function Page(i, buf) {
  this.offset = i * buf.length;
  this.buffer = buf;
  this.updated = false;
  this.deduplicate = 0;
}

function factor(n, out) {
  n = (n - (out[0] = n & 32767)) / 32768;
  n = (n - (out[1] = n & 32767)) / 32768;
  out[3] = ((n - (out[2] = n & 32767)) / 32768) & 32767;
}

var pager = memoryPager;

var sparseBitfield = Bitfield;

function Bitfield(opts) {
  if (!(this instanceof Bitfield)) return new Bitfield(opts);
  if (!opts) opts = {};
  if (Buffer.isBuffer(opts)) opts = { buffer: opts };

  this.pageOffset = opts.pageOffset || 0;
  this.pageSize = opts.pageSize || 1024;
  this.pages = opts.pages || pager(this.pageSize);

  this.byteLength = this.pages.length * this.pageSize;
  this.length = 8 * this.byteLength;

  if (!powerOfTwo(this.pageSize))
    throw new Error("The page size should be a power of two");

  this._trackUpdates = !!opts.trackUpdates;
  this._pageMask = this.pageSize - 1;

  if (opts.buffer) {
    for (var i = 0; i < opts.buffer.length; i += this.pageSize) {
      this.pages.set(
        i / this.pageSize,
        opts.buffer.slice(i, i + this.pageSize),
      );
    }
    this.byteLength = opts.buffer.length;
    this.length = 8 * this.byteLength;
  }
}

Bitfield.prototype.get = function (i) {
  var o = i & 7;
  var j = (i - o) / 8;

  return !!(this.getByte(j) & (128 >> o));
};

Bitfield.prototype.getByte = function (i) {
  var o = i & this._pageMask;
  var j = (i - o) / this.pageSize;
  var page = this.pages.get(j, true);

  return page ? page.buffer[o + this.pageOffset] : 0;
};

Bitfield.prototype.set = function (i, v) {
  var o = i & 7;
  var j = (i - o) / 8;
  var b = this.getByte(j);

  return this.setByte(j, v ? b | (128 >> o) : b & (255 ^ (128 >> o)));
};

Bitfield.prototype.toBuffer = function () {
  var all = alloc(this.pages.length * this.pageSize);

  for (var i = 0; i < this.pages.length; i++) {
    var next = this.pages.get(i, true);
    var allOffset = i * this.pageSize;
    if (next)
      next.buffer.copy(
        all,
        allOffset,
        this.pageOffset,
        this.pageOffset + this.pageSize,
      );
  }

  return all;
};

Bitfield.prototype.setByte = function (i, b) {
  var o = i & this._pageMask;
  var j = (i - o) / this.pageSize;
  var page = this.pages.get(j, false);

  o += this.pageOffset;

  if (page.buffer[o] === b) return false;
  page.buffer[o] = b;

  if (i >= this.byteLength) {
    this.byteLength = i + 1;
    this.length = this.byteLength * 8;
  }

  if (this._trackUpdates) this.pages.updated(page);

  return true;
};

function alloc(n) {
  if (Buffer.alloc) return Buffer.alloc(n);
  var b = new Buffer(n);
  b.fill(0);
  return b;
}

function powerOfTwo(x) {
  return !(x & (x - 1));
}

var codePointsData = {};

Object.defineProperty(codePointsData, "__esModule", { value: true });
const zlib_1 = $nodeZlib;
codePointsData.default = (0, zlib_1.gunzipSync)(
  Buffer.from(
    "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",
    "base64",
  ),
);

var __importDefault =
  (commonjsGlobal && commonjsGlobal.__importDefault) ||
  function (mod) {
    return mod && mod.__esModule ? mod : { default: mod };
  };
Object.defineProperty(memoryCodePoints, "__esModule", { value: true });
memoryCodePoints.bidirectional_l =
  memoryCodePoints.bidirectional_r_al =
  memoryCodePoints.prohibited_characters =
  memoryCodePoints.non_ASCII_space_characters =
  memoryCodePoints.commonly_mapped_to_nothing =
  memoryCodePoints.unassigned_code_points =
    void 0;
const sparse_bitfield_1 = __importDefault(sparseBitfield);
const code_points_data_1 = __importDefault(codePointsData);
let offset = 0;
function read() {
  const size = code_points_data_1.default.readUInt32BE(offset);
  offset += 4;
  const codepoints = code_points_data_1.default.slice(offset, offset + size);
  offset += size;
  return (0, sparse_bitfield_1.default)({ buffer: codepoints });
}
memoryCodePoints.unassigned_code_points = read();
memoryCodePoints.commonly_mapped_to_nothing = read();
memoryCodePoints.non_ASCII_space_characters = read();
memoryCodePoints.prohibited_characters = read();
memoryCodePoints.bidirectional_r_al = read();
memoryCodePoints.bidirectional_l = read();

const memory_code_points_1 = memoryCodePoints;
const mapping2space = memory_code_points_1.non_ASCII_space_characters;
const mapping2nothing = memory_code_points_1.commonly_mapped_to_nothing;
const getCodePoint = (character) => character.codePointAt(0);
const first = (x) => x[0];
const last = (x) => x[x.length - 1];
function toCodePoints(input) {
  const codepoints = [];
  const size = input.length;
  for (let i = 0; i < size; i += 1) {
    const before = input.charCodeAt(i);
    if (before >= 0xd800 && before <= 0xdbff && size > i + 1) {
      const next = input.charCodeAt(i + 1);
      if (next >= 0xdc00 && next <= 0xdfff) {
        codepoints.push((before - 0xd800) * 0x400 + next - 0xdc00 + 0x10000);
        i += 1;
        continue;
      }
    }
    codepoints.push(before);
  }
  return codepoints;
}
function saslprep(input, opts = {}) {
  if (typeof input !== "string") {
    throw new TypeError("Expected string.");
  }
  if (input.length === 0) {
    return "";
  }
  const mapped_input = toCodePoints(input)
    .map((character) => (mapping2space.get(character) ? 0x20 : character))
    .filter((character) => !mapping2nothing.get(character));
  const normalized_input = String.fromCodePoint
    .apply(null, mapped_input)
    .normalize("NFKC");
  const normalized_map = toCodePoints(normalized_input);
  const hasProhibited = normalized_map.some((character) =>
    memory_code_points_1.prohibited_characters.get(character),
  );
  if (hasProhibited) {
    throw new Error(
      "Prohibited character, see https://tools.ietf.org/html/rfc4013#section-2.3",
    );
  }
  if (opts.allowUnassigned !== true) {
    const hasUnassigned = normalized_map.some((character) =>
      memory_code_points_1.unassigned_code_points.get(character),
    );
    if (hasUnassigned) {
      throw new Error(
        "Unassigned code point, see https://tools.ietf.org/html/rfc4013#section-2.5",
      );
    }
  }
  const hasBidiRAL = normalized_map.some((character) =>
    memory_code_points_1.bidirectional_r_al.get(character),
  );
  const hasBidiL = normalized_map.some((character) =>
    memory_code_points_1.bidirectional_l.get(character),
  );
  if (hasBidiRAL && hasBidiL) {
    throw new Error(
      "String must not contain RandALCat and LCat at the same time," +
        " see https://tools.ietf.org/html/rfc3454#section-6",
    );
  }
  const isFirstBidiRAL = memory_code_points_1.bidirectional_r_al.get(
    getCodePoint(first(normalized_input)),
  );
  const isLastBidiRAL = memory_code_points_1.bidirectional_r_al.get(
    getCodePoint(last(normalized_input)),
  );
  if (hasBidiRAL && !(isFirstBidiRAL && isLastBidiRAL)) {
    throw new Error(
      "Bidirectional RandALCat character must be the first and the last" +
        " character of the string, see https://tools.ietf.org/html/rfc3454#section-6",
    );
  }
  return normalized_input;
}
saslprep.saslprep = saslprep;
saslprep.default = saslprep;
var dist = saslprep;

Object.defineProperty(scram, "__esModule", { value: true });
scram.ScramSHA256 = scram.ScramSHA1 = void 0;
const saslprep_1 = dist;
const crypto = $nodeCrypto;
const util_1 = $noteUtil;
const bson_1$2 = bson$2;
const error_1$6 = error;
const utils_1$3 = utils$2;
const auth_provider_1$1 = auth_provider;
const providers_1 = providers$1;
class ScramSHA extends auth_provider_1$1.AuthProvider {
  constructor(cryptoMethod) {
    super();
    this.cryptoMethod = cryptoMethod || "sha1";
    this.randomBytesAsync = (0, util_1.promisify)(crypto.randomBytes);
  }
  async prepare(handshakeDoc, authContext) {
    const cryptoMethod = this.cryptoMethod;
    const credentials = authContext.credentials;
    if (!credentials) {
      throw new error_1$6.MongoMissingCredentialsError(
        "AuthContext must provide credentials.",
      );
    }
    const nonce = await this.randomBytesAsync(24);
    // store the nonce for later use
    authContext.nonce = nonce;
    const request = {
      ...handshakeDoc,
      speculativeAuthenticate: {
        ...makeFirstMessage(cryptoMethod, credentials, nonce),
        db: credentials.source,
      },
    };
    return request;
  }
  async auth(authContext) {
    const { reauthenticating, response } = authContext;
    if (response?.speculativeAuthenticate && !reauthenticating) {
      return continueScramConversation(
        this.cryptoMethod,
        response.speculativeAuthenticate,
        authContext,
      );
    }
    return executeScram(this.cryptoMethod, authContext);
  }
}
function cleanUsername(username) {
  return username.replace("=", "=3D").replace(",", "=2C");
}
function clientFirstMessageBare(username, nonce) {
  // NOTE: This is done b/c Javascript uses UTF-16, but the server is hashing in UTF-8.
  // Since the username is not sasl-prep-d, we need to do this here.
  return Buffer.concat([
    Buffer.from("n=", "utf8"),
    Buffer.from(username, "utf8"),
    Buffer.from(",r=", "utf8"),
    Buffer.from(nonce.toString("base64"), "utf8"),
  ]);
}
function makeFirstMessage(cryptoMethod, credentials, nonce) {
  const username = cleanUsername(credentials.username);
  const mechanism =
    cryptoMethod === "sha1"
      ? providers_1.AuthMechanism.MONGODB_SCRAM_SHA1
      : providers_1.AuthMechanism.MONGODB_SCRAM_SHA256;
  // NOTE: This is done b/c Javascript uses UTF-16, but the server is hashing in UTF-8.
  // Since the username is not sasl-prep-d, we need to do this here.
  return {
    saslStart: 1,
    mechanism,
    payload: new bson_1$2.Binary(
      Buffer.concat([
        Buffer.from("n,,", "utf8"),
        clientFirstMessageBare(username, nonce),
      ]),
    ),
    autoAuthorize: 1,
    options: { skipEmptyExchange: true },
  };
}
async function executeScram(cryptoMethod, authContext) {
  const { connection, credentials } = authContext;
  if (!credentials) {
    throw new error_1$6.MongoMissingCredentialsError(
      "AuthContext must provide credentials.",
    );
  }
  if (!authContext.nonce) {
    throw new error_1$6.MongoInvalidArgumentError(
      "AuthContext must contain a valid nonce property",
    );
  }
  const nonce = authContext.nonce;
  const db = credentials.source;
  const saslStartCmd = makeFirstMessage(cryptoMethod, credentials, nonce);
  const response = await connection.commandAsync(
    (0, utils_1$3.ns)(`${db}.$cmd`),
    saslStartCmd,
    undefined,
  );
  await continueScramConversation(cryptoMethod, response, authContext);
}
async function continueScramConversation(cryptoMethod, response, authContext) {
  const connection = authContext.connection;
  const credentials = authContext.credentials;
  if (!credentials) {
    throw new error_1$6.MongoMissingCredentialsError(
      "AuthContext must provide credentials.",
    );
  }
  if (!authContext.nonce) {
    throw new error_1$6.MongoInvalidArgumentError(
      "Unable to continue SCRAM without valid nonce",
    );
  }
  const nonce = authContext.nonce;
  const db = credentials.source;
  const username = cleanUsername(credentials.username);
  const password = credentials.password;
  const processedPassword =
    cryptoMethod === "sha256"
      ? (0, saslprep_1.saslprep)(password)
      : passwordDigest(username, password);
  const payload = Buffer.isBuffer(response.payload)
    ? new bson_1$2.Binary(response.payload)
    : response.payload;
  const dict = parsePayload(payload);
  const iterations = parseInt(dict.i, 10);
  if (iterations && iterations < 4096) {
    // TODO(NODE-3483)
    throw new error_1$6.MongoRuntimeError(
      `Server returned an invalid iteration count ${iterations}`,
    );
  }
  const salt = dict.s;
  const rnonce = dict.r;
  if (rnonce.startsWith("nonce")) {
    // TODO(NODE-3483)
    throw new error_1$6.MongoRuntimeError(
      `Server returned an invalid nonce: ${rnonce}`,
    );
  }
  // Set up start of proof
  const withoutProof = `c=biws,r=${rnonce}`;
  const saltedPassword = HI(
    processedPassword,
    Buffer.from(salt, "base64"),
    iterations,
    cryptoMethod,
  );
  const clientKey = HMAC(cryptoMethod, saltedPassword, "Client Key");
  const serverKey = HMAC(cryptoMethod, saltedPassword, "Server Key");
  const storedKey = H(cryptoMethod, clientKey);
  const authMessage = [
    clientFirstMessageBare(username, nonce),
    payload.toString("utf8"),
    withoutProof,
  ].join(",");
  const clientSignature = HMAC(cryptoMethod, storedKey, authMessage);
  const clientProof = `p=${xor(clientKey, clientSignature)}`;
  const clientFinal = [withoutProof, clientProof].join(",");
  const serverSignature = HMAC(cryptoMethod, serverKey, authMessage);
  const saslContinueCmd = {
    saslContinue: 1,
    conversationId: response.conversationId,
    payload: new bson_1$2.Binary(Buffer.from(clientFinal)),
  };
  const r = await connection.commandAsync(
    (0, utils_1$3.ns)(`${db}.$cmd`),
    saslContinueCmd,
    undefined,
  );
  const parsedResponse = parsePayload(r.payload);
  if (
    !compareDigest(Buffer.from(parsedResponse.v, "base64"), serverSignature)
  ) {
    throw new error_1$6.MongoRuntimeError(
      "Server returned an invalid signature",
    );
  }
  if (r.done !== false) {
    // If the server sends r.done === true we can save one RTT
    return;
  }
  const retrySaslContinueCmd = {
    saslContinue: 1,
    conversationId: r.conversationId,
    payload: Buffer.alloc(0),
  };
  await connection.commandAsync(
    (0, utils_1$3.ns)(`${db}.$cmd`),
    retrySaslContinueCmd,
    undefined,
  );
}
function parsePayload(payload) {
  const payloadStr = payload.toString("utf8");
  const dict = {};
  const parts = payloadStr.split(",");
  for (let i = 0; i < parts.length; i++) {
    const valueParts = parts[i].split("=");
    dict[valueParts[0]] = valueParts[1];
  }
  return dict;
}
function passwordDigest(username, password) {
  if (typeof username !== "string") {
    throw new error_1$6.MongoInvalidArgumentError("Username must be a string");
  }
  if (typeof password !== "string") {
    throw new error_1$6.MongoInvalidArgumentError("Password must be a string");
  }
  if (password.length === 0) {
    throw new error_1$6.MongoInvalidArgumentError("Password cannot be empty");
  }
  let md5;
  try {
    md5 = crypto.createHash("md5");
  } catch (err) {
    if (crypto.getFips()) {
      // This error is (slightly) more helpful than what comes from OpenSSL directly, e.g.
      // 'Error: error:060800C8:digital envelope routines:EVP_DigestInit_ex:disabled for FIPS'
      throw new Error(
        "Auth mechanism SCRAM-SHA-1 is not supported in FIPS mode",
      );
    }
    throw err;
  }
  md5.update(`${username}:mongo:${password}`, "utf8");
  return md5.digest("hex");
}
// XOR two buffers
function xor(a, b) {
  if (!Buffer.isBuffer(a)) {
    a = Buffer.from(a);
  }
  if (!Buffer.isBuffer(b)) {
    b = Buffer.from(b);
  }
  const length = Math.max(a.length, b.length);
  const res = [];
  for (let i = 0; i < length; i += 1) {
    res.push(a[i] ^ b[i]);
  }
  return Buffer.from(res).toString("base64");
}
function H(method, text) {
  return crypto.createHash(method).update(text).digest();
}
function HMAC(method, key, text) {
  return crypto.createHmac(method, key).update(text).digest();
}
let _hiCache = {};
let _hiCacheCount = 0;
function _hiCachePurge() {
  _hiCache = {};
  _hiCacheCount = 0;
}
const hiLengthMap = {
  sha256: 32,
  sha1: 20,
};
function HI(data, salt, iterations, cryptoMethod) {
  // omit the work if already generated
  const key = [data, salt.toString("base64"), iterations].join("_");
  if (_hiCache[key] != null) {
    return _hiCache[key];
  }
  // generate the salt
  const saltedData = crypto.pbkdf2Sync(
    data,
    salt,
    iterations,
    hiLengthMap[cryptoMethod],
    cryptoMethod,
  );
  // cache a copy to speed up the next lookup, but prevent unbounded cache growth
  if (_hiCacheCount >= 200) {
    _hiCachePurge();
  }
  _hiCache[key] = saltedData;
  _hiCacheCount += 1;
  return saltedData;
}
function compareDigest(lhs, rhs) {
  if (lhs.length !== rhs.length) {
    return false;
  }
  if (typeof crypto.timingSafeEqual === "function") {
    return crypto.timingSafeEqual(lhs, rhs);
  }
  let result = 0;
  for (let i = 0; i < lhs.length; i++) {
    result |= lhs[i] ^ rhs[i];
  }
  return result === 0;
}
class ScramSHA1 extends ScramSHA {
  constructor() {
    super("sha1");
  }
}
scram.ScramSHA1 = ScramSHA1;
class ScramSHA256 extends ScramSHA {
  constructor() {
    super("sha256");
  }
}
scram.ScramSHA256 = ScramSHA256;

var x509 = {};

Object.defineProperty(x509, "__esModule", { value: true });
x509.X509 = void 0;
const error_1$5 = error;
const utils_1$2 = utils$2;
const auth_provider_1 = auth_provider;
class X509 extends auth_provider_1.AuthProvider {
  async prepare(handshakeDoc, authContext) {
    const { credentials } = authContext;
    if (!credentials) {
      throw new error_1$5.MongoMissingCredentialsError(
        "AuthContext must provide credentials.",
      );
    }
    return {
      ...handshakeDoc,
      speculativeAuthenticate: x509AuthenticateCommand(credentials),
    };
  }
  async auth(authContext) {
    const connection = authContext.connection;
    const credentials = authContext.credentials;
    if (!credentials) {
      throw new error_1$5.MongoMissingCredentialsError(
        "AuthContext must provide credentials.",
      );
    }
    const response = authContext.response;
    if (response?.speculativeAuthenticate) {
      return;
    }
    await connection.commandAsync(
      (0, utils_1$2.ns)("$external.$cmd"),
      x509AuthenticateCommand(credentials),
      undefined,
    );
  }
}
x509.X509 = X509;
function x509AuthenticateCommand(credentials) {
  const command = { authenticate: 1, mechanism: "MONGODB-X509" };
  if (credentials.username) {
    command.user = credentials.username;
  }
  return command;
}

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.LEGAL_TCP_SOCKET_OPTIONS =
    exports.LEGAL_TLS_SOCKET_OPTIONS =
    exports.prepareHandshakeDocument =
    exports.connect =
    exports.AUTH_PROVIDERS =
      void 0;
  const net = $nodeNet;
  const tls = $nodeTls;
  const constants_1 = constants;
  const deps_1 = deps;
  const error_1 = error;
  const utils_1 = utils$2;
  const auth_provider_1 = auth_provider;
  const gssapi_1 = gssapi;
  const mongocr_1 = mongocr;
  const mongodb_aws_1 = mongodb_aws;
  const mongodb_oidc_1 = mongodb_oidc;
  const plain_1 = plain;
  const providers_1 = providers$1;
  const scram_1 = scram;
  const x509_1 = x509;
  const connection_1 = connection;
  const constants_2 = constants$1;
  /** @internal */
  exports.AUTH_PROVIDERS = new Map([
    [providers_1.AuthMechanism.MONGODB_AWS, new mongodb_aws_1.MongoDBAWS()],
    [providers_1.AuthMechanism.MONGODB_CR, new mongocr_1.MongoCR()],
    [providers_1.AuthMechanism.MONGODB_GSSAPI, new gssapi_1.GSSAPI()],
    [providers_1.AuthMechanism.MONGODB_OIDC, new mongodb_oidc_1.MongoDBOIDC()],
    [providers_1.AuthMechanism.MONGODB_PLAIN, new plain_1.Plain()],
    [providers_1.AuthMechanism.MONGODB_SCRAM_SHA1, new scram_1.ScramSHA1()],
    [providers_1.AuthMechanism.MONGODB_SCRAM_SHA256, new scram_1.ScramSHA256()],
    [providers_1.AuthMechanism.MONGODB_X509, new x509_1.X509()],
  ]);
  function connect(options, callback) {
    makeConnection({ ...options, existingSocket: undefined }, (err, socket) => {
      if (err || !socket) {
        return callback(err);
      }
      let ConnectionType = options.connectionType ?? connection_1.Connection;
      if (options.autoEncrypter) {
        ConnectionType = connection_1.CryptoConnection;
      }
      const connection = new ConnectionType(socket, options);
      performInitialHandshake(connection, options).then(
        () => callback(undefined, connection),
        (error) => {
          connection.destroy({ force: false });
          callback(error);
        },
      );
    });
  }
  exports.connect = connect;
  function checkSupportedServer(hello, options) {
    const maxWireVersion = Number(hello.maxWireVersion);
    const minWireVersion = Number(hello.minWireVersion);
    const serverVersionHighEnough =
      !Number.isNaN(maxWireVersion) &&
      maxWireVersion >= constants_2.MIN_SUPPORTED_WIRE_VERSION;
    const serverVersionLowEnough =
      !Number.isNaN(minWireVersion) &&
      minWireVersion <= constants_2.MAX_SUPPORTED_WIRE_VERSION;
    if (serverVersionHighEnough) {
      if (serverVersionLowEnough) {
        return null;
      }
      const message = `Server at ${
        options.hostAddress
      } reports minimum wire version ${JSON.stringify(
        hello.minWireVersion,
      )}, but this version of the Node.js Driver requires at most ${
        constants_2.MAX_SUPPORTED_WIRE_VERSION
      } (MongoDB ${constants_2.MAX_SUPPORTED_SERVER_VERSION})`;
      return new error_1.MongoCompatibilityError(message);
    }
    const message = `Server at ${
      options.hostAddress
    } reports maximum wire version ${
      JSON.stringify(hello.maxWireVersion) ?? 0
    }, but this version of the Node.js Driver requires at least ${
      constants_2.MIN_SUPPORTED_WIRE_VERSION
    } (MongoDB ${constants_2.MIN_SUPPORTED_SERVER_VERSION})`;
    return new error_1.MongoCompatibilityError(message);
  }
  async function performInitialHandshake(conn, options) {
    const credentials = options.credentials;
    if (credentials) {
      if (
        !(
          credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT
        ) &&
        !exports.AUTH_PROVIDERS.get(credentials.mechanism)
      ) {
        throw new error_1.MongoInvalidArgumentError(
          `AuthMechanism '${credentials.mechanism}' not supported`,
        );
      }
    }
    const authContext = new auth_provider_1.AuthContext(
      conn,
      credentials,
      options,
    );
    conn.authContext = authContext;
    const handshakeDoc = await prepareHandshakeDocument(authContext);
    // @ts-expect-error: TODO(NODE-5141): The options need to be filtered properly, Connection options differ from Command options
    const handshakeOptions = { ...options };
    if (typeof options.connectTimeoutMS === "number") {
      // The handshake technically is a monitoring check, so its socket timeout should be connectTimeoutMS
      handshakeOptions.socketTimeoutMS = options.connectTimeoutMS;
    }
    const start = new Date().getTime();
    const response = await conn.commandAsync(
      (0, utils_1.ns)("admin.$cmd"),
      handshakeDoc,
      handshakeOptions,
    );
    if (!("isWritablePrimary" in response)) {
      // Provide hello-style response document.
      response.isWritablePrimary = response[constants_1.LEGACY_HELLO_COMMAND];
    }
    if (response.helloOk) {
      conn.helloOk = true;
    }
    const supportedServerErr = checkSupportedServer(response, options);
    if (supportedServerErr) {
      throw supportedServerErr;
    }
    if (options.loadBalanced) {
      if (!response.serviceId) {
        throw new error_1.MongoCompatibilityError(
          "Driver attempted to initialize in load balancing mode, " +
            "but the server does not support this mode.",
        );
      }
    }
    // NOTE: This is metadata attached to the connection while porting away from
    //       handshake being done in the `Server` class. Likely, it should be
    //       relocated, or at very least restructured.
    conn.hello = response;
    conn.lastHelloMS = new Date().getTime() - start;
    if (!response.arbiterOnly && credentials) {
      // store the response on auth context
      authContext.response = response;
      const resolvedCredentials = credentials.resolveAuthMechanism(response);
      const provider = exports.AUTH_PROVIDERS.get(
        resolvedCredentials.mechanism,
      );
      if (!provider) {
        throw new error_1.MongoInvalidArgumentError(
          `No AuthProvider for ${resolvedCredentials.mechanism} defined.`,
        );
      }
      try {
        await provider.auth(authContext);
      } catch (error) {
        if (error instanceof error_1.MongoError) {
          error.addErrorLabel(error_1.MongoErrorLabel.HandshakeError);
          if (
            (0, error_1.needsRetryableWriteLabel)(
              error,
              response.maxWireVersion,
            )
          ) {
            error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);
          }
        }
        throw error;
      }
    }
  }
  /**
   * @internal
   *
   * This function is only exposed for testing purposes.
   */
  async function prepareHandshakeDocument(authContext) {
    const options = authContext.options;
    const compressors = options.compressors ? options.compressors : [];
    const { serverApi } = authContext.connection;
    const handshakeDoc = {
      [serverApi?.version ? "hello" : constants_1.LEGACY_HELLO_COMMAND]: 1,
      helloOk: true,
      client: options.metadata,
      compression: compressors,
    };
    if (options.loadBalanced === true) {
      handshakeDoc.loadBalanced = true;
    }
    const credentials = authContext.credentials;
    if (credentials) {
      if (
        credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT &&
        credentials.username
      ) {
        handshakeDoc.saslSupportedMechs = `${credentials.source}.${credentials.username}`;
        const provider = exports.AUTH_PROVIDERS.get(
          providers_1.AuthMechanism.MONGODB_SCRAM_SHA256,
        );
        if (!provider) {
          // This auth mechanism is always present.
          throw new error_1.MongoInvalidArgumentError(
            `No AuthProvider for ${providers_1.AuthMechanism.MONGODB_SCRAM_SHA256} defined.`,
          );
        }
        return provider.prepare(handshakeDoc, authContext);
      }
      const provider = exports.AUTH_PROVIDERS.get(credentials.mechanism);
      if (!provider) {
        throw new error_1.MongoInvalidArgumentError(
          `No AuthProvider for ${credentials.mechanism} defined.`,
        );
      }
      return provider.prepare(handshakeDoc, authContext);
    }
    return handshakeDoc;
  }
  exports.prepareHandshakeDocument = prepareHandshakeDocument;
  /** @public */
  exports.LEGAL_TLS_SOCKET_OPTIONS = [
    "ALPNProtocols",
    "ca",
    "cert",
    "checkServerIdentity",
    "ciphers",
    "crl",
    "ecdhCurve",
    "key",
    "minDHSize",
    "passphrase",
    "pfx",
    "rejectUnauthorized",
    "secureContext",
    "secureProtocol",
    "servername",
    "session",
  ];
  /** @public */
  exports.LEGAL_TCP_SOCKET_OPTIONS = [
    "family",
    "hints",
    "localAddress",
    "localPort",
    "lookup",
  ];
  function parseConnectOptions(options) {
    const hostAddress = options.hostAddress;
    if (!hostAddress)
      throw new error_1.MongoInvalidArgumentError(
        'Option "hostAddress" is required',
      );
    const result = {};
    for (const name of exports.LEGAL_TCP_SOCKET_OPTIONS) {
      if (options[name] != null) {
        result[name] = options[name];
      }
    }
    if (typeof hostAddress.socketPath === "string") {
      result.path = hostAddress.socketPath;
      return result;
    } else if (typeof hostAddress.host === "string") {
      result.host = hostAddress.host;
      result.port = hostAddress.port;
      return result;
    } else {
      // This should never happen since we set up HostAddresses
      // But if we don't throw here the socket could hang until timeout
      // TODO(NODE-3483)
      throw new error_1.MongoRuntimeError(
        `Unexpected HostAddress ${JSON.stringify(hostAddress)}`,
      );
    }
  }
  function parseSslOptions(options) {
    const result = parseConnectOptions(options);
    // Merge in valid SSL options
    for (const name of exports.LEGAL_TLS_SOCKET_OPTIONS) {
      if (options[name] != null) {
        result[name] = options[name];
      }
    }
    if (options.existingSocket) {
      result.socket = options.existingSocket;
    }
    // Set default sni servername to be the same as host
    if (result.servername == null && result.host && !net.isIP(result.host)) {
      result.servername = result.host;
    }
    return result;
  }
  const SOCKET_ERROR_EVENT_LIST = ["error", "close", "timeout", "parseError"];
  const SOCKET_ERROR_EVENTS = new Set(SOCKET_ERROR_EVENT_LIST);
  function makeConnection(options, _callback) {
    const useTLS = options.tls ?? false;
    const noDelay = options.noDelay ?? true;
    const connectTimeoutMS = options.connectTimeoutMS ?? 30000;
    const rejectUnauthorized = options.rejectUnauthorized ?? true;
    const existingSocket = options.existingSocket;
    let socket;
    const callback = function (err, ret) {
      if (err && socket) {
        socket.destroy();
      }
      _callback(err, ret);
    };
    if (options.proxyHost != null) {
      // Currently, only Socks5 is supported.
      return makeSocks5Connection(
        {
          ...options,
          connectTimeoutMS, // Should always be present for Socks5
        },
        callback,
      );
    }
    if (useTLS) {
      const tlsSocket = tls.connect(parseSslOptions(options));
      if (typeof tlsSocket.disableRenegotiation === "function") {
        tlsSocket.disableRenegotiation();
      }
      socket = tlsSocket;
    } else if (existingSocket) {
      // In the TLS case, parseSslOptions() sets options.socket to existingSocket,
      // so we only need to handle the non-TLS case here (where existingSocket
      // gives us all we need out of the box).
      socket = existingSocket;
    } else {
      socket = net.createConnection(parseConnectOptions(options));
    }
    socket.setKeepAlive(true, 300000);
    socket.setTimeout(connectTimeoutMS);
    socket.setNoDelay(noDelay);
    const connectEvent = useTLS ? "secureConnect" : "connect";
    let cancellationHandler;
    function errorHandler(eventName) {
      return (err) => {
        SOCKET_ERROR_EVENTS.forEach((event) =>
          socket.removeAllListeners(event),
        );
        if (cancellationHandler && options.cancellationToken) {
          options.cancellationToken.removeListener(
            "cancel",
            cancellationHandler,
          );
        }
        socket.removeListener(connectEvent, connectHandler);
        callback(connectionFailureError(eventName, err));
      };
    }
    function connectHandler() {
      SOCKET_ERROR_EVENTS.forEach((event) => socket.removeAllListeners(event));
      if (cancellationHandler && options.cancellationToken) {
        options.cancellationToken.removeListener("cancel", cancellationHandler);
      }
      if ("authorizationError" in socket) {
        if (socket.authorizationError && rejectUnauthorized) {
          // TODO(NODE-5192): wrap this with a MongoError subclass
          return callback(socket.authorizationError);
        }
      }
      socket.setTimeout(0);
      callback(undefined, socket);
    }
    SOCKET_ERROR_EVENTS.forEach((event) =>
      socket.once(event, errorHandler(event)),
    );
    if (options.cancellationToken) {
      cancellationHandler = errorHandler("cancel");
      options.cancellationToken.once("cancel", cancellationHandler);
    }
    if (existingSocket) {
      process.nextTick(connectHandler);
    } else {
      socket.once(connectEvent, connectHandler);
    }
  }
  let socks = null;
  function loadSocks() {
    if (socks == null) {
      const socksImport = (0, deps_1.getSocks)();
      if ("kModuleError" in socksImport) {
        throw socksImport.kModuleError;
      }
      socks = socksImport;
    }
    return socks;
  }
  function makeSocks5Connection(options, callback) {
    const hostAddress = utils_1.HostAddress.fromHostPort(
      options.proxyHost ?? "", // proxyHost is guaranteed to set here
      options.proxyPort ?? 1080,
    );
    // First, connect to the proxy server itself:
    makeConnection(
      {
        ...options,
        hostAddress,
        tls: false,
        proxyHost: undefined,
      },
      (err, rawSocket) => {
        if (err || !rawSocket) {
          return callback(err);
        }
        const destination = parseConnectOptions(options);
        if (
          typeof destination.host !== "string" ||
          typeof destination.port !== "number"
        ) {
          return callback(
            new error_1.MongoInvalidArgumentError(
              "Can only make Socks5 connections to TCP hosts",
            ),
          );
        }
        try {
          socks ??= loadSocks();
        } catch (error) {
          return callback(error);
        }
        // Then, establish the Socks5 proxy connection:
        socks.SocksClient.createConnection({
          existing_socket: rawSocket,
          timeout: options.connectTimeoutMS,
          command: "connect",
          destination: {
            host: destination.host,
            port: destination.port,
          },
          proxy: {
            // host and port are ignored because we pass existing_socket
            host: "iLoveJavaScript",
            port: 0,
            type: 5,
            userId: options.proxyUsername || undefined,
            password: options.proxyPassword || undefined,
          },
        }).then(
          ({ socket }) => {
            // Finally, now treat the resulting duplex stream as the
            // socket over which we send and receive wire protocol messages:
            makeConnection(
              {
                ...options,
                existingSocket: socket,
                proxyHost: undefined,
              },
              callback,
            );
          },
          (error) => callback(connectionFailureError("error", error)),
        );
      },
    );
  }
  function connectionFailureError(type, err) {
    switch (type) {
      case "error":
        return new error_1.MongoNetworkError(
          error_1.MongoError.buildErrorMessage(err),
          { cause: err },
        );
      case "timeout":
        return new error_1.MongoNetworkTimeoutError("connection timed out");
      case "close":
        return new error_1.MongoNetworkError("connection closed");
      case "cancel":
        return new error_1.MongoNetworkError(
          "connection establishment was cancelled",
        );
      default:
        return new error_1.MongoNetworkError("unknown network error");
    }
  }
})(connect);

var connection_pool_events = {};

Object.defineProperty(connection_pool_events, "__esModule", { value: true });
connection_pool_events.ConnectionPoolClearedEvent =
  connection_pool_events.ConnectionCheckedInEvent =
  connection_pool_events.ConnectionCheckedOutEvent =
  connection_pool_events.ConnectionCheckOutFailedEvent =
  connection_pool_events.ConnectionCheckOutStartedEvent =
  connection_pool_events.ConnectionClosedEvent =
  connection_pool_events.ConnectionReadyEvent =
  connection_pool_events.ConnectionCreatedEvent =
  connection_pool_events.ConnectionPoolClosedEvent =
  connection_pool_events.ConnectionPoolReadyEvent =
  connection_pool_events.ConnectionPoolCreatedEvent =
  connection_pool_events.ConnectionPoolMonitoringEvent =
    void 0;
const constants_1 = constants;
/**
 * The base export class for all monitoring events published from the connection pool
 * @public
 * @category Event
 */
let ConnectionPoolMonitoringEvent$1 = class ConnectionPoolMonitoringEvent {
  /** @internal */
  constructor(pool) {
    this.time = new Date();
    this.address = pool.address;
  }
};
connection_pool_events.ConnectionPoolMonitoringEvent =
  ConnectionPoolMonitoringEvent$1;
/**
 * An event published when a connection pool is created
 * @public
 * @category Event
 */
let ConnectionPoolCreatedEvent$1 = class ConnectionPoolCreatedEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_POOL_CREATED;
    const {
      maxConnecting,
      maxPoolSize,
      minPoolSize,
      maxIdleTimeMS,
      waitQueueTimeoutMS,
    } = pool.options;
    this.options = {
      maxConnecting,
      maxPoolSize,
      minPoolSize,
      maxIdleTimeMS,
      waitQueueTimeoutMS,
    };
  }
};
connection_pool_events.ConnectionPoolCreatedEvent =
  ConnectionPoolCreatedEvent$1;
/**
 * An event published when a connection pool is ready
 * @public
 * @category Event
 */
let ConnectionPoolReadyEvent$1 = class ConnectionPoolReadyEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_POOL_READY;
  }
};
connection_pool_events.ConnectionPoolReadyEvent = ConnectionPoolReadyEvent$1;
/**
 * An event published when a connection pool is closed
 * @public
 * @category Event
 */
let ConnectionPoolClosedEvent$1 = class ConnectionPoolClosedEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_POOL_CLOSED;
  }
};
connection_pool_events.ConnectionPoolClosedEvent = ConnectionPoolClosedEvent$1;
/**
 * An event published when a connection pool creates a new connection
 * @public
 * @category Event
 */
let ConnectionCreatedEvent$1 = class ConnectionCreatedEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool, connection) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_CREATED;
    this.connectionId = connection.id;
  }
};
connection_pool_events.ConnectionCreatedEvent = ConnectionCreatedEvent$1;
/**
 * An event published when a connection is ready for use
 * @public
 * @category Event
 */
let ConnectionReadyEvent$1 = class ConnectionReadyEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool, connection) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_READY;
    this.connectionId = connection.id;
  }
};
connection_pool_events.ConnectionReadyEvent = ConnectionReadyEvent$1;
/**
 * An event published when a connection is closed
 * @public
 * @category Event
 */
let ConnectionClosedEvent$1 = class ConnectionClosedEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool, connection, reason, error) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_CLOSED;
    this.connectionId = connection.id;
    this.reason = reason;
    this.serviceId = connection.serviceId;
    this.error = error ?? null;
  }
};
connection_pool_events.ConnectionClosedEvent = ConnectionClosedEvent$1;
/**
 * An event published when a request to check a connection out begins
 * @public
 * @category Event
 */
let ConnectionCheckOutStartedEvent$1 = class ConnectionCheckOutStartedEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_CHECK_OUT_STARTED;
  }
};
connection_pool_events.ConnectionCheckOutStartedEvent =
  ConnectionCheckOutStartedEvent$1;
/**
 * An event published when a request to check a connection out fails
 * @public
 * @category Event
 */
let ConnectionCheckOutFailedEvent$1 = class ConnectionCheckOutFailedEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool, reason, error) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_CHECK_OUT_FAILED;
    this.reason = reason;
    this.error = error;
  }
};
connection_pool_events.ConnectionCheckOutFailedEvent =
  ConnectionCheckOutFailedEvent$1;
/**
 * An event published when a connection is checked out of the connection pool
 * @public
 * @category Event
 */
let ConnectionCheckedOutEvent$1 = class ConnectionCheckedOutEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool, connection) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_CHECKED_OUT;
    this.connectionId = connection.id;
  }
};
connection_pool_events.ConnectionCheckedOutEvent = ConnectionCheckedOutEvent$1;
/**
 * An event published when a connection is checked into the connection pool
 * @public
 * @category Event
 */
let ConnectionCheckedInEvent$1 = class ConnectionCheckedInEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool, connection) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_CHECKED_IN;
    this.connectionId = connection.id;
  }
};
connection_pool_events.ConnectionCheckedInEvent = ConnectionCheckedInEvent$1;
/**
 * An event published when a connection pool is cleared
 * @public
 * @category Event
 */
let ConnectionPoolClearedEvent$1 = class ConnectionPoolClearedEvent extends ConnectionPoolMonitoringEvent$1 {
  /** @internal */
  constructor(pool, options = {}) {
    super(pool);
    /** @internal */
    this.name = constants_1.CONNECTION_POOL_CLEARED;
    this.serviceId = options.serviceId;
    this.interruptInUseConnections = options.interruptInUseConnections;
  }
};
connection_pool_events.ConnectionPoolClearedEvent =
  ConnectionPoolClearedEvent$1;

var errors = {};

Object.defineProperty(errors, "__esModule", { value: true });
errors.WaitQueueTimeoutError =
  errors.PoolClearedOnNetworkError =
  errors.PoolClearedError =
  errors.PoolClosedError =
    void 0;
const error_1$4 = error;
/**
 * An error indicating a connection pool is closed
 * @category Error
 */
class PoolClosedError extends error_1$4.MongoDriverError {
  /**
   * **Do not use this constructor!**
   *
   * Meant for internal use only.
   *
   * @remarks
   * This class is only meant to be constructed within the driver. This constructor is
   * not subject to semantic versioning compatibility guarantees and may change at any time.
   *
   * @public
   **/
  constructor(pool) {
    super("Attempted to check out a connection from closed connection pool");
    this.address = pool.address;
  }
  get name() {
    return "MongoPoolClosedError";
  }
}
errors.PoolClosedError = PoolClosedError;
/**
 * An error indicating a connection pool is currently paused
 * @category Error
 */
class PoolClearedError extends error_1$4.MongoNetworkError {
  /**
   * **Do not use this constructor!**
   *
   * Meant for internal use only.
   *
   * @remarks
   * This class is only meant to be constructed within the driver. This constructor is
   * not subject to semantic versioning compatibility guarantees and may change at any time.
   *
   * @public
   **/
  constructor(pool, message) {
    const errorMessage = message
      ? message
      : `Connection pool for ${pool.address} was cleared because another operation failed with: "${pool.serverError?.message}"`;
    super(
      errorMessage,
      pool.serverError ? { cause: pool.serverError } : undefined,
    );
    this.address = pool.address;
    this.addErrorLabel(error_1$4.MongoErrorLabel.RetryableWriteError);
  }
  get name() {
    return "MongoPoolClearedError";
  }
}
errors.PoolClearedError = PoolClearedError;
/**
 * An error indicating that a connection pool has been cleared after the monitor for that server timed out.
 * @category Error
 */
class PoolClearedOnNetworkError extends PoolClearedError {
  /**
   * **Do not use this constructor!**
   *
   * Meant for internal use only.
   *
   * @remarks
   * This class is only meant to be constructed within the driver. This constructor is
   * not subject to semantic versioning compatibility guarantees and may change at any time.
   *
   * @public
   **/
  constructor(pool) {
    super(
      pool,
      `Connection to ${pool.address} interrupted due to server monitor timeout`,
    );
  }
  get name() {
    return "PoolClearedOnNetworkError";
  }
}
errors.PoolClearedOnNetworkError = PoolClearedOnNetworkError;
/**
 * An error thrown when a request to check out a connection times out
 * @category Error
 */
class WaitQueueTimeoutError extends error_1$4.MongoDriverError {
  /**
   * **Do not use this constructor!**
   *
   * Meant for internal use only.
   *
   * @remarks
   * This class is only meant to be constructed within the driver. This constructor is
   * not subject to semantic versioning compatibility guarantees and may change at any time.
   *
   * @public
   **/
  constructor(message, address) {
    super(message);
    this.address = address;
  }
  get name() {
    return "MongoWaitQueueTimeoutError";
  }
}
errors.WaitQueueTimeoutError = WaitQueueTimeoutError;

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.ConnectionPool = exports.PoolState = void 0;
  const timers_1 = $nodeTimers;
  const constants_1 = constants;
  const error_1 = error;
  const mongo_types_1 = mongo_types;
  const utils_1 = utils$2;
  const connect_1 = connect;
  const connection_1 = connection;
  const connection_pool_events_1 = connection_pool_events;
  const errors_1 = errors;
  const metrics_1 = metrics;
  /** @internal */
  const kServer = Symbol("server");
  /** @internal */
  const kConnections = Symbol("connections");
  /** @internal */
  const kPending = Symbol("pending");
  /** @internal */
  const kCheckedOut = Symbol("checkedOut");
  /** @internal */
  const kMinPoolSizeTimer = Symbol("minPoolSizeTimer");
  /** @internal */
  const kGeneration = Symbol("generation");
  /** @internal */
  const kServiceGenerations = Symbol("serviceGenerations");
  /** @internal */
  const kConnectionCounter = Symbol("connectionCounter");
  /** @internal */
  const kCancellationToken = Symbol("cancellationToken");
  /** @internal */
  const kWaitQueue = Symbol("waitQueue");
  /** @internal */
  const kCancelled = Symbol("cancelled");
  /** @internal */
  const kMetrics = Symbol("metrics");
  /** @internal */
  const kProcessingWaitQueue = Symbol("processingWaitQueue");
  /** @internal */
  const kPoolState = Symbol("poolState");
  /** @internal */
  exports.PoolState = Object.freeze({
    paused: "paused",
    ready: "ready",
    closed: "closed",
  });
  /**
   * A pool of connections which dynamically resizes, and emit events related to pool activity
   * @internal
   */
  class ConnectionPool extends mongo_types_1.TypedEventEmitter {
    constructor(server, options) {
      super();
      this.options = Object.freeze({
        ...options,
        connectionType: connection_1.Connection,
        maxPoolSize: options.maxPoolSize ?? 100,
        minPoolSize: options.minPoolSize ?? 0,
        maxConnecting: options.maxConnecting ?? 2,
        maxIdleTimeMS: options.maxIdleTimeMS ?? 0,
        waitQueueTimeoutMS: options.waitQueueTimeoutMS ?? 0,
        minPoolSizeCheckFrequencyMS: options.minPoolSizeCheckFrequencyMS ?? 100,
        autoEncrypter: options.autoEncrypter,
        metadata: options.metadata,
      });
      if (this.options.minPoolSize > this.options.maxPoolSize) {
        throw new error_1.MongoInvalidArgumentError(
          "Connection pool minimum size must not be greater than maximum pool size",
        );
      }
      this[kPoolState] = exports.PoolState.paused;
      this[kServer] = server;
      this[kConnections] = new utils_1.List();
      this[kPending] = 0;
      this[kCheckedOut] = new Set();
      this[kMinPoolSizeTimer] = undefined;
      this[kGeneration] = 0;
      this[kServiceGenerations] = new Map();
      this[kConnectionCounter] = (0, utils_1.makeCounter)(1);
      this[kCancellationToken] = new mongo_types_1.CancellationToken();
      this[kCancellationToken].setMaxListeners(Infinity);
      this[kWaitQueue] = new utils_1.List();
      this[kMetrics] = new metrics_1.ConnectionPoolMetrics();
      this[kProcessingWaitQueue] = false;
      this.mongoLogger = this[kServer].topology.client.mongoLogger;
      this.component = "connection";
      process.nextTick(() => {
        this.emitAndLog(
          ConnectionPool.CONNECTION_POOL_CREATED,
          new connection_pool_events_1.ConnectionPoolCreatedEvent(this),
        );
      });
    }
    /** The address of the endpoint the pool is connected to */
    get address() {
      return this.options.hostAddress.toString();
    }
    /**
     * Check if the pool has been closed
     *
     * TODO(NODE-3263): We can remove this property once shell no longer needs it
     */
    get closed() {
      return this[kPoolState] === exports.PoolState.closed;
    }
    /** An integer representing the SDAM generation of the pool */
    get generation() {
      return this[kGeneration];
    }
    /** An integer expressing how many total connections (available + pending + in use) the pool currently has */
    get totalConnectionCount() {
      return (
        this.availableConnectionCount +
        this.pendingConnectionCount +
        this.currentCheckedOutCount
      );
    }
    /** An integer expressing how many connections are currently available in the pool. */
    get availableConnectionCount() {
      return this[kConnections].length;
    }
    get pendingConnectionCount() {
      return this[kPending];
    }
    get currentCheckedOutCount() {
      return this[kCheckedOut].size;
    }
    get waitQueueSize() {
      return this[kWaitQueue].length;
    }
    get loadBalanced() {
      return this.options.loadBalanced;
    }
    get serviceGenerations() {
      return this[kServiceGenerations];
    }
    get serverError() {
      return this[kServer].description.error;
    }
    /**
     * This is exposed ONLY for use in mongosh, to enable
     * killing all connections if a user quits the shell with
     * operations in progress.
     *
     * This property may be removed as a part of NODE-3263.
     */
    get checkedOutConnections() {
      return this[kCheckedOut];
    }
    /**
     * Get the metrics information for the pool when a wait queue timeout occurs.
     */
    waitQueueErrorMetrics() {
      return this[kMetrics].info(this.options.maxPoolSize);
    }
    /**
     * Set the pool state to "ready"
     */
    ready() {
      if (this[kPoolState] !== exports.PoolState.paused) {
        return;
      }
      this[kPoolState] = exports.PoolState.ready;
      this.emitAndLog(
        ConnectionPool.CONNECTION_POOL_READY,
        new connection_pool_events_1.ConnectionPoolReadyEvent(this),
      );
      (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);
      this.ensureMinPoolSize();
    }
    /**
     * Check a connection out of this pool. The connection will continue to be tracked, but no reference to it
     * will be held by the pool. This means that if a connection is checked out it MUST be checked back in or
     * explicitly destroyed by the new owner.
     */
    checkOut(callback) {
      this.emitAndLog(
        ConnectionPool.CONNECTION_CHECK_OUT_STARTED,
        new connection_pool_events_1.ConnectionCheckOutStartedEvent(this),
      );
      const waitQueueTimeoutMS = this.options.waitQueueTimeoutMS;
      const waitQueueMember = {
        callback,
        timeoutController: new utils_1.TimeoutController(waitQueueTimeoutMS),
      };
      waitQueueMember.timeoutController.signal.addEventListener("abort", () => {
        waitQueueMember[kCancelled] = true;
        waitQueueMember.timeoutController.clear();
        this.emitAndLog(
          ConnectionPool.CONNECTION_CHECK_OUT_FAILED,
          new connection_pool_events_1.ConnectionCheckOutFailedEvent(
            this,
            "timeout",
          ),
        );
        waitQueueMember.callback(
          new errors_1.WaitQueueTimeoutError(
            this.loadBalanced
              ? this.waitQueueErrorMetrics()
              : "Timed out while checking out a connection from connection pool",
            this.address,
          ),
        );
      });
      this[kWaitQueue].push(waitQueueMember);
      process.nextTick(() => this.processWaitQueue());
    }
    /**
     * Check a connection into the pool.
     *
     * @param connection - The connection to check in
     */
    checkIn(connection) {
      if (!this[kCheckedOut].has(connection)) {
        return;
      }
      const poolClosed = this.closed;
      const stale = this.connectionIsStale(connection);
      const willDestroy = !!(poolClosed || stale || connection.closed);
      if (!willDestroy) {
        connection.markAvailable();
        this[kConnections].unshift(connection);
      }
      this[kCheckedOut].delete(connection);
      this.emitAndLog(
        ConnectionPool.CONNECTION_CHECKED_IN,
        new connection_pool_events_1.ConnectionCheckedInEvent(this, connection),
      );
      if (willDestroy) {
        const reason = connection.closed
          ? "error"
          : poolClosed
          ? "poolClosed"
          : "stale";
        this.destroyConnection(connection, reason);
      }
      process.nextTick(() => this.processWaitQueue());
    }
    /**
     * Clear the pool
     *
     * Pool reset is handled by incrementing the pool's generation count. Any existing connection of a
     * previous generation will eventually be pruned during subsequent checkouts.
     */
    clear(options = {}) {
      if (this.closed) {
        return;
      }
      // handle load balanced case
      if (this.loadBalanced) {
        const { serviceId } = options;
        if (!serviceId) {
          throw new error_1.MongoRuntimeError(
            "ConnectionPool.clear() called in load balanced mode with no serviceId.",
          );
        }
        const sid = serviceId.toHexString();
        const generation = this.serviceGenerations.get(sid);
        // Only need to worry if the generation exists, since it should
        // always be there but typescript needs the check.
        if (generation == null) {
          throw new error_1.MongoRuntimeError(
            "Service generations are required in load balancer mode.",
          );
        } else {
          // Increment the generation for the service id.
          this.serviceGenerations.set(sid, generation + 1);
        }
        this.emitAndLog(
          ConnectionPool.CONNECTION_POOL_CLEARED,
          new connection_pool_events_1.ConnectionPoolClearedEvent(this, {
            serviceId,
          }),
        );
        return;
      }
      // handle non load-balanced case
      const interruptInUseConnections =
        options.interruptInUseConnections ?? false;
      const oldGeneration = this[kGeneration];
      this[kGeneration] += 1;
      const alreadyPaused = this[kPoolState] === exports.PoolState.paused;
      this[kPoolState] = exports.PoolState.paused;
      this.clearMinPoolSizeTimer();
      if (!alreadyPaused) {
        this.emitAndLog(
          ConnectionPool.CONNECTION_POOL_CLEARED,
          new connection_pool_events_1.ConnectionPoolClearedEvent(this, {
            interruptInUseConnections,
          }),
        );
      }
      if (interruptInUseConnections) {
        process.nextTick(() => this.interruptInUseConnections(oldGeneration));
      }
      this.processWaitQueue();
    }
    /**
     * Closes all stale in-use connections in the pool with a resumable PoolClearedOnNetworkError.
     *
     * Only connections where `connection.generation <= minGeneration` are killed.
     */
    interruptInUseConnections(minGeneration) {
      for (const connection of this[kCheckedOut]) {
        if (connection.generation <= minGeneration) {
          this.checkIn(connection);
          connection.onError(new errors_1.PoolClearedOnNetworkError(this));
        }
      }
    }
    close(_options, _cb) {
      let options = _options;
      const callback = _cb ?? _options;
      if (typeof options === "function") {
        options = {};
      }
      options = Object.assign({ force: false }, options);
      if (this.closed) {
        return callback();
      }
      // immediately cancel any in-flight connections
      this[kCancellationToken].emit("cancel");
      // end the connection counter
      if (typeof this[kConnectionCounter].return === "function") {
        this[kConnectionCounter].return(undefined);
      }
      this[kPoolState] = exports.PoolState.closed;
      this.clearMinPoolSizeTimer();
      this.processWaitQueue();
      (0, utils_1.eachAsync)(
        this[kConnections].toArray(),
        (conn, cb) => {
          this.emitAndLog(
            ConnectionPool.CONNECTION_CLOSED,
            new connection_pool_events_1.ConnectionClosedEvent(
              this,
              conn,
              "poolClosed",
            ),
          );
          conn.destroy({ force: !!options.force }, cb);
        },
        (err) => {
          this[kConnections].clear();
          this.emitAndLog(
            ConnectionPool.CONNECTION_POOL_CLOSED,
            new connection_pool_events_1.ConnectionPoolClosedEvent(this),
          );
          callback(err);
        },
      );
    }
    /**
     * Runs a lambda with an implicitly checked out connection, checking that connection back in when the lambda
     * has completed by calling back.
     *
     * NOTE: please note the required signature of `fn`
     *
     * @remarks When in load balancer mode, connections can be pinned to cursors or transactions.
     *   In these cases we pass the connection in to this method to ensure it is used and a new
     *   connection is not checked out.
     *
     * @param conn - A pinned connection for use in load balancing mode.
     * @param fn - A function which operates on a managed connection
     * @param callback - The original callback
     */
    withConnection(conn, fn, callback) {
      if (conn) {
        // use the provided connection, and do _not_ check it in after execution
        fn(undefined, conn, (fnErr, result) => {
          if (fnErr) {
            return this.withReauthentication(fnErr, conn, fn, callback);
          }
          callback(undefined, result);
        });
        return;
      }
      this.checkOut((err, conn) => {
        // don't callback with `err` here, we might want to act upon it inside `fn`
        fn(err, conn, (fnErr, result) => {
          if (fnErr) {
            if (conn) {
              this.withReauthentication(fnErr, conn, fn, callback);
            } else {
              callback(fnErr);
            }
          } else {
            callback(undefined, result);
          }
          if (conn) {
            this.checkIn(conn);
          }
        });
      });
    }
    withReauthentication(fnErr, conn, fn, callback) {
      if (
        fnErr instanceof error_1.MongoError &&
        fnErr.code === error_1.MONGODB_ERROR_CODES.Reauthenticate
      ) {
        this.reauthenticate(conn, fn, (error, res) => {
          if (error) {
            return callback(error);
          }
          callback(undefined, res);
        });
      } else {
        callback(fnErr);
      }
    }
    /**
     * Reauthenticate on the same connection and then retry the operation.
     */
    reauthenticate(connection, fn, callback) {
      const authContext = connection.authContext;
      if (!authContext) {
        return callback(
          new error_1.MongoRuntimeError("No auth context found on connection."),
        );
      }
      const credentials = authContext.credentials;
      if (!credentials) {
        return callback(
          new error_1.MongoMissingCredentialsError(
            "Connection is missing credentials when asked to reauthenticate",
          ),
        );
      }
      const resolvedCredentials = credentials.resolveAuthMechanism(
        connection.hello || undefined,
      );
      const provider = connect_1.AUTH_PROVIDERS.get(
        resolvedCredentials.mechanism,
      );
      if (!provider) {
        return callback(
          new error_1.MongoMissingCredentialsError(
            `Reauthenticate failed due to no auth provider for ${credentials.mechanism}`,
          ),
        );
      }
      provider.reauth(authContext).then(
        () => {
          fn(undefined, connection, (fnErr, fnResult) => {
            if (fnErr) {
              return callback(fnErr);
            }
            callback(undefined, fnResult);
          });
        },
        (error) => callback(error),
      );
    }
    /** Clear the min pool size timer */
    clearMinPoolSizeTimer() {
      const minPoolSizeTimer = this[kMinPoolSizeTimer];
      if (minPoolSizeTimer) {
        (0, timers_1.clearTimeout)(minPoolSizeTimer);
      }
    }
    destroyConnection(connection, reason) {
      this.emitAndLog(
        ConnectionPool.CONNECTION_CLOSED,
        new connection_pool_events_1.ConnectionClosedEvent(
          this,
          connection,
          reason,
        ),
      );
      // destroy the connection
      process.nextTick(() => connection.destroy({ force: false }));
    }
    connectionIsStale(connection) {
      const serviceId = connection.serviceId;
      if (this.loadBalanced && serviceId) {
        const sid = serviceId.toHexString();
        const generation = this.serviceGenerations.get(sid);
        return connection.generation !== generation;
      }
      return connection.generation !== this[kGeneration];
    }
    connectionIsIdle(connection) {
      return !!(
        this.options.maxIdleTimeMS &&
        connection.idleTime > this.options.maxIdleTimeMS
      );
    }
    /**
     * Destroys a connection if the connection is perished.
     *
     * @returns `true` if the connection was destroyed, `false` otherwise.
     */
    destroyConnectionIfPerished(connection) {
      const isStale = this.connectionIsStale(connection);
      const isIdle = this.connectionIsIdle(connection);
      if (!isStale && !isIdle && !connection.closed) {
        return false;
      }
      const reason = connection.closed ? "error" : isStale ? "stale" : "idle";
      this.destroyConnection(connection, reason);
      return true;
    }
    createConnection(callback) {
      const connectOptions = {
        ...this.options,
        id: this[kConnectionCounter].next().value,
        generation: this[kGeneration],
        cancellationToken: this[kCancellationToken],
      };
      this[kPending]++;
      // This is our version of a "virtual" no-I/O connection as the spec requires
      this.emitAndLog(
        ConnectionPool.CONNECTION_CREATED,
        new connection_pool_events_1.ConnectionCreatedEvent(this, {
          id: connectOptions.id,
        }),
      );
      (0, connect_1.connect)(connectOptions, (err, connection) => {
        if (err || !connection) {
          this[kPending]--;
          this.emitAndLog(
            ConnectionPool.CONNECTION_CLOSED,
            new connection_pool_events_1.ConnectionClosedEvent(
              this,
              { id: connectOptions.id, serviceId: undefined },
              "error",
              // TODO(NODE-5192): Remove this cast
              err,
            ),
          );
          if (
            err instanceof error_1.MongoNetworkError ||
            err instanceof error_1.MongoServerError
          ) {
            err.connectionGeneration = connectOptions.generation;
          }
          callback(
            err ??
              new error_1.MongoRuntimeError(
                "Connection creation failed without error",
              ),
          );
          return;
        }
        // The pool might have closed since we started trying to create a connection
        if (this[kPoolState] !== exports.PoolState.ready) {
          this[kPending]--;
          connection.destroy({ force: true });
          callback(
            this.closed
              ? new errors_1.PoolClosedError(this)
              : new errors_1.PoolClearedError(this),
          );
          return;
        }
        // forward all events from the connection to the pool
        for (const event of [
          ...constants_1.APM_EVENTS,
          connection_1.Connection.CLUSTER_TIME_RECEIVED,
        ]) {
          connection.on(event, (e) => this.emit(event, e));
        }
        if (this.loadBalanced) {
          connection.on(connection_1.Connection.PINNED, (pinType) =>
            this[kMetrics].markPinned(pinType),
          );
          connection.on(connection_1.Connection.UNPINNED, (pinType) =>
            this[kMetrics].markUnpinned(pinType),
          );
          const serviceId = connection.serviceId;
          if (serviceId) {
            let generation;
            const sid = serviceId.toHexString();
            if ((generation = this.serviceGenerations.get(sid))) {
              connection.generation = generation;
            } else {
              this.serviceGenerations.set(sid, 0);
              connection.generation = 0;
            }
          }
        }
        connection.markAvailable();
        this.emitAndLog(
          ConnectionPool.CONNECTION_READY,
          new connection_pool_events_1.ConnectionReadyEvent(this, connection),
        );
        this[kPending]--;
        callback(undefined, connection);
        return;
      });
    }
    ensureMinPoolSize() {
      const minPoolSize = this.options.minPoolSize;
      if (this[kPoolState] !== exports.PoolState.ready || minPoolSize === 0) {
        return;
      }
      this[kConnections].prune((connection) =>
        this.destroyConnectionIfPerished(connection),
      );
      if (
        this.totalConnectionCount < minPoolSize &&
        this.pendingConnectionCount < this.options.maxConnecting
      ) {
        // NOTE: ensureMinPoolSize should not try to get all the pending
        // connection permits because that potentially delays the availability of
        // the connection to a checkout request
        this.createConnection((err, connection) => {
          if (err) {
            this[kServer].handleError(err);
          }
          if (!err && connection) {
            this[kConnections].push(connection);
            process.nextTick(() => this.processWaitQueue());
          }
          if (this[kPoolState] === exports.PoolState.ready) {
            (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);
            this[kMinPoolSizeTimer] = (0, timers_1.setTimeout)(
              () => this.ensureMinPoolSize(),
              this.options.minPoolSizeCheckFrequencyMS,
            );
          }
        });
      } else {
        (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);
        this[kMinPoolSizeTimer] = (0, timers_1.setTimeout)(
          () => this.ensureMinPoolSize(),
          this.options.minPoolSizeCheckFrequencyMS,
        );
      }
    }
    processWaitQueue() {
      if (this[kProcessingWaitQueue]) {
        return;
      }
      this[kProcessingWaitQueue] = true;
      while (this.waitQueueSize) {
        const waitQueueMember = this[kWaitQueue].first();
        if (!waitQueueMember) {
          this[kWaitQueue].shift();
          continue;
        }
        if (waitQueueMember[kCancelled]) {
          this[kWaitQueue].shift();
          continue;
        }
        if (this[kPoolState] !== exports.PoolState.ready) {
          const reason = this.closed ? "poolClosed" : "connectionError";
          const error = this.closed
            ? new errors_1.PoolClosedError(this)
            : new errors_1.PoolClearedError(this);
          this.emitAndLog(
            ConnectionPool.CONNECTION_CHECK_OUT_FAILED,
            new connection_pool_events_1.ConnectionCheckOutFailedEvent(
              this,
              reason,
              error,
            ),
          );
          waitQueueMember.timeoutController.clear();
          this[kWaitQueue].shift();
          waitQueueMember.callback(error);
          continue;
        }
        if (!this.availableConnectionCount) {
          break;
        }
        const connection = this[kConnections].shift();
        if (!connection) {
          break;
        }
        if (!this.destroyConnectionIfPerished(connection)) {
          this[kCheckedOut].add(connection);
          this.emitAndLog(
            ConnectionPool.CONNECTION_CHECKED_OUT,
            new connection_pool_events_1.ConnectionCheckedOutEvent(
              this,
              connection,
            ),
          );
          waitQueueMember.timeoutController.clear();
          this[kWaitQueue].shift();
          waitQueueMember.callback(undefined, connection);
        }
      }
      const { maxPoolSize, maxConnecting } = this.options;
      while (
        this.waitQueueSize > 0 &&
        this.pendingConnectionCount < maxConnecting &&
        (maxPoolSize === 0 || this.totalConnectionCount < maxPoolSize)
      ) {
        const waitQueueMember = this[kWaitQueue].shift();
        if (!waitQueueMember || waitQueueMember[kCancelled]) {
          continue;
        }
        this.createConnection((err, connection) => {
          if (waitQueueMember[kCancelled]) {
            if (!err && connection) {
              this[kConnections].push(connection);
            }
          } else {
            if (err) {
              this.emitAndLog(
                ConnectionPool.CONNECTION_CHECK_OUT_FAILED,
                // TODO(NODE-5192): Remove this cast
                new connection_pool_events_1.ConnectionCheckOutFailedEvent(
                  this,
                  "connectionError",
                  err,
                ),
              );
            } else if (connection) {
              this[kCheckedOut].add(connection);
              this.emitAndLog(
                ConnectionPool.CONNECTION_CHECKED_OUT,
                new connection_pool_events_1.ConnectionCheckedOutEvent(
                  this,
                  connection,
                ),
              );
            }
            waitQueueMember.timeoutController.clear();
            waitQueueMember.callback(err, connection);
          }
          process.nextTick(() => this.processWaitQueue());
        });
      }
      this[kProcessingWaitQueue] = false;
    }
  }
  /**
   * Emitted when the connection pool is created.
   * @event
   */
  ConnectionPool.CONNECTION_POOL_CREATED = constants_1.CONNECTION_POOL_CREATED;
  /**
   * Emitted once when the connection pool is closed
   * @event
   */
  ConnectionPool.CONNECTION_POOL_CLOSED = constants_1.CONNECTION_POOL_CLOSED;
  /**
   * Emitted each time the connection pool is cleared and it's generation incremented
   * @event
   */
  ConnectionPool.CONNECTION_POOL_CLEARED = constants_1.CONNECTION_POOL_CLEARED;
  /**
   * Emitted each time the connection pool is marked ready
   * @event
   */
  ConnectionPool.CONNECTION_POOL_READY = constants_1.CONNECTION_POOL_READY;
  /**
   * Emitted when a connection is created.
   * @event
   */
  ConnectionPool.CONNECTION_CREATED = constants_1.CONNECTION_CREATED;
  /**
   * Emitted when a connection becomes established, and is ready to use
   * @event
   */
  ConnectionPool.CONNECTION_READY = constants_1.CONNECTION_READY;
  /**
   * Emitted when a connection is closed
   * @event
   */
  ConnectionPool.CONNECTION_CLOSED = constants_1.CONNECTION_CLOSED;
  /**
   * Emitted when an attempt to check out a connection begins
   * @event
   */
  ConnectionPool.CONNECTION_CHECK_OUT_STARTED =
    constants_1.CONNECTION_CHECK_OUT_STARTED;
  /**
   * Emitted when an attempt to check out a connection fails
   * @event
   */
  ConnectionPool.CONNECTION_CHECK_OUT_FAILED =
    constants_1.CONNECTION_CHECK_OUT_FAILED;
  /**
   * Emitted each time a connection is successfully checked out of the connection pool
   * @event
   */
  ConnectionPool.CONNECTION_CHECKED_OUT = constants_1.CONNECTION_CHECKED_OUT;
  /**
   * Emitted each time a connection is successfully checked into the connection pool
   * @event
   */
  ConnectionPool.CONNECTION_CHECKED_IN = constants_1.CONNECTION_CHECKED_IN;
  exports.ConnectionPool = ConnectionPool;
})(connection_pool);

var monitor = {};

var hasRequiredMonitor;

function requireMonitor() {
  if (hasRequiredMonitor) return monitor;
  hasRequiredMonitor = 1;
  Object.defineProperty(monitor, "__esModule", { value: true });
  monitor.MonitorInterval = monitor.RTTPinger = monitor.Monitor = void 0;
  const timers_1 = $nodeTimers;
  const bson_1 = bson$2;
  const connect_1 = connect;
  const connection_1 = connection;
  const constants_1 = constants;
  const error_1 = error;
  const mongo_types_1 = mongo_types;
  const utils_1 = utils$2;
  const common_1 = common$1;
  const events_1 = events;
  const server_1 = requireServer();
  /** @internal */
  const kServer = Symbol("server");
  /** @internal */
  const kMonitorId = Symbol("monitorId");
  /** @internal */
  const kConnection = Symbol("connection");
  /** @internal */
  const kCancellationToken = Symbol("cancellationToken");
  /** @internal */
  const kRTTPinger = Symbol("rttPinger");
  /** @internal */
  const kRoundTripTime = Symbol("roundTripTime");
  const STATE_IDLE = "idle";
  const STATE_MONITORING = "monitoring";
  const stateTransition = (0, utils_1.makeStateMachine)({
    [common_1.STATE_CLOSING]: [
      common_1.STATE_CLOSING,
      STATE_IDLE,
      common_1.STATE_CLOSED,
    ],
    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, STATE_MONITORING],
    [STATE_IDLE]: [STATE_IDLE, STATE_MONITORING, common_1.STATE_CLOSING],
    [STATE_MONITORING]: [STATE_MONITORING, STATE_IDLE, common_1.STATE_CLOSING],
  });
  const INVALID_REQUEST_CHECK_STATES = new Set([
    common_1.STATE_CLOSING,
    common_1.STATE_CLOSED,
    STATE_MONITORING,
  ]);
  function isInCloseState(monitor) {
    return (
      monitor.s.state === common_1.STATE_CLOSED ||
      monitor.s.state === common_1.STATE_CLOSING
    );
  }
  /** @internal */
  class Monitor extends mongo_types_1.TypedEventEmitter {
    get connection() {
      return this[kConnection];
    }
    constructor(server, options) {
      super();
      this[kServer] = server;
      this[kConnection] = undefined;
      this[kCancellationToken] = new mongo_types_1.CancellationToken();
      this[kCancellationToken].setMaxListeners(Infinity);
      this[kMonitorId] = undefined;
      this.s = {
        state: common_1.STATE_CLOSED,
      };
      this.address = server.description.address;
      this.options = Object.freeze({
        connectTimeoutMS: options.connectTimeoutMS ?? 10000,
        heartbeatFrequencyMS: options.heartbeatFrequencyMS ?? 10000,
        minHeartbeatFrequencyMS: options.minHeartbeatFrequencyMS ?? 500,
      });
      const cancellationToken = this[kCancellationToken];
      // TODO: refactor this to pull it directly from the pool, requires new ConnectionPool integration
      const connectOptions = Object.assign(
        {
          id: "<monitor>",
          generation: server.pool.generation,
          connectionType: connection_1.Connection,
          cancellationToken,
          hostAddress: server.description.hostAddress,
        },
        options,
        // force BSON serialization options
        {
          raw: false,
          useBigInt64: false,
          promoteLongs: true,
          promoteValues: true,
          promoteBuffers: true,
        },
      );
      // ensure no authentication is used for monitoring
      delete connectOptions.credentials;
      if (connectOptions.autoEncrypter) {
        delete connectOptions.autoEncrypter;
      }
      this.connectOptions = Object.freeze(connectOptions);
    }
    connect() {
      if (this.s.state !== common_1.STATE_CLOSED) {
        return;
      }
      // start
      const heartbeatFrequencyMS = this.options.heartbeatFrequencyMS;
      const minHeartbeatFrequencyMS = this.options.minHeartbeatFrequencyMS;
      this[kMonitorId] = new MonitorInterval(monitorServer(this), {
        heartbeatFrequencyMS: heartbeatFrequencyMS,
        minHeartbeatFrequencyMS: minHeartbeatFrequencyMS,
        immediate: true,
      });
    }
    requestCheck() {
      if (INVALID_REQUEST_CHECK_STATES.has(this.s.state)) {
        return;
      }
      this[kMonitorId]?.wake();
    }
    reset() {
      const topologyVersion = this[kServer].description.topologyVersion;
      if (isInCloseState(this) || topologyVersion == null) {
        return;
      }
      stateTransition(this, common_1.STATE_CLOSING);
      resetMonitorState(this);
      // restart monitor
      stateTransition(this, STATE_IDLE);
      // restart monitoring
      const heartbeatFrequencyMS = this.options.heartbeatFrequencyMS;
      const minHeartbeatFrequencyMS = this.options.minHeartbeatFrequencyMS;
      this[kMonitorId] = new MonitorInterval(monitorServer(this), {
        heartbeatFrequencyMS: heartbeatFrequencyMS,
        minHeartbeatFrequencyMS: minHeartbeatFrequencyMS,
      });
    }
    close() {
      if (isInCloseState(this)) {
        return;
      }
      stateTransition(this, common_1.STATE_CLOSING);
      resetMonitorState(this);
      // close monitor
      this.emit("close");
      stateTransition(this, common_1.STATE_CLOSED);
    }
  }
  monitor.Monitor = Monitor;
  function resetMonitorState(monitor) {
    monitor[kMonitorId]?.stop();
    monitor[kMonitorId] = undefined;
    monitor[kRTTPinger]?.close();
    monitor[kRTTPinger] = undefined;
    monitor[kCancellationToken].emit("cancel");
    monitor[kConnection]?.destroy({ force: true });
    monitor[kConnection] = undefined;
  }
  function checkServer(monitor, callback) {
    let start = (0, utils_1.now)();
    const topologyVersion = monitor[kServer].description.topologyVersion;
    const isAwaitable = topologyVersion != null;
    monitor.emit(
      server_1.Server.SERVER_HEARTBEAT_STARTED,
      new events_1.ServerHeartbeatStartedEvent(monitor.address, isAwaitable),
    );
    function failureHandler(err) {
      monitor[kConnection]?.destroy({ force: true });
      monitor[kConnection] = undefined;
      monitor.emit(
        server_1.Server.SERVER_HEARTBEAT_FAILED,
        new events_1.ServerHeartbeatFailedEvent(
          monitor.address,
          (0, utils_1.calculateDurationInMs)(start),
          err,
          isAwaitable,
        ),
      );
      const error = !(err instanceof error_1.MongoError)
        ? new error_1.MongoError(error_1.MongoError.buildErrorMessage(err), {
            cause: err,
          })
        : err;
      error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);
      if (error instanceof error_1.MongoNetworkTimeoutError) {
        error.addErrorLabel(error_1.MongoErrorLabel.InterruptInUseConnections);
      }
      monitor.emit("resetServer", error);
      callback(err);
    }
    const connection = monitor[kConnection];
    if (connection && !connection.closed) {
      const { serverApi, helloOk } = connection;
      const connectTimeoutMS = monitor.options.connectTimeoutMS;
      const maxAwaitTimeMS = monitor.options.heartbeatFrequencyMS;
      const cmd = {
        [serverApi?.version || helloOk
          ? "hello"
          : constants_1.LEGACY_HELLO_COMMAND]: 1,
        ...(isAwaitable && topologyVersion
          ? {
              maxAwaitTimeMS,
              topologyVersion: makeTopologyVersion(topologyVersion),
            }
          : {}),
      };
      const options = isAwaitable
        ? {
            socketTimeoutMS: connectTimeoutMS
              ? connectTimeoutMS + maxAwaitTimeMS
              : 0,
            exhaustAllowed: true,
          }
        : { socketTimeoutMS: connectTimeoutMS };
      if (isAwaitable && monitor[kRTTPinger] == null) {
        monitor[kRTTPinger] = new RTTPinger(
          monitor[kCancellationToken],
          Object.assign(
            { heartbeatFrequencyMS: monitor.options.heartbeatFrequencyMS },
            monitor.connectOptions,
          ),
        );
      }
      connection.command(
        (0, utils_1.ns)("admin.$cmd"),
        cmd,
        options,
        (err, hello) => {
          if (err) {
            return failureHandler(err);
          }
          if (!("isWritablePrimary" in hello)) {
            // Provide hello-style response document.
            hello.isWritablePrimary = hello[constants_1.LEGACY_HELLO_COMMAND];
          }
          const rttPinger = monitor[kRTTPinger];
          const duration =
            isAwaitable && rttPinger
              ? rttPinger.roundTripTime
              : (0, utils_1.calculateDurationInMs)(start);
          const awaited = isAwaitable && hello.topologyVersion != null;
          monitor.emit(
            server_1.Server.SERVER_HEARTBEAT_SUCCEEDED,
            new events_1.ServerHeartbeatSucceededEvent(
              monitor.address,
              duration,
              hello,
              awaited,
            ),
          );
          // if we are using the streaming protocol then we immediately issue another `started`
          // event, otherwise the "check" is complete and return to the main monitor loop
          if (awaited) {
            monitor.emit(
              server_1.Server.SERVER_HEARTBEAT_STARTED,
              new events_1.ServerHeartbeatStartedEvent(monitor.address, true),
            );
            start = (0, utils_1.now)();
          } else {
            monitor[kRTTPinger]?.close();
            monitor[kRTTPinger] = undefined;
            callback(undefined, hello);
          }
        },
      );
      return;
    }
    // connecting does an implicit `hello`
    (0, connect_1.connect)(monitor.connectOptions, (err, conn) => {
      if (err) {
        monitor[kConnection] = undefined;
        failureHandler(err);
        return;
      }
      if (conn) {
        // Tell the connection that we are using the streaming protocol so that the
        // connection's message stream will only read the last hello on the buffer.
        conn.isMonitoringConnection = true;
        if (isInCloseState(monitor)) {
          conn.destroy({ force: true });
          return;
        }
        monitor[kConnection] = conn;
        monitor.emit(
          server_1.Server.SERVER_HEARTBEAT_SUCCEEDED,
          new events_1.ServerHeartbeatSucceededEvent(
            monitor.address,
            (0, utils_1.calculateDurationInMs)(start),
            conn.hello,
            false,
          ),
        );
        callback(undefined, conn.hello);
      }
    });
  }
  function monitorServer(monitor) {
    return (callback) => {
      if (monitor.s.state === STATE_MONITORING) {
        process.nextTick(callback);
        return;
      }
      stateTransition(monitor, STATE_MONITORING);
      function done() {
        if (!isInCloseState(monitor)) {
          stateTransition(monitor, STATE_IDLE);
        }
        callback();
      }
      checkServer(monitor, (err, hello) => {
        if (err) {
          // otherwise an error occurred on initial discovery, also bail
          if (
            monitor[kServer].description.type === common_1.ServerType.Unknown
          ) {
            return done();
          }
        }
        // if the check indicates streaming is supported, immediately reschedule monitoring
        if (hello && hello.topologyVersion) {
          (0, timers_1.setTimeout)(() => {
            if (!isInCloseState(monitor)) {
              monitor[kMonitorId]?.wake();
            }
          }, 0);
        }
        done();
      });
    };
  }
  function makeTopologyVersion(tv) {
    return {
      processId: tv.processId,
      // tests mock counter as just number, but in a real situation counter should always be a Long
      // TODO(NODE-2674): Preserve int64 sent from MongoDB
      counter: bson_1.Long.isLong(tv.counter)
        ? tv.counter
        : bson_1.Long.fromNumber(tv.counter),
    };
  }
  /** @internal */
  class RTTPinger {
    constructor(cancellationToken, options) {
      this[kConnection] = undefined;
      this[kCancellationToken] = cancellationToken;
      this[kRoundTripTime] = 0;
      this.closed = false;
      const heartbeatFrequencyMS = options.heartbeatFrequencyMS;
      this[kMonitorId] = (0, timers_1.setTimeout)(
        () => measureRoundTripTime(this, options),
        heartbeatFrequencyMS,
      );
    }
    get roundTripTime() {
      return this[kRoundTripTime];
    }
    close() {
      this.closed = true;
      (0, timers_1.clearTimeout)(this[kMonitorId]);
      this[kConnection]?.destroy({ force: true });
      this[kConnection] = undefined;
    }
  }
  monitor.RTTPinger = RTTPinger;
  function measureRoundTripTime(rttPinger, options) {
    const start = (0, utils_1.now)();
    options.cancellationToken = rttPinger[kCancellationToken];
    const heartbeatFrequencyMS = options.heartbeatFrequencyMS;
    if (rttPinger.closed) {
      return;
    }
    function measureAndReschedule(conn) {
      if (rttPinger.closed) {
        conn?.destroy({ force: true });
        return;
      }
      if (rttPinger[kConnection] == null) {
        rttPinger[kConnection] = conn;
      }
      rttPinger[kRoundTripTime] = (0, utils_1.calculateDurationInMs)(start);
      rttPinger[kMonitorId] = (0, timers_1.setTimeout)(
        () => measureRoundTripTime(rttPinger, options),
        heartbeatFrequencyMS,
      );
    }
    const connection = rttPinger[kConnection];
    if (connection == null) {
      (0, connect_1.connect)(options, (err, conn) => {
        if (err) {
          rttPinger[kConnection] = undefined;
          rttPinger[kRoundTripTime] = 0;
          return;
        }
        measureAndReschedule(conn);
      });
      return;
    }
    connection.command(
      (0, utils_1.ns)("admin.$cmd"),
      { [constants_1.LEGACY_HELLO_COMMAND]: 1 },
      undefined,
      (err) => {
        if (err) {
          rttPinger[kConnection] = undefined;
          rttPinger[kRoundTripTime] = 0;
          return;
        }
        measureAndReschedule();
      },
    );
  }
  /**
   * @internal
   */
  class MonitorInterval {
    constructor(fn, options = {}) {
      this.isExpeditedCallToFnScheduled = false;
      this.stopped = false;
      this.isExecutionInProgress = false;
      this.hasExecutedOnce = false;
      this._executeAndReschedule = () => {
        if (this.stopped) return;
        if (this.timerId) {
          (0, timers_1.clearTimeout)(this.timerId);
        }
        this.isExpeditedCallToFnScheduled = false;
        this.isExecutionInProgress = true;
        this.fn(() => {
          this.lastExecutionEnded = (0, utils_1.now)();
          this.isExecutionInProgress = false;
          this._reschedule(this.heartbeatFrequencyMS);
        });
      };
      this.fn = fn;
      this.lastExecutionEnded = -Infinity;
      this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 1000;
      this.minHeartbeatFrequencyMS = options.minHeartbeatFrequencyMS ?? 500;
      if (options.immediate) {
        this._executeAndReschedule();
      } else {
        this._reschedule(undefined);
      }
    }
    wake() {
      const currentTime = (0, utils_1.now)();
      const timeSinceLastCall = currentTime - this.lastExecutionEnded;
      // TODO(NODE-4674): Add error handling and logging to the monitor
      if (timeSinceLastCall < 0) {
        return this._executeAndReschedule();
      }
      if (this.isExecutionInProgress) {
        return;
      }
      // debounce multiple calls to wake within the `minInterval`
      if (this.isExpeditedCallToFnScheduled) {
        return;
      }
      // reschedule a call as soon as possible, ensuring the call never happens
      // faster than the `minInterval`
      if (timeSinceLastCall < this.minHeartbeatFrequencyMS) {
        this.isExpeditedCallToFnScheduled = true;
        this._reschedule(this.minHeartbeatFrequencyMS - timeSinceLastCall);
        return;
      }
      this._executeAndReschedule();
    }
    stop() {
      this.stopped = true;
      if (this.timerId) {
        (0, timers_1.clearTimeout)(this.timerId);
        this.timerId = undefined;
      }
      this.lastExecutionEnded = -Infinity;
      this.isExpeditedCallToFnScheduled = false;
    }
    toString() {
      return JSON.stringify(this);
    }
    toJSON() {
      const currentTime = (0, utils_1.now)();
      const timeSinceLastCall = currentTime - this.lastExecutionEnded;
      return {
        timerId: this.timerId != null ? "set" : "cleared",
        lastCallTime: this.lastExecutionEnded,
        isExpeditedCheckScheduled: this.isExpeditedCallToFnScheduled,
        stopped: this.stopped,
        heartbeatFrequencyMS: this.heartbeatFrequencyMS,
        minHeartbeatFrequencyMS: this.minHeartbeatFrequencyMS,
        currentTime,
        timeSinceLastCall,
      };
    }
    _reschedule(ms) {
      if (this.stopped) return;
      if (this.timerId) {
        (0, timers_1.clearTimeout)(this.timerId);
      }
      this.timerId = (0, timers_1.setTimeout)(
        this._executeAndReschedule,
        ms || this.heartbeatFrequencyMS,
      );
    }
  }
  monitor.MonitorInterval = MonitorInterval;

  return monitor;
}

var hasRequiredServer;

function requireServer() {
  if (hasRequiredServer) return server;
  hasRequiredServer = 1;
  Object.defineProperty(server, "__esModule", { value: true });
  server.Server = void 0;
  const util_1 = $noteUtil;
  const connection_1 = connection;
  const connection_pool_1 = connection_pool;
  const errors_1 = errors;
  const constants_1 = constants;
  const error_1 = error;
  const mongo_types_1 = mongo_types;
  const transactions_1 = transactions;
  const utils_1 = utils$2;
  const common_1 = common$1;
  const monitor_1 = requireMonitor();
  const server_description_1 = server_description;
  const stateTransition = (0, utils_1.makeStateMachine)({
    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, common_1.STATE_CONNECTING],
    [common_1.STATE_CONNECTING]: [
      common_1.STATE_CONNECTING,
      common_1.STATE_CLOSING,
      common_1.STATE_CONNECTED,
      common_1.STATE_CLOSED,
    ],
    [common_1.STATE_CONNECTED]: [
      common_1.STATE_CONNECTED,
      common_1.STATE_CLOSING,
      common_1.STATE_CLOSED,
    ],
    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, common_1.STATE_CLOSED],
  });
  /** @internal */
  const kMonitor = Symbol("monitor");
  /** @internal */
  class Server extends mongo_types_1.TypedEventEmitter {
    /**
     * Create a server
     */
    constructor(topology, description, options) {
      super();
      this.commandAsync = (0, util_1.promisify)(
        (
          ns,
          cmd,
          options,
          // callback type defines Document result because result is never nullish when it succeeds, otherwise promise rejects
          callback,
        ) => this.command(ns, cmd, options, callback),
      );
      this.serverApi = options.serverApi;
      const poolOptions = { hostAddress: description.hostAddress, ...options };
      this.topology = topology;
      this.pool = new connection_pool_1.ConnectionPool(this, poolOptions);
      this.s = {
        description,
        options,
        state: common_1.STATE_CLOSED,
        operationCount: 0,
      };
      for (const event of [
        ...constants_1.CMAP_EVENTS,
        ...constants_1.APM_EVENTS,
      ]) {
        this.pool.on(event, (e) => this.emit(event, e));
      }
      this.pool.on(
        connection_1.Connection.CLUSTER_TIME_RECEIVED,
        (clusterTime) => {
          this.clusterTime = clusterTime;
        },
      );
      if (this.loadBalanced) {
        this[kMonitor] = null;
        // monitoring is disabled in load balancing mode
        return;
      }
      // create the monitor
      // TODO(NODE-4144): Remove new variable for type narrowing
      const monitor = new monitor_1.Monitor(this, this.s.options);
      this[kMonitor] = monitor;
      for (const event of constants_1.HEARTBEAT_EVENTS) {
        monitor.on(event, (e) => this.emit(event, e));
      }
      monitor.on("resetServer", (error) => markServerUnknown(this, error));
      monitor.on(Server.SERVER_HEARTBEAT_SUCCEEDED, (event) => {
        this.emit(
          Server.DESCRIPTION_RECEIVED,
          new server_description_1.ServerDescription(
            this.description.hostAddress,
            event.reply,
            {
              roundTripTime: calculateRoundTripTime(
                this.description.roundTripTime,
                event.duration,
              ),
            },
          ),
        );
        if (this.s.state === common_1.STATE_CONNECTING) {
          stateTransition(this, common_1.STATE_CONNECTED);
          this.emit(Server.CONNECT, this);
        }
      });
    }
    get clusterTime() {
      return this.topology.clusterTime;
    }
    set clusterTime(clusterTime) {
      this.topology.clusterTime = clusterTime;
    }
    get description() {
      return this.s.description;
    }
    get name() {
      return this.s.description.address;
    }
    get autoEncrypter() {
      if (this.s.options && this.s.options.autoEncrypter) {
        return this.s.options.autoEncrypter;
      }
      return;
    }
    get loadBalanced() {
      return (
        this.topology.description.type === common_1.TopologyType.LoadBalanced
      );
    }
    /**
     * Initiate server connect
     */
    connect() {
      if (this.s.state !== common_1.STATE_CLOSED) {
        return;
      }
      stateTransition(this, common_1.STATE_CONNECTING);
      // If in load balancer mode we automatically set the server to
      // a load balancer. It never transitions out of this state and
      // has no monitor.
      if (!this.loadBalanced) {
        this[kMonitor]?.connect();
      } else {
        stateTransition(this, common_1.STATE_CONNECTED);
        this.emit(Server.CONNECT, this);
      }
    }
    /** Destroy the server connection */
    destroy(options, callback) {
      if (typeof options === "function") {
        callback = options;
        options = { force: false };
      }
      options = Object.assign({}, { force: false }, options);
      if (this.s.state === common_1.STATE_CLOSED) {
        if (typeof callback === "function") {
          callback();
        }
        return;
      }
      stateTransition(this, common_1.STATE_CLOSING);
      if (!this.loadBalanced) {
        this[kMonitor]?.close();
      }
      this.pool.close(options, (err) => {
        stateTransition(this, common_1.STATE_CLOSED);
        this.emit("closed");
        if (typeof callback === "function") {
          callback(err);
        }
      });
    }
    /**
     * Immediately schedule monitoring of this server. If there already an attempt being made
     * this will be a no-op.
     */
    requestCheck() {
      if (!this.loadBalanced) {
        this[kMonitor]?.requestCheck();
      }
    }
    /**
     * Execute a command
     * @internal
     */
    command(ns, cmd, options, callback) {
      if (callback == null) {
        throw new error_1.MongoInvalidArgumentError(
          "Callback must be provided",
        );
      }
      if (ns.db == null || typeof ns === "string") {
        throw new error_1.MongoInvalidArgumentError(
          "Namespace must not be a string",
        );
      }
      if (
        this.s.state === common_1.STATE_CLOSING ||
        this.s.state === common_1.STATE_CLOSED
      ) {
        callback(new error_1.MongoServerClosedError());
        return;
      }
      // Clone the options
      const finalOptions = Object.assign({}, options, {
        wireProtocolCommand: false,
      });
      // There are cases where we need to flag the read preference not to get sent in
      // the command, such as pre-5.0 servers attempting to perform an aggregate write
      // with a non-primary read preference. In this case the effective read preference
      // (primary) is not the same as the provided and must be removed completely.
      if (finalOptions.omitReadPreference) {
        delete finalOptions.readPreference;
      }
      const session = finalOptions.session;
      const conn = session?.pinnedConnection;
      // NOTE: This is a hack! We can't retrieve the connections used for executing an operation
      //       (and prevent them from being checked back in) at the point of operation execution.
      //       This should be considered as part of the work for NODE-2882
      // NOTE:
      //       When incrementing operation count, it's important that we increment it before we
      //       attempt to check out a connection from the pool.  This ensures that operations that
      //       are waiting for a connection are included in the operation count.  Load balanced
      //       mode will only ever have a single server, so the operation count doesn't matter.
      //       Incrementing the operation count above the logic to handle load balanced mode would
      //       require special logic to decrement it again, or would double increment (the load
      //       balanced code makes a recursive call).  Instead, we increment the count after this
      //       check.
      if (
        this.loadBalanced &&
        session &&
        conn == null &&
        isPinnableCommand(cmd, session)
      ) {
        this.pool.checkOut((err, checkedOut) => {
          if (err || checkedOut == null) {
            if (callback) return callback(err);
            return;
          }
          session.pin(checkedOut);
          this.command(ns, cmd, finalOptions, callback);
        });
        return;
      }
      this.incrementOperationCount();
      this.pool.withConnection(
        conn,
        (err, conn, cb) => {
          if (err || !conn) {
            this.decrementOperationCount();
            if (!err) {
              return cb(
                new error_1.MongoRuntimeError(
                  "Failed to create connection without error",
                ),
              );
            }
            if (!(err instanceof errors_1.PoolClearedError)) {
              this.handleError(err);
            }
            return cb(err);
          }
          conn.command(
            ns,
            cmd,
            finalOptions,
            makeOperationHandler(
              this,
              conn,
              cmd,
              finalOptions,
              (error, response) => {
                this.decrementOperationCount();
                cb(error, response);
              },
            ),
          );
        },
        callback,
      );
    }
    /**
     * Handle SDAM error
     * @internal
     */
    handleError(error, connection) {
      if (!(error instanceof error_1.MongoError)) {
        return;
      }
      const isStaleError =
        error.connectionGeneration &&
        error.connectionGeneration < this.pool.generation;
      if (isStaleError) {
        return;
      }
      const isNetworkNonTimeoutError =
        error instanceof error_1.MongoNetworkError &&
        !(error instanceof error_1.MongoNetworkTimeoutError);
      const isNetworkTimeoutBeforeHandshakeError = (0,
      error_1.isNetworkErrorBeforeHandshake)(error);
      const isAuthHandshakeError = error.hasErrorLabel(
        error_1.MongoErrorLabel.HandshakeError,
      );
      if (
        isNetworkNonTimeoutError ||
        isNetworkTimeoutBeforeHandshakeError ||
        isAuthHandshakeError
      ) {
        // In load balanced mode we never mark the server as unknown and always
        // clear for the specific service id.
        if (!this.loadBalanced) {
          error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);
          markServerUnknown(this, error);
        } else if (connection) {
          this.pool.clear({ serviceId: connection.serviceId });
        }
      } else {
        if ((0, error_1.isSDAMUnrecoverableError)(error)) {
          if (shouldHandleStateChangeError(this, error)) {
            const shouldClearPool =
              (0, utils_1.maxWireVersion)(this) <= 7 ||
              (0, error_1.isNodeShuttingDownError)(error);
            if (this.loadBalanced && connection && shouldClearPool) {
              this.pool.clear({ serviceId: connection.serviceId });
            }
            if (!this.loadBalanced) {
              if (shouldClearPool) {
                error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);
              }
              markServerUnknown(this, error);
              process.nextTick(() => this.requestCheck());
            }
          }
        }
      }
    }
    /**
     * Decrement the operation count, returning the new count.
     */
    decrementOperationCount() {
      return (this.s.operationCount -= 1);
    }
    /**
     * Increment the operation count, returning the new count.
     */
    incrementOperationCount() {
      return (this.s.operationCount += 1);
    }
  }
  /** @event */
  Server.SERVER_HEARTBEAT_STARTED = constants_1.SERVER_HEARTBEAT_STARTED;
  /** @event */
  Server.SERVER_HEARTBEAT_SUCCEEDED = constants_1.SERVER_HEARTBEAT_SUCCEEDED;
  /** @event */
  Server.SERVER_HEARTBEAT_FAILED = constants_1.SERVER_HEARTBEAT_FAILED;
  /** @event */
  Server.CONNECT = constants_1.CONNECT;
  /** @event */
  Server.DESCRIPTION_RECEIVED = constants_1.DESCRIPTION_RECEIVED;
  /** @event */
  Server.CLOSED = constants_1.CLOSED;
  /** @event */
  Server.ENDED = constants_1.ENDED;
  server.Server = Server;
  function calculateRoundTripTime(oldRtt, duration) {
    if (oldRtt === -1) {
      return duration;
    }
    const alpha = 0.2;
    return alpha * duration + (1 - alpha) * oldRtt;
  }
  function markServerUnknown(server, error) {
    // Load balancer servers can never be marked unknown.
    if (server.loadBalanced) {
      return;
    }
    if (
      error instanceof error_1.MongoNetworkError &&
      !(error instanceof error_1.MongoNetworkTimeoutError)
    ) {
      server[kMonitor]?.reset();
    }
    server.emit(
      Server.DESCRIPTION_RECEIVED,
      new server_description_1.ServerDescription(
        server.description.hostAddress,
        undefined,
        { error },
      ),
    );
  }
  function isPinnableCommand(cmd, session) {
    if (session) {
      return (
        session.inTransaction() ||
        "aggregate" in cmd ||
        "find" in cmd ||
        "getMore" in cmd ||
        "listCollections" in cmd ||
        "listIndexes" in cmd
      );
    }
    return false;
  }
  function connectionIsStale(pool, connection) {
    if (connection.serviceId) {
      return (
        connection.generation !==
        pool.serviceGenerations.get(connection.serviceId.toHexString())
      );
    }
    return connection.generation !== pool.generation;
  }
  function shouldHandleStateChangeError(server, err) {
    const etv = err.topologyVersion;
    const stv = server.description.topologyVersion;
    return (0, server_description_1.compareTopologyVersion)(stv, etv) < 0;
  }
  function inActiveTransaction(session, cmd) {
    return (
      session &&
      session.inTransaction() &&
      !(0, transactions_1.isTransactionCommand)(cmd)
    );
  }
  /** this checks the retryWrites option passed down from the client options, it
   * does not check if the server supports retryable writes */
  function isRetryableWritesEnabled(topology) {
    return topology.s.options.retryWrites !== false;
  }
  function makeOperationHandler(server, connection, cmd, options, callback) {
    const session = options?.session;
    return function handleOperationResult(error, result) {
      // We should not swallow an error if it is present.
      if (error == null && result != null) {
        return callback(undefined, result);
      }
      if (
        options != null &&
        "noResponse" in options &&
        options.noResponse === true
      ) {
        return callback(undefined, null);
      }
      if (!error) {
        return callback(
          new error_1.MongoUnexpectedServerResponseError(
            "Empty response with no error",
          ),
        );
      }
      if (!(error instanceof error_1.MongoError)) {
        // Node.js or some other error we have not special handling for
        return callback(error);
      }
      if (connectionIsStale(server.pool, connection)) {
        return callback(error);
      }
      if (error instanceof error_1.MongoNetworkError) {
        if (session && !session.hasEnded && session.serverSession) {
          session.serverSession.isDirty = true;
        }
        // inActiveTransaction check handles commit and abort.
        if (
          inActiveTransaction(session, cmd) &&
          !error.hasErrorLabel(
            error_1.MongoErrorLabel.TransientTransactionError,
          )
        ) {
          error.addErrorLabel(
            error_1.MongoErrorLabel.TransientTransactionError,
          );
        }
        if (
          (isRetryableWritesEnabled(server.topology) ||
            (0, transactions_1.isTransactionCommand)(cmd)) &&
          (0, utils_1.supportsRetryableWrites)(server) &&
          !inActiveTransaction(session, cmd)
        ) {
          error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);
        }
      } else {
        if (
          (isRetryableWritesEnabled(server.topology) ||
            (0, transactions_1.isTransactionCommand)(cmd)) &&
          (0, error_1.needsRetryableWriteLabel)(
            error,
            (0, utils_1.maxWireVersion)(server),
          ) &&
          !inActiveTransaction(session, cmd)
        ) {
          error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);
        }
      }
      if (
        session &&
        session.isPinned &&
        error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)
      ) {
        session.unpin({ force: true });
      }
      server.handleError(error, connection);
      return callback(error);
    };
  }

  return server;
}

var srv_polling = {};

Object.defineProperty(srv_polling, "__esModule", { value: true });
srv_polling.SrvPoller = srv_polling.SrvPollingEvent = void 0;
const dns = $nodeDns;
const timers_1 = $nodeTimers;
const error_1$3 = error;
const mongo_types_1$1 = mongo_types;
const utils_1$1 = utils$2;
/**
 * @internal
 * @category Event
 */
let SrvPollingEvent$1 = class SrvPollingEvent {
  constructor(srvRecords) {
    this.srvRecords = srvRecords;
  }
  hostnames() {
    return new Set(
      this.srvRecords.map((r) =>
        utils_1$1.HostAddress.fromSrvRecord(r).toString(),
      ),
    );
  }
};
srv_polling.SrvPollingEvent = SrvPollingEvent$1;
/** @internal */
class SrvPoller extends mongo_types_1$1.TypedEventEmitter {
  constructor(options) {
    super();
    if (!options || !options.srvHost) {
      throw new error_1$3.MongoRuntimeError(
        "Options for SrvPoller must exist and include srvHost",
      );
    }
    this.srvHost = options.srvHost;
    this.srvMaxHosts = options.srvMaxHosts ?? 0;
    this.srvServiceName = options.srvServiceName ?? "mongodb";
    this.rescanSrvIntervalMS = 60000;
    this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 10000;
    this.haMode = false;
    this.generation = 0;
    this._timeout = undefined;
  }
  get srvAddress() {
    return `_${this.srvServiceName}._tcp.${this.srvHost}`;
  }
  get intervalMS() {
    return this.haMode ? this.heartbeatFrequencyMS : this.rescanSrvIntervalMS;
  }
  start() {
    if (!this._timeout) {
      this.schedule();
    }
  }
  stop() {
    if (this._timeout) {
      (0, timers_1.clearTimeout)(this._timeout);
      this.generation += 1;
      this._timeout = undefined;
    }
  }
  // TODO(NODE-4994): implement new logging logic for SrvPoller failures
  schedule() {
    if (this._timeout) {
      (0, timers_1.clearTimeout)(this._timeout);
    }
    this._timeout = (0, timers_1.setTimeout)(() => {
      this._poll().catch(() => null);
    }, this.intervalMS);
  }
  success(srvRecords) {
    this.haMode = false;
    this.schedule();
    this.emit(
      SrvPoller.SRV_RECORD_DISCOVERY,
      new SrvPollingEvent$1(srvRecords),
    );
  }
  failure() {
    this.haMode = true;
    this.schedule();
  }
  async _poll() {
    const generation = this.generation;
    let srvRecords;
    try {
      srvRecords = await dns.promises.resolveSrv(this.srvAddress);
    } catch (dnsError) {
      this.failure();
      return;
    }
    if (generation !== this.generation) {
      return;
    }
    const finalAddresses = [];
    for (const record of srvRecords) {
      if ((0, utils_1$1.matchesParentDomain)(record.name, this.srvHost)) {
        finalAddresses.push(record);
      }
    }
    if (!finalAddresses.length) {
      this.failure();
      return;
    }
    this.success(finalAddresses);
  }
}
/** @event */
SrvPoller.SRV_RECORD_DISCOVERY = "srvRecordDiscovery";
srv_polling.SrvPoller = SrvPoller;

var hasRequiredTopology;

function requireTopology() {
  if (hasRequiredTopology) return topology;
  hasRequiredTopology = 1;
  Object.defineProperty(topology, "__esModule", { value: true });
  topology.ServerCapabilities = topology.Topology = void 0;
  const util_1 = $noteUtil;
  const connection_string_1 = requireConnection_string();
  const constants_1 = constants;
  const error_1 = error;
  const mongo_types_1 = mongo_types;
  const read_preference_1 = read_preference;
  const utils_1 = utils$2;
  const common_1 = common$1;
  const events_1 = events;
  const server_1 = requireServer();
  const server_description_1 = server_description;
  const server_selection_1 = server_selection;
  const srv_polling_1 = srv_polling;
  const topology_description_1 = topology_description;
  // Global state
  let globalTopologyCounter = 0;
  const stateTransition = (0, utils_1.makeStateMachine)({
    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, common_1.STATE_CONNECTING],
    [common_1.STATE_CONNECTING]: [
      common_1.STATE_CONNECTING,
      common_1.STATE_CLOSING,
      common_1.STATE_CONNECTED,
      common_1.STATE_CLOSED,
    ],
    [common_1.STATE_CONNECTED]: [
      common_1.STATE_CONNECTED,
      common_1.STATE_CLOSING,
      common_1.STATE_CLOSED,
    ],
    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, common_1.STATE_CLOSED],
  });
  /** @internal */
  const kCancelled = Symbol("cancelled");
  /** @internal */
  const kWaitQueue = Symbol("waitQueue");
  /**
   * A container of server instances representing a connection to a MongoDB topology.
   * @internal
   */
  class Topology extends mongo_types_1.TypedEventEmitter {
    /**
     * @param seedlist - a list of HostAddress instances to connect to
     */
    constructor(client, seeds, options) {
      super();
      this.client = client;
      this.selectServerAsync = (0, util_1.promisify)(
        (selector, options, callback) =>
          this.selectServer(selector, options, callback),
      );
      // Options should only be undefined in tests, MongoClient will always have defined options
      options = options ?? {
        hosts: [utils_1.HostAddress.fromString("localhost:27017")],
        ...Object.fromEntries(connection_string_1.DEFAULT_OPTIONS.entries()),
        ...Object.fromEntries(connection_string_1.FEATURE_FLAGS.entries()),
      };
      if (typeof seeds === "string") {
        seeds = [utils_1.HostAddress.fromString(seeds)];
      } else if (!Array.isArray(seeds)) {
        seeds = [seeds];
      }
      const seedlist = [];
      for (const seed of seeds) {
        if (typeof seed === "string") {
          seedlist.push(utils_1.HostAddress.fromString(seed));
        } else if (seed instanceof utils_1.HostAddress) {
          seedlist.push(seed);
        } else {
          // FIXME(NODE-3483): May need to be a MongoParseError
          throw new error_1.MongoRuntimeError(
            `Topology cannot be constructed from ${JSON.stringify(seed)}`,
          );
        }
      }
      const topologyType = topologyTypeFromOptions(options);
      const topologyId = globalTopologyCounter++;
      const selectedHosts =
        options.srvMaxHosts == null ||
        options.srvMaxHosts === 0 ||
        options.srvMaxHosts >= seedlist.length
          ? seedlist
          : (0, utils_1.shuffle)(seedlist, options.srvMaxHosts);
      const serverDescriptions = new Map();
      for (const hostAddress of selectedHosts) {
        serverDescriptions.set(
          hostAddress.toString(),
          new server_description_1.ServerDescription(hostAddress),
        );
      }
      this[kWaitQueue] = new utils_1.List();
      this.s = {
        // the id of this topology
        id: topologyId,
        // passed in options
        options,
        // initial seedlist of servers to connect to
        seedlist,
        // initial state
        state: common_1.STATE_CLOSED,
        // the topology description
        description: new topology_description_1.TopologyDescription(
          topologyType,
          serverDescriptions,
          options.replicaSet,
          undefined,
          undefined,
          undefined,
          options,
        ),
        serverSelectionTimeoutMS: options.serverSelectionTimeoutMS,
        heartbeatFrequencyMS: options.heartbeatFrequencyMS,
        minHeartbeatFrequencyMS: options.minHeartbeatFrequencyMS,
        // a map of server instances to normalized addresses
        servers: new Map(),
        credentials: options?.credentials,
        clusterTime: undefined,
        // timer management
        connectionTimers: new Set(),
        detectShardedTopology: (ev) => this.detectShardedTopology(ev),
        detectSrvRecords: (ev) => this.detectSrvRecords(ev),
      };
      if (options.srvHost && !options.loadBalanced) {
        this.s.srvPoller =
          options.srvPoller ??
          new srv_polling_1.SrvPoller({
            heartbeatFrequencyMS: this.s.heartbeatFrequencyMS,
            srvHost: options.srvHost,
            srvMaxHosts: options.srvMaxHosts,
            srvServiceName: options.srvServiceName,
          });
        this.on(
          Topology.TOPOLOGY_DESCRIPTION_CHANGED,
          this.s.detectShardedTopology,
        );
      }
    }
    detectShardedTopology(event) {
      const previousType = event.previousDescription.type;
      const newType = event.newDescription.type;
      const transitionToSharded =
        previousType !== common_1.TopologyType.Sharded &&
        newType === common_1.TopologyType.Sharded;
      const srvListeners = this.s.srvPoller?.listeners(
        srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY,
      );
      const listeningToSrvPolling = !!srvListeners?.includes(
        this.s.detectSrvRecords,
      );
      if (transitionToSharded && !listeningToSrvPolling) {
        this.s.srvPoller?.on(
          srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY,
          this.s.detectSrvRecords,
        );
        this.s.srvPoller?.start();
      }
    }
    detectSrvRecords(ev) {
      const previousTopologyDescription = this.s.description;
      this.s.description = this.s.description.updateFromSrvPollingEvent(
        ev,
        this.s.options.srvMaxHosts,
      );
      if (this.s.description === previousTopologyDescription) {
        // Nothing changed, so return
        return;
      }
      updateServers(this);
      this.emit(
        Topology.TOPOLOGY_DESCRIPTION_CHANGED,
        new events_1.TopologyDescriptionChangedEvent(
          this.s.id,
          previousTopologyDescription,
          this.s.description,
        ),
      );
    }
    /**
     * @returns A `TopologyDescription` for this topology
     */
    get description() {
      return this.s.description;
    }
    get loadBalanced() {
      return this.s.options.loadBalanced;
    }
    get capabilities() {
      return new ServerCapabilities(this.lastHello());
    }
    connect(options, callback) {
      if (typeof options === "function") (callback = options), (options = {});
      options = options ?? {};
      if (this.s.state === common_1.STATE_CONNECTED) {
        if (typeof callback === "function") {
          callback();
        }
        return;
      }
      stateTransition(this, common_1.STATE_CONNECTING);
      // emit SDAM monitoring events
      this.emit(
        Topology.TOPOLOGY_OPENING,
        new events_1.TopologyOpeningEvent(this.s.id),
      );
      // emit an event for the topology change
      this.emit(
        Topology.TOPOLOGY_DESCRIPTION_CHANGED,
        new events_1.TopologyDescriptionChangedEvent(
          this.s.id,
          new topology_description_1.TopologyDescription(
            common_1.TopologyType.Unknown,
          ), // initial is always Unknown
          this.s.description,
        ),
      );
      // connect all known servers, then attempt server selection to connect
      const serverDescriptions = Array.from(
        this.s.description.servers.values(),
      );
      this.s.servers = new Map(
        serverDescriptions.map((serverDescription) => [
          serverDescription.address,
          createAndConnectServer(this, serverDescription),
        ]),
      );
      // In load balancer mode we need to fake a server description getting
      // emitted from the monitor, since the monitor doesn't exist.
      if (this.s.options.loadBalanced) {
        for (const description of serverDescriptions) {
          const newDescription = new server_description_1.ServerDescription(
            description.hostAddress,
            undefined,
            {
              loadBalanced: this.s.options.loadBalanced,
            },
          );
          this.serverUpdateHandler(newDescription);
        }
      }
      const exitWithError = (error) =>
        callback ? callback(error) : this.emit(Topology.ERROR, error);
      const readPreference =
        options.readPreference ?? read_preference_1.ReadPreference.primary;
      this.selectServer(
        (0, server_selection_1.readPreferenceServerSelector)(readPreference),
        options,
        (err, server) => {
          if (err) {
            return this.close({ force: false }, () => exitWithError(err));
          }
          // TODO: NODE-2471
          const skipPingOnConnect =
            this.s.options[Symbol.for("@@mdb.skipPingOnConnect")] === true;
          if (!skipPingOnConnect && server && this.s.credentials) {
            server.command(
              (0, utils_1.ns)("admin.$cmd"),
              { ping: 1 },
              {},
              (err) => {
                if (err) {
                  return exitWithError(err);
                }
                stateTransition(this, common_1.STATE_CONNECTED);
                this.emit(Topology.OPEN, this);
                this.emit(Topology.CONNECT, this);
                callback?.(undefined, this);
              },
            );
            return;
          }
          stateTransition(this, common_1.STATE_CONNECTED);
          this.emit(Topology.OPEN, this);
          this.emit(Topology.CONNECT, this);
          callback?.(undefined, this);
        },
      );
    }
    close(options, callback) {
      options = options ?? { force: false };
      if (
        this.s.state === common_1.STATE_CLOSED ||
        this.s.state === common_1.STATE_CLOSING
      ) {
        return callback?.();
      }
      const destroyedServers = Array.from(this.s.servers.values(), (server) => {
        return (0, util_1.promisify)(destroyServer)(server, this, {
          force: !!options?.force,
        });
      });
      Promise.all(destroyedServers)
        .then(() => {
          this.s.servers.clear();
          stateTransition(this, common_1.STATE_CLOSING);
          drainWaitQueue(
            this[kWaitQueue],
            new error_1.MongoTopologyClosedError(),
          );
          (0, common_1.drainTimerQueue)(this.s.connectionTimers);
          if (this.s.srvPoller) {
            this.s.srvPoller.stop();
            this.s.srvPoller.removeListener(
              srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY,
              this.s.detectSrvRecords,
            );
          }
          this.removeListener(
            Topology.TOPOLOGY_DESCRIPTION_CHANGED,
            this.s.detectShardedTopology,
          );
          stateTransition(this, common_1.STATE_CLOSED);
          // emit an event for close
          this.emit(
            Topology.TOPOLOGY_CLOSED,
            new events_1.TopologyClosedEvent(this.s.id),
          );
        })
        .finally(() => callback?.());
    }
    /**
     * Selects a server according to the selection predicate provided
     *
     * @param selector - An optional selector to select servers by, defaults to a random selection within a latency window
     * @param options - Optional settings related to server selection
     * @param callback - The callback used to indicate success or failure
     * @returns An instance of a `Server` meeting the criteria of the predicate provided
     */
    selectServer(selector, options, callback) {
      let serverSelector;
      if (typeof selector !== "function") {
        if (typeof selector === "string") {
          serverSelector = (0, server_selection_1.readPreferenceServerSelector)(
            read_preference_1.ReadPreference.fromString(selector),
          );
        } else {
          let readPreference;
          if (selector instanceof read_preference_1.ReadPreference) {
            readPreference = selector;
          } else {
            read_preference_1.ReadPreference.translate(options);
            readPreference =
              options.readPreference ||
              read_preference_1.ReadPreference.primary;
          }
          serverSelector = (0, server_selection_1.readPreferenceServerSelector)(
            readPreference,
          );
        }
      } else {
        serverSelector = selector;
      }
      options = Object.assign(
        {},
        { serverSelectionTimeoutMS: this.s.serverSelectionTimeoutMS },
        options,
      );
      const isSharded = this.description.type === common_1.TopologyType.Sharded;
      const session = options.session;
      const transaction = session && session.transaction;
      if (isSharded && transaction && transaction.server) {
        callback(undefined, transaction.server);
        return;
      }
      const waitQueueMember = {
        serverSelector,
        transaction,
        callback,
        timeoutController: new utils_1.TimeoutController(
          options.serverSelectionTimeoutMS,
        ),
      };
      waitQueueMember.timeoutController.signal.addEventListener("abort", () => {
        waitQueueMember[kCancelled] = true;
        waitQueueMember.timeoutController.clear();
        const timeoutError = new error_1.MongoServerSelectionError(
          `Server selection timed out after ${options.serverSelectionTimeoutMS} ms`,
          this.description,
        );
        waitQueueMember.callback(timeoutError);
      });
      this[kWaitQueue].push(waitQueueMember);
      processWaitQueue(this);
    }
    /**
     * Update the internal TopologyDescription with a ServerDescription
     *
     * @param serverDescription - The server to update in the internal list of server descriptions
     */
    serverUpdateHandler(serverDescription) {
      if (!this.s.description.hasServer(serverDescription.address)) {
        return;
      }
      // ignore this server update if its from an outdated topologyVersion
      if (isStaleServerDescription(this.s.description, serverDescription)) {
        return;
      }
      // these will be used for monitoring events later
      const previousTopologyDescription = this.s.description;
      const previousServerDescription = this.s.description.servers.get(
        serverDescription.address,
      );
      if (!previousServerDescription) {
        return;
      }
      // Driver Sessions Spec: "Whenever a driver receives a cluster time from
      // a server it MUST compare it to the current highest seen cluster time
      // for the deployment. If the new cluster time is higher than the
      // highest seen cluster time it MUST become the new highest seen cluster
      // time. Two cluster times are compared using only the BsonTimestamp
      // value of the clusterTime embedded field."
      const clusterTime = serverDescription.$clusterTime;
      if (clusterTime) {
        (0, common_1._advanceClusterTime)(this, clusterTime);
      }
      // If we already know all the information contained in this updated description, then
      // we don't need to emit SDAM events, but still need to update the description, in order
      // to keep client-tracked attributes like last update time and round trip time up to date
      const equalDescriptions =
        previousServerDescription &&
        previousServerDescription.equals(serverDescription);
      // first update the TopologyDescription
      this.s.description = this.s.description.update(serverDescription);
      if (this.s.description.compatibilityError) {
        this.emit(
          Topology.ERROR,
          new error_1.MongoCompatibilityError(
            this.s.description.compatibilityError,
          ),
        );
        return;
      }
      // emit monitoring events for this change
      if (!equalDescriptions) {
        const newDescription = this.s.description.servers.get(
          serverDescription.address,
        );
        if (newDescription) {
          this.emit(
            Topology.SERVER_DESCRIPTION_CHANGED,
            new events_1.ServerDescriptionChangedEvent(
              this.s.id,
              serverDescription.address,
              previousServerDescription,
              newDescription,
            ),
          );
        }
      }
      // update server list from updated descriptions
      updateServers(this, serverDescription);
      // attempt to resolve any outstanding server selection attempts
      if (this[kWaitQueue].length > 0) {
        processWaitQueue(this);
      }
      if (!equalDescriptions) {
        this.emit(
          Topology.TOPOLOGY_DESCRIPTION_CHANGED,
          new events_1.TopologyDescriptionChangedEvent(
            this.s.id,
            previousTopologyDescription,
            this.s.description,
          ),
        );
      }
    }
    auth(credentials, callback) {
      if (typeof credentials === "function")
        (callback = credentials), (credentials = undefined);
      if (typeof callback === "function") callback(undefined, true);
    }
    get clientMetadata() {
      return this.s.options.metadata;
    }
    isConnected() {
      return this.s.state === common_1.STATE_CONNECTED;
    }
    isDestroyed() {
      return this.s.state === common_1.STATE_CLOSED;
    }
    // NOTE: There are many places in code where we explicitly check the last hello
    //       to do feature support detection. This should be done any other way, but for
    //       now we will just return the first hello seen, which should suffice.
    lastHello() {
      const serverDescriptions = Array.from(this.description.servers.values());
      if (serverDescriptions.length === 0) return {};
      const sd = serverDescriptions.filter(
        (sd) => sd.type !== common_1.ServerType.Unknown,
      )[0];
      const result = sd || {
        maxWireVersion: this.description.commonWireVersion,
      };
      return result;
    }
    get commonWireVersion() {
      return this.description.commonWireVersion;
    }
    get logicalSessionTimeoutMinutes() {
      return this.description.logicalSessionTimeoutMinutes;
    }
    get clusterTime() {
      return this.s.clusterTime;
    }
    set clusterTime(clusterTime) {
      this.s.clusterTime = clusterTime;
    }
  }
  /** @event */
  Topology.SERVER_OPENING = constants_1.SERVER_OPENING;
  /** @event */
  Topology.SERVER_CLOSED = constants_1.SERVER_CLOSED;
  /** @event */
  Topology.SERVER_DESCRIPTION_CHANGED = constants_1.SERVER_DESCRIPTION_CHANGED;
  /** @event */
  Topology.TOPOLOGY_OPENING = constants_1.TOPOLOGY_OPENING;
  /** @event */
  Topology.TOPOLOGY_CLOSED = constants_1.TOPOLOGY_CLOSED;
  /** @event */
  Topology.TOPOLOGY_DESCRIPTION_CHANGED =
    constants_1.TOPOLOGY_DESCRIPTION_CHANGED;
  /** @event */
  Topology.ERROR = constants_1.ERROR;
  /** @event */
  Topology.OPEN = constants_1.OPEN;
  /** @event */
  Topology.CONNECT = constants_1.CONNECT;
  /** @event */
  Topology.CLOSE = constants_1.CLOSE;
  /** @event */
  Topology.TIMEOUT = constants_1.TIMEOUT;
  topology.Topology = Topology;
  /** Destroys a server, and removes all event listeners from the instance */
  function destroyServer(server, topology, options, callback) {
    options = options ?? { force: false };
    for (const event of constants_1.LOCAL_SERVER_EVENTS) {
      server.removeAllListeners(event);
    }
    server.destroy(options, () => {
      topology.emit(
        Topology.SERVER_CLOSED,
        new events_1.ServerClosedEvent(
          topology.s.id,
          server.description.address,
        ),
      );
      for (const event of constants_1.SERVER_RELAY_EVENTS) {
        server.removeAllListeners(event);
      }
      if (typeof callback === "function") {
        callback();
      }
    });
  }
  /** Predicts the TopologyType from options */
  function topologyTypeFromOptions(options) {
    if (options?.directConnection) {
      return common_1.TopologyType.Single;
    }
    if (options?.replicaSet) {
      return common_1.TopologyType.ReplicaSetNoPrimary;
    }
    if (options?.loadBalanced) {
      return common_1.TopologyType.LoadBalanced;
    }
    return common_1.TopologyType.Unknown;
  }
  /**
   * Creates new server instances and attempts to connect them
   *
   * @param topology - The topology that this server belongs to
   * @param serverDescription - The description for the server to initialize and connect to
   */
  function createAndConnectServer(topology, serverDescription) {
    topology.emit(
      Topology.SERVER_OPENING,
      new events_1.ServerOpeningEvent(topology.s.id, serverDescription.address),
    );
    const server = new server_1.Server(
      topology,
      serverDescription,
      topology.s.options,
    );
    for (const event of constants_1.SERVER_RELAY_EVENTS) {
      server.on(event, (e) => topology.emit(event, e));
    }
    server.on(server_1.Server.DESCRIPTION_RECEIVED, (description) =>
      topology.serverUpdateHandler(description),
    );
    server.connect();
    return server;
  }
  /**
   * @param topology - Topology to update.
   * @param incomingServerDescription - New server description.
   */
  function updateServers(topology, incomingServerDescription) {
    // update the internal server's description
    if (
      incomingServerDescription &&
      topology.s.servers.has(incomingServerDescription.address)
    ) {
      const server = topology.s.servers.get(incomingServerDescription.address);
      if (server) {
        server.s.description = incomingServerDescription;
        if (
          incomingServerDescription.error instanceof error_1.MongoError &&
          incomingServerDescription.error.hasErrorLabel(
            error_1.MongoErrorLabel.ResetPool,
          )
        ) {
          const interruptInUseConnections =
            incomingServerDescription.error.hasErrorLabel(
              error_1.MongoErrorLabel.InterruptInUseConnections,
            );
          server.pool.clear({ interruptInUseConnections });
        } else if (incomingServerDescription.error == null) {
          const newTopologyType = topology.s.description.type;
          const shouldMarkPoolReady =
            incomingServerDescription.isDataBearing ||
            (incomingServerDescription.type !== common_1.ServerType.Unknown &&
              newTopologyType === common_1.TopologyType.Single);
          if (shouldMarkPoolReady) {
            server.pool.ready();
          }
        }
      }
    }
    // add new servers for all descriptions we currently don't know about locally
    for (const serverDescription of topology.description.servers.values()) {
      if (!topology.s.servers.has(serverDescription.address)) {
        const server = createAndConnectServer(topology, serverDescription);
        topology.s.servers.set(serverDescription.address, server);
      }
    }
    // for all servers no longer known, remove their descriptions and destroy their instances
    for (const entry of topology.s.servers) {
      const serverAddress = entry[0];
      if (topology.description.hasServer(serverAddress)) {
        continue;
      }
      if (!topology.s.servers.has(serverAddress)) {
        continue;
      }
      const server = topology.s.servers.get(serverAddress);
      topology.s.servers.delete(serverAddress);
      // prepare server for garbage collection
      if (server) {
        destroyServer(server, topology);
      }
    }
  }
  function drainWaitQueue(queue, err) {
    while (queue.length) {
      const waitQueueMember = queue.shift();
      if (!waitQueueMember) {
        continue;
      }
      waitQueueMember.timeoutController.clear();
      if (!waitQueueMember[kCancelled]) {
        waitQueueMember.callback(err);
      }
    }
  }
  function processWaitQueue(topology) {
    if (topology.s.state === common_1.STATE_CLOSED) {
      drainWaitQueue(
        topology[kWaitQueue],
        new error_1.MongoTopologyClosedError(),
      );
      return;
    }
    const isSharded =
      topology.description.type === common_1.TopologyType.Sharded;
    const serverDescriptions = Array.from(
      topology.description.servers.values(),
    );
    const membersToProcess = topology[kWaitQueue].length;
    for (let i = 0; i < membersToProcess; ++i) {
      const waitQueueMember = topology[kWaitQueue].shift();
      if (!waitQueueMember) {
        continue;
      }
      if (waitQueueMember[kCancelled]) {
        continue;
      }
      let selectedDescriptions;
      try {
        const serverSelector = waitQueueMember.serverSelector;
        selectedDescriptions = serverSelector
          ? serverSelector(topology.description, serverDescriptions)
          : serverDescriptions;
      } catch (e) {
        waitQueueMember.timeoutController.clear();
        waitQueueMember.callback(e);
        continue;
      }
      let selectedServer;
      if (selectedDescriptions.length === 0) {
        topology[kWaitQueue].push(waitQueueMember);
        continue;
      } else if (selectedDescriptions.length === 1) {
        selectedServer = topology.s.servers.get(
          selectedDescriptions[0].address,
        );
      } else {
        const descriptions = (0, utils_1.shuffle)(selectedDescriptions, 2);
        const server1 = topology.s.servers.get(descriptions[0].address);
        const server2 = topology.s.servers.get(descriptions[1].address);
        selectedServer =
          server1 &&
          server2 &&
          server1.s.operationCount < server2.s.operationCount
            ? server1
            : server2;
      }
      if (!selectedServer) {
        waitQueueMember.callback(
          new error_1.MongoServerSelectionError(
            "server selection returned a server description but the server was not found in the topology",
            topology.description,
          ),
        );
        return;
      }
      const transaction = waitQueueMember.transaction;
      if (isSharded && transaction && transaction.isActive && selectedServer) {
        transaction.pinServer(selectedServer);
      }
      waitQueueMember.timeoutController.clear();
      waitQueueMember.callback(undefined, selectedServer);
    }
    if (topology[kWaitQueue].length > 0) {
      // ensure all server monitors attempt monitoring soon
      for (const [, server] of topology.s.servers) {
        process.nextTick(function scheduleServerCheck() {
          return server.requestCheck();
        });
      }
    }
  }
  function isStaleServerDescription(
    topologyDescription,
    incomingServerDescription,
  ) {
    const currentServerDescription = topologyDescription.servers.get(
      incomingServerDescription.address,
    );
    const currentTopologyVersion = currentServerDescription?.topologyVersion;
    return (
      (0, server_description_1.compareTopologyVersion)(
        currentTopologyVersion,
        incomingServerDescription.topologyVersion,
      ) > 0
    );
  }
  /** @public */
  class ServerCapabilities {
    constructor(hello) {
      this.minWireVersion = hello.minWireVersion || 0;
      this.maxWireVersion = hello.maxWireVersion || 0;
    }
    get hasAggregationCursor() {
      return this.maxWireVersion >= 1;
    }
    get hasWriteCommands() {
      return this.maxWireVersion >= 2;
    }
    get hasTextSearch() {
      return this.minWireVersion >= 0;
    }
    get hasAuthCommands() {
      return this.maxWireVersion >= 1;
    }
    get hasListCollectionsCommand() {
      return this.maxWireVersion >= 3;
    }
    get hasListIndexesCommand() {
      return this.maxWireVersion >= 3;
    }
    get supportsSnapshotReads() {
      return this.maxWireVersion >= 13;
    }
    get commandsTakeWriteConcern() {
      return this.maxWireVersion >= 5;
    }
    get commandsTakeCollation() {
      return this.maxWireVersion >= 5;
    }
  }
  topology.ServerCapabilities = ServerCapabilities;

  return topology;
}

var hasRequiredMongo_client;

function requireMongo_client() {
  if (hasRequiredMongo_client) return mongo_client;
  hasRequiredMongo_client = 1;
  Object.defineProperty(mongo_client, "__esModule", { value: true });
  mongo_client.MongoClient = mongo_client.ServerApiVersion = void 0;
  const fs_1 = $nodeFs;
  const util_1 = $noteUtil;
  const bson_1 = bson$2;
  const change_stream_1 = requireChange_stream();
  const mongo_credentials_1 = mongo_credentials;
  const providers_1 = providers$1;
  const connection_string_1 = requireConnection_string();
  const constants_1 = constants;
  const db_1 = requireDb();
  const error_1 = error;
  const mongo_logger_1 = mongo_logger;
  const mongo_types_1 = mongo_types;
  const execute_operation_1 = execute_operation;
  const run_command_1 = run_command;
  const read_preference_1 = read_preference;
  const server_selection_1 = server_selection;
  const topology_1 = requireTopology();
  const sessions_1 = sessions;
  const utils_1 = utils$2;
  /** @public */
  mongo_client.ServerApiVersion = Object.freeze({
    v1: "1",
  });
  /** @internal */
  const kOptions = Symbol("options");
  /**
   * The **MongoClient** class is a class that allows for making Connections to MongoDB.
   * @public
   *
   * @remarks
   * The programmatically provided options take precedence over the URI options.
   *
   * @example
   * ```ts
   * import { MongoClient } from 'mongodb';
   *
   * // Enable command monitoring for debugging
   * const client = new MongoClient('mongodb://localhost:27017', { monitorCommands: true });
   *
   * client.on('commandStarted', started => console.log(started));
   * client.db().collection('pets');
   * await client.insertOne({ name: 'spot', kind: 'dog' });
   * ```
   */
  class MongoClient extends mongo_types_1.TypedEventEmitter {
    constructor(url, options) {
      super();
      this[kOptions] = (0, connection_string_1.parseOptions)(
        url,
        this,
        options,
      );
      this.mongoLogger = new mongo_logger_1.MongoLogger(
        this[kOptions].mongoLoggerOptions,
      );
      // eslint-disable-next-line @typescript-eslint/no-this-alias
      const client = this;
      // The internal state
      this.s = {
        url,
        bsonOptions: (0, bson_1.resolveBSONOptions)(this[kOptions]),
        namespace: (0, utils_1.ns)("admin"),
        hasBeenClosed: false,
        sessionPool: new sessions_1.ServerSessionPool(this),
        activeSessions: new Set(),
        get options() {
          return client[kOptions];
        },
        get readConcern() {
          return client[kOptions].readConcern;
        },
        get writeConcern() {
          return client[kOptions].writeConcern;
        },
        get readPreference() {
          return client[kOptions].readPreference;
        },
        get isMongoClient() {
          return true;
        },
      };
    }
    /** @see MongoOptions */
    get options() {
      return Object.freeze({ ...this[kOptions] });
    }
    get serverApi() {
      return (
        this[kOptions].serverApi &&
        Object.freeze({ ...this[kOptions].serverApi })
      );
    }
    /**
     * Intended for APM use only
     * @internal
     */
    get monitorCommands() {
      return this[kOptions].monitorCommands;
    }
    set monitorCommands(value) {
      this[kOptions].monitorCommands = value;
    }
    /** @internal */
    get autoEncrypter() {
      return this[kOptions].autoEncrypter;
    }
    get readConcern() {
      return this.s.readConcern;
    }
    get writeConcern() {
      return this.s.writeConcern;
    }
    get readPreference() {
      return this.s.readPreference;
    }
    get bsonOptions() {
      return this.s.bsonOptions;
    }
    /**
     * Connect to MongoDB using a url
     *
     * @see docs.mongodb.org/manual/reference/connection-string/
     */
    async connect() {
      if (this.connectionLock) {
        return this.connectionLock;
      }
      try {
        this.connectionLock = this._connect();
        await this.connectionLock;
      } finally {
        // release
        this.connectionLock = undefined;
      }
      return this;
    }
    /**
     * Create a topology to open the connection, must be locked to avoid topology leaks in concurrency scenario.
     * Locking is enforced by the connect method.
     *
     * @internal
     */
    async _connect() {
      if (this.topology && this.topology.isConnected()) {
        return this;
      }
      const options = this[kOptions];
      if (options.tls) {
        if (typeof options.tlsCAFile === "string") {
          options.ca ??= await fs_1.promises.readFile(options.tlsCAFile);
        }
        if (typeof options.tlsCRLFile === "string") {
          options.crl ??= await fs_1.promises.readFile(options.tlsCRLFile);
        }
        if (typeof options.tlsCertificateKeyFile === "string") {
          if (!options.key || !options.cert) {
            const contents = await fs_1.promises.readFile(
              options.tlsCertificateKeyFile,
            );
            options.key ??= contents;
            options.cert ??= contents;
          }
        }
      }
      if (typeof options.srvHost === "string") {
        const hosts = await (0, connection_string_1.resolveSRVRecord)(options);
        for (const [index, host] of hosts.entries()) {
          options.hosts[index] = host;
        }
      }
      // It is important to perform validation of hosts AFTER SRV resolution, to check the real hostname,
      // but BEFORE we even attempt connecting with a potentially not allowed hostname
      if (
        options.credentials?.mechanism ===
        providers_1.AuthMechanism.MONGODB_OIDC
      ) {
        const allowedHosts =
          options.credentials?.mechanismProperties?.ALLOWED_HOSTS ||
          mongo_credentials_1.DEFAULT_ALLOWED_HOSTS;
        const isServiceAuth =
          !!options.credentials?.mechanismProperties?.PROVIDER_NAME;
        if (!isServiceAuth) {
          for (const host of options.hosts) {
            if (
              !(0, utils_1.hostMatchesWildcards)(
                host.toHostPort().host,
                allowedHosts,
              )
            ) {
              throw new error_1.MongoInvalidArgumentError(
                `Host '${host}' is not valid for OIDC authentication with ALLOWED_HOSTS of '${allowedHosts.join(
                  ",",
                )}'`,
              );
            }
          }
        }
      }
      this.topology = new topology_1.Topology(this, options.hosts, options);
      // Events can be emitted before initialization is complete so we have to
      // save the reference to the topology on the client ASAP if the event handlers need to access it
      this.topology.once(topology_1.Topology.OPEN, () =>
        this.emit("open", this),
      );
      for (const event of constants_1.MONGO_CLIENT_EVENTS) {
        this.topology.on(event, (...args) => this.emit(event, ...args));
      }
      const topologyConnect = async () => {
        try {
          await (0, util_1.promisify)((callback) =>
            this.topology?.connect(options, callback),
          )();
        } catch (error) {
          this.topology?.close({ force: true });
          throw error;
        }
      };
      if (this.autoEncrypter) {
        await this.autoEncrypter?.init();
        await topologyConnect();
        await options.encrypter.connectInternalClient();
      } else {
        await topologyConnect();
      }
      return this;
    }
    /**
     * Close the client and its underlying connections
     *
     * @param force - Force close, emitting no events
     */
    async close(force = false) {
      // There's no way to set hasBeenClosed back to false
      Object.defineProperty(this.s, "hasBeenClosed", {
        value: true,
        enumerable: true,
        configurable: false,
        writable: false,
      });
      const activeSessionEnds = Array.from(this.s.activeSessions, (session) =>
        session.endSession(),
      );
      this.s.activeSessions.clear();
      await Promise.all(activeSessionEnds);
      if (this.topology == null) {
        return;
      }
      // If we would attempt to select a server and get nothing back we short circuit
      // to avoid the server selection timeout.
      const selector = (0, server_selection_1.readPreferenceServerSelector)(
        read_preference_1.ReadPreference.primaryPreferred,
      );
      const topologyDescription = this.topology.description;
      const serverDescriptions = Array.from(
        topologyDescription.servers.values(),
      );
      const servers = selector(topologyDescription, serverDescriptions);
      if (servers.length !== 0) {
        const endSessions = Array.from(
          this.s.sessionPool.sessions,
          ({ id }) => id,
        );
        if (endSessions.length !== 0) {
          await (0, execute_operation_1.executeOperation)(
            this,
            new run_command_1.RunAdminCommandOperation(
              { endSessions },
              {
                readPreference:
                  read_preference_1.ReadPreference.primaryPreferred,
                noResponse: true,
              },
            ),
          ).catch(() => null); // outcome does not matter;
        }
      }
      // clear out references to old topology
      const topology = this.topology;
      this.topology = undefined;
      await new Promise((resolve, reject) => {
        topology.close({ force }, (error) => {
          if (error) return reject(error);
          const { encrypter } = this[kOptions];
          if (encrypter) {
            return encrypter.closeCallback(this, force, (error) => {
              if (error) return reject(error);
              resolve();
            });
          }
          resolve();
        });
      });
    }
    /**
     * Create a new Db instance sharing the current socket connections.
     *
     * @param dbName - The name of the database we want to use. If not provided, use database name from connection string.
     * @param options - Optional settings for Db construction
     */
    db(dbName, options) {
      options = options ?? {};
      // Default to db from connection string if not provided
      if (!dbName) {
        dbName = this.options.dbName;
      }
      // Copy the options and add out internal override of the not shared flag
      const finalOptions = Object.assign({}, this[kOptions], options);
      // Return the db object
      const db = new db_1.Db(this, dbName, finalOptions);
      // Return the database
      return db;
    }
    /**
     * Connect to MongoDB using a url
     *
     * @remarks
     * The programmatically provided options take precedence over the URI options.
     *
     * @see https://www.mongodb.com/docs/manual/reference/connection-string/
     */
    static async connect(url, options) {
      const client = new this(url, options);
      return client.connect();
    }
    /**
     * Creates a new ClientSession. When using the returned session in an operation
     * a corresponding ServerSession will be created.
     *
     * @remarks
     * A ClientSession instance may only be passed to operations being performed on the same
     * MongoClient it was started from.
     */
    startSession(options) {
      const session = new sessions_1.ClientSession(
        this,
        this.s.sessionPool,
        { explicit: true, ...options },
        this[kOptions],
      );
      this.s.activeSessions.add(session);
      session.once("ended", () => {
        this.s.activeSessions.delete(session);
      });
      return session;
    }
    async withSession(optionsOrExecutor, executor) {
      const options = {
        // Always define an owner
        owner: Symbol(),
        // If it's an object inherit the options
        ...(typeof optionsOrExecutor === "object" ? optionsOrExecutor : {}),
      };
      const withSessionCallback =
        typeof optionsOrExecutor === "function" ? optionsOrExecutor : executor;
      if (withSessionCallback == null) {
        throw new error_1.MongoInvalidArgumentError(
          "Missing required callback parameter",
        );
      }
      const session = this.startSession(options);
      try {
        return await withSessionCallback(session);
      } finally {
        try {
          await session.endSession();
        } catch {
          // We are not concerned with errors from endSession()
        }
      }
    }
    /**
     * Create a new Change Stream, watching for new changes (insertions, updates,
     * replacements, deletions, and invalidations) in this cluster. Will ignore all
     * changes to system collections, as well as the local, admin, and config databases.
     *
     * @remarks
     * watch() accepts two generic arguments for distinct use cases:
     * - The first is to provide the schema that may be defined for all the data within the current cluster
     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument
     *
     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.
     * @param options - Optional settings for the command
     * @typeParam TSchema - Type of the data being detected by the change stream
     * @typeParam TChange - Type of the whole change stream document emitted
     */
    watch(pipeline = [], options = {}) {
      // Allow optionally not specifying a pipeline
      if (!Array.isArray(pipeline)) {
        options = pipeline;
        pipeline = [];
      }
      return new change_stream_1.ChangeStream(
        this,
        pipeline,
        (0, utils_1.resolveOptions)(this, options),
      );
    }
  }
  mongo_client.MongoClient = MongoClient;

  return mongo_client;
}

var hasRequiredChange_stream;

function requireChange_stream() {
  if (hasRequiredChange_stream) return change_stream;
  hasRequiredChange_stream = 1;
  Object.defineProperty(change_stream, "__esModule", { value: true });
  change_stream.ChangeStream = void 0;
  const collection_1 = requireCollection();
  const constants_1 = constants;
  const change_stream_cursor_1 = requireChange_stream_cursor();
  const db_1 = requireDb();
  const error_1 = error;
  const mongo_client_1 = requireMongo_client();
  const mongo_types_1 = mongo_types;
  const utils_1 = utils$2;
  /** @internal */
  const kCursorStream = Symbol("cursorStream");
  /** @internal */
  const kClosed = Symbol("closed");
  /** @internal */
  const kMode = Symbol("mode");
  const CHANGE_STREAM_OPTIONS = [
    "resumeAfter",
    "startAfter",
    "startAtOperationTime",
    "fullDocument",
    "fullDocumentBeforeChange",
    "showExpandedEvents",
  ];
  const CHANGE_DOMAIN_TYPES = {
    COLLECTION: Symbol("Collection"),
    DATABASE: Symbol("Database"),
    CLUSTER: Symbol("Cluster"),
  };
  const CHANGE_STREAM_EVENTS = [
    constants_1.RESUME_TOKEN_CHANGED,
    constants_1.END,
    constants_1.CLOSE,
  ];
  const NO_RESUME_TOKEN_ERROR =
    "A change stream document has been received that lacks a resume token (_id).";
  const CHANGESTREAM_CLOSED_ERROR = "ChangeStream is closed";
  /**
   * Creates a new Change Stream instance. Normally created using {@link Collection#watch|Collection.watch()}.
   * @public
   */
  class ChangeStream extends mongo_types_1.TypedEventEmitter {
    /**
     * @internal
     *
     * @param parent - The parent object that created this change stream
     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents
     */
    constructor(parent, pipeline = [], options = {}) {
      super();
      this.pipeline = pipeline;
      this.options = { ...options };
      delete this.options.writeConcern;
      if (parent instanceof collection_1.Collection) {
        this.type = CHANGE_DOMAIN_TYPES.COLLECTION;
      } else if (parent instanceof db_1.Db) {
        this.type = CHANGE_DOMAIN_TYPES.DATABASE;
      } else if (parent instanceof mongo_client_1.MongoClient) {
        this.type = CHANGE_DOMAIN_TYPES.CLUSTER;
      } else {
        throw new error_1.MongoChangeStreamError(
          "Parent provided to ChangeStream constructor must be an instance of Collection, Db, or MongoClient",
        );
      }
      this.parent = parent;
      this.namespace = parent.s.namespace;
      if (!this.options.readPreference && parent.readPreference) {
        this.options.readPreference = parent.readPreference;
      }
      // Create contained Change Stream cursor
      this.cursor = this._createChangeStreamCursor(options);
      this[kClosed] = false;
      this[kMode] = false;
      // Listen for any `change` listeners being added to ChangeStream
      this.on("newListener", (eventName) => {
        if (
          eventName === "change" &&
          this.cursor &&
          this.listenerCount("change") === 0
        ) {
          this._streamEvents(this.cursor);
        }
      });
      this.on("removeListener", (eventName) => {
        if (
          eventName === "change" &&
          this.listenerCount("change") === 0 &&
          this.cursor
        ) {
          this[kCursorStream]?.removeAllListeners("data");
        }
      });
    }
    /** @internal */
    get cursorStream() {
      return this[kCursorStream];
    }
    /** The cached resume token that is used to resume after the most recently returned change. */
    get resumeToken() {
      return this.cursor?.resumeToken;
    }
    /** Check if there is any document still available in the Change Stream */
    async hasNext() {
      this._setIsIterator();
      // Change streams must resume indefinitely while each resume event succeeds.
      // This loop continues until either a change event is received or until a resume attempt
      // fails.
      // eslint-disable-next-line no-constant-condition
      while (true) {
        try {
          const hasNext = await this.cursor.hasNext();
          return hasNext;
        } catch (error) {
          try {
            await this._processErrorIteratorMode(error);
          } catch (error) {
            try {
              await this.close();
            } catch {
              // We are not concerned with errors from close()
            }
            throw error;
          }
        }
      }
    }
    /** Get the next available document from the Change Stream. */
    async next() {
      this._setIsIterator();
      // Change streams must resume indefinitely while each resume event succeeds.
      // This loop continues until either a change event is received or until a resume attempt
      // fails.
      // eslint-disable-next-line no-constant-condition
      while (true) {
        try {
          const change = await this.cursor.next();
          const processedChange = this._processChange(change ?? null);
          return processedChange;
        } catch (error) {
          try {
            await this._processErrorIteratorMode(error);
          } catch (error) {
            try {
              await this.close();
            } catch {
              // We are not concerned with errors from close()
            }
            throw error;
          }
        }
      }
    }
    /**
     * Try to get the next available document from the Change Stream's cursor or `null` if an empty batch is returned
     */
    async tryNext() {
      this._setIsIterator();
      // Change streams must resume indefinitely while each resume event succeeds.
      // This loop continues until either a change event is received or until a resume attempt
      // fails.
      // eslint-disable-next-line no-constant-condition
      while (true) {
        try {
          const change = await this.cursor.tryNext();
          return change ?? null;
        } catch (error) {
          try {
            await this._processErrorIteratorMode(error);
          } catch (error) {
            try {
              await this.close();
            } catch {
              // We are not concerned with errors from close()
            }
            throw error;
          }
        }
      }
    }
    async *[Symbol.asyncIterator]() {
      if (this.closed) {
        return;
      }
      try {
        // Change streams run indefinitely as long as errors are resumable
        // So the only loop breaking condition is if `next()` throws
        while (true) {
          yield await this.next();
        }
      } finally {
        try {
          await this.close();
        } catch {
          // we're not concerned with errors from close()
        }
      }
    }
    /** Is the cursor closed */
    get closed() {
      return this[kClosed] || this.cursor.closed;
    }
    /** Close the Change Stream */
    async close() {
      this[kClosed] = true;
      const cursor = this.cursor;
      try {
        await cursor.close();
      } finally {
        this._endStream();
      }
    }
    /**
     * Return a modified Readable stream including a possible transform method.
     *
     * NOTE: When using a Stream to process change stream events, the stream will
     * NOT automatically resume in the case a resumable error is encountered.
     *
     * @throws MongoChangeStreamError if the underlying cursor or the change stream is closed
     */
    stream(options) {
      if (this.closed) {
        throw new error_1.MongoChangeStreamError(CHANGESTREAM_CLOSED_ERROR);
      }
      this.streamOptions = options;
      return this.cursor.stream(options);
    }
    /** @internal */
    _setIsEmitter() {
      if (this[kMode] === "iterator") {
        // TODO(NODE-3485): Replace with MongoChangeStreamModeError
        throw new error_1.MongoAPIError(
          "ChangeStream cannot be used as an EventEmitter after being used as an iterator",
        );
      }
      this[kMode] = "emitter";
    }
    /** @internal */
    _setIsIterator() {
      if (this[kMode] === "emitter") {
        // TODO(NODE-3485): Replace with MongoChangeStreamModeError
        throw new error_1.MongoAPIError(
          "ChangeStream cannot be used as an iterator after being used as an EventEmitter",
        );
      }
      this[kMode] = "iterator";
    }
    /**
     * Create a new change stream cursor based on self's configuration
     * @internal
     */
    _createChangeStreamCursor(options) {
      const changeStreamStageOptions = (0, utils_1.filterOptions)(
        options,
        CHANGE_STREAM_OPTIONS,
      );
      if (this.type === CHANGE_DOMAIN_TYPES.CLUSTER) {
        changeStreamStageOptions.allChangesForCluster = true;
      }
      const pipeline = [
        { $changeStream: changeStreamStageOptions },
        ...this.pipeline,
      ];
      const client =
        this.type === CHANGE_DOMAIN_TYPES.CLUSTER
          ? this.parent
          : this.type === CHANGE_DOMAIN_TYPES.DATABASE
          ? this.parent.client
          : this.type === CHANGE_DOMAIN_TYPES.COLLECTION
          ? this.parent.client
          : null;
      if (client == null) {
        // This should never happen because of the assertion in the constructor
        throw new error_1.MongoRuntimeError(
          `Changestream type should only be one of cluster, database, collection. Found ${this.type.toString()}`,
        );
      }
      const changeStreamCursor = new change_stream_cursor_1.ChangeStreamCursor(
        client,
        this.namespace,
        pipeline,
        options,
      );
      for (const event of CHANGE_STREAM_EVENTS) {
        changeStreamCursor.on(event, (e) => this.emit(event, e));
      }
      if (this.listenerCount(ChangeStream.CHANGE) > 0) {
        this._streamEvents(changeStreamCursor);
      }
      return changeStreamCursor;
    }
    /** @internal */
    _closeEmitterModeWithError(error) {
      this.emit(ChangeStream.ERROR, error);
      this.close().catch(() => null);
    }
    /** @internal */
    _streamEvents(cursor) {
      this._setIsEmitter();
      const stream = this[kCursorStream] ?? cursor.stream();
      this[kCursorStream] = stream;
      stream.on("data", (change) => {
        try {
          const processedChange = this._processChange(change);
          this.emit(ChangeStream.CHANGE, processedChange);
        } catch (error) {
          this.emit(ChangeStream.ERROR, error);
        }
      });
      stream.on("error", (error) => this._processErrorStreamMode(error));
    }
    /** @internal */
    _endStream() {
      const cursorStream = this[kCursorStream];
      if (cursorStream) {
        ["data", "close", "end", "error"].forEach((event) =>
          cursorStream.removeAllListeners(event),
        );
        cursorStream.destroy();
      }
      this[kCursorStream] = undefined;
    }
    /** @internal */
    _processChange(change) {
      if (this[kClosed]) {
        // TODO(NODE-3485): Replace with MongoChangeStreamClosedError
        throw new error_1.MongoAPIError(CHANGESTREAM_CLOSED_ERROR);
      }
      // a null change means the cursor has been notified, implicitly closing the change stream
      if (change == null) {
        // TODO(NODE-3485): Replace with MongoChangeStreamClosedError
        throw new error_1.MongoRuntimeError(CHANGESTREAM_CLOSED_ERROR);
      }
      if (change && !change._id) {
        throw new error_1.MongoChangeStreamError(NO_RESUME_TOKEN_ERROR);
      }
      // cache the resume token
      this.cursor.cacheResumeToken(change._id);
      // wipe the startAtOperationTime if there was one so that there won't be a conflict
      // between resumeToken and startAtOperationTime if we need to reconnect the cursor
      this.options.startAtOperationTime = undefined;
      return change;
    }
    /** @internal */
    _processErrorStreamMode(changeStreamError) {
      // If the change stream has been closed explicitly, do not process error.
      if (this[kClosed]) return;
      if (
        (0, error_1.isResumableError)(
          changeStreamError,
          this.cursor.maxWireVersion,
        )
      ) {
        this._endStream();
        this.cursor.close().catch(() => null);
        const topology = (0, utils_1.getTopology)(this.parent);
        topology.selectServer(
          this.cursor.readPreference,
          {},
          (serverSelectionError) => {
            if (serverSelectionError)
              return this._closeEmitterModeWithError(changeStreamError);
            this.cursor = this._createChangeStreamCursor(
              this.cursor.resumeOptions,
            );
          },
        );
      } else {
        this._closeEmitterModeWithError(changeStreamError);
      }
    }
    /** @internal */
    async _processErrorIteratorMode(changeStreamError) {
      if (this[kClosed]) {
        // TODO(NODE-3485): Replace with MongoChangeStreamClosedError
        throw new error_1.MongoAPIError(CHANGESTREAM_CLOSED_ERROR);
      }
      if (
        !(0, error_1.isResumableError)(
          changeStreamError,
          this.cursor.maxWireVersion,
        )
      ) {
        try {
          await this.close();
        } catch {
          // ignore errors from close
        }
        throw changeStreamError;
      }
      await this.cursor.close().catch(() => null);
      const topology = (0, utils_1.getTopology)(this.parent);
      try {
        await topology.selectServerAsync(this.cursor.readPreference, {});
        this.cursor = this._createChangeStreamCursor(this.cursor.resumeOptions);
      } catch {
        // if the topology can't reconnect, close the stream
        await this.close();
        throw changeStreamError;
      }
    }
  }
  /** @event */
  ChangeStream.RESPONSE = constants_1.RESPONSE;
  /** @event */
  ChangeStream.MORE = constants_1.MORE;
  /** @event */
  ChangeStream.INIT = constants_1.INIT;
  /** @event */
  ChangeStream.CLOSE = constants_1.CLOSE;
  /**
   * Fired for each new matching change in the specified namespace. Attaching a `change`
   * event listener to a Change Stream will switch the stream into flowing mode. Data will
   * then be passed as soon as it is available.
   * @event
   */
  ChangeStream.CHANGE = constants_1.CHANGE;
  /** @event */
  ChangeStream.END = constants_1.END;
  /** @event */
  ChangeStream.ERROR = constants_1.ERROR;
  /**
   * Emitted each time the change stream stores a new resume token.
   * @event
   */
  ChangeStream.RESUME_TOKEN_CHANGED = constants_1.RESUME_TOKEN_CHANGED;
  change_stream.ChangeStream = ChangeStream;

  return change_stream;
}

var gridfs = {};

var download = {};

Object.defineProperty(download, "__esModule", { value: true });
download.GridFSBucketReadStream = void 0;
const stream_1$1 = $nodeStream;
const error_1$2 = error;
/**
 * A readable stream that enables you to read buffers from GridFS.
 *
 * Do not instantiate this class directly. Use `openDownloadStream()` instead.
 * @public
 */
let GridFSBucketReadStream$1 = class GridFSBucketReadStream extends stream_1$1.Readable {
  /**
   * @param chunks - Handle for chunks collection
   * @param files - Handle for files collection
   * @param readPreference - The read preference to use
   * @param filter - The filter to use to find the file document
   * @internal
   */
  constructor(chunks, files, readPreference, filter, options) {
    super({ emitClose: true });
    this.s = {
      bytesToTrim: 0,
      bytesToSkip: 0,
      bytesRead: 0,
      chunks,
      expected: 0,
      files,
      filter,
      init: false,
      expectedEnd: 0,
      options: {
        start: 0,
        end: 0,
        ...options,
      },
      readPreference,
    };
  }
  /**
   * Reads from the cursor and pushes to the stream.
   * Private Impl, do not call directly
   * @internal
   */
  _read() {
    if (this.destroyed) return;
    waitForFile(this, () => doRead(this));
  }
  /**
   * Sets the 0-based offset in bytes to start streaming from. Throws
   * an error if this stream has entered flowing mode
   * (e.g. if you've already called `on('data')`)
   *
   * @param start - 0-based offset in bytes to start streaming from
   */
  start(start = 0) {
    throwIfInitialized(this);
    this.s.options.start = start;
    return this;
  }
  /**
   * Sets the 0-based offset in bytes to start streaming from. Throws
   * an error if this stream has entered flowing mode
   * (e.g. if you've already called `on('data')`)
   *
   * @param end - Offset in bytes to stop reading at
   */
  end(end = 0) {
    throwIfInitialized(this);
    this.s.options.end = end;
    return this;
  }
  /**
   * Marks this stream as aborted (will never push another `data` event)
   * and kills the underlying cursor. Will emit the 'end' event, and then
   * the 'close' event once the cursor is successfully killed.
   */
  async abort() {
    this.push(null);
    this.destroy();
    await this.s.cursor?.close();
  }
};
/**
 * Fires when the stream loaded the file document corresponding to the provided id.
 * @event
 */
GridFSBucketReadStream$1.FILE = "file";
download.GridFSBucketReadStream = GridFSBucketReadStream$1;
function throwIfInitialized(stream) {
  if (stream.s.init) {
    throw new error_1$2.MongoGridFSStreamError(
      "Options cannot be changed after the stream is initialized",
    );
  }
}
function doRead(stream) {
  if (stream.destroyed) return;
  if (!stream.s.cursor) return;
  if (!stream.s.file) return;
  const handleReadResult = ({ error, doc }) => {
    if (stream.destroyed) {
      return;
    }
    if (error) {
      stream.destroy(error);
      return;
    }
    if (!doc) {
      stream.push(null);
      stream.s.cursor?.close().then(
        () => null,
        (error) => stream.destroy(error),
      );
      return;
    }
    if (!stream.s.file) return;
    const bytesRemaining = stream.s.file.length - stream.s.bytesRead;
    const expectedN = stream.s.expected++;
    const expectedLength = Math.min(stream.s.file.chunkSize, bytesRemaining);
    if (doc.n > expectedN) {
      return stream.destroy(
        new error_1$2.MongoGridFSChunkError(
          `ChunkIsMissing: Got unexpected n: ${doc.n}, expected: ${expectedN}`,
        ),
      );
    }
    if (doc.n < expectedN) {
      return stream.destroy(
        new error_1$2.MongoGridFSChunkError(
          `ExtraChunk: Got unexpected n: ${doc.n}, expected: ${expectedN}`,
        ),
      );
    }
    let buf = Buffer.isBuffer(doc.data) ? doc.data : doc.data.buffer;
    if (buf.byteLength !== expectedLength) {
      if (bytesRemaining <= 0) {
        return stream.destroy(
          new error_1$2.MongoGridFSChunkError(
            `ExtraChunk: Got unexpected n: ${doc.n}, expected file length ${stream.s.file.length} bytes but already read ${stream.s.bytesRead} bytes`,
          ),
        );
      }
      return stream.destroy(
        new error_1$2.MongoGridFSChunkError(
          `ChunkIsWrongSize: Got unexpected length: ${buf.byteLength}, expected: ${expectedLength}`,
        ),
      );
    }
    stream.s.bytesRead += buf.byteLength;
    if (buf.byteLength === 0) {
      return stream.push(null);
    }
    let sliceStart = null;
    let sliceEnd = null;
    if (stream.s.bytesToSkip != null) {
      sliceStart = stream.s.bytesToSkip;
      stream.s.bytesToSkip = 0;
    }
    const atEndOfStream = expectedN === stream.s.expectedEnd - 1;
    const bytesLeftToRead = stream.s.options.end - stream.s.bytesToSkip;
    if (atEndOfStream && stream.s.bytesToTrim != null) {
      sliceEnd = stream.s.file.chunkSize - stream.s.bytesToTrim;
    } else if (stream.s.options.end && bytesLeftToRead < doc.data.byteLength) {
      sliceEnd = bytesLeftToRead;
    }
    if (sliceStart != null || sliceEnd != null) {
      buf = buf.slice(sliceStart || 0, sliceEnd || buf.byteLength);
    }
    stream.push(buf);
    return;
  };
  stream.s.cursor.next().then(
    (doc) => handleReadResult({ error: null, doc }),
    (error) => handleReadResult({ error, doc: null }),
  );
}
function init(stream) {
  const findOneOptions = {};
  if (stream.s.readPreference) {
    findOneOptions.readPreference = stream.s.readPreference;
  }
  if (stream.s.options && stream.s.options.sort) {
    findOneOptions.sort = stream.s.options.sort;
  }
  if (stream.s.options && stream.s.options.skip) {
    findOneOptions.skip = stream.s.options.skip;
  }
  const handleReadResult = ({ error, doc }) => {
    if (error) {
      return stream.destroy(error);
    }
    if (!doc) {
      const identifier = stream.s.filter._id
        ? stream.s.filter._id.toString()
        : stream.s.filter.filename;
      const errmsg = `FileNotFound: file ${identifier} was not found`;
      // TODO(NODE-3483)
      const err = new error_1$2.MongoRuntimeError(errmsg);
      err.code = "ENOENT"; // TODO: NODE-3338 set property as part of constructor
      return stream.destroy(err);
    }
    // If document is empty, kill the stream immediately and don't
    // execute any reads
    if (doc.length <= 0) {
      stream.push(null);
      return;
    }
    if (stream.destroyed) {
      // If user destroys the stream before we have a cursor, wait
      // until the query is done to say we're 'closed' because we can't
      // cancel a query.
      stream.destroy();
      return;
    }
    try {
      stream.s.bytesToSkip = handleStartOption(stream, doc, stream.s.options);
    } catch (error) {
      return stream.destroy(error);
    }
    const filter = { files_id: doc._id };
    // Currently (MongoDB 3.4.4) skip function does not support the index,
    // it needs to retrieve all the documents first and then skip them. (CS-25811)
    // As work around we use $gte on the "n" field.
    if (stream.s.options && stream.s.options.start != null) {
      const skip = Math.floor(stream.s.options.start / doc.chunkSize);
      if (skip > 0) {
        filter["n"] = { $gte: skip };
      }
    }
    stream.s.cursor = stream.s.chunks.find(filter).sort({ n: 1 });
    if (stream.s.readPreference) {
      stream.s.cursor.withReadPreference(stream.s.readPreference);
    }
    stream.s.expectedEnd = Math.ceil(doc.length / doc.chunkSize);
    stream.s.file = doc;
    try {
      stream.s.bytesToTrim = handleEndOption(
        stream,
        doc,
        stream.s.cursor,
        stream.s.options,
      );
    } catch (error) {
      return stream.destroy(error);
    }
    stream.emit(GridFSBucketReadStream$1.FILE, doc);
    return;
  };
  stream.s.files.findOne(stream.s.filter, findOneOptions).then(
    (doc) => handleReadResult({ error: null, doc }),
    (error) => handleReadResult({ error, doc: null }),
  );
}
function waitForFile(stream, callback) {
  if (stream.s.file) {
    return callback();
  }
  if (!stream.s.init) {
    init(stream);
    stream.s.init = true;
  }
  stream.once("file", () => {
    callback();
  });
}
function handleStartOption(stream, doc, options) {
  if (options && options.start != null) {
    if (options.start > doc.length) {
      throw new error_1$2.MongoInvalidArgumentError(
        `Stream start (${options.start}) must not be more than the length of the file (${doc.length})`,
      );
    }
    if (options.start < 0) {
      throw new error_1$2.MongoInvalidArgumentError(
        `Stream start (${options.start}) must not be negative`,
      );
    }
    if (options.end != null && options.end < options.start) {
      throw new error_1$2.MongoInvalidArgumentError(
        `Stream start (${options.start}) must not be greater than stream end (${options.end})`,
      );
    }
    stream.s.bytesRead =
      Math.floor(options.start / doc.chunkSize) * doc.chunkSize;
    stream.s.expected = Math.floor(options.start / doc.chunkSize);
    return options.start - stream.s.bytesRead;
  }
  throw new error_1$2.MongoInvalidArgumentError("Start option must be defined");
}
function handleEndOption(stream, doc, cursor, options) {
  if (options && options.end != null) {
    if (options.end > doc.length) {
      throw new error_1$2.MongoInvalidArgumentError(
        `Stream end (${options.end}) must not be more than the length of the file (${doc.length})`,
      );
    }
    if (options.start == null || options.start < 0) {
      throw new error_1$2.MongoInvalidArgumentError(
        `Stream end (${options.end}) must not be negative`,
      );
    }
    const start =
      options.start != null ? Math.floor(options.start / doc.chunkSize) : 0;
    cursor.limit(Math.ceil(options.end / doc.chunkSize) - start);
    stream.s.expectedEnd = Math.ceil(options.end / doc.chunkSize);
    return Math.ceil(options.end / doc.chunkSize) * doc.chunkSize - options.end;
  }
  throw new error_1$2.MongoInvalidArgumentError("End option must be defined");
}

var upload = {};

Object.defineProperty(upload, "__esModule", { value: true });
upload.GridFSBucketWriteStream = void 0;
const stream_1 = $nodeStream;
const bson_1$1 = bson$2;
const error_1$1 = error;
const write_concern_1$1 = write_concern;
/**
 * A writable stream that enables you to write buffers to GridFS.
 *
 * Do not instantiate this class directly. Use `openUploadStream()` instead.
 * @public
 */
let GridFSBucketWriteStream$1 = class GridFSBucketWriteStream extends stream_1.Writable {
  /**
   * @param bucket - Handle for this stream's corresponding bucket
   * @param filename - The value of the 'filename' key in the files doc
   * @param options - Optional settings.
   * @internal
   */
  constructor(bucket, filename, options) {
    super();
    /**
     * The document containing information about the inserted file.
     * This property is defined _after_ the finish event has been emitted.
     * It will remain `null` if an error occurs.
     *
     * @example
     * ```ts
     * fs.createReadStream('file.txt')
     *   .pipe(bucket.openUploadStream('file.txt'))
     *   .on('finish', function () {
     *     console.log(this.gridFSFile)
     *   })
     * ```
     */
    this.gridFSFile = null;
    options = options ?? {};
    this.bucket = bucket;
    this.chunks = bucket.s._chunksCollection;
    this.filename = filename;
    this.files = bucket.s._filesCollection;
    this.options = options;
    this.writeConcern =
      write_concern_1$1.WriteConcern.fromOptions(options) ||
      bucket.s.options.writeConcern;
    // Signals the write is all done
    this.done = false;
    this.id = options.id ? options.id : new bson_1$1.ObjectId();
    // properly inherit the default chunksize from parent
    this.chunkSizeBytes =
      options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;
    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);
    this.length = 0;
    this.n = 0;
    this.pos = 0;
    this.state = {
      streamEnd: false,
      outstandingRequests: 0,
      errored: false,
      aborted: false,
    };
    if (!this.bucket.s.calledOpenUploadStream) {
      this.bucket.s.calledOpenUploadStream = true;
      checkIndexes(this).then(
        () => {
          this.bucket.s.checkedIndexes = true;
          this.bucket.emit("index");
        },
        () => null,
      );
    }
  }
  /**
   * @internal
   *
   * The stream is considered constructed when the indexes are done being created
   */
  _construct(callback) {
    if (this.bucket.s.checkedIndexes) {
      return process.nextTick(callback);
    }
    this.bucket.once("index", callback);
  }
  /**
   * @internal
   * Write a buffer to the stream.
   *
   * @param chunk - Buffer to write
   * @param encoding - Optional encoding for the buffer
   * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.
   */
  _write(chunk, encoding, callback) {
    doWrite(this, chunk, encoding, callback);
  }
  /** @internal */
  _final(callback) {
    if (this.state.streamEnd) {
      return process.nextTick(callback);
    }
    this.state.streamEnd = true;
    writeRemnant(this, callback);
  }
  /**
   * Places this write stream into an aborted state (all future writes fail)
   * and deletes all chunks that have already been written.
   */
  async abort() {
    if (this.state.streamEnd) {
      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed
      throw new error_1$1.MongoAPIError(
        "Cannot abort a stream that has already completed",
      );
    }
    if (this.state.aborted) {
      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed
      throw new error_1$1.MongoAPIError(
        "Cannot call abort() on a stream twice",
      );
    }
    this.state.aborted = true;
    await this.chunks.deleteMany({ files_id: this.id });
  }
};
upload.GridFSBucketWriteStream = GridFSBucketWriteStream$1;
function handleError(stream, error, callback) {
  if (stream.state.errored) {
    process.nextTick(callback);
    return;
  }
  stream.state.errored = true;
  process.nextTick(callback, error);
}
function createChunkDoc(filesId, n, data) {
  return {
    _id: new bson_1$1.ObjectId(),
    files_id: filesId,
    n,
    data,
  };
}
async function checkChunksIndex(stream) {
  const index = { files_id: 1, n: 1 };
  let indexes;
  try {
    indexes = await stream.chunks.listIndexes().toArray();
  } catch (error) {
    if (
      error instanceof error_1$1.MongoError &&
      error.code === error_1$1.MONGODB_ERROR_CODES.NamespaceNotFound
    ) {
      indexes = [];
    } else {
      throw error;
    }
  }
  const hasChunksIndex = !!indexes.find((index) => {
    const keys = Object.keys(index.key);
    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {
      return true;
    }
    return false;
  });
  if (!hasChunksIndex) {
    await stream.chunks.createIndex(index, {
      ...stream.writeConcern,
      background: true,
      unique: true,
    });
  }
}
function checkDone(stream, callback) {
  if (stream.done) {
    return process.nextTick(callback);
  }
  if (
    stream.state.streamEnd &&
    stream.state.outstandingRequests === 0 &&
    !stream.state.errored
  ) {
    // Set done so we do not trigger duplicate createFilesDoc
    stream.done = true;
    // Create a new files doc
    const gridFSFile = createFilesDoc(
      stream.id,
      stream.length,
      stream.chunkSizeBytes,
      stream.filename,
      stream.options.contentType,
      stream.options.aliases,
      stream.options.metadata,
    );
    if (isAborted(stream, callback)) {
      return;
    }
    stream.files
      .insertOne(gridFSFile, { writeConcern: stream.writeConcern })
      .then(
        () => {
          stream.gridFSFile = gridFSFile;
          callback();
        },
        (error) => handleError(stream, error, callback),
      );
    return;
  }
  process.nextTick(callback);
}
async function checkIndexes(stream) {
  const doc = await stream.files.findOne({}, { projection: { _id: 1 } });
  if (doc != null) {
    // If at least one document exists assume the collection has the required index
    return;
  }
  const index = { filename: 1, uploadDate: 1 };
  let indexes;
  try {
    indexes = await stream.files.listIndexes().toArray();
  } catch (error) {
    if (
      error instanceof error_1$1.MongoError &&
      error.code === error_1$1.MONGODB_ERROR_CODES.NamespaceNotFound
    ) {
      indexes = [];
    } else {
      throw error;
    }
  }
  const hasFileIndex = !!indexes.find((index) => {
    const keys = Object.keys(index.key);
    if (
      keys.length === 2 &&
      index.key.filename === 1 &&
      index.key.uploadDate === 1
    ) {
      return true;
    }
    return false;
  });
  if (!hasFileIndex) {
    await stream.files.createIndex(index, { background: false });
  }
  await checkChunksIndex(stream);
}
function createFilesDoc(
  _id,
  length,
  chunkSize,
  filename,
  contentType,
  aliases,
  metadata,
) {
  const ret = {
    _id,
    length,
    chunkSize,
    uploadDate: new Date(),
    filename,
  };
  if (contentType) {
    ret.contentType = contentType;
  }
  if (aliases) {
    ret.aliases = aliases;
  }
  if (metadata) {
    ret.metadata = metadata;
  }
  return ret;
}
function doWrite(stream, chunk, encoding, callback) {
  if (isAborted(stream, callback)) {
    return;
  }
  const inputBuf = Buffer.isBuffer(chunk)
    ? chunk
    : Buffer.from(chunk, encoding);
  stream.length += inputBuf.length;
  // Input is small enough to fit in our buffer
  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {
    inputBuf.copy(stream.bufToStore, stream.pos);
    stream.pos += inputBuf.length;
    process.nextTick(callback);
    return;
  }
  // Otherwise, buffer is too big for current chunk, so we need to flush
  // to MongoDB.
  let inputBufRemaining = inputBuf.length;
  let spaceRemaining = stream.chunkSizeBytes - stream.pos;
  let numToCopy = Math.min(spaceRemaining, inputBuf.length);
  let outstandingRequests = 0;
  while (inputBufRemaining > 0) {
    const inputBufPos = inputBuf.length - inputBufRemaining;
    inputBuf.copy(
      stream.bufToStore,
      stream.pos,
      inputBufPos,
      inputBufPos + numToCopy,
    );
    stream.pos += numToCopy;
    spaceRemaining -= numToCopy;
    let doc;
    if (spaceRemaining === 0) {
      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));
      ++stream.state.outstandingRequests;
      ++outstandingRequests;
      if (isAborted(stream, callback)) {
        return;
      }
      stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(
        () => {
          --stream.state.outstandingRequests;
          --outstandingRequests;
          if (!outstandingRequests) {
            checkDone(stream, callback);
          }
        },
        (error) => handleError(stream, error, callback),
      );
      spaceRemaining = stream.chunkSizeBytes;
      stream.pos = 0;
      ++stream.n;
    }
    inputBufRemaining -= numToCopy;
    numToCopy = Math.min(spaceRemaining, inputBufRemaining);
  }
}
function writeRemnant(stream, callback) {
  // Buffer is empty, so don't bother to insert
  if (stream.pos === 0) {
    return checkDone(stream, callback);
  }
  ++stream.state.outstandingRequests;
  // Create a new buffer to make sure the buffer isn't bigger than it needs
  // to be.
  const remnant = Buffer.alloc(stream.pos);
  stream.bufToStore.copy(remnant, 0, 0, stream.pos);
  const doc = createChunkDoc(stream.id, stream.n, remnant);
  // If the stream was aborted, do not write remnant
  if (isAborted(stream, callback)) {
    return;
  }
  stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(
    () => {
      --stream.state.outstandingRequests;
      checkDone(stream, callback);
    },
    (error) => handleError(stream, error, callback),
  );
}
function isAborted(stream, callback) {
  if (stream.state.aborted) {
    process.nextTick(
      callback,
      new error_1$1.MongoAPIError("Stream has been aborted"),
    );
    return true;
  }
  return false;
}

Object.defineProperty(gridfs, "__esModule", { value: true });
gridfs.GridFSBucket = void 0;
const error_1 = error;
const mongo_types_1 = mongo_types;
const write_concern_1 = write_concern;
const download_1 = download;
const upload_1 = upload;
const DEFAULT_GRIDFS_BUCKET_OPTIONS = {
  bucketName: "fs",
  chunkSizeBytes: 255 * 1024,
};
/**
 * Constructor for a streaming GridFS interface
 * @public
 */
let GridFSBucket$1 = class GridFSBucket extends mongo_types_1.TypedEventEmitter {
  constructor(db, options) {
    super();
    this.setMaxListeners(0);
    const privateOptions = {
      ...DEFAULT_GRIDFS_BUCKET_OPTIONS,
      ...options,
      writeConcern: write_concern_1.WriteConcern.fromOptions(options),
    };
    this.s = {
      db,
      options: privateOptions,
      _chunksCollection: db.collection(privateOptions.bucketName + ".chunks"),
      _filesCollection: db.collection(privateOptions.bucketName + ".files"),
      checkedIndexes: false,
      calledOpenUploadStream: false,
    };
  }
  /**
   * Returns a writable stream (GridFSBucketWriteStream) for writing
   * buffers to GridFS. The stream's 'id' property contains the resulting
   * file's id.
   *
   * @param filename - The value of the 'filename' key in the files doc
   * @param options - Optional settings.
   */
  openUploadStream(filename, options) {
    return new upload_1.GridFSBucketWriteStream(this, filename, options);
  }
  /**
   * Returns a writable stream (GridFSBucketWriteStream) for writing
   * buffers to GridFS for a custom file id. The stream's 'id' property contains the resulting
   * file's id.
   */
  openUploadStreamWithId(id, filename, options) {
    return new upload_1.GridFSBucketWriteStream(this, filename, {
      ...options,
      id,
    });
  }
  /** Returns a readable stream (GridFSBucketReadStream) for streaming file data from GridFS. */
  openDownloadStream(id, options) {
    return new download_1.GridFSBucketReadStream(
      this.s._chunksCollection,
      this.s._filesCollection,
      this.s.options.readPreference,
      { _id: id },
      options,
    );
  }
  /**
   * Deletes a file with the given id
   *
   * @param id - The id of the file doc
   */
  async delete(id) {
    const { deletedCount } = await this.s._filesCollection.deleteOne({
      _id: id,
    });
    // Delete orphaned chunks before returning FileNotFound
    await this.s._chunksCollection.deleteMany({ files_id: id });
    if (deletedCount === 0) {
      // TODO(NODE-3483): Replace with more appropriate error
      // Consider creating new error MongoGridFSFileNotFoundError
      throw new error_1.MongoRuntimeError(`File not found for id ${id}`);
    }
  }
  /** Convenience wrapper around find on the files collection */
  find(filter = {}, options = {}) {
    return this.s._filesCollection.find(filter, options);
  }
  /**
   * Returns a readable stream (GridFSBucketReadStream) for streaming the
   * file with the given name from GridFS. If there are multiple files with
   * the same name, this will stream the most recent file with the given name
   * (as determined by the `uploadDate` field). You can set the `revision`
   * option to change this behavior.
   */
  openDownloadStreamByName(filename, options) {
    let sort = { uploadDate: -1 };
    let skip = undefined;
    if (options && options.revision != null) {
      if (options.revision >= 0) {
        sort = { uploadDate: 1 };
        skip = options.revision;
      } else {
        skip = -options.revision - 1;
      }
    }
    return new download_1.GridFSBucketReadStream(
      this.s._chunksCollection,
      this.s._filesCollection,
      this.s.options.readPreference,
      { filename },
      { ...options, sort, skip },
    );
  }
  /**
   * Renames the file with the given _id to the given string
   *
   * @param id - the id of the file to rename
   * @param filename - new name for the file
   */
  async rename(id, filename) {
    const filter = { _id: id };
    const update = { $set: { filename } };
    const { matchedCount } = await this.s._filesCollection.updateOne(
      filter,
      update,
    );
    if (matchedCount === 0) {
      throw new error_1.MongoRuntimeError(`File with id ${id} not found`);
    }
  }
  /** Removes this bucket's files collection, followed by its chunks collection. */
  async drop() {
    await this.s._filesCollection.drop();
    await this.s._chunksCollection.drop();
  }
};
/**
 * When the first call to openUploadStream is made, the upload stream will
 * check to see if it needs to create the proper indexes on the chunks and
 * files collections. This event is fired either when 1) it determines that
 * no index creation is necessary, 2) when it successfully creates the
 * necessary indexes.
 * @event
 */
GridFSBucket$1.INDEX = "index";
gridfs.GridFSBucket = GridFSBucket$1;

var client_encryption = {};

Object.defineProperty(client_encryption, "__esModule", { value: true });
client_encryption.ClientEncryption = void 0;
const bson_1 = bson$2;
const deps_1 = deps;
const utils_1 = utils$2;
const cryptoCallbacks = crypto_callbacks;
const errors_1 = errors$1;
const index_1 = providers;
const state_machine_1 = state_machine;
/**
 * @public
 * The public interface for explicit in-use encryption
 */
let ClientEncryption$1 = class ClientEncryption {
  /** @internal */
  static getMongoCrypt() {
    const encryption = (0, deps_1.getMongoDBClientEncryption)();
    if ("kModuleError" in encryption) {
      throw encryption.kModuleError;
    }
    return encryption.MongoCrypt;
  }
  /**
   * Create a new encryption instance
   *
   * @example
   * ```ts
   * new ClientEncryption(mongoClient, {
   *   keyVaultNamespace: 'client.encryption',
   *   kmsProviders: {
   *     local: {
   *       key: masterKey // The master key used for encryption/decryption. A 96-byte long Buffer
   *     }
   *   }
   * });
   * ```
   *
   * @example
   * ```ts
   * new ClientEncryption(mongoClient, {
   *   keyVaultNamespace: 'client.encryption',
   *   kmsProviders: {
   *     aws: {
   *       accessKeyId: AWS_ACCESS_KEY,
   *       secretAccessKey: AWS_SECRET_KEY
   *     }
   *   }
   * });
   * ```
   */
  constructor(client, options) {
    this._client = client;
    this._proxyOptions = options.proxyOptions ?? {};
    this._tlsOptions = options.tlsOptions ?? {};
    this._kmsProviders = options.kmsProviders || {};
    if (options.keyVaultNamespace == null) {
      throw new errors_1.MongoCryptInvalidArgumentError(
        "Missing required option `keyVaultNamespace`",
      );
    }
    const mongoCryptOptions = {
      ...options,
      cryptoCallbacks,
      kmsProviders: !Buffer.isBuffer(this._kmsProviders)
        ? (0, bson_1.serialize)(this._kmsProviders)
        : this._kmsProviders,
    };
    this._keyVaultNamespace = options.keyVaultNamespace;
    this._keyVaultClient = options.keyVaultClient || client;
    const MongoCrypt = ClientEncryption.getMongoCrypt();
    this._mongoCrypt = new MongoCrypt(mongoCryptOptions);
  }
  /**
   * Creates a data key used for explicit encryption and inserts it into the key vault namespace
   *
   * @example
   * ```ts
   * // Using async/await to create a local key
   * const dataKeyId = await clientEncryption.createDataKey('local');
   * ```
   *
   * @example
   * ```ts
   * // Using async/await to create an aws key
   * const dataKeyId = await clientEncryption.createDataKey('aws', {
   *   masterKey: {
   *     region: 'us-east-1',
   *     key: 'xxxxxxxxxxxxxx' // CMK ARN here
   *   }
   * });
   * ```
   *
   * @example
   * ```ts
   * // Using async/await to create an aws key with a keyAltName
   * const dataKeyId = await clientEncryption.createDataKey('aws', {
   *   masterKey: {
   *     region: 'us-east-1',
   *     key: 'xxxxxxxxxxxxxx' // CMK ARN here
   *   },
   *   keyAltNames: [ 'mySpecialKey' ]
   * });
   * ```
   */
  async createDataKey(provider, options = {}) {
    if (options.keyAltNames && !Array.isArray(options.keyAltNames)) {
      throw new errors_1.MongoCryptInvalidArgumentError(
        `Option "keyAltNames" must be an array of strings, but was of type ${typeof options.keyAltNames}.`,
      );
    }
    let keyAltNames = undefined;
    if (options.keyAltNames && options.keyAltNames.length > 0) {
      keyAltNames = options.keyAltNames.map((keyAltName, i) => {
        if (typeof keyAltName !== "string") {
          throw new errors_1.MongoCryptInvalidArgumentError(
            `Option "keyAltNames" must be an array of strings, but item at index ${i} was of type ${typeof keyAltName}`,
          );
        }
        return (0, bson_1.serialize)({ keyAltName });
      });
    }
    let keyMaterial = undefined;
    if (options.keyMaterial) {
      keyMaterial = (0, bson_1.serialize)({ keyMaterial: options.keyMaterial });
    }
    const dataKeyBson = (0, bson_1.serialize)({
      provider,
      ...options.masterKey,
    });
    const context = this._mongoCrypt.makeDataKeyContext(dataKeyBson, {
      keyAltNames,
      keyMaterial,
    });
    const stateMachine = new state_machine_1.StateMachine({
      proxyOptions: this._proxyOptions,
      tlsOptions: this._tlsOptions,
    });
    const dataKey = await stateMachine.execute(this, context);
    const { db: dbName, collection: collectionName } =
      utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);
    const { insertedId } = await this._keyVaultClient
      .db(dbName)
      .collection(collectionName)
      .insertOne(dataKey, { writeConcern: { w: "majority" } });
    return insertedId;
  }
  /**
   * Searches the keyvault for any data keys matching the provided filter.  If there are matches, rewrapManyDataKey then attempts to re-wrap the data keys using the provided options.
   *
   * If no matches are found, then no bulk write is performed.
   *
   * @example
   * ```ts
   * // rewrapping all data data keys (using a filter that matches all documents)
   * const filter = {};
   *
   * const result = await clientEncryption.rewrapManyDataKey(filter);
   * if (result.bulkWriteResult != null) {
   *  // keys were re-wrapped, results will be available in the bulkWrite object.
   * }
   * ```
   *
   * @example
   * ```ts
   * // attempting to rewrap all data keys with no matches
   * const filter = { _id: new Binary() } // assume _id matches no documents in the database
   * const result = await clientEncryption.rewrapManyDataKey(filter);
   *
   * if (result.bulkWriteResult == null) {
   *  // no keys matched, `bulkWriteResult` does not exist on the result object
   * }
   * ```
   */
  async rewrapManyDataKey(filter, options) {
    let keyEncryptionKeyBson = undefined;
    if (options) {
      const keyEncryptionKey = Object.assign(
        { provider: options.provider },
        options.masterKey,
      );
      keyEncryptionKeyBson = (0, bson_1.serialize)(keyEncryptionKey);
    }
    const filterBson = (0, bson_1.serialize)(filter);
    const context = this._mongoCrypt.makeRewrapManyDataKeyContext(
      filterBson,
      keyEncryptionKeyBson,
    );
    const stateMachine = new state_machine_1.StateMachine({
      proxyOptions: this._proxyOptions,
      tlsOptions: this._tlsOptions,
    });
    const { v: dataKeys } = await stateMachine.execute(this, context);
    if (dataKeys.length === 0) {
      return {};
    }
    const { db: dbName, collection: collectionName } =
      utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);
    const replacements = dataKeys.map((key) => ({
      updateOne: {
        filter: { _id: key._id },
        update: {
          $set: {
            masterKey: key.masterKey,
            keyMaterial: key.keyMaterial,
          },
          $currentDate: {
            updateDate: true,
          },
        },
      },
    }));
    const result = await this._keyVaultClient
      .db(dbName)
      .collection(collectionName)
      .bulkWrite(replacements, {
        writeConcern: { w: "majority" },
      });
    return { bulkWriteResult: result };
  }
  /**
   * Deletes the key with the provided id from the keyvault, if it exists.
   *
   * @example
   * ```ts
   * // delete a key by _id
   * const id = new Binary(); // id is a bson binary subtype 4 object
   * const { deletedCount } = await clientEncryption.deleteKey(id);
   *
   * if (deletedCount != null && deletedCount > 0) {
   *   // successful deletion
   * }
   * ```
   *
   */
  async deleteKey(_id) {
    const { db: dbName, collection: collectionName } =
      utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);
    return this._keyVaultClient
      .db(dbName)
      .collection(collectionName)
      .deleteOne({ _id }, { writeConcern: { w: "majority" } });
  }
  /**
   * Finds all the keys currently stored in the keyvault.
   *
   * This method will not throw.
   *
   * @returns a FindCursor over all keys in the keyvault.
   * @example
   * ```ts
   * // fetching all keys
   * const keys = await clientEncryption.getKeys().toArray();
   * ```
   */
  getKeys() {
    const { db: dbName, collection: collectionName } =
      utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);
    return this._keyVaultClient
      .db(dbName)
      .collection(collectionName)
      .find({}, { readConcern: { level: "majority" } });
  }
  /**
   * Finds a key in the keyvault with the specified _id.
   *
   * Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents
   * match the id.  The promise rejects with an error if an error is thrown.
   * @example
   * ```ts
   * // getting a key by id
   * const id = new Binary(); // id is a bson binary subtype 4 object
   * const key = await clientEncryption.getKey(id);
   * if (!key) {
   *  // key is null if there was no matching key
   * }
   * ```
   */
  async getKey(_id) {
    const { db: dbName, collection: collectionName } =
      utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);
    return this._keyVaultClient
      .db(dbName)
      .collection(collectionName)
      .findOne({ _id }, { readConcern: { level: "majority" } });
  }
  /**
   * Finds a key in the keyvault which has the specified keyAltName.
   *
   * @param keyAltName - a keyAltName to search for a key
   * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents
   * match the keyAltName.  The promise rejects with an error if an error is thrown.
   * @example
   * ```ts
   * // get a key by alt name
   * const keyAltName = 'keyAltName';
   * const key = await clientEncryption.getKeyByAltName(keyAltName);
   * if (!key) {
   *  // key is null if there is no matching key
   * }
   * ```
   */
  async getKeyByAltName(keyAltName) {
    const { db: dbName, collection: collectionName } =
      utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);
    return this._keyVaultClient
      .db(dbName)
      .collection(collectionName)
      .findOne(
        { keyAltNames: keyAltName },
        { readConcern: { level: "majority" } },
      );
  }
  /**
   * Adds a keyAltName to a key identified by the provided _id.
   *
   * This method resolves to/returns the *old* key value (prior to adding the new altKeyName).
   *
   * @param _id - The id of the document to update.
   * @param keyAltName - a keyAltName to search for a key
   * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents
   * match the id.  The promise rejects with an error if an error is thrown.
   * @example
   * ```ts
   * // adding an keyAltName to a data key
   * const id = new Binary();  // id is a bson binary subtype 4 object
   * const keyAltName = 'keyAltName';
   * const oldKey = await clientEncryption.addKeyAltName(id, keyAltName);
   * if (!oldKey) {
   *  // null is returned if there is no matching document with an id matching the supplied id
   * }
   * ```
   */
  async addKeyAltName(_id, keyAltName) {
    const { db: dbName, collection: collectionName } =
      utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);
    const value = await this._keyVaultClient
      .db(dbName)
      .collection(collectionName)
      .findOneAndUpdate(
        { _id },
        { $addToSet: { keyAltNames: keyAltName } },
        { writeConcern: { w: "majority" }, returnDocument: "before" },
      );
    return value;
  }
  /**
   * Adds a keyAltName to a key identified by the provided _id.
   *
   * This method resolves to/returns the *old* key value (prior to removing the new altKeyName).
   *
   * If the removed keyAltName is the last keyAltName for that key, the `altKeyNames` property is unset from the document.
   *
   * @param _id - The id of the document to update.
   * @param keyAltName - a keyAltName to search for a key
   * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents
   * match the id.  The promise rejects with an error if an error is thrown.
   * @example
   * ```ts
   * // removing a key alt name from a data key
   * const id = new Binary();  // id is a bson binary subtype 4 object
   * const keyAltName = 'keyAltName';
   * const oldKey = await clientEncryption.removeKeyAltName(id, keyAltName);
   *
   * if (!oldKey) {
   *  // null is returned if there is no matching document with an id matching the supplied id
   * }
   * ```
   */
  async removeKeyAltName(_id, keyAltName) {
    const { db: dbName, collection: collectionName } =
      utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);
    const pipeline = [
      {
        $set: {
          keyAltNames: {
            $cond: [
              {
                $eq: ["$keyAltNames", [keyAltName]],
              },
              "$$REMOVE",
              {
                $filter: {
                  input: "$keyAltNames",
                  cond: {
                    $ne: ["$$this", keyAltName],
                  },
                },
              },
            ],
          },
        },
      },
    ];
    const value = await this._keyVaultClient
      .db(dbName)
      .collection(collectionName)
      .findOneAndUpdate({ _id }, pipeline, {
        writeConcern: { w: "majority" },
        returnDocument: "before",
      });
    return value;
  }
  /**
   * A convenience method for creating an encrypted collection.
   * This method will create data keys for any encryptedFields that do not have a `keyId` defined
   * and then create a new collection with the full set of encryptedFields.
   *
   * @param db - A Node.js driver Db object with which to create the collection
   * @param name - The name of the collection to be created
   * @param options - Options for createDataKey and for createCollection
   * @returns created collection and generated encryptedFields
   * @throws MongoCryptCreateDataKeyError - If part way through the process a createDataKey invocation fails, an error will be rejected that has the partial `encryptedFields` that were created.
   * @throws MongoCryptCreateEncryptedCollectionError - If creating the collection fails, an error will be rejected that has the entire `encryptedFields` that were created.
   */
  async createEncryptedCollection(db, name, options) {
    const {
      provider,
      masterKey,
      createCollectionOptions: {
        encryptedFields: { ...encryptedFields },
        ...createCollectionOptions
      },
    } = options;
    if (Array.isArray(encryptedFields.fields)) {
      const createDataKeyPromises = encryptedFields.fields.map(async (field) =>
        field == null || typeof field !== "object" || field.keyId != null
          ? field
          : {
              ...field,
              keyId: await this.createDataKey(provider, { masterKey }),
            },
      );
      const createDataKeyResolutions = await Promise.allSettled(
        createDataKeyPromises,
      );
      encryptedFields.fields = createDataKeyResolutions.map(
        (resolution, index) =>
          resolution.status === "fulfilled"
            ? resolution.value
            : encryptedFields.fields[index],
      );
      const rejection = createDataKeyResolutions.find(
        (result) => result.status === "rejected",
      );
      if (rejection != null) {
        throw new errors_1.MongoCryptCreateDataKeyError(encryptedFields, {
          cause: rejection.reason,
        });
      }
    }
    try {
      const collection = await db.createCollection(name, {
        ...createCollectionOptions,
        encryptedFields,
      });
      return { collection, encryptedFields };
    } catch (cause) {
      throw new errors_1.MongoCryptCreateEncryptedCollectionError(
        encryptedFields,
        { cause },
      );
    }
  }
  /**
   * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must
   * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.
   *
   * @param value - The value that you wish to serialize. Must be of a type that can be serialized into BSON
   * @param options -
   * @returns a Promise that either resolves with the encrypted value, or rejects with an error.
   *
   * @example
   * ```ts
   * // Encryption with async/await api
   * async function encryptMyData(value) {
   *   const keyId = await clientEncryption.createDataKey('local');
   *   return clientEncryption.encrypt(value, { keyId, algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });
   * }
   * ```
   *
   * @example
   * ```ts
   * // Encryption using a keyAltName
   * async function encryptMyData(value) {
   *   await clientEncryption.createDataKey('local', { keyAltNames: 'mySpecialKey' });
   *   return clientEncryption.encrypt(value, { keyAltName: 'mySpecialKey', algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });
   * }
   * ```
   */
  async encrypt(value, options) {
    return this._encrypt(value, false, options);
  }
  /**
   * Encrypts a Match Expression or Aggregate Expression to query a range index.
   *
   * Only supported when queryType is "rangePreview" and algorithm is "RangePreview".
   *
   * @experimental The Range algorithm is experimental only. It is not intended for production use. It is subject to breaking changes.
   *
   * @param expression - a BSON document of one of the following forms:
   *  1. A Match Expression of this form:
   *      `{$and: [{<field>: {$gt: <value1>}}, {<field>: {$lt: <value2> }}]}`
   *  2. An Aggregate Expression of this form:
   *      `{$and: [{$gt: [<fieldpath>, <value1>]}, {$lt: [<fieldpath>, <value2>]}]}`
   *
   *    `$gt` may also be `$gte`. `$lt` may also be `$lte`.
   *
   * @param options -
   * @returns Returns a Promise that either resolves with the encrypted value or rejects with an error.
   */
  async encryptExpression(expression, options) {
    return this._encrypt(expression, true, options);
  }
  /**
   * Explicitly decrypt a provided encrypted value
   *
   * @param value - An encrypted value
   * @returns a Promise that either resolves with the decrypted value, or rejects with an error
   *
   * @example
   * ```ts
   * // Decrypting value with async/await API
   * async function decryptMyValue(value) {
   *   return clientEncryption.decrypt(value);
   * }
   * ```
   */
  async decrypt(value) {
    const valueBuffer = (0, bson_1.serialize)({ v: value });
    const context = this._mongoCrypt.makeExplicitDecryptionContext(valueBuffer);
    const stateMachine = new state_machine_1.StateMachine({
      proxyOptions: this._proxyOptions,
      tlsOptions: this._tlsOptions,
    });
    const { v } = await stateMachine.execute(this, context);
    return v;
  }
  /**
   * @internal
   * Ask the user for KMS credentials.
   *
   * This returns anything that looks like the kmsProviders original input
   * option. It can be empty, and any provider specified here will override
   * the original ones.
   */
  async askForKMSCredentials() {
    return (0, index_1.refreshKMSCredentials)(this._kmsProviders);
  }
  static get libmongocryptVersion() {
    return ClientEncryption.getMongoCrypt().libmongocryptVersion;
  }
  /**
   * @internal
   * A helper that perform explicit encryption of values and expressions.
   * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must
   * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.
   *
   * @param value - The value that you wish to encrypt. Must be of a type that can be serialized into BSON
   * @param expressionMode - a boolean that indicates whether or not to encrypt the value as an expression
   * @param options - options to pass to encrypt
   * @returns the raw result of the call to stateMachine.execute().  When expressionMode is set to true, the return
   *          value will be a bson document.  When false, the value will be a BSON Binary.
   *
   */
  async _encrypt(value, expressionMode, options) {
    const {
      algorithm,
      keyId,
      keyAltName,
      contentionFactor,
      queryType,
      rangeOptions,
    } = options;
    const contextOptions = {
      expressionMode,
      algorithm,
    };
    if (keyId) {
      contextOptions.keyId = keyId.buffer;
    }
    if (keyAltName) {
      if (keyId) {
        throw new errors_1.MongoCryptInvalidArgumentError(
          `"options" cannot contain both "keyId" and "keyAltName"`,
        );
      }
      if (typeof keyAltName !== "string") {
        throw new errors_1.MongoCryptInvalidArgumentError(
          `"options.keyAltName" must be of type string, but was of type ${typeof keyAltName}`,
        );
      }
      contextOptions.keyAltName = (0, bson_1.serialize)({ keyAltName });
    }
    if (
      typeof contentionFactor === "number" ||
      typeof contentionFactor === "bigint"
    ) {
      contextOptions.contentionFactor = contentionFactor;
    }
    if (typeof queryType === "string") {
      contextOptions.queryType = queryType;
    }
    if (typeof rangeOptions === "object") {
      contextOptions.rangeOptions = (0, bson_1.serialize)(rangeOptions);
    }
    const valueBuffer = (0, bson_1.serialize)({ v: value });
    const stateMachine = new state_machine_1.StateMachine({
      proxyOptions: this._proxyOptions,
      tlsOptions: this._tlsOptions,
    });
    const context = this._mongoCrypt.makeExplicitEncryptionContext(
      valueBuffer,
      contextOptions,
    );
    const result = await stateMachine.execute(this, context);
    return result.v;
  }
};
client_encryption.ClientEncryption = ClientEncryption$1;

(function (exports) {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.MongoUnexpectedServerResponseError =
    exports.MongoTransactionError =
    exports.MongoTopologyClosedError =
    exports.MongoTailableCursorError =
    exports.MongoSystemError =
    exports.MongoServerSelectionError =
    exports.MongoServerError =
    exports.MongoServerClosedError =
    exports.MongoRuntimeError =
    exports.MongoParseError =
    exports.MongoNotConnectedError =
    exports.MongoNetworkTimeoutError =
    exports.MongoNetworkError =
    exports.MongoMissingDependencyError =
    exports.MongoMissingCredentialsError =
    exports.MongoKerberosError =
    exports.MongoInvalidArgumentError =
    exports.MongoGridFSStreamError =
    exports.MongoGridFSChunkError =
    exports.MongoExpiredSessionError =
    exports.MongoError =
    exports.MongoDriverError =
    exports.MongoDecompressionError =
    exports.MongoCursorInUseError =
    exports.MongoCursorExhaustedError =
    exports.MongoCompatibilityError =
    exports.MongoChangeStreamError =
    exports.MongoBatchReExecutionError =
    exports.MongoAzureError =
    exports.MongoAWSError =
    exports.MongoAPIError =
    exports.ChangeStreamCursor =
    exports.ClientEncryption =
    exports.MongoBulkWriteError =
    exports.UUID =
    exports.Timestamp =
    exports.ObjectId =
    exports.MinKey =
    exports.MaxKey =
    exports.Long =
    exports.Int32 =
    exports.Double =
    exports.Decimal128 =
    exports.DBRef =
    exports.Code =
    exports.BSONType =
    exports.BSONSymbol =
    exports.BSONRegExp =
    exports.Binary =
    exports.BSON =
      void 0;
  exports.ConnectionPoolReadyEvent =
    exports.ConnectionPoolMonitoringEvent =
    exports.ConnectionPoolCreatedEvent =
    exports.ConnectionPoolClosedEvent =
    exports.ConnectionPoolClearedEvent =
    exports.ConnectionCreatedEvent =
    exports.ConnectionClosedEvent =
    exports.ConnectionCheckOutStartedEvent =
    exports.ConnectionCheckOutFailedEvent =
    exports.ConnectionCheckedOutEvent =
    exports.ConnectionCheckedInEvent =
    exports.CommandSucceededEvent =
    exports.CommandStartedEvent =
    exports.CommandFailedEvent =
    exports.WriteConcern =
    exports.ReadPreference =
    exports.ReadConcern =
    exports.TopologyType =
    exports.ServerType =
    exports.ReadPreferenceMode =
    exports.ReadConcernLevel =
    exports.ProfilingLevel =
    exports.ReturnDocument =
    exports.ServerApiVersion =
    exports.ExplainVerbosity =
    exports.MongoErrorLabel =
    exports.CURSOR_FLAGS =
    exports.Compressor =
    exports.AuthMechanism =
    exports.GSSAPICanonicalizationValue =
    exports.AutoEncryptionLoggerLevel =
    exports.BatchType =
    exports.UnorderedBulkOperation =
    exports.OrderedBulkOperation =
    exports.MongoClient =
    exports.ListIndexesCursor =
    exports.ListCollectionsCursor =
    exports.GridFSBucketWriteStream =
    exports.GridFSBucketReadStream =
    exports.GridFSBucket =
    exports.FindCursor =
    exports.Db =
    exports.Collection =
    exports.ClientSession =
    exports.ChangeStream =
    exports.CancellationToken =
    exports.AggregationCursor =
    exports.Admin =
    exports.AbstractCursor =
    exports.MongoWriteConcernError =
      void 0;
  exports.MongoCryptKMSRequestNetworkTimeoutError =
    exports.MongoCryptInvalidArgumentError =
    exports.MongoCryptError =
    exports.MongoCryptCreateEncryptedCollectionError =
    exports.MongoCryptCreateDataKeyError =
    exports.MongoCryptAzureKMSRequestError =
    exports.SrvPollingEvent =
    exports.TopologyOpeningEvent =
    exports.TopologyDescriptionChangedEvent =
    exports.TopologyClosedEvent =
    exports.ServerOpeningEvent =
    exports.ServerHeartbeatSucceededEvent =
    exports.ServerHeartbeatStartedEvent =
    exports.ServerHeartbeatFailedEvent =
    exports.ServerDescriptionChangedEvent =
    exports.ServerClosedEvent =
    exports.ConnectionReadyEvent =
      void 0;
  const admin_1 = admin;
  Object.defineProperty(exports, "Admin", {
    enumerable: true,
    get: function () {
      return admin_1.Admin;
    },
  });
  const ordered_1 = ordered;
  Object.defineProperty(exports, "OrderedBulkOperation", {
    enumerable: true,
    get: function () {
      return ordered_1.OrderedBulkOperation;
    },
  });
  const unordered_1 = unordered;
  Object.defineProperty(exports, "UnorderedBulkOperation", {
    enumerable: true,
    get: function () {
      return unordered_1.UnorderedBulkOperation;
    },
  });
  const change_stream_1 = requireChange_stream();
  Object.defineProperty(exports, "ChangeStream", {
    enumerable: true,
    get: function () {
      return change_stream_1.ChangeStream;
    },
  });
  const collection_1 = requireCollection();
  Object.defineProperty(exports, "Collection", {
    enumerable: true,
    get: function () {
      return collection_1.Collection;
    },
  });
  const abstract_cursor_1 = abstract_cursor;
  Object.defineProperty(exports, "AbstractCursor", {
    enumerable: true,
    get: function () {
      return abstract_cursor_1.AbstractCursor;
    },
  });
  const aggregation_cursor_1 = aggregation_cursor;
  Object.defineProperty(exports, "AggregationCursor", {
    enumerable: true,
    get: function () {
      return aggregation_cursor_1.AggregationCursor;
    },
  });
  const find_cursor_1 = find_cursor;
  Object.defineProperty(exports, "FindCursor", {
    enumerable: true,
    get: function () {
      return find_cursor_1.FindCursor;
    },
  });
  const list_collections_cursor_1 = list_collections_cursor;
  Object.defineProperty(exports, "ListCollectionsCursor", {
    enumerable: true,
    get: function () {
      return list_collections_cursor_1.ListCollectionsCursor;
    },
  });
  const list_indexes_cursor_1 = list_indexes_cursor;
  Object.defineProperty(exports, "ListIndexesCursor", {
    enumerable: true,
    get: function () {
      return list_indexes_cursor_1.ListIndexesCursor;
    },
  });
  const db_1 = requireDb();
  Object.defineProperty(exports, "Db", {
    enumerable: true,
    get: function () {
      return db_1.Db;
    },
  });
  const gridfs_1 = gridfs;
  Object.defineProperty(exports, "GridFSBucket", {
    enumerable: true,
    get: function () {
      return gridfs_1.GridFSBucket;
    },
  });
  const download_1 = download;
  Object.defineProperty(exports, "GridFSBucketReadStream", {
    enumerable: true,
    get: function () {
      return download_1.GridFSBucketReadStream;
    },
  });
  const upload_1 = upload;
  Object.defineProperty(exports, "GridFSBucketWriteStream", {
    enumerable: true,
    get: function () {
      return upload_1.GridFSBucketWriteStream;
    },
  });
  const mongo_client_1 = requireMongo_client();
  Object.defineProperty(exports, "MongoClient", {
    enumerable: true,
    get: function () {
      return mongo_client_1.MongoClient;
    },
  });
  const mongo_types_1 = mongo_types;
  Object.defineProperty(exports, "CancellationToken", {
    enumerable: true,
    get: function () {
      return mongo_types_1.CancellationToken;
    },
  });
  const sessions_1 = sessions;
  Object.defineProperty(exports, "ClientSession", {
    enumerable: true,
    get: function () {
      return sessions_1.ClientSession;
    },
  });
  /** @public */
  var bson_1 = bson$2;
  Object.defineProperty(exports, "BSON", {
    enumerable: true,
    get: function () {
      return bson_1.BSON;
    },
  });
  var bson_2 = bson$2;
  Object.defineProperty(exports, "Binary", {
    enumerable: true,
    get: function () {
      return bson_2.Binary;
    },
  });
  Object.defineProperty(exports, "BSONRegExp", {
    enumerable: true,
    get: function () {
      return bson_2.BSONRegExp;
    },
  });
  Object.defineProperty(exports, "BSONSymbol", {
    enumerable: true,
    get: function () {
      return bson_2.BSONSymbol;
    },
  });
  Object.defineProperty(exports, "BSONType", {
    enumerable: true,
    get: function () {
      return bson_2.BSONType;
    },
  });
  Object.defineProperty(exports, "Code", {
    enumerable: true,
    get: function () {
      return bson_2.Code;
    },
  });
  Object.defineProperty(exports, "DBRef", {
    enumerable: true,
    get: function () {
      return bson_2.DBRef;
    },
  });
  Object.defineProperty(exports, "Decimal128", {
    enumerable: true,
    get: function () {
      return bson_2.Decimal128;
    },
  });
  Object.defineProperty(exports, "Double", {
    enumerable: true,
    get: function () {
      return bson_2.Double;
    },
  });
  Object.defineProperty(exports, "Int32", {
    enumerable: true,
    get: function () {
      return bson_2.Int32;
    },
  });
  Object.defineProperty(exports, "Long", {
    enumerable: true,
    get: function () {
      return bson_2.Long;
    },
  });
  Object.defineProperty(exports, "MaxKey", {
    enumerable: true,
    get: function () {
      return bson_2.MaxKey;
    },
  });
  Object.defineProperty(exports, "MinKey", {
    enumerable: true,
    get: function () {
      return bson_2.MinKey;
    },
  });
  Object.defineProperty(exports, "ObjectId", {
    enumerable: true,
    get: function () {
      return bson_2.ObjectId;
    },
  });
  Object.defineProperty(exports, "Timestamp", {
    enumerable: true,
    get: function () {
      return bson_2.Timestamp;
    },
  });
  Object.defineProperty(exports, "UUID", {
    enumerable: true,
    get: function () {
      return bson_2.UUID;
    },
  });
  var common_1 = common;
  Object.defineProperty(exports, "MongoBulkWriteError", {
    enumerable: true,
    get: function () {
      return common_1.MongoBulkWriteError;
    },
  });
  var client_encryption_1 = client_encryption;
  Object.defineProperty(exports, "ClientEncryption", {
    enumerable: true,
    get: function () {
      return client_encryption_1.ClientEncryption;
    },
  });
  var change_stream_cursor_1 = requireChange_stream_cursor();
  Object.defineProperty(exports, "ChangeStreamCursor", {
    enumerable: true,
    get: function () {
      return change_stream_cursor_1.ChangeStreamCursor;
    },
  });
  var error_1 = error;
  Object.defineProperty(exports, "MongoAPIError", {
    enumerable: true,
    get: function () {
      return error_1.MongoAPIError;
    },
  });
  Object.defineProperty(exports, "MongoAWSError", {
    enumerable: true,
    get: function () {
      return error_1.MongoAWSError;
    },
  });
  Object.defineProperty(exports, "MongoAzureError", {
    enumerable: true,
    get: function () {
      return error_1.MongoAzureError;
    },
  });
  Object.defineProperty(exports, "MongoBatchReExecutionError", {
    enumerable: true,
    get: function () {
      return error_1.MongoBatchReExecutionError;
    },
  });
  Object.defineProperty(exports, "MongoChangeStreamError", {
    enumerable: true,
    get: function () {
      return error_1.MongoChangeStreamError;
    },
  });
  Object.defineProperty(exports, "MongoCompatibilityError", {
    enumerable: true,
    get: function () {
      return error_1.MongoCompatibilityError;
    },
  });
  Object.defineProperty(exports, "MongoCursorExhaustedError", {
    enumerable: true,
    get: function () {
      return error_1.MongoCursorExhaustedError;
    },
  });
  Object.defineProperty(exports, "MongoCursorInUseError", {
    enumerable: true,
    get: function () {
      return error_1.MongoCursorInUseError;
    },
  });
  Object.defineProperty(exports, "MongoDecompressionError", {
    enumerable: true,
    get: function () {
      return error_1.MongoDecompressionError;
    },
  });
  Object.defineProperty(exports, "MongoDriverError", {
    enumerable: true,
    get: function () {
      return error_1.MongoDriverError;
    },
  });
  Object.defineProperty(exports, "MongoError", {
    enumerable: true,
    get: function () {
      return error_1.MongoError;
    },
  });
  Object.defineProperty(exports, "MongoExpiredSessionError", {
    enumerable: true,
    get: function () {
      return error_1.MongoExpiredSessionError;
    },
  });
  Object.defineProperty(exports, "MongoGridFSChunkError", {
    enumerable: true,
    get: function () {
      return error_1.MongoGridFSChunkError;
    },
  });
  Object.defineProperty(exports, "MongoGridFSStreamError", {
    enumerable: true,
    get: function () {
      return error_1.MongoGridFSStreamError;
    },
  });
  Object.defineProperty(exports, "MongoInvalidArgumentError", {
    enumerable: true,
    get: function () {
      return error_1.MongoInvalidArgumentError;
    },
  });
  Object.defineProperty(exports, "MongoKerberosError", {
    enumerable: true,
    get: function () {
      return error_1.MongoKerberosError;
    },
  });
  Object.defineProperty(exports, "MongoMissingCredentialsError", {
    enumerable: true,
    get: function () {
      return error_1.MongoMissingCredentialsError;
    },
  });
  Object.defineProperty(exports, "MongoMissingDependencyError", {
    enumerable: true,
    get: function () {
      return error_1.MongoMissingDependencyError;
    },
  });
  Object.defineProperty(exports, "MongoNetworkError", {
    enumerable: true,
    get: function () {
      return error_1.MongoNetworkError;
    },
  });
  Object.defineProperty(exports, "MongoNetworkTimeoutError", {
    enumerable: true,
    get: function () {
      return error_1.MongoNetworkTimeoutError;
    },
  });
  Object.defineProperty(exports, "MongoNotConnectedError", {
    enumerable: true,
    get: function () {
      return error_1.MongoNotConnectedError;
    },
  });
  Object.defineProperty(exports, "MongoParseError", {
    enumerable: true,
    get: function () {
      return error_1.MongoParseError;
    },
  });
  Object.defineProperty(exports, "MongoRuntimeError", {
    enumerable: true,
    get: function () {
      return error_1.MongoRuntimeError;
    },
  });
  Object.defineProperty(exports, "MongoServerClosedError", {
    enumerable: true,
    get: function () {
      return error_1.MongoServerClosedError;
    },
  });
  Object.defineProperty(exports, "MongoServerError", {
    enumerable: true,
    get: function () {
      return error_1.MongoServerError;
    },
  });
  Object.defineProperty(exports, "MongoServerSelectionError", {
    enumerable: true,
    get: function () {
      return error_1.MongoServerSelectionError;
    },
  });
  Object.defineProperty(exports, "MongoSystemError", {
    enumerable: true,
    get: function () {
      return error_1.MongoSystemError;
    },
  });
  Object.defineProperty(exports, "MongoTailableCursorError", {
    enumerable: true,
    get: function () {
      return error_1.MongoTailableCursorError;
    },
  });
  Object.defineProperty(exports, "MongoTopologyClosedError", {
    enumerable: true,
    get: function () {
      return error_1.MongoTopologyClosedError;
    },
  });
  Object.defineProperty(exports, "MongoTransactionError", {
    enumerable: true,
    get: function () {
      return error_1.MongoTransactionError;
    },
  });
  Object.defineProperty(exports, "MongoUnexpectedServerResponseError", {
    enumerable: true,
    get: function () {
      return error_1.MongoUnexpectedServerResponseError;
    },
  });
  Object.defineProperty(exports, "MongoWriteConcernError", {
    enumerable: true,
    get: function () {
      return error_1.MongoWriteConcernError;
    },
  });
  // enums
  var common_2 = common;
  Object.defineProperty(exports, "BatchType", {
    enumerable: true,
    get: function () {
      return common_2.BatchType;
    },
  });
  var auto_encrypter_1 = requireAuto_encrypter();
  Object.defineProperty(exports, "AutoEncryptionLoggerLevel", {
    enumerable: true,
    get: function () {
      return auto_encrypter_1.AutoEncryptionLoggerLevel;
    },
  });
  var gssapi_1 = gssapi;
  Object.defineProperty(exports, "GSSAPICanonicalizationValue", {
    enumerable: true,
    get: function () {
      return gssapi_1.GSSAPICanonicalizationValue;
    },
  });
  var providers_1 = providers$1;
  Object.defineProperty(exports, "AuthMechanism", {
    enumerable: true,
    get: function () {
      return providers_1.AuthMechanism;
    },
  });
  var compression_1 = compression;
  Object.defineProperty(exports, "Compressor", {
    enumerable: true,
    get: function () {
      return compression_1.Compressor;
    },
  });
  var abstract_cursor_2 = abstract_cursor;
  Object.defineProperty(exports, "CURSOR_FLAGS", {
    enumerable: true,
    get: function () {
      return abstract_cursor_2.CURSOR_FLAGS;
    },
  });
  var error_2 = error;
  Object.defineProperty(exports, "MongoErrorLabel", {
    enumerable: true,
    get: function () {
      return error_2.MongoErrorLabel;
    },
  });
  var explain_1 = explain;
  Object.defineProperty(exports, "ExplainVerbosity", {
    enumerable: true,
    get: function () {
      return explain_1.ExplainVerbosity;
    },
  });
  var mongo_client_2 = requireMongo_client();
  Object.defineProperty(exports, "ServerApiVersion", {
    enumerable: true,
    get: function () {
      return mongo_client_2.ServerApiVersion;
    },
  });
  var find_and_modify_1 = find_and_modify;
  Object.defineProperty(exports, "ReturnDocument", {
    enumerable: true,
    get: function () {
      return find_and_modify_1.ReturnDocument;
    },
  });
  var set_profiling_level_1 = set_profiling_level;
  Object.defineProperty(exports, "ProfilingLevel", {
    enumerable: true,
    get: function () {
      return set_profiling_level_1.ProfilingLevel;
    },
  });
  var read_concern_1 = read_concern;
  Object.defineProperty(exports, "ReadConcernLevel", {
    enumerable: true,
    get: function () {
      return read_concern_1.ReadConcernLevel;
    },
  });
  var read_preference_1 = read_preference;
  Object.defineProperty(exports, "ReadPreferenceMode", {
    enumerable: true,
    get: function () {
      return read_preference_1.ReadPreferenceMode;
    },
  });
  var common_3 = common$1;
  Object.defineProperty(exports, "ServerType", {
    enumerable: true,
    get: function () {
      return common_3.ServerType;
    },
  });
  Object.defineProperty(exports, "TopologyType", {
    enumerable: true,
    get: function () {
      return common_3.TopologyType;
    },
  });
  // Helper classes
  var read_concern_2 = read_concern;
  Object.defineProperty(exports, "ReadConcern", {
    enumerable: true,
    get: function () {
      return read_concern_2.ReadConcern;
    },
  });
  var read_preference_2 = read_preference;
  Object.defineProperty(exports, "ReadPreference", {
    enumerable: true,
    get: function () {
      return read_preference_2.ReadPreference;
    },
  });
  var write_concern_1 = write_concern;
  Object.defineProperty(exports, "WriteConcern", {
    enumerable: true,
    get: function () {
      return write_concern_1.WriteConcern;
    },
  });
  // events
  var command_monitoring_events_1 = command_monitoring_events;
  Object.defineProperty(exports, "CommandFailedEvent", {
    enumerable: true,
    get: function () {
      return command_monitoring_events_1.CommandFailedEvent;
    },
  });
  Object.defineProperty(exports, "CommandStartedEvent", {
    enumerable: true,
    get: function () {
      return command_monitoring_events_1.CommandStartedEvent;
    },
  });
  Object.defineProperty(exports, "CommandSucceededEvent", {
    enumerable: true,
    get: function () {
      return command_monitoring_events_1.CommandSucceededEvent;
    },
  });
  var connection_pool_events_1 = connection_pool_events;
  Object.defineProperty(exports, "ConnectionCheckedInEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionCheckedInEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionCheckedOutEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionCheckedOutEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionCheckOutFailedEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionCheckOutFailedEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionCheckOutStartedEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionCheckOutStartedEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionClosedEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionClosedEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionCreatedEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionCreatedEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionPoolClearedEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionPoolClearedEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionPoolClosedEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionPoolClosedEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionPoolCreatedEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionPoolCreatedEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionPoolMonitoringEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionPoolMonitoringEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionPoolReadyEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionPoolReadyEvent;
    },
  });
  Object.defineProperty(exports, "ConnectionReadyEvent", {
    enumerable: true,
    get: function () {
      return connection_pool_events_1.ConnectionReadyEvent;
    },
  });
  var events_1 = events;
  Object.defineProperty(exports, "ServerClosedEvent", {
    enumerable: true,
    get: function () {
      return events_1.ServerClosedEvent;
    },
  });
  Object.defineProperty(exports, "ServerDescriptionChangedEvent", {
    enumerable: true,
    get: function () {
      return events_1.ServerDescriptionChangedEvent;
    },
  });
  Object.defineProperty(exports, "ServerHeartbeatFailedEvent", {
    enumerable: true,
    get: function () {
      return events_1.ServerHeartbeatFailedEvent;
    },
  });
  Object.defineProperty(exports, "ServerHeartbeatStartedEvent", {
    enumerable: true,
    get: function () {
      return events_1.ServerHeartbeatStartedEvent;
    },
  });
  Object.defineProperty(exports, "ServerHeartbeatSucceededEvent", {
    enumerable: true,
    get: function () {
      return events_1.ServerHeartbeatSucceededEvent;
    },
  });
  Object.defineProperty(exports, "ServerOpeningEvent", {
    enumerable: true,
    get: function () {
      return events_1.ServerOpeningEvent;
    },
  });
  Object.defineProperty(exports, "TopologyClosedEvent", {
    enumerable: true,
    get: function () {
      return events_1.TopologyClosedEvent;
    },
  });
  Object.defineProperty(exports, "TopologyDescriptionChangedEvent", {
    enumerable: true,
    get: function () {
      return events_1.TopologyDescriptionChangedEvent;
    },
  });
  Object.defineProperty(exports, "TopologyOpeningEvent", {
    enumerable: true,
    get: function () {
      return events_1.TopologyOpeningEvent;
    },
  });
  var srv_polling_1 = srv_polling;
  Object.defineProperty(exports, "SrvPollingEvent", {
    enumerable: true,
    get: function () {
      return srv_polling_1.SrvPollingEvent;
    },
  });
  var errors_1 = errors$1;
  Object.defineProperty(exports, "MongoCryptAzureKMSRequestError", {
    enumerable: true,
    get: function () {
      return errors_1.MongoCryptAzureKMSRequestError;
    },
  });
  Object.defineProperty(exports, "MongoCryptCreateDataKeyError", {
    enumerable: true,
    get: function () {
      return errors_1.MongoCryptCreateDataKeyError;
    },
  });
  Object.defineProperty(exports, "MongoCryptCreateEncryptedCollectionError", {
    enumerable: true,
    get: function () {
      return errors_1.MongoCryptCreateEncryptedCollectionError;
    },
  });
  Object.defineProperty(exports, "MongoCryptError", {
    enumerable: true,
    get: function () {
      return errors_1.MongoCryptError;
    },
  });
  Object.defineProperty(exports, "MongoCryptInvalidArgumentError", {
    enumerable: true,
    get: function () {
      return errors_1.MongoCryptInvalidArgumentError;
    },
  });
  Object.defineProperty(exports, "MongoCryptKMSRequestNetworkTimeoutError", {
    enumerable: true,
    get: function () {
      return errors_1.MongoCryptKMSRequestNetworkTimeoutError;
    },
  });
})(lib$2);

const {
  BSON,
  Binary,
  BSONRegExp,
  BSONSymbol,
  BSONType,
  Code,
  DBRef,
  Decimal128,
  Double,
  Int32,
  Long,
  MaxKey,
  MinKey,
  ObjectId,
  Timestamp,
  UUID,
  MongoBulkWriteError,
  ClientEncryption,
  ChangeStreamCursor,
  MongoAPIError,
  MongoAWSError,
  MongoAzureError,
  MongoBatchReExecutionError,
  MongoChangeStreamError,
  MongoCompatibilityError,
  MongoCursorExhaustedError,
  MongoCursorInUseError,
  MongoDecompressionError,
  MongoDriverError,
  MongoError,
  MongoExpiredSessionError,
  MongoGridFSChunkError,
  MongoGridFSStreamError,
  MongoInvalidArgumentError,
  MongoKerberosError,
  MongoMissingCredentialsError,
  MongoMissingDependencyError,
  MongoNetworkError,
  MongoNetworkTimeoutError,
  MongoNotConnectedError,
  MongoParseError,
  MongoRuntimeError,
  MongoServerClosedError,
  MongoServerError,
  MongoServerSelectionError,
  MongoSystemError,
  MongoTailableCursorError,
  MongoTopologyClosedError,
  MongoTransactionError,
  MongoUnexpectedServerResponseError,
  MongoWriteConcernError,
  AbstractCursor,
  Admin,
  AggregationCursor,
  CancellationToken,
  ChangeStream,
  ClientSession,
  Collection,
  Db,
  FindCursor,
  GridFSBucket,
  GridFSBucketReadStream,
  GridFSBucketWriteStream,
  ListCollectionsCursor,
  ListIndexesCursor,
  MongoClient,
  OrderedBulkOperation,
  UnorderedBulkOperation,
  BatchType,
  AutoEncryptionLoggerLevel,
  GSSAPICanonicalizationValue,
  AuthMechanism,
  Compressor,
  CURSOR_FLAGS,
  MongoErrorLabel,
  ExplainVerbosity,
  ServerApiVersion,
  ReturnDocument,
  ProfilingLevel,
  ReadConcernLevel,
  ReadPreferenceMode,
  ServerType,
  TopologyType,
  ReadConcern,
  ReadPreference,
  WriteConcern,
  CommandFailedEvent,
  CommandStartedEvent,
  CommandSucceededEvent,
  ConnectionCheckedInEvent,
  ConnectionCheckedOutEvent,
  ConnectionCheckOutFailedEvent,
  ConnectionCheckOutStartedEvent,
  ConnectionClosedEvent,
  ConnectionCreatedEvent,
  ConnectionPoolClearedEvent,
  ConnectionPoolClosedEvent,
  ConnectionPoolCreatedEvent,
  ConnectionPoolMonitoringEvent,
  ConnectionPoolReadyEvent,
  ConnectionReadyEvent,
  ServerClosedEvent,
  ServerDescriptionChangedEvent,
  ServerHeartbeatFailedEvent,
  ServerHeartbeatStartedEvent,
  ServerHeartbeatSucceededEvent,
  ServerOpeningEvent,
  TopologyClosedEvent,
  TopologyDescriptionChangedEvent,
  TopologyOpeningEvent,
  SrvPollingEvent,
  MongoCryptAzureKMSRequestError,
  MongoCryptCreateDataKeyError,
  MongoCryptCreateEncryptedCollectionError,
  MongoCryptError,
  MongoCryptInvalidArgumentError,
  MongoCryptKMSRequestNetworkTimeoutError,
} = lib$2;

export {
  BSON,
  Binary,
  BSONRegExp,
  BSONSymbol,
  BSONType,
  Code,
  DBRef,
  Decimal128,
  Double,
  Int32,
  Long,
  MaxKey,
  MinKey,
  ObjectId,
  Timestamp,
  UUID,
  MongoBulkWriteError,
  ClientEncryption,
  ChangeStreamCursor,
  MongoAPIError,
  MongoAWSError,
  MongoAzureError,
  MongoBatchReExecutionError,
  MongoChangeStreamError,
  MongoCompatibilityError,
  MongoCursorExhaustedError,
  MongoCursorInUseError,
  MongoDecompressionError,
  MongoDriverError,
  MongoError,
  MongoExpiredSessionError,
  MongoGridFSChunkError,
  MongoGridFSStreamError,
  MongoInvalidArgumentError,
  MongoKerberosError,
  MongoMissingCredentialsError,
  MongoMissingDependencyError,
  MongoNetworkError,
  MongoNetworkTimeoutError,
  MongoNotConnectedError,
  MongoParseError,
  MongoRuntimeError,
  MongoServerClosedError,
  MongoServerError,
  MongoServerSelectionError,
  MongoSystemError,
  MongoTailableCursorError,
  MongoTopologyClosedError,
  MongoTransactionError,
  MongoUnexpectedServerResponseError,
  MongoWriteConcernError,
  AbstractCursor,
  Admin,
  AggregationCursor,
  CancellationToken,
  ChangeStream,
  ClientSession,
  Collection,
  Db,
  FindCursor,
  GridFSBucket,
  GridFSBucketReadStream,
  GridFSBucketWriteStream,
  ListCollectionsCursor,
  ListIndexesCursor,
  MongoClient,
  OrderedBulkOperation,
  UnorderedBulkOperation,
  BatchType,
  AutoEncryptionLoggerLevel,
  GSSAPICanonicalizationValue,
  AuthMechanism,
  Compressor,
  CURSOR_FLAGS,
  MongoErrorLabel,
  ExplainVerbosity,
  ServerApiVersion,
  ReturnDocument,
  ProfilingLevel,
  ReadConcernLevel,
  ReadPreferenceMode,
  ServerType,
  TopologyType,
  ReadConcern,
  ReadPreference,
  WriteConcern,
  CommandFailedEvent,
  CommandStartedEvent,
  CommandSucceededEvent,
  ConnectionCheckedInEvent,
  ConnectionCheckedOutEvent,
  ConnectionCheckOutFailedEvent,
  ConnectionCheckOutStartedEvent,
  ConnectionClosedEvent,
  ConnectionCreatedEvent,
  ConnectionPoolClearedEvent,
  ConnectionPoolClosedEvent,
  ConnectionPoolCreatedEvent,
  ConnectionPoolMonitoringEvent,
  ConnectionPoolReadyEvent,
  ConnectionReadyEvent,
  ServerClosedEvent,
  ServerDescriptionChangedEvent,
  ServerHeartbeatFailedEvent,
  ServerHeartbeatStartedEvent,
  ServerHeartbeatSucceededEvent,
  ServerOpeningEvent,
  TopologyClosedEvent,
  TopologyDescriptionChangedEvent,
  TopologyOpeningEvent,
  SrvPollingEvent,
  MongoCryptAzureKMSRequestError,
  MongoCryptCreateDataKeyError,
  MongoCryptCreateEncryptedCollectionError,
  MongoCryptError,
  MongoCryptInvalidArgumentError,
  MongoCryptKMSRequestNetworkTimeoutError,
};
